[{"text": "cal and clinical applications. Early work relied on the Gene Ontology (GO)3, which is a hierarchy of terms used to describe genomic information.", "acronyms": [[71, 73]], "long-forms": [[56, 69]]}, {"text": "a seminal work on CCGbank (Hockenmaier and Steedman, 2007), in which the phrase structure trees of the Penn Treebank (PTB) (Marcus et al, 1993) are converted into CCG derivations and a", "acronyms": [[118, 121], [18, 25], [163, 166]], "long-forms": [[103, 116]]}, {"text": "of the reparandum coincides with the termination of  the fluent portion of the utterance, which we term the  INTERRUPTION SITE (IS). The DISFLUENCY INTERVAL ", "acronyms": [[128, 130]], "long-forms": [[109, 126]]}, {"text": "716 Figure 5: The NUMBERS System Architecture (CA = communicative act) The module network topology of the system is", "acronyms": [[47, 49], [18, 25]], "long-forms": [[52, 69]]}, {"text": "5 Conclusion and Further Works   In this paper we have proposed a reestimation algorithm and a best-first parsing algorithm  for probabilistic dependency grammars(PDG). The reestimation algorithm is a variation of ", "acronyms": [[163, 166]], "long-forms": [[129, 161]]}, {"text": "ordinating conjunction; JJ = adjective; JJR = comparative adjective; NN = singular or mass noun; NNS = plural noun; POS = possessive clitic; RB = adverb; RBR = comparative adverb; RP = particle; UH = interjection; VB =", "acronyms": [[116, 119], [24, 26], [40, 43], [69, 71], [97, 100], [141, 143], [154, 157], [180, 182], [195, 197], [214, 216]], "long-forms": [[122, 132], [29, 38], [46, 67], [74, 95], [103, 114], [146, 152], [160, 178], [185, 193], [200, 212]]}, {"text": "on the base. ( Code-a-phone, 1989)  (2d) In the STBY (standby) position, the phone  will ring whether the handset .is on the base or ", "acronyms": [[48, 52]], "long-forms": [[54, 61]]}, {"text": "The first observation is that the task is quite difficult as evidenced by extremely poor performance  of the bag of words approach (BOW). The correct ", "acronyms": [[132, 135]], "long-forms": [[109, 121]]}, {"text": "or database .  Superficially, DEFT resembles a Natural language Understanding (NLUI) system ; however, there are key differences .", "acronyms": [[79, 83]], "long-forms": [[47, 77]]}, {"text": "Normalization (WCCN) (Dehak et al., 2011) and Eigen Factor Radial (EFR) (Bousquet et al., 2011).", "acronyms": [[67, 70], [15, 19]], "long-forms": [[46, 65]]}, {"text": " Semantic relatedness of two given terms (text fragments, phrases or words) can be obtained by calculating the correlation between two high dimensional vectors of a Distributional Semantic Model (DSM), which is based on the assumption that semantic meaning of a text can be inferred from its usage in context", "acronyms": [[196, 199]], "long-forms": [[165, 194]]}, {"text": "Constant 5.23 1.18 19.67 <0.000* 187.25 ADAG, n=242; HAG, n = 242; S.E = standard error; OR = Odds ratio or Exp(?); CI = confidence Interval. ", "acronyms": [[116, 118], [89, 91], [53, 56]], "long-forms": [[121, 140], [94, 104]]}, {"text": "partially completed subproof or function of the system. The implementation f this  was the IPSIM (Interruptible Prolog SIMulator) theorem prover, which can maintain  a set of partially completed proofs and jump to the appropriate one as dialog pro- ", "acronyms": [[91, 96]], "long-forms": [[98, 128]]}, {"text": "actions and boolean b (> or ?) are used to ensure that unary reductions (RU) can only take place once after a SHIFT action.", "acronyms": [[73, 75], [110, 115]], "long-forms": [[61, 71]]}, {"text": "Information Retrieval (CLIR). It is also important for Machine Translation (MT), especially when the languages do not use the same scripts.", "acronyms": [[76, 78], [23, 27]], "long-forms": [[55, 74], [0, 21]]}, {"text": " 3.2.2 Optimization We use stochastic gradient descent (SGD) to maximize the simplified objectives.", "acronyms": [[56, 59]], "long-forms": [[27, 54]]}, {"text": "In second method we compare CLIR performance of the two systems using Cross Language Evaluation Forum (CLEF) 2007 ad-hoc bilingual track (Hindi-English) docu-", "acronyms": [[103, 107], [28, 32]], "long-forms": [[70, 101]]}, {"text": "tive standard deviation of three intervals, left  edge to anchor (LE-A), center to anchor (CC-A),  right edge to anchor (RE-A), calculated across  productions of pot, sot, spot, lot, plot, and splot ", "acronyms": [[121, 125], [91, 95], [66, 70]], "long-forms": [[99, 119], [73, 89], [44, 64]]}, {"text": " At the shallowest level of attachment we find the conjunctions (CONJ+) +\u0000 w+ ? and?", "acronyms": [[65, 70]], "long-forms": [[51, 63]]}, {"text": "and only these. The possible binary tree structures of ABCD are covered by  ABCD = A(BCD) U (AB)(CD) U (ABC)D.  Since we are to handle binary concatenations only, we consider two concatenations ", "acronyms": [[76, 80], [55, 59]], "long-forms": [[83, 88]]}, {"text": "cabbage 9 chou 1 chou blossom 25 fleur 73 commande carpet 39 tapis 1 tapis bitter 59 amer 1 amer hammer 67 marteau 1 marteau bread 82 pain 1 pain citizen 115 citoyen 1 citoyen bath 178 bain 1 bain butterfly 201 papillon 1 papillon eat 208 manger 1 manger butter 220 beurre 59 terre eagle 282 aigle 1 aigle cheese 527 fromage 1 fromage cold 539 froid 1 froid deep 585 profond 1 profond cottage 624 cabanon 1 cabanon earth 702 terre 53 tabac child 735 enfant 1 enfant bed 806 lit 2 table beautiful 923 beau 1 beau care 1267 soin 1 soin hand 1810 main 2 main city 2610 ville 1 ville girl 2673 fille 1 fille green 2861 vert 1 vert blue 2914 bleu 1 bleu hard 3615 dur 1 dur black 9626 noir 1 noir Bible 17791 Bible 1 Bible foot 23548 pied 8 siffler chair 24027 chaise 1 chaise fruit 38544 fruit 1 fruit  Table 2: Results for the language pair English ? French. The meaning of the columns is as follows: ESW = English source word; CF = corpus frequency of English source word; ET = expected translation according to gold standard; RE = computed rank of expected translation; CT = computed translation. ", "acronyms": [[925, 927], [1069, 1071], [898, 901], [971, 973], [1025, 1027]], "long-forms": [[930, 946], [1074, 1094], [904, 923], [976, 996], [1039, 1055]]}, {"text": "The Office. Television series, the National Broadcasting Company (NBC). ", "acronyms": [[66, 69]], "long-forms": [[35, 64]]}, {"text": "Beijing University of Posts and Telecommunications (BUPT) ? ?  Beijing Institute of Technology (BIT) ?  ", "acronyms": [[96, 99], [52, 56]], "long-forms": [[63, 94], [0, 49]]}, {"text": " 4. Template Relation(TR) recognition: Finding the relation between TEs and a question", "acronyms": [[22, 24]], "long-forms": [[4, 20]]}, {"text": "A necessary (if not sufficient) condition for true natural language understanding is a mastery of open-domain natural language inference (NLI): the task of determining whether a natural-language", "acronyms": [[138, 141]], "long-forms": [[110, 136]]}, {"text": "Pattern Pattern Patterns composed of high frequency words (HFWs) 4", "acronyms": [[59, 63]], "long-forms": [[37, 57]]}, {"text": "4. Crowdsourcing We used the Amazon Mechanical Turk (AMT) service to obtain annotations for different kinds of opposites.", "acronyms": [[53, 56]], "long-forms": [[29, 51]]}, {"text": " X '1\"~,. \\[-1  Def in i t ion 2.2 A N:M sur face coerc ion  (SC)  ru le ix a quadruple (/,c/,c~,r) where l and r ", "acronyms": [[62, 64]], "long-forms": [[41, 59]]}, {"text": " Introduction  Categorial Grammars (CGs) consist of two compo-  nents: (i) a lexicon, which assigns syntactic types ", "acronyms": [[36, 39]], "long-forms": [[15, 34]]}, {"text": "Our data comes from English (ENG), Chinese (CHI), Portuguese (POR), and Kinyarwanda (KIN). ", "acronyms": [[85, 88], [29, 32], [44, 47], [62, 65]], "long-forms": [[72, 83], [20, 27], [35, 42], [50, 60]]}, {"text": "ical analyzer for English (Sekine, 2001)are selected and translation candidates having POS tags other than NN (noun) are discarded. Selected translation", "acronyms": [[107, 109], [87, 90]], "long-forms": [[111, 115]]}, {"text": "2 mark up tool in Shakti Standard Format (SSF) (Bharati et al, 2005). For", "acronyms": [[42, 45]], "long-forms": [[18, 40]]}, {"text": "markert@l3s.de Abstract Automatic timeline summarization (TLS) generates precise, dated overviews over", "acronyms": [[58, 61]], "long-forms": [[34, 56]]}, {"text": "(RA (NULL))))))  (NPOS (NULL)))  (NVAR (N='BYPASS':(SINGULAR) \" ('BYPASS')))  (RN (NULL))))) ", "acronyms": [[34, 38], [18, 22], [1, 3], [5, 9], [24, 28], [79, 81], [83, 87]], "long-forms": [[40, 60]]}, {"text": "The IE results are stored in a database which  is the basis for IE-related applications like QA,  BR (Browsing, threading and visualization) and  AS (Automatic Summarization).", "acronyms": [[98, 100], [4, 6], [64, 66], [93, 95], [146, 148]], "long-forms": [[102, 110], [150, 173]]}, {"text": "classifier.  6.1   Language Model (LM)  As language model has already been used in question classification [7], it is taken as ", "acronyms": [[35, 37]], "long-forms": [[19, 33]]}, {"text": "U, x /y /z ,  T, V ~ VYw\\[Y /X\\ ]   (14)  5Here the 'full' version of (VR) is being used, incorpo-  rating a change of bound variable.", "acronyms": [[71, 73]], "long-forms": [[59, 66]]}, {"text": "t have also been used.  2.2 EasyAdapt (EA) In this section, we give a brief overview of", "acronyms": [[39, 41]], "long-forms": [[28, 37]]}, {"text": "schematic representations of situations involving  various participants, props, and other conceptual  roles, each of which is a frame element (FE). ", "acronyms": [[143, 145]], "long-forms": [[128, 141]]}, {"text": "tions of words. In Proceedings of the International Conference on Computational Linguistics (COLING), Bombay, India, December.", "acronyms": [[93, 99]], "long-forms": [[66, 91]]}, {"text": "Table 2: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, ML=Machine Learning researcher, L=Linguist, Porter=Porter stemmer, McCCJ=McClosky-Charniak-Johnson parser, SD=Stanford Dependency conversion, Dict=Dictionary", "acronyms": [[138, 140], [73, 75], [94, 97], [182, 188], [205, 210], [245, 247], [280, 284]], "long-forms": [[141, 157], [76, 92], [98, 125], [172, 180], [189, 195], [211, 236], [248, 267], [285, 295]]}, {"text": "We set aside the blind TEST set for evaluating the final performance of our named entity recognition (NER) and relation extraction (RE) 2http://code.google.com/apis/ajaxsearch", "acronyms": [[132, 134], [102, 105]], "long-forms": [[111, 130], [76, 100]]}, {"text": "not be effective due to the brevity of contributions.  Barzilay and Lee?s algorithm (B&L) did not  generalize well to either dialogue corpus.", "acronyms": [[85, 88]], "long-forms": [[55, 83]]}, {"text": " We trained a dialog independent (DI) class based LM and dialog dependent (DD) grammar based LM. In all LMs n is set to 3.", "acronyms": [[75, 77], [34, 36], [93, 95], [104, 107]], "long-forms": [[64, 73], [14, 32]]}, {"text": "translators with the help of computer-aided translation tools (CAT), (3) rule-based MT systems (RBMT) and (4) statistical MT systems (SMT). ", "acronyms": [[134, 137], [63, 66], [96, 100]], "long-forms": [[110, 132], [29, 55], [73, 86]]}, {"text": "and Johnson, 2011), particularly from the DARPA EARS (Effective, Affordable, Reusable Speech-toText) MDE (MetaData Extraction) (DARPA Information Processing Technology Office, 2003) pro-", "acronyms": [[101, 104], [42, 47], [48, 52], [128, 133]], "long-forms": [[106, 125], [54, 99]]}, {"text": "tive two-step model. We compare models based on the Akaike Information Criterion (AIC). ", "acronyms": [[82, 85]], "long-forms": [[52, 80]]}, {"text": "systems that learn new representations for opendomain NLP using latent-variable language models like Hidden Markov Models (HMMs). In POS-", "acronyms": [[123, 127], [54, 57], [133, 136]], "long-forms": [[101, 121]]}, {"text": "phases that are performed sequentially without feedback: Question Processing (QP), Passage Retrieval (PR) and Answer Extraction (AE). More", "acronyms": [[129, 131], [78, 80], [102, 104]], "long-forms": [[110, 127], [57, 76], [83, 100]]}, {"text": "  ? PT (parse tree)  ", "acronyms": [[4, 6]], "long-forms": [[8, 18]]}, {"text": " 5 Conclusions and Future Work Distributed Smoothed Trees (DST) are a novel class of Compositional Distributional Semantics Models (CDSM) that effectively encode structural information and distributional semantics in tractable 2-", "acronyms": [[59, 62], [132, 136]], "long-forms": [[31, 57], [85, 129]]}, {"text": " NB-B uses full Bayesian inference and NB-M uses Maximum a posteriori (MAP). ", "acronyms": [[71, 74]], "long-forms": [[49, 69]]}, {"text": "O. Introduction.  Since 1971 the research group \"Maschinelle Syntaxanalyse\" (MasA)  has been working as a part of the project \"Linguistische Datenverar- ", "acronyms": [[77, 81]], "long-forms": [[49, 74]]}, {"text": "All conditions were assigned a section and are  thereby excluded. TE = temporal expression; TT = trigger term; V = scoped by verb.", "acronyms": [[66, 68], [92, 94]], "long-forms": [[71, 90], [97, 109], [125, 129]]}, {"text": "3.3 Evaluation Metric We use both Root Mean Square (RMS) error and Correlation Coefficient (CRCoef) to evaluate our model, since the two metrics evaluate different as-", "acronyms": [[92, 98]], "long-forms": [[67, 90]]}, {"text": "PrecisionCorrectTransliterations (PTrans)  2. RecallCorrectTransliteration (RTrans)  3.", "acronyms": [[76, 82], [34, 40]], "long-forms": [[46, 74], [0, 32]]}, {"text": "Stanford Dependencies (SDC), as described by de Marneffe et al (2006), were generated by converting Penn Treebank (PTB)-style (Marcus et al, 1993) output using the Stanford CoreNLP Tools2 into the", "acronyms": [[115, 118], [23, 26], [177, 180]], "long-forms": [[100, 113], [0, 21]]}, {"text": "2003. MDA Guide Version 1.0.1. Technical report, Object Management Group (OMG). ", "acronyms": [[74, 77], [6, 9]], "long-forms": [[49, 72]]}, {"text": "Various traditional  information retrieval(IR) techniques combined  with natural language processing(NLP) tech-  niques have been re-targeted to enable efficient ", "acronyms": [[101, 104], [43, 45]], "long-forms": [[73, 99], [21, 42]]}, {"text": "2.2 Hidden Markov Models One simple family of models for part-of-speech induction are the Hidden Markov Models (HMMs), in which there is a sequence of hidden state vari-", "acronyms": [[112, 116]], "long-forms": [[90, 110]]}, {"text": " 2 Methodologies The Hidden Vector State (HVS) model (He and Young, 2005) is a discrete Hidden Markov Model", "acronyms": [[42, 45]], "long-forms": [[21, 40]]}, {"text": "  1 Introduction  Many Natural Language Processing (NLP)  applications need to recognize when the meaning ", "acronyms": [[52, 55]], "long-forms": [[23, 50]]}, {"text": "? ?  Table 4: Results for the best baseline (B5) and the learning to rank method (LTR), using all entity pairs in the dataset, including those without any relevant sentences.", "acronyms": [[82, 85]], "long-forms": [[57, 73]]}, {"text": "explicitly addresses the language ambiguity issue. Key to our approach is the use of Word Sense Induction (WSI), that is, techniques aimed at automatically discovering the different meanings of a given term (i.e., query).", "acronyms": [[107, 110]], "long-forms": [[85, 105]]}, {"text": "Four training and testing corpora were used in the first bakeoff (Sproat and Emerson, 2003), including the Academia Sinica Corpus (AS), the Penn Chinese Treebank Corpus (CTB), the Hong Kong City Uni-", "acronyms": [[131, 133], [170, 173]], "long-forms": [[107, 129], [145, 161]]}, {"text": "837 (a) (b) Figure 1: Deep recurrent neural network (DRNN) architectures: arrows represent connection matrices; white, black, and grey circles represent input frames, hidden states, and output frames, respectively; (a): L intermediate layer DRNN with recurrent connections", "acronyms": [[53, 57], [241, 245]], "long-forms": [[22, 51]]}, {"text": "We need to \"cross\" an instrument the_phone to reach another person, thus we also refer to the intermediate locus IME(LOC) in the domain of communication.", "acronyms": [[117, 120], [113, 116]], "long-forms": [[107, 112]]}, {"text": "also accessible through a phrase internal reordering. A negative consequence of source order (SO) scoring as done by (Zhang et al, 2007) and (Li", "acronyms": [[94, 96]], "long-forms": [[80, 92]]}, {"text": "nique was used in The MAYO Clinic Vocabulary  Server (MCVS)5, which encodes clinical expressions into medical ontology (SNOMED-CT) and  identifies whether the event is positive or negative.", "acronyms": [[120, 129], [22, 26], [54, 58]], "long-forms": []}, {"text": "boring dependency structures. CC = coordinate concatenate, LA = left adjoining, and RA = right adjoining.", "acronyms": [[59, 61]], "long-forms": [[64, 78]]}, {"text": "making valuable data resources publicly available . The author is a member of the Institute for Robotics and Intelligent Systems (IRIS) and wishes to acknowledge the support of the Networks of Centres of Excellenc e Program of the Government of Canada, the Natural Sciences and Engineering Research Council (NSERC) ,", "acronyms": [[130, 134], [308, 313]], "long-forms": [[82, 128], [257, 306]]}, {"text": " In addition, the user can supply relevance judgements on  any document by clicking Rel (relevant), NRel (not rel-  evant), or PRel (probably relevant).", "acronyms": [[100, 104], [84, 87], [127, 131]], "long-forms": [[106, 121], [89, 97], [133, 150]]}, {"text": "our method in this domain. The analysis of variance (ANOVA) and Tukey?s honestly significant differences (HSD) tests on the classification accuracies", "acronyms": [[53, 58], [106, 109]], "long-forms": [[31, 51], [72, 104]]}, {"text": "siderable progress. The bakeoff series hosted by  the Chinese Information Processing Society (CIPS)  and ACL SIGHAN shows that an F measure of ", "acronyms": [[94, 98], [105, 108], [109, 115]], "long-forms": [[54, 92]]}, {"text": "The bacteria track consists of two tasks, BB and BI.  2.4.1 Bacteria biotope task (BB) The aim of the BB task (Bossy et al, 2011) is to ex-", "acronyms": [[83, 85], [102, 104], [42, 44], [49, 51]], "long-forms": [[60, 76]]}, {"text": " In Proceedings of the International Conference on Computational Linguistics (COLING-04). ", "acronyms": [[78, 87]], "long-forms": [[51, 76]]}, {"text": "tial state for HMM, then experiment with different inference algorithms such as ExpectationMaximization (EM), Variational Bayers (VB) or Gibbs sampling (GS).5 Gao and Johnson (2008) compare", "acronyms": [[130, 132], [15, 18], [105, 107], [153, 155]], "long-forms": [[110, 128], [80, 103], [137, 151]]}, {"text": " org/wiki/California?. It is distinct from named entity extraction (NEE) in that it identifies not the occurrence of names but their reference.", "acronyms": [[68, 71]], "long-forms": [[43, 66]]}, {"text": "FS = false start  E = echo  ADD = added information  SELF = talking to oneself ", "acronyms": [[28, 31], [0, 2], [53, 57]], "long-forms": [[34, 39], [5, 16], [22, 26], [60, 78]]}, {"text": "Data. We evaluate our model on predicting paraphrases from the Lexical Substitution (LexSub) dataset (McCarthy and Navigli, 2009).", "acronyms": [[85, 91]], "long-forms": [[63, 83]]}, {"text": "The different resources used to build ArSenL.       The English WordNet (EWN) (Miller et al., ", "acronyms": [[73, 76]], "long-forms": [[56, 71]]}, {"text": "get node and another node on the dependency parsed tree: ANC (ancestor), DES (descendant), SIB (sibling), and TARGET (target word). Figure 5 shows", "acronyms": [[110, 116], [57, 60], [73, 76], [91, 94]], "long-forms": [[118, 124], [62, 70], [78, 88], [96, 103]]}, {"text": "the curve (AUC) from the trained detector on the heldout test set. Results are reported in terms of the mean and standard deviation (SD) of the AUC across all splits. ", "acronyms": [[133, 135], [11, 14], [144, 147]], "long-forms": [[113, 131]]}, {"text": "active (ACT) and passive (PASS) 3. causative (CAUS) 4.", "acronyms": [[46, 50], [8, 11], [26, 30]], "long-forms": [[35, 44], [0, 6], [17, 24]]}, {"text": "also republish the baseline results of Schnabel and Sch?utze (2014) using the Stanford POS Tagger, a maximum entropy Markov model (MEMM) tagger. ", "acronyms": [[131, 135], [87, 90]], "long-forms": [[101, 129]]}, {"text": "= Europarl). TOOL = grammatical words, PCT/NB = punctuation and numbers, ADJ/ADV = adjectives and adverbs, NAM = proper name, NOM = noun,", "acronyms": [[39, 45], [73, 80], [107, 110], [126, 129]], "long-forms": [[48, 71], [83, 105], [120, 124], [132, 136]]}, {"text": "contributing to the irregularity of hangul orthography is the differences in spelling between South Korea (S.K.) and North Korea (N.K.). The", "acronyms": [[107, 111], [130, 134]], "long-forms": [[94, 105], [117, 128]]}, {"text": "Saccade Length (SL) Real Sum of saccade lengths (measured by number of words) divided by word count Simple Regression Count (REG) Real Total number of gaze regressions Gaze Skip count (SKIP) Real Number of words skipped divided by total word count", "acronyms": [[125, 128], [16, 18], [185, 189]], "long-forms": [[107, 117], [0, 14]]}, {"text": "categories include NOUN, VERB, ADJ = adjective, ADV = adverb, NUM = number, ADP = adposition, CONJ = conjunction, DET = determiner, PRON = 1http://www.wiktionary.org/", "acronyms": [[94, 98], [114, 117], [31, 34], [48, 51], [62, 65], [76, 79], [132, 136]], "long-forms": [[101, 112], [120, 130], [37, 46], [54, 60], [68, 74], [82, 92]]}, {"text": "2 VIP targeted technologies  Current products for VIP such as screen readers mainly depend on speech synthesis or Braille solutions, e.g. ChromeVox [3], Windows-Eyes [4], or JAWS (Job Access With Speech) [5]. Braille displays ", "acronyms": [[174, 178], [2, 5], [50, 53]], "long-forms": [[180, 202]]}, {"text": "mdiab@ccls.columbia.edu Abstract We analyze overt displays of power (ODPs) in written dialogs.", "acronyms": [[69, 73]], "long-forms": [[44, 58]]}, {"text": "init ial ly be described. I wil l  c laim that  such an initial descr ipt ion (ID) is  cr it ical  to both model synthesis and ", "acronyms": [[79, 81]], "long-forms": [[56, 69]]}, {"text": "2214  Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 1?9, Gothenburg, Sweden, April 26-30 2014.", "acronyms": [[74, 76], [32, 36]], "long-forms": [[54, 72]]}, {"text": "errors; English had three, and German one.   While it is worth noting that (II) is not without  counterexamples, it is significant that true ", "acronyms": [[76, 78]], "long-forms": [[54, 69]]}, {"text": "training data (Surdeanu et al, 2008). We report purity (PU), collocation (CO), and their harmonic mean (F1) evaluated on gold arguments in two set-", "acronyms": [[56, 58], [74, 76]], "long-forms": [[48, 54], [61, 72]]}, {"text": "Conf.  Fifth Generation Computer Systems 1992 (FGCS'92),  pp.1133-1140, 1992.", "acronyms": [[47, 54]], "long-forms": [[7, 45]]}, {"text": " 4 DOM Tree Alignment Model  The Document Object Model (DOM) is an application programming interface for valid HTML ", "acronyms": [[56, 59], [3, 6], [111, 115]], "long-forms": [[33, 54]]}, {"text": " To evaluate feature effectiveness, we group the features into seven groups: textual features (TX), utterance features (UT), pointing gesture fea-", "acronyms": [[95, 97], [120, 122]], "long-forms": [[77, 84], [100, 109]]}, {"text": "Advanced Research and Development Activity (ARDA)?s Advanced Question Answering for Intelligence (AQUAINT) Program, a DOI grant under the Reflex", "acronyms": [[98, 105], [44, 48], [118, 121]], "long-forms": [[0, 42], [52, 96]]}, {"text": "P2 = < ash, c >}.  3-3 Mixed String Adjunct Language (MAL)  We now have two different styles of rules in G, namely, the ", "acronyms": [[54, 57]], "long-forms": [[23, 52]]}, {"text": " 1 Introduction Verb Phrase Ellipsis (VPE) is an anaphoric construction in which a verbal constituent has been omitted.", "acronyms": [[38, 41]], "long-forms": [[16, 36]]}, {"text": " The output is a prediction of whether the tweet is inside region (IR) or outside region (OR). We", "acronyms": [[67, 69], [90, 92]], "long-forms": [[52, 65], [74, 88]]}, {"text": "= li), ? Hierarchical loss (H-Loss) function is defined as:", "acronyms": [[28, 34]], "long-forms": [[9, 26]]}, {"text": " Figure 1: Graphical representation of the phrase pair topic (PPT) model. ", "acronyms": [[62, 65]], "long-forms": [[43, 60]]}, {"text": "system of Conceptual Dependency (Schank 1975). Some of the  Conceptual Dependency (CD) s t r u c t u r e s  are passed on to a program  which expresses them in E n g l i s h .", "acronyms": [[83, 85]], "long-forms": [[60, 81]]}, {"text": "els on a previously unseen test set ? the test split of part 3 of the PATB (PATB3-TEST). Table 6 shows", "acronyms": [[76, 86]], "long-forms": [[56, 74]]}, {"text": "Document d1 Document d2 Customization Requirement : City, County or State names within sports articles may refer to a sports team  or to the location itself. Customization Solution (CS) :Within sports articles, Identify all occurrences of city/county/state as Organizations, Except when a contextual clue indicates that the reference is to the location Organization Location", "acronyms": [[182, 184], [9, 11], [21, 23]], "long-forms": [[158, 180]]}, {"text": "from comparable in-domain corpora. We used the AFP (Agence France Presse) and APW (Associated Press Worldstream Service) news texts since there", "acronyms": [[47, 50], [78, 81], [83, 111]], "long-forms": [[52, 72]]}, {"text": "2013 temporal summarization. In Proceedings of the 22nd Text Retrieval Conference (TREC), November.", "acronyms": [[83, 87]], "long-forms": [[56, 81]]}, {"text": " 1 Introduction Ever since Question Answering (QA) emerged as an active research field, the community has slowly", "acronyms": [[47, 49]], "long-forms": [[27, 45]]}, {"text": "not explicit about this. ? P5E2N4S3, F W A Computer Processable Language (CPL) (Clark et al. 2005) is a controlled variant of", "acronyms": [[74, 77], [27, 35]], "long-forms": [[43, 72]]}, {"text": "An effective semi-supervised extractor will have good performance over a range of extraction tasks and corpora. However, many of the learning procedures just cited have been tested on only one or two extraction tasks, so their generality is uncertain. To remedy this, we have tested learners based on both assumptions, targeting both a MUC (Message Understanding Conference) scenario and several ACE (Automatic Content Extraction) event types. We identify shortcomings of the prior bootstrapping methods, propose a more effective and stable ranking method, and consider the effect of different corpora and evaluation metrics.", "acronyms": [[336, 339], [396, 399]], "long-forms": [[341, 373], [401, 429]]}, {"text": "Within Acquilex IP Project, a unification framework  based on typed feature structures \\[4\\] was ddveloped, the  LKB (Lexical Knowledge Base), in order to represent  conceptual units corresponding to lexieal senses, lexical ", "acronyms": [[113, 116], [16, 18]], "long-forms": [[118, 140]]}, {"text": "We therefore use a different type of filter in order to detect these errors, which we call the Verb Arity Sampling Test (VAST). ", "acronyms": [[121, 125]], "long-forms": [[95, 119]]}, {"text": " Conf. Computational Linguistics (COLING), pages 89?97.", "acronyms": [[34, 40]], "long-forms": [[7, 32]]}, {"text": "We show that the recently proposed RelationalRealizational (RR) model consistently outperforms state-of-the-art Head-Driven", "acronyms": [[60, 62]], "long-forms": [[35, 58]]}, {"text": "most frequent sense of the training corpus (TRAIN-MFS). However, all of them are far below to the Topic Signatures acquired using the training corpus (TRAIN). ", "acronyms": [[151, 156], [44, 53]], "long-forms": [[134, 142], [27, 35]]}, {"text": "Hence, it seems plausible to  utilize a back-off mechanism for these sentences  via a combined system (COMB) incorporating  NB only for the sentences that fail to parse.", "acronyms": [[103, 107], [124, 126]], "long-forms": [[86, 94]]}, {"text": "P2E5N5S1, C W D I FAA Air Traffic Control Phraseology (FAA 2010) is a controlled language defined by the Federal Aviation Administration (FAA) and used for the communication in air traffic 135", "acronyms": [[138, 141], [0, 8], [55, 58], [18, 21]], "long-forms": [[105, 136]]}, {"text": "AST = Adjectival Sta~ VST = Verb Stem  DET = Determine~ N-FLEX = Nominal Inflexion  NST = Noun Stem V-FLEX = Verbal Inflsxion  PRN = Pronoun A-FLEX = Adjectival Inflexion ", "acronyms": [[84, 87], [0, 3], [22, 25], [39, 42], [56, 62], [100, 106], [127, 130], [141, 147]], "long-forms": [[90, 99], [6, 20], [28, 37], [45, 54], [65, 82], [109, 125], [133, 140], [150, 170]]}, {"text": "not vacillate, vacillate is, line vacillate?  English Context(EC): shake/vacillate  Putting on Search Engine and getting counts:  ", "acronyms": [[62, 64]], "long-forms": [[46, 60]]}, {"text": "model, it then shows how meaning specificity affects the linguistic behavior and semantic content of Chinese resultative verb compounds (RVCs). ", "acronyms": [[137, 141]], "long-forms": [[109, 135]]}, {"text": "calculating the posterior probabilities.  Active SVM with self-training (ASSVM) is an extension of ASVM where each round of training has", "acronyms": [[73, 78], [99, 103]], "long-forms": [[42, 52]]}, {"text": "3.1 Graph-based parsing model The graph-based parsing model aims to search for the maximum spanning tree (MST) in a graph (McDonald et al, 2005).", "acronyms": [[106, 109]], "long-forms": [[83, 104]]}, {"text": "534 3.1 Cross Validation on the Training Queries Random Walk with Restart (RWR) (also called personalized PageRank (Haveliwala, 2002)) is a", "acronyms": [[75, 78]], "long-forms": [[49, 73]]}, {"text": "The two main Modern Standard Arabic dependency treebanks currently available are the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009) and the Prague Arabic Dependency", "acronyms": [[111, 116]], "long-forms": [[85, 109]]}, {"text": "In this section, we compare the running time5 of our sampling algorithm (FAST) and our algorithm with the refined bucket (RB) against the unfactored Gibbs sampler (NAI?VE) and examine the effect of sorting.", "acronyms": [[122, 124], [73, 77], [164, 170]], "long-forms": [[106, 120]]}, {"text": "given for each environment. For example, Q appeared eight  times in the context EH--EN ( E - n ,  and a check of the  reference list shows that all these occurrences were in the ", "acronyms": [[84, 86], [80, 82]], "long-forms": [[89, 94]]}, {"text": "LS (List item marker) LS  MD (Modal) MD  NN (Noun, singular or mass) N  NNS (Noun, plural) N ", "acronyms": [[41, 43], [0, 2], [22, 24], [26, 28], [37, 39], [72, 75]], "long-forms": [[45, 49], [30, 35], [77, 81]]}, {"text": "ogy (GO), Cell Type Ontology (CTO), BRENDA Tissue Ontology (BTO), Foundational Model of Anatomy (FMA), Cell Cycle Ontology (CCO), and Sequence Ontology (SO)?and a small number of", "acronyms": [[124, 127], [5, 7], [30, 33], [60, 63], [97, 100], [153, 155]], "long-forms": [[103, 122], [10, 28], [36, 58], [66, 95], [134, 151]]}, {"text": "tution is the same as the cost of insertion or deletion. A normalized edit distance (NED) is calculated by dividing the total edit cost by the length of", "acronyms": [[85, 88]], "long-forms": [[59, 83]]}, {"text": " 4.1 Task  The Spontaneous Scheduling Task (SST) databases  are a collection of dialogues in which two speak- ", "acronyms": [[44, 47]], "long-forms": [[15, 42]]}, {"text": "the verb that contained in a subordinate clause.  We use semantic role labeling (SRL) to help  solve this problem in which the coordinated can ", "acronyms": [[81, 84]], "long-forms": [[57, 79]]}, {"text": "e i Algorithm 1 Sparse projection (SP) Require: v // Vocabulary: vector of n words", "acronyms": [[35, 37]], "long-forms": [[16, 33]]}, {"text": "6 , Guardian Weekly and its manually simplified versions for language learners (Allen, 2009), and the FIRST corpus of various texts simplified for people with autism spectrum disorder (ASD) 7", "acronyms": [[185, 188], [102, 107]], "long-forms": [[159, 183]]}, {"text": "prove sentiment classification. In Annual Meeting of the Association for Computational Linguistics (ACL). ", "acronyms": [[100, 103]], "long-forms": [[57, 98]]}, {"text": "new opportunity: part of Attempto Controlled English (ACE) was mapped to OWL (Kaljurand and Fuchs, 2007), and Processable English (PENG) evolved to Sydney OWL Syntax (SOS) (Cregan et", "acronyms": [[131, 135]], "long-forms": [[110, 129]]}, {"text": "in the clustering.  Cumulative Micro Precision (CMP). As pointed", "acronyms": [[48, 51]], "long-forms": [[20, 46]]}, {"text": "                  Threshold is a function of Length(LR) and text  size. The basic idea is larger amount of length(LR)  or text size matches larger amount of Threshold.", "acronyms": [[114, 116]], "long-forms": [[90, 96]]}, {"text": "They refer to  syntactical features of a constituent such as number  (NUM), gender (GEN) etc. and to grammatical functions ", "acronyms": [[84, 87]], "long-forms": [[76, 82]]}, {"text": "   By contrast, our approach operates at the level  of inflectional property sets (IPS), or more  properly, at the level of inflectional paradigms.", "acronyms": [[83, 86]], "long-forms": [[55, 81]]}, {"text": "implicit (assuming a good enough coverage of the marker resource). The Annodis corpus lists rhetorical relations between elementary discourse units (EDUs), typically clauses, and complex discourse units (sets of EDUs) ; as a simplification we only consider EDUs, since the question of what is a main verb of", "acronyms": [[149, 153], [212, 216], [257, 261]], "long-forms": [[121, 147]]}, {"text": "Table 1: First five SentiWordNet entries for cold#a In our experiments we use two different versions of SWN: SentiWordNet 1.0 (SWN1), the first release of SWN, and its updated version SentiWord-", "acronyms": [[127, 131], [104, 107], [155, 158]], "long-forms": [[109, 125]]}, {"text": "far and formulate new ones inspired by latent semantic analysis (LSA), which was developed within the information retrieval (IR) community to treat synonymous and polysemous terms (Deerwester et", "acronyms": [[125, 127], [65, 68]], "long-forms": [[102, 123], [39, 63]]}, {"text": "fore and after the SVD improved results slightly.  For the accumulated tag counts (ACT) we annotate the data with our baseline model and extract word-", "acronyms": [[83, 86]], "long-forms": [[59, 81]]}, {"text": "By experiments, we show that the proposed model outperforms the bigram Hidden Markov model (HMM)based tagging model.", "acronyms": [[92, 95]], "long-forms": [[71, 90]]}, {"text": " Within this framework, in this paper we describe our attempt to bridge Semantic Role Labeling (SRL) and CE by modeling proposition-level semantics for", "acronyms": [[96, 99], [105, 107]], "long-forms": [[72, 94]]}, {"text": "at a supermarket 2 1 1 0 able unable 1 0 0 1 Table 1: Word-based Levenshtein distance (LD) feature and separated edit operations (D = deletions, I", "acronyms": [[87, 89]], "long-forms": [[65, 85]]}, {"text": " These classifiers are based on a discriminative model: Support Vector Machine (SVM)6 (Vapnik, 1995).", "acronyms": [[80, 83]], "long-forms": [[56, 78]]}, {"text": "Table 3: The configurations of our systems. The abbreviations in the last column mean  training set(TS) and validating set(VS) explaining in section 5.1. ", "acronyms": [[100, 102], [123, 125]], "long-forms": [[87, 99], [108, 122]]}, {"text": "additional computation costs, and can be applied to  several different learners, such as Naive Bayes  (NB), Maximum Entropy (ME), and Support  Vector Machines (SVMs) models.", "acronyms": [[125, 127], [103, 105], [160, 164]], "long-forms": [[108, 123], [89, 100], [134, 158]]}, {"text": "1. Grider, T., Mosley, H., Snow, L, and Wilson, W., \"Users Manual for the  Dynamic Analytical Replanning Tool (DRAFT)\", prepared for BBN by  Systems Research and Applications Corporation, 9 November 1990.", "acronyms": [[111, 116]], "long-forms": [[75, 109]]}, {"text": "tion) strategies. All systems are evaluated according to their Mean Average Precision 6 (MAP) as computed by the trec eval software on the pre-", "acronyms": [[89, 92]], "long-forms": [[63, 85]]}, {"text": "namely the overall accuracy (Total-A) and the recall with respect to in-vocabulary words (IV-R),  OOV words (OOV-R) or multi-POS words (MTR).", "acronyms": [[109, 114], [90, 94], [125, 128], [136, 139]], "long-forms": [[98, 107], [69, 82]]}, {"text": " 1 Introduction Information Extraction (IE) is a natural language processing task in which text documents are ana-", "acronyms": [[40, 42]], "long-forms": [[16, 38]]}, {"text": " (Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL). ", "acronyms": [[87, 90]], "long-forms": [[57, 86]]}, {"text": " 2 Sign language phenomena Sign Languages (SLs) involve simultaneous manual and non-manual components for conveying mean-", "acronyms": [[43, 46]], "long-forms": [[27, 41]]}, {"text": "859  Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 217?226, Seoul, South Korea, 5-6 July 2012.", "acronyms": [[101, 108]], "long-forms": [[51, 99]]}, {"text": "Haile) and (?????, Selassie). TM has been shown to be effective in several Information Retrieval (IR) and Natural Language Processing (NLP) applications. For example, in cross language IR, TM was used to handle out-of-vocabulary query words by mining transliterations between words in queries and top n retrieved documents and then using transliterations to expand queries (Udupa et al, 2009a).", "acronyms": [[98, 100], [135, 138], [185, 188], [189, 191], [30, 32]], "long-forms": [[75, 96], [106, 133]]}, {"text": "Transcutaneous Oxygen (TcPO2 ) = 9.5. Transcutaneous CO2 (TcPCO2) = 6.7. ", "acronyms": [[58, 64], [23, 28]], "long-forms": [[38, 56], [0, 21]]}, {"text": "argument structure agreement (Das, 2009), the  analysis of Non-MonoClausal Verb (NMCV) or  Serial Verb, Control Construction (CC),  Modal Control Construction (MCC), Passives ", "acronyms": [[126, 128], [81, 85], [160, 163]], "long-forms": [[104, 124], [59, 79], [132, 158]]}, {"text": "RERANKED 92.7 42.9 92.0 32.6 ORACLE 97.6 81.2 96.7 72.5 Table 4: Word accuracies and error rate reductions (ERR) in percentages for CELEX G2P augmented by Combilex", "acronyms": [[108, 111]], "long-forms": [[85, 106]]}, {"text": "tion of them is also given: WH-Subject (WHS), WH-Object (WHO), passive Subject (PSubj), control Subject (CSubj), and the anaphor of the relative clause pronoun (RclSubjA).", "acronyms": [[105, 110], [40, 43], [57, 60], [80, 85], [161, 169]], "long-forms": [[88, 103], [28, 38], [46, 55], [63, 78], [121, 159]]}, {"text": "46 date the current hypothesis after each observation; b) Confidence Weighted (CW) learning?a probabilistic large margin online learning algorithm (Dredze et", "acronyms": [[79, 81]], "long-forms": [[58, 77]]}, {"text": "representing natural language in a traversable graph, composed of propositions and their semantic interrelations ? A Propositional Knowledge Graph (PKG). The resulting structure provides a representation", "acronyms": [[148, 151]], "long-forms": [[117, 146]]}, {"text": "enizes, tags, lemmatizes and parses the input sentences, outputting syntactic trees and then adding grammatical relations (GR) as described by (Buttery and Korhonen, 2005).", "acronyms": [[123, 125]], "long-forms": [[100, 121]]}, {"text": "of two kinds of data: One is the hand built seg-  mentation dictionary (HBSD)  and the other is the  simple noun dictionary for segmentation (SND). ", "acronyms": [[142, 145], [72, 76]], "long-forms": [[101, 123], [33, 70]]}, {"text": "5.5.3 Corpus Statistics. For training of the question detection module, we used the manually annotated set of about 200,000 SWITCHBOARD speech acts14 (SAs);15 for training of the answer detection component, we used the eight English CALLHOME dia-", "acronyms": [[151, 154]], "long-forms": [[136, 149]]}, {"text": "These models, variously known as vector spaces, semantic spaces, word spaces, corpus-based semantic models, or, using the term we will adopt, distributional semantic models (DSMs), all rely on some version of the distributional hypothesis (Harris 1954; Miller and Charles 1991), stating that the degree", "acronyms": [[174, 178]], "long-forms": [[142, 172]]}, {"text": "2-21. For Chinese, we experimented on the Penn Chinese Treebank 4.0 (CTB4) (Palmer et al, 2004) and we used the rules in (Bikel, 2004) for conver-", "acronyms": [[69, 73]], "long-forms": [[47, 67]]}, {"text": " (MAP) adaptation of maximum entropy (MaxEnt) and maximum entropy Markov models (MEMM) is presented.", "acronyms": [[81, 85], [38, 44], [2, 5]], "long-forms": [[50, 79], [21, 36]]}, {"text": "topic distributions for all phrase pairs in the phrase table in an unsupervised fashion, using a variant of Latent Dirichlet Allocation (LDA). The underly-", "acronyms": [[137, 140]], "long-forms": [[108, 135]]}, {"text": "For each disjunetiort in indef.\"  Let compatible-disjuncts = CHECK-DISJ (disjunction, cond). ", "acronyms": [[61, 71]], "long-forms": [[73, 84]]}, {"text": "Some other related works should be mentioned. A notable method is Locality Sensitive Hashing (LSH) (Indyk et al, 1998).", "acronyms": [[94, 97]], "long-forms": [[66, 92]]}, {"text": "tropy modeling. Berger et al (1996) presents an incremental feature selection (IFS) algorithm, which computes the approximate gains", "acronyms": [[79, 82]], "long-forms": [[48, 77]]}, {"text": "of the label candidates. For the supervised method, we use a support vector regression (SVR) model (Joachims, 2006) over all of the features.", "acronyms": [[88, 91]], "long-forms": [[61, 86]]}, {"text": "Section 2  introduces some relevant work in IR and  question answering (QA). Section 3 talks about ", "acronyms": [[72, 74], [44, 46]], "long-forms": [[52, 70]]}, {"text": "pairments. Many have advocated the potential benefits of language sample analysis (LSA) (Johnston, 2006; Dunn et al.,", "acronyms": [[83, 86]], "long-forms": [[57, 81]]}, {"text": "the number of sentences in each review.  Latent Dirichlet Allocation (LDA) We also apply Latent Dirichlet Allocation (Blei et al.,", "acronyms": [[70, 73]], "long-forms": [[41, 68]]}, {"text": "Abstract One of the most neglected areas of biomedical Text Mining (TM) is the development of systems based on carefully assessed user", "acronyms": [[68, 70]], "long-forms": [[55, 66]]}, {"text": "Head and Obj3 and the counts f(gf, fe) of occurrences of the grammatical functions together with the roles DEGREE (DEG), THEME (THM), DEPICTIVE (DEP) and LOCATION (LOC).", "acronyms": [[128, 131], [9, 13], [115, 118], [145, 148], [164, 167]], "long-forms": [[121, 126], [107, 113], [134, 143], [154, 162]]}, {"text": "to such an extent that?)  Multiword interjections (MWI) are a small category with expressions such as mille sabords (?", "acronyms": [[51, 54]], "long-forms": [[26, 49]]}, {"text": "We used five retrieval systems to generate  relevance scores for query-document pairs:  Fuzzy Boolean (FB). This system translates a query ", "acronyms": [[103, 105]], "long-forms": [[88, 101]]}, {"text": "2003; Shen et al, 2006; Wubben et al, 2009) The first manually collected paraphrase corpus is the Microsoft Research Paraphrase (MSRP) Corpus (Dolan et al, 2004), consisting of 5,801 sentence", "acronyms": [[129, 133]], "long-forms": [[98, 127]]}, {"text": "mation is likely to be found). This is similar to  tasks such as named entity recognition (NER) or  part-of-speech tagging, where sequence modeling ", "acronyms": [[91, 94]], "long-forms": [[65, 89]]}, {"text": "WordNet Domains (Magnini and Cavagli a`, 2000).  Conceptual Density (CD) is a measure of the correlation among the sense of a given word and its", "acronyms": [[69, 71]], "long-forms": [[49, 67]]}, {"text": "cessing. In Proceedings of the 2nd International Conference on Knowledge Capture(K-CAP). USA.", "acronyms": [[81, 86], [89, 92]], "long-forms": [[63, 80]]}, {"text": "Data Annotated. The data to be annotated in WSsim-1 were taken primarily from Semcor (Miller et al1993) and the Senseval-3 English lexical sample (SE-3) (Mihalcea, Chklovski, and Kilgarriff 2004).", "acronyms": [[147, 151]], "long-forms": [[112, 122]]}, {"text": "take advantage of the capabilities of a vectofized  concurrent processor (an Alliant FX/80) which consists  of a cluster of up to 8 computing elements (CE's) that  can execute code in vector concurrent mode.", "acronyms": [[152, 156], [85, 90]], "long-forms": [[132, 150]]}, {"text": "TI = fTW; F; ADV; AUX; V A; V C; V V; Pg Each type of the indicators, e.g. TW , contains a set of words, such as TW = twlist = ftw", "acronyms": [[113, 115], [75, 77], [18, 21], [13, 16], [0, 2]], "long-forms": [[118, 124]]}, {"text": "al., ( 2013) but replace Markov Logic Networks with Probabilistic Soft Logic (PSL) (Kimmig et al.,", "acronyms": [[78, 81]], "long-forms": [[52, 76]]}, {"text": "LM. This approach has been successfully applied in automatic speech recognition (ASR) (Tam and Schultz, 2006) using the Latent Dirichlet Alloca-", "acronyms": [[81, 84], [0, 2]], "long-forms": [[51, 79]]}, {"text": "tion of the reference xamples takes place.  Translation Memories (TMs) are such purely  memory based MT-systems.", "acronyms": [[66, 69], [101, 103]], "long-forms": [[44, 64]]}, {"text": "51 Table 1: Semantic restrictions on Task 2 event arguments. CCO = Cell Cycle Ontology, FMA = Foundational Model of Anatomy, other ontologies identified in the text.", "acronyms": [[61, 64], [88, 91]], "long-forms": [[67, 86], [94, 123]]}, {"text": " From the annotation pipeline we extracted as features: the polar words (PolW) and their basic polarity (Pol); the sentiment annotations from LIWC", "acronyms": [[73, 77], [105, 108], [142, 146]], "long-forms": [[60, 71], [95, 103]]}, {"text": "BP as a computational expression graph ? Automatic differentiation (AD) 7.", "acronyms": [[68, 70], [0, 2]], "long-forms": [[41, 66]]}, {"text": "tf iD j  is the inverse document frequency(IDF)  of the j-th word calculated as below: ", "acronyms": [[43, 46]], "long-forms": [[16, 41]]}, {"text": "In order to make it man-  ageable and intuitive, it employs yntactic constructs  called Typed Feature Structures (TFSs). The ,~vocab- ", "acronyms": [[114, 118]], "long-forms": [[88, 112]]}, {"text": " (UT = Utterance as actually made by the user, UR = Utterance as recognized by the system, SU = System utterance).", "acronyms": [[47, 49], [2, 4], [91, 93]], "long-forms": [[52, 61], [7, 16], [96, 112]]}, {"text": "verbs. But, the second Light Verb (LV) may be  a part of another Complex Predicate (CP). This ", "acronyms": [[84, 86], [35, 37]], "long-forms": [[65, 82], [23, 33]]}, {"text": "be expressed via correspondences. We will define a  variant of SSTC called synchronous SSTC (S-SSTC).  ", "acronyms": [[93, 99], [63, 67]], "long-forms": [[75, 91]]}, {"text": "a t tachment  (PP): the attachment ofa PP  in the sequence VP hip PP (VP = verb  phrase, 51P = noun phrase, PP = prepo-  sitional phrase).", "acronyms": [[108, 110], [15, 17], [39, 41], [59, 61], [66, 68], [70, 72]], "long-forms": [[113, 119], [75, 87]]}, {"text": "constituents. For example, discussing the possible adaptation of Phillips' algorithm to incremental gener-  ation, Lager and Black (1994) point out that some versions of Categorial Grammar (CG) would make the  generator more talkative, by giving rise to \"a more generous notion of constituency\".", "acronyms": [[190, 192]], "long-forms": [[170, 188]]}, {"text": "The paper first provides a brief overview of Lexical Functional Grammar, and the Penn Arabic Treebank (ATB). The next section presents", "acronyms": [[103, 106]], "long-forms": [[86, 101]]}, {"text": "lief chunk), B-NCB (Beginning of non committed belief chunk), I-NCB (Inside of a non committed belief chunk), B-NA (Beginning of a not applicable chunk), I-NA (Inside a not applicable", "acronyms": [[110, 114], [13, 18], [62, 67], [154, 158]], "long-forms": [[116, 130], [20, 59], [69, 107], [160, 183]]}, {"text": "Our corpus for this task is collected from Facebook and contains instances of Bengali(BN)English(EN)-Hindi(HI) code mixing. ", "acronyms": [[97, 99], [107, 109], [86, 88]], "long-forms": [[89, 95], [101, 106], [78, 85]]}, {"text": "bath?). The builder can choose to represent binaries as either relational noun phrases (RELNP) or generalized transitive verbs (VP/NP).", "acronyms": [[88, 93], [128, 133]], "long-forms": [[63, 86], [121, 126]]}, {"text": "V (verb) 6946 81.9 85.8 PR (preposition) 5302 60.0 79.0 CONJ (conjunction) 2998 76.1 80.7 ADV (adverb) 2855 72.3 83.3", "acronyms": [[56, 60], [24, 26], [90, 93]], "long-forms": [[62, 73], [3, 7], [28, 39], [95, 101]]}, {"text": "+ b) (4) where f is a non-linear activation function such as rectified linear unit (ReLu) or sigmoid function. ", "acronyms": [[84, 88]], "long-forms": [[61, 82]]}, {"text": "ing decision can be made directly based on attention weights from the two query components or further rescored by the maximum spanning tree (MST) search algorithm.", "acronyms": [[141, 144]], "long-forms": [[118, 139]]}, {"text": "guage varieties: the language of native speakers (N), the language of advanced, highly fluent nonnative speakers (NN), and translationese (T). We", "acronyms": [[114, 116], [50, 52], [139, 141]], "long-forms": [[97, 103], [33, 39], [123, 137]]}, {"text": "ity, to validate Boosting NER hypotheses. We also use three Markov chain Monte Carlo (MCMC) algorithms for probabilistic inference in MLNs.", "acronyms": [[86, 90], [26, 29], [134, 138]], "long-forms": [[60, 84]]}, {"text": "on adjunction (Joshi, 1987):  ? Null adjunction (NA): disallow any adjunc-  tion on the given node.", "acronyms": [[49, 51]], "long-forms": [[32, 47]]}, {"text": " and Iryna Gurevych Ubiquitous Knowledge Processing (UKP) Lab Computer Science Department", "acronyms": [[53, 56]], "long-forms": [[20, 51]]}, {"text": "the sentence. The segmentation model is a chain LVM (latent variable model) that aims to maximize a linear objective defined by:", "acronyms": [[48, 51]], "long-forms": [[53, 74]]}, {"text": "NP and selection of the head NP by the relative 1The following abbreviations are used in glosses: NOM = nominative, ACC = accusative, PRES = non-past and POT = potential. ( )", "acronyms": [[116, 119], [29, 31], [0, 2], [98, 101], [134, 138], [154, 157]], "long-forms": [[122, 132], [104, 114], [160, 169]]}, {"text": "extraction. Using the alignments from HIER, we created phrase tables using model probabilities (MOD), and heuristic extraction on words (HEUR-W), blocks", "acronyms": [[96, 99], [38, 42], [137, 143]], "long-forms": [[75, 80], [106, 135]]}, {"text": "WordNet  In another related effort, SRI performed experiments  in utilizing WordNet (WN) as a knowledge source for  IE.", "acronyms": [[85, 87], [36, 39], [116, 118]], "long-forms": [[76, 83]]}, {"text": "the ratio of system?s moves stating that the requested information is not available; Number of abandoned requests (NAR) and abandoned-request ratio (ARR), i.e., the number and the ratio of the information-providing games", "acronyms": [[115, 118]], "long-forms": [[85, 113]]}, {"text": "Figure 1: Top-k Accuracy Level Configuration MRR 0 Baseline (BL) 0.6559 1", "acronyms": [[61, 63], [45, 48]], "long-forms": [[51, 59]]}, {"text": " A project that is based on a roughly similar notion of text meaning representation (TMR) concepts is the ?", "acronyms": [[85, 88]], "long-forms": [[56, 83]]}, {"text": " (5) Rank Value:  i. Top Rank (T-Rank): The rank of snippet  that first contains the candidate.", "acronyms": [[31, 37]], "long-forms": [[21, 29]]}, {"text": "                                                           8  Feature type: CB=Clause boundary based feature type,  PT=Parse tree based feature type  9A ?", "acronyms": [[116, 118], [76, 78]], "long-forms": [[119, 129], [79, 94]]}, {"text": "EUD1.2 has the added benefit of being natively annotated with gold-standard Universal Dependencies (UD) parses (Nivre et al, 2015).", "acronyms": [[100, 102], [0, 3]], "long-forms": [[76, 98]]}, {"text": "the conjunction but. Turney and Littman (2003) use pointwise mutual information (PMI) (Church and Hanks, 1990) and latent semantic analysis", "acronyms": [[81, 84]], "long-forms": [[51, 79]]}, {"text": "DOC system, and they observe a close correspondence.  We have employed Functional Grammar (FG) (c.f \\[6\\])  as a principal analysis tool to developing representations ", "acronyms": [[91, 93], [0, 3]], "long-forms": [[71, 89]]}, {"text": "stem of JUMP = <jump>.   sense of JUMP = jumping. ", "acronyms": [[34, 38], [8, 12]], "long-forms": [[41, 48], [16, 20]]}, {"text": "R6mi Zajac Inheritance and Constraint-Based Grammar Formalisms  13th International Conference on  Computational Linguistics (COLING'90). ", "acronyms": [[125, 134]], "long-forms": [[98, 123]]}, {"text": "and a segment relation are identified.  Topic break index (TBI) takes the value of 1 or 2: the boundary with TBI=2 is less con-", "acronyms": [[59, 62], [109, 112]], "long-forms": [[40, 57]]}, {"text": "25 Techniques like self-training (SELF) and system combinations (COMBO) can further improve parsing accuracies, but are also orthogonal to our work.", "acronyms": [[65, 70], [34, 38]], "long-forms": [[51, 63], [19, 32]]}, {"text": "KEA: Practical automatic keyphrase  extraction. Proceedings of Digital Libraries 99 (DL'99), pp. ", "acronyms": [[85, 90], [0, 3], [93, 95]], "long-forms": [[63, 83]]}, {"text": "?? ( sE) one or more times are considered to be locative MWEs (LOC). In contrast, bigrams", "acronyms": [[63, 66], [57, 61]], "long-forms": [[48, 56]]}, {"text": "TIGER treebank. In Proceedings of the 1st Workshop on Treebanks and Linguistic Theories (TLT), pages 24?42. ", "acronyms": [[89, 92], [0, 5]], "long-forms": [[54, 87]]}, {"text": "We train a source-totarget PBMT system (SYS_ST) and a target-tosource PBMT system (SYS_TS) on the parallel  corpus.", "acronyms": [[83, 89], [40, 46], [27, 31]], "long-forms": [[63, 81], [32, 38]]}, {"text": "trated in Figure 1. At the outset, the table (T1), the  pump (PU), the apprentice (you) and the compressor  (COMP) are in \"primary focus\".", "acronyms": [[62, 64], [109, 113]], "long-forms": [[56, 60], [39, 44], [96, 106]]}, {"text": "TF (Term Frequency)  is the word frequency within a document;  IDF (Inverse Document Frequency) is the  logarithm of the ratio of the total number of ", "acronyms": [[63, 66], [0, 2]], "long-forms": [[68, 94], [4, 18]]}, {"text": "Improvements in a simulated speech-recognition example. Nine versions of a phonemically  identical oronym, ordered by weighted average (W.A.) probability (x 10-20). The W.A. ", "acronyms": [[136, 140], [169, 173]], "long-forms": [[118, 134]]}, {"text": "al. were entered into Graph Spider using the  metapattern language (MPL) designed by the  Graph Spider authors.", "acronyms": [[68, 71]], "long-forms": [[46, 66]]}, {"text": " In Proceedings ofthe 12th International Conference on  Computational Linguistics (COLING), Budapest. ", "acronyms": [[83, 89]], "long-forms": [[56, 81]]}, {"text": "MUC-6, 1995; Agirre, 2007). By contrast, gold  standard Named Entity (NE) annotations are easy  to produce; indeed, there are many NE annotated ", "acronyms": [[70, 72]], "long-forms": [[56, 68]]}, {"text": "tailment pairs to train an entailment classifier, our model was only trained on the 800 text-hypothesis pairs found in the RTE-3 Development Set (DevSet). ", "acronyms": [[146, 152], [123, 128]], "long-forms": [[129, 144]]}, {"text": "In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL). ", "acronyms": [[92, 95]], "long-forms": [[49, 90]]}, {"text": " 1 Introduction Topical Text Categorization (TC), the task of classifying documents by pre-defined topics, is most", "acronyms": [[45, 47]], "long-forms": [[24, 43]]}, {"text": "lar, at the level of additional information (CR), we observed some differences in judgement in particular between restrictions (AR) and warnings (AA), and a few others between CSFH and CSFC whose", "acronyms": [[146, 148], [45, 47], [128, 130], [176, 180], [185, 189]], "long-forms": []}, {"text": "e-mail: lynet te@goldilocks.lcs.mit.edu  ABSTRACT  The Air Travel Information System (ATIS) domain serves as  the common task for DARPA spoken language system re- ", "acronyms": [[86, 90], [130, 135]], "long-forms": [[55, 84]]}, {"text": "that of Visweswariah et al(2011) ? hereby called Travelling Salesman Problem (TSP) model ? with", "acronyms": [[78, 81]], "long-forms": [[49, 76]]}, {"text": "Measuring speech quality for text-to-speech systems: Development and assessment of a modified mean opinion score (MOS) scale. Computer Speech", "acronyms": [[114, 117]], "long-forms": [[94, 112]]}, {"text": "ductive transfer learning. In Proceedings of the IEEE International Conference on Data Mining (ICDM) 2007 Workshop on Mining and Management of Bio-", "acronyms": [[95, 99], [49, 53]], "long-forms": [[54, 93]]}, {"text": "as source domain training data (STrain), files 271300 as source domain testing data (STest) and files 590-596 as target domain testing data (TTest). We", "acronyms": [[141, 146], [32, 38], [85, 90]], "long-forms": [[113, 139], [3, 30], [57, 83]]}, {"text": " The implemented system has three main modules: the Feature Extractor (FE), the Generalized Iterative Scaling (GIS), and the Classifica-", "acronyms": [[71, 73], [111, 114]], "long-forms": [[52, 69], [80, 109]]}, {"text": "1.10% 0.20% 18.86% 0    We define Simple MNP (SMNP) whose  length is less than 5 words and Complete MNP ", "acronyms": [[46, 50], [100, 103]], "long-forms": [[34, 44]]}, {"text": "  1 Introduction  Sign Language (SL) is a visual-gestural language, using the whole upper body articulators ", "acronyms": [[33, 35]], "long-forms": [[18, 31]]}, {"text": "two requirements. Since it has to be transformed  into context?free grammar (CFG) for recognition,  features must have a finite number of values, as ", "acronyms": [[77, 80]], "long-forms": [[55, 75]]}, {"text": "Expanding  on a suggestion of Nfichieis (1982), we classify verbs  as subject equi (SEqui), object equi (OEqul), sub-  ject raising (SRals ing)  or object raising (ORuls ing) ", "acronyms": [[84, 89], [105, 110], [164, 173], [133, 142]], "long-forms": [[70, 82], [92, 103], [148, 162], [113, 131]]}, {"text": "In this paper we investigate the relation between positive and negative pairs in Textual Entailment (TE), in order to highlight the role of contradiction in TE", "acronyms": [[101, 103], [157, 159]], "long-forms": [[81, 99]]}, {"text": "opinions are about the 20 most popular Chicago hotels; deceptive opinions were generated using the Amazon Mechanical Turk (AMT)3, whereas ?", "acronyms": [[123, 126]], "long-forms": [[99, 121]]}, {"text": "  Daniel S. Leite1, Lucia H. M. Rino1, Thiago A. S. Pardo2, Maria das Gra?as V. Nunes2  N?cleo Interinstitucional de Ling??stica Computacional (NILC)  http://www.nilc.icmc.usp.br ", "acronyms": [[144, 148]], "long-forms": [[88, 142]]}, {"text": "TOP (PRP ? I?) ( VP (VBP ? NEED?) (", "acronyms": [[17, 19], [0, 3], [5, 8]], "long-forms": [[21, 24]]}, {"text": "Kearns (2002) distinguishes between two usages of light verbs in LVCs: what she calls a true light verb (TLV), as in give a groan, and what she calls a vague action verb (VAV), as in", "acronyms": [[105, 108], [65, 69], [171, 174]], "long-forms": [[88, 103], [152, 169]]}, {"text": " ? ALGN (alignment-based): We ran a sentence alignment algorithm (Gale and Church, 1993)", "acronyms": [[3, 7]], "long-forms": [[9, 18], [45, 54]]}, {"text": " LTP. LTP (Language Technology Platform  developed by HIT) is a package of tools to ", "acronyms": [[6, 9], [1, 4], [54, 57]], "long-forms": [[11, 39]]}, {"text": "A workaround is to restrict the possible tag candidates per position by using either morphological analyzers (MAs), dictionaries or heuristics (Hajic?,", "acronyms": [[110, 113]], "long-forms": [[85, 108]]}, {"text": "Table 1: Comparison of knowledge acquisition strategies. Interactive query expansion (IQE)?s poor task completion indicates keywords can?t bridge the knowledge", "acronyms": [[86, 89]], "long-forms": [[57, 84]]}, {"text": "  The word sea is ambiguous and has three senses as  given in the Princeton Wordnet (PWN):  S1: (n) sea (a division of an ocean or a large body ", "acronyms": [[85, 88]], "long-forms": [[66, 83]]}, {"text": "1 Int roduct ion   In a recent paper Boguraev and Levin (1990) point out inadequacies in common concep-  tions of what a Lexical Knowledge Base (LKB) should be, inadequacies which stem from  the assumption that a machine-readable dictionary (MRD) is not only the right source for ", "acronyms": [[145, 148]], "long-forms": [[121, 143]]}, {"text": "of the intuition behind the inclusion of Tree Adjoining Lan-  gages (TAL) in the class of languages generated by a variant  of HG's called Modified Head Grammars (MHG's). In the ", "acronyms": [[163, 168], [69, 72], [127, 131]], "long-forms": [[139, 161], [41, 67]]}, {"text": "counted through specifier phrases. A Malay example, where biji is the count classifier (CL) for fruit, is given in (1).", "acronyms": [[88, 90]], "long-forms": [[76, 86]]}, {"text": "sider this sentence is correctly tagged.  Test data set 1 (TDS 1): contains about 10%  of the sentences from the complete emotion-", "acronyms": [[59, 64]], "long-forms": [[42, 57]]}, {"text": " (Choudhury et al, 2007) modeled each standard English word as a hidden Markov model (HMM) and calculated the probability of observing the noisy-", "acronyms": [[86, 89]], "long-forms": [[65, 84]]}, {"text": " The practical application of flame-based knowledge-based systems, such as in expert systems, requires the maintenance of  potentially very large amounts of declarative knowledge stored in their knowledge bases (KBs). As a KB grows in size and ", "acronyms": [[212, 215], [223, 225]], "long-forms": [[195, 210]]}, {"text": " Connectivity Strength Features provide two scores, Source Connectivity Strength (SCS) and Target Connectivity Strength (TCS).", "acronyms": [[82, 85], [121, 124]], "long-forms": [[52, 80], [91, 119]]}, {"text": "3.1 Data and preprocessing All embeddings are trained on 22 million tokens from the the North American News Text (NANT) corpus (Graff, 1995).", "acronyms": [[114, 118]], "long-forms": [[88, 112]]}, {"text": "tilogue, but rather a number of parallel dialogues.  The Mission Rehearsal Exercise (MRE) Project (Traum and Rickel, 2002), one of the largest multilogue", "acronyms": [[85, 88]], "long-forms": [[57, 83]]}, {"text": "include: 1) candidate frequency and its distribution in different Web pages, 2) length ratio between source terms and target candidates (S-T), 3)  distance between S-T, and 4) keywords, key ", "acronyms": [[137, 140], [164, 167]], "long-forms": [[101, 135]]}, {"text": "University of Brighton There is growing interest in using automatically computed corpus-based evaluation metrics to evaluate Natural Language Generation (NLG) systems, because these are often considerably cheaper than the human-based evaluations which have traditionally been used in NLG.", "acronyms": [[154, 157], [284, 287]], "long-forms": [[125, 152]]}, {"text": "tors of a lower-dimensional space. LSI, which is based on Singular Value Decomposition (SVD) of matrices, has showed to have the ability to ex-", "acronyms": [[88, 91], [35, 38]], "long-forms": [[58, 86]]}, {"text": "derstand what is being tested. In projects where independent verification and validation (IVV) is required this might be a problem, as most stake-", "acronyms": [[90, 93]], "long-forms": [[49, 88]]}, {"text": "user?s state in the given session. In this research, the support vector machine (SVM) is used as a classifier.", "acronyms": [[81, 84]], "long-forms": [[57, 79]]}, {"text": "74.80 ?  Table 2: Parsing accuracy; AS = attachment score; ER = error reduction w.r.t. projective baseline (%)", "acronyms": [[36, 38], [59, 61]], "long-forms": [[41, 57], [64, 79]]}, {"text": "The English supervised NE tagger correctly identifies Asian as a named entity of type MISC (miscellaneous). The word-alignments sug-", "acronyms": [[86, 90], [23, 25]], "long-forms": [[92, 105]]}, {"text": " 2 In Pisa two dictionaries of Italian, ,are being used: the  Nuovo Dizionario Garzanti (GRZ) and the Dlzionario-  Macchina dell'ltaliano (DMI), a MRD mainly based on the ", "acronyms": [[89, 92], [139, 142], [147, 150]], "long-forms": [[79, 87], [102, 137]]}, {"text": "elements and punctuation. We used the same evaluation metrics for unlabeled precision (UP) and unlabeled recall (UR) as defined in Klein (2005: 21-", "acronyms": [[87, 89], [113, 115]], "long-forms": [[66, 85], [95, 111]]}, {"text": "In LREC 2006, Genoa Yes?im Aksan and Mustafa Aksan 2012. Construction of the Turkish National Corpus (TNC). In LREC 2012,", "acronyms": [[102, 105], [3, 7]], "long-forms": [[77, 100]]}, {"text": "Figure 2: Accuracy by sentence length for Method 5 measured on separate grammatical and ungrammatical data: Gr = Grammatical, AG = Agreement, RW = Real-Word, EW = Extra Word, MW = Missing", "acronyms": [[126, 128], [108, 110], [142, 144], [158, 160], [175, 177]], "long-forms": [[131, 140], [113, 124], [147, 156], [163, 173], [180, 187]]}, {"text": "tion, corpora from seven different genres are used: the MSNBC broadcasting conversation (BC), the CNN broadcasting news (BN), the Sinorama news magazine (MZ), the WSJ newswire (NW), and the", "acronyms": [[121, 123], [56, 61], [89, 91], [98, 101], [154, 156], [163, 166], [177, 179]], "long-forms": [[102, 119], [62, 87], [144, 152], [167, 175]]}, {"text": "and documents created by three or four New York Times columnists (TF = Thomas Friedman, PK = Paul Krugman, MD = Maureeen Dowd, GC = Gail Collins).", "acronyms": [[88, 90], [66, 68], [107, 109], [127, 129]], "long-forms": [[93, 105], [71, 86], [112, 125], [132, 144]]}, {"text": "In particular, the work of (Pietra et al, 1997) is inspiring to us, but the improved iterative scaling (IIS) method for parameter estimation and the Gibbs sampler", "acronyms": [[104, 107]], "long-forms": [[76, 102]]}, {"text": "controlled vocabulary. As an application of the  Resource Description Framework (RDF), SKOS  allows concepts to be composed and published on the ", "acronyms": [[81, 84], [87, 91]], "long-forms": [[49, 79]]}, {"text": "PER (PN), only PER candidates beginning with  the family name is considered. For PER (FN), a  candidate is generated only if all its composing ", "acronyms": [[86, 88], [0, 3], [5, 7], [15, 18]], "long-forms": [[77, 84]]}, {"text": "We experimentally evaluated the test collection for single document summarization contained in the RST Discourse Treebank (RST-DTB) (Carlson et al.,", "acronyms": [[123, 130]], "long-forms": [[99, 121]]}, {"text": "Inspired by our experience of dealing with different text classification problems, we decide to  employ a linear support vector machine (SVM) in  our NLI2013 system.", "acronyms": [[137, 140], [150, 157]], "long-forms": [[113, 135]]}, {"text": "Therefore, we refined our reference performance level by combining the ME models (MEM) and handcrafted models (HCM). Suppose the score of a", "acronyms": [[111, 114], [82, 85]], "long-forms": [[91, 109], [71, 79]]}, {"text": " 1 Introduction Word Sense Disambiguation (WSD) is considered one of the most important prob-", "acronyms": [[43, 46]], "long-forms": [[16, 41]]}, {"text": "Examples of failure of analysis  (i) JISSAI (in fact), CHOSHA-TACHI-WA (authors) {\\[KORE-WO (it) TSUKATTE  (using), JUURYOKU-SOUGO-SAYOU-GA (gravitationally interacting) SHIHAI-SURU (govern-  ing)\\] TENTAI-NO (astronomical) UNDOU-NI-TSUITE (about the motion), KOUSEIDO-DE (high- ", "acronyms": [[137, 139], [37, 43], [55, 70], [170, 181], [199, 208], [224, 239]], "long-forms": [[141, 156], [183, 195], [210, 222], [241, 257]]}, {"text": "data are used to train a classifier, using any cost-sensitive classification (CSC) method (line 15). New pi", "acronyms": [[78, 81]], "long-forms": [[47, 76]]}, {"text": "rules are learned from the alignment of manuallytranscribed text (T ) with automatically-generated transcripts (TASR) of training data, ranked according to a scoring function (S) and applied to the", "acronyms": [[112, 116]], "long-forms": [[99, 110], [60, 64]]}, {"text": " 3.1.1 Pre-Processing For Feature Extraction Phrase Analysis(PA): Using basic syntactic analysis (shallow parsing), the PA module re-builds", "acronyms": [[61, 63], [120, 122]], "long-forms": [[45, 59]]}, {"text": "search engine, e.g., Google, Bing, etc. and (ii) a database (DB) system for accessing previously resolved crossword puz-", "acronyms": [[61, 63]], "long-forms": [[51, 59]]}, {"text": "difficult to disambiguate.  Preposition sense disambiguation (PSD) has many potential uses.", "acronyms": [[62, 65]], "long-forms": [[28, 60]]}, {"text": "Evaluation of Online Dialogue Policy Learning Techniques, Proceedings of the 8th Conference on Language Resources and Evaluation (LREC) 2012, to appear.", "acronyms": [[130, 134]], "long-forms": [[95, 113]]}, {"text": "sures for each portion of the results. One is a relevance score (RS) with the target document \u0001 \u0002", "acronyms": [[65, 67]], "long-forms": [[48, 63]]}, {"text": "edges the support of Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract No.", "acronyms": [[132, 136], [64, 69]], "long-forms": [[101, 130], [21, 62]]}, {"text": "quences here).  1PARTMOD=participial modifier, PREP=prepositional modifier, POBJ=object of preposition.", "acronyms": [[47, 51], [16, 24], [76, 80]], "long-forms": [[52, 65], [25, 45], [81, 102]]}, {"text": "tween arguments. We thus propose to model the reranking phase (RR) as a HMM sequence labeling task.", "acronyms": [[63, 65], [72, 75]], "long-forms": [[46, 55]]}, {"text": "For attribute selection on the composed vector, we use two methods we found to perform best in Hartung and Frank (2010): Entropy Selection (ESel) and Most Prominent Component (MPC).", "acronyms": [[140, 144], [176, 179]], "long-forms": [[121, 138], [150, 174]]}, {"text": "Statistical machine translation based on LDA.  In Universal Communication Symposium (IUCS), 2010 4th International, pages 286?290.", "acronyms": [[85, 89], [41, 44]], "long-forms": [[47, 83]]}, {"text": " IHMM-based: He et al (2008) propose an  indirect hidden Markov model (IHMM) for hypothesis alignment.", "acronyms": [[71, 75], [1, 5]], "long-forms": [[41, 69]]}, {"text": "Ensemble NN + LR (w/o alternate grammar) 54.38 41.90 Ensemble NN + LR (w/o synthetic data) 53.98 42.41 Table 1: Accuracy of the Neural Network (NN) and Logistic Regression (LR) implementations of our system with various configurations.", "acronyms": [[144, 146], [173, 175], [9, 16], [62, 69]], "long-forms": [[128, 142], [152, 171]]}, {"text": "have a tea and read a good criminal book) and we cannot forget that entertainment is also one of this Embodied Conversational Agent (ECA)?s goal. ", "acronyms": [[133, 136]], "long-forms": [[102, 131]]}, {"text": " Generation Challenges 2010 brought together three sets of STECs: the three GREC Challenges, GREC Named Entity Generation (GREC-NEG), Named Entity Reference Detection (GREC-NER), and Named Entity Reference Regeneration", "acronyms": [[123, 131], [59, 64], [76, 80], [168, 176]], "long-forms": [[93, 121], [183, 218]]}, {"text": "SOl,licit(co+ t{ach of these phrases conlpriscs a contigtlous  sequence o1 tags that satisfies a strut+h: gral,illilar, l\"or  example, a II(,itlll pluase eltil be simi)ly a plonoull  t~ig or (,in  all:l itlaly setitlellce (:,I lie(It1 lind ad.iective lags, pms ib ly  ", "acronyms": [[137, 139]], "long-forms": [[141, 159]]}, {"text": "the (Penn Treebank) annotation style, (3) the (LexTract) extraction tool, (4) possible unsuitability of the (TAG) model, and (5) annotation errors. We", "acronyms": [[109, 112], [47, 55]], "long-forms": []}, {"text": "vantages while considering the consistency, we further propose a global decoding strategy using Integer Linear Programming(ILP). The constraints", "acronyms": [[123, 126]], "long-forms": [[96, 121]]}, {"text": "for candidate summary sentence selection  by standard page rank algorithms used in  Information Retrieval (IR). As Bengali is ", "acronyms": [[107, 109]], "long-forms": [[84, 105]]}, {"text": "tions. Following Bahdanau et al (2014), we employ the Gated Recurrent Unit (GRU) as our RNN unit due to its capacity in capturing long-distance depen-", "acronyms": [[76, 79]], "long-forms": [[54, 74]]}, {"text": "2 where AF = adjusted frequency di = relative size of category i", "acronyms": [[8, 10]], "long-forms": [[13, 31]]}, {"text": "280  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1203?1209, October 25-29, 2014, Doha, Qatar.", "acronyms": [[93, 98]], "long-forms": [[43, 91]]}, {"text": "represented in Table 3 based on the place (bilabial  (BL), lab-dental (LD), dental (DE), alveopalatal  (AP), velar (VL), uvular (UV) and glottal (GT))  and manner of articulation (stops (ST), fricatives ", "acronyms": [[146, 148], [54, 56], [71, 73], [84, 86], [104, 106], [116, 118], [129, 131], [187, 189]], "long-forms": [[137, 144], [43, 51], [59, 69], [76, 82], [89, 101], [109, 114], [121, 127], [180, 185]]}, {"text": "sub-tasks: ? Multimedia Information Network (MiNet) Construction: Construct MiNet from cross-media and cross-genre information (i.e. tweets, images, sentences of web doc-", "acronyms": [[45, 50], [76, 81]], "long-forms": [[13, 43]]}, {"text": "Figure 5: Example GMM fitting 2. Gaussian mixture model (GMM)-based POI probability (prior) calculation", "acronyms": [[57, 60], [18, 21], [68, 71]], "long-forms": [[33, 55]]}, {"text": "retrieval with locality information using smart. In  Text retrieval conferenc (TREC-1) (pp. 59-72).", "acronyms": [[79, 85], [88, 90]], "long-forms": [[53, 77]]}, {"text": " ? Left Reveal (LRev) : Pop the top two nodes in the stack (left, right).", "acronyms": [[16, 20]], "long-forms": [[3, 14]]}, {"text": "The output of our experiments was evaluated using two metrics, (1) BLEU (Papineni et al, 2002), and (2) Lexical Accuracy (LexAcc). Lexical ac-", "acronyms": [[122, 128], [67, 71]], "long-forms": [[104, 120]]}, {"text": " 5 Word Sense Disambiguation(WSD) is the process of assigning a meaning to a word based on the context in which it occurs. { 4,5}", "acronyms": [[29, 32]], "long-forms": [[3, 27]]}, {"text": "the specified length limit. This idea is realized using the integer linear programming-based (ILP) optimization framework, with objective function set to", "acronyms": [[94, 97]], "long-forms": [[60, 86]]}, {"text": "Social media in general exhibit a rich variety of  information sources. Question answering (QA) has  been particularly amenable to social media, as it ", "acronyms": [[92, 94]], "long-forms": [[72, 90]]}, {"text": " More recently, Galley and Quirk (2011) have introduced linear programming MERT (LP-MERT) as an exact search algorithm that reaches the global op-", "acronyms": [[81, 88]], "long-forms": [[56, 79]]}, {"text": "12 Base+FrameNet (FN) 61.8 71.9 66.5 59.8 69.3 64.2 53.5 60.0 56.6 51.1 57.9 54.3 13 Base+Verb Pairs (VP) 62.1 72.2 66.8 60.1 69.3 64.4 54.4 60.1 57.1 51.9 58.2 54.9 14 Base+Appositives (AP) 63.1 71.7 67.1 60.5 69.4 64.6 54.1 60.1 56.9 51.9 57.8 54.7 Table 1: Results obtained by applying different types of features in isolation to the Baseline system.", "acronyms": [[187, 189], [18, 20], [102, 104]], "long-forms": [[169, 185], [8, 16], [90, 99]]}, {"text": "Our approach to this problem is influenced by the named entity annotation in the Automatic Content Extraction (ACE) project (Consortium, 2002), in which ?", "acronyms": [[111, 114]], "long-forms": [[81, 109]]}, {"text": " The single product opinion summarizer we consider is the Sentiment Aspect Match model (SAM) described and evaluated in (Lerman et al, 2009).", "acronyms": [[88, 91]], "long-forms": [[58, 80]]}, {"text": " 1 Introduction Currently the Machine Translation (MT) research community attempts to seamlessly integrate both", "acronyms": [[51, 53]], "long-forms": [[30, 49]]}, {"text": "Figure 4: Weight of links and category selection  3 .1  Representat ion  o f  OPED  The Oxford Pictorial English Dictionary(OPED) h,~s  very simple form of text and picture (Fig.3).", "acronyms": [[124, 128], [78, 82]], "long-forms": [[88, 122]]}, {"text": "domain-independent mpirical induction algorithm. We test this idea by examining the  machine learning of simple Sound Pattern of English (SPE)-style phonological rules  (Chomsky and Halle 1968), beginning by representing phonological rules as finite- ", "acronyms": [[138, 141]], "long-forms": [[112, 136]]}, {"text": "The feature av is derived from unsupervised segmentation as in (Zhao and Kit, 2008a), and the accessor variety (AV) (Feng et al, 2004) is adopted as the unsupervised segmentation crite-", "acronyms": [[112, 114]], "long-forms": [[94, 110]]}, {"text": "for the different settings. GM = Google Maps, CI = Campus Indoor, CO = Campus Outdoor. ", "acronyms": [[66, 68], [28, 30], [46, 48]], "long-forms": [[71, 85], [33, 44], [51, 64]]}, {"text": "direct analogy to Sidner's \\[26\\] potential local foci,  and assumes only one temporal referent in the  temporal focus (TF). ", "acronyms": [[120, 122]], "long-forms": [[104, 118]]}, {"text": "CoTrain vs. BaseCN2 1.8E-07 0.00257 0.000182 CoTrain vs. BaseCN3 1.27E-06 0.00922 0.000765 CoTrain vs. LEX(CN) 6.09E-29 3.72E-21 1.61E-24 CoTrain vs. LEX(EN) 0.0018 0.0276 0.00329", "acronyms": [[107, 109], [103, 106], [150, 153], [154, 156]], "long-forms": [[91, 98]]}, {"text": "1 Quantification resolution We are concerned with ambiguously quantified noun phrases (NPs) and their interpretation, as illustrated by the following examples:", "acronyms": [[87, 90]], "long-forms": [[73, 85]]}, {"text": "ters instead of Y or N as labels. The character-level machine translation (MT) approach (Pennell and Liu, 2011) was modified in (Li and Liu, 2012a)", "acronyms": [[75, 77]], "long-forms": [[54, 73]]}, {"text": "2.2 Graphical Representation Recently, Ding et al (2008) use skip-chain and 2D Conditional Random Fields (CRFs) (Lafferty et al, 2001) to perform the relational learning for", "acronyms": [[106, 110], [76, 78]], "long-forms": [[79, 104]]}, {"text": "account for these generalizations by decom-  posing the grammar rules to Immediate Dom-  inance(ID) rules and Linear Preeedence(LP)  rules.", "acronyms": [[128, 130], [96, 98]], "long-forms": [[110, 126], [73, 95]]}, {"text": "number of correcVi'abeled-constituents in proposed parse  number of correct matched constituent inproposed parse  6) Sentence parsing ratio(SPg) =  number\" of sentences having a proposed parse by parser ", "acronyms": [[140, 143]], "long-forms": [[117, 133]]}, {"text": " Finally there is a set of measures relating to the receiver operating characteristic (ROC) curves, which measure the discrimination of the scores for", "acronyms": [[87, 90]], "long-forms": [[52, 85]]}, {"text": "kept on a ventilator for medical reasons.     Change of state (COS) is most often understood  as an aspectual difference that is reflected in verb ", "acronyms": [[63, 66]], "long-forms": [[46, 61]]}, {"text": "entire sentence length.  SyntaxBased (SyntB): contextual features have been computed according to the ?", "acronyms": [[38, 43]], "long-forms": [[25, 36]]}, {"text": "1 ? Active Node List (ANL): a list that records all ?", "acronyms": [[22, 25]], "long-forms": [[4, 20]]}, {"text": "of Petrov et al. ( 2012): NOUN (nouns), VERB (verbs), ADJ (adjectives), ADV (adverbs), PRON (pronouns), DET (determiners and articles), ADP", "acronyms": [[54, 57], [72, 75]], "long-forms": [[59, 69], [77, 84]]}, {"text": " CTexT. 2005. CKarma (C5 KompositumAnaliseerder vir Robuuste Morfologiese Analise). [ C5 Compound", "acronyms": [[14, 20], [1, 6]], "long-forms": [[22, 47]]}, {"text": "One team participated in the GRO task, and their results were compared with those of a preliminary system prepared by the task organizers. An analysis of the evaluation results leads us to study issues such as the need to consider the ontology structure and the need for semantic analysis, which are not seriously dealt with by current approaches to event extraction. 6 Organization of the workshop The BioNLP Shared Task 2013 (BioNLP-ST) workshop was organized as part of the ACL BioNLP 2013 workshop. After submission of their system results, participants were invited to submit a paper on their systems to the workshop.", "acronyms": [[428, 437], [29, 32], [477, 480], [481, 487]], "long-forms": [[403, 421]]}, {"text": "1] proposed a language-neutral framework for representing semantic tense. This framework is called the Language Neutral Syntax (LNS). Based on ", "acronyms": [[128, 131]], "long-forms": [[103, 126]]}, {"text": " 1 Introduction Multiword Expressions (MWEs) are commonly defined as ?", "acronyms": [[39, 43]], "long-forms": [[16, 37]]}, {"text": "2.1 Description of the procedure Two specialized topics In this study MA student interpreters were invited to prepare for simultaneous interpreting tasks on two specialised topics: fast reactors (FR) and Seabed minerals (SM). They", "acronyms": [[196, 198], [221, 223], [70, 72]], "long-forms": [[181, 194], [204, 219]]}, {"text": "TEMPLATE GENERATO R Template Generation Algorithm The memory-based parser generates one or several concept sequence instances (CSI's) for each sentence . ", "acronyms": [[127, 132]], "long-forms": [[99, 125]]}, {"text": "this mode\\]., the linguistic facts that pertain solely  to the source language (SL) are supposed to be  clearly separated from the facts that pertain solely ", "acronyms": [[80, 82]], "long-forms": [[63, 78]]}, {"text": "O-ADVL = Object Adverbial: lie ran two miles.  APP = Apposition: Helsinki, the capital of Finland,  N = Title: King George and Mr. ", "acronyms": [[47, 50], [0, 6]], "long-forms": [[53, 63], [9, 25], [104, 109]]}, {"text": "framework. This algorithm uses grammars in the Chomsky Normal Form (CNF) so we employed the open source Natural Language Toolkit2", "acronyms": [[68, 71]], "long-forms": [[47, 66]]}, {"text": "Here, we assume :  P(t i I G~ )  IP(tt I Pi-i PiWi) Pi-I piwi E dp  \\[ P(ti / Pi ) Pi-I Pi Wi ~ 1I) ", "acronyms": [[33, 35]], "long-forms": [[39, 43]]}, {"text": " We evaluate performance using 3 measures:  exact match (EM), head match (HM), and partial  match (PM), similar to Choi et al (2006).", "acronyms": [[57, 59], [74, 76], [99, 101]], "long-forms": [[44, 55], [62, 72], [83, 97]]}, {"text": "Each extractor receives a sentence as input and determines which noun phrases (NPs) in the sentence are fillers for the event role.", "acronyms": [[79, 82]], "long-forms": [[65, 77]]}, {"text": "As an example, the following arrow property says that within an interrogative phrase (Pint), an interrogative chunk (IntC) with an interrogative pronoun inside (pint) ar-", "acronyms": [[117, 121]], "long-forms": [[96, 115]]}, {"text": "nextpos part of speech of next word in the sentence determiner if the word has a determiner prepgoverning if the word is governed by a prepositional phrase (PP), we extract the preposition insidequotes if the word is inside quotes", "acronyms": [[157, 159]], "long-forms": [[135, 155]]}, {"text": "Mean values (with standard deviations) of each of the first eight features on each sub-corpus are displayed in Table 4. The number of unusual punctuation marks (UnPunc) is the only feature whose value does not differ significantly between the original and simplified versions of the texts in any of the four", "acronyms": [[161, 167]], "long-forms": [[134, 153]]}, {"text": " 110  ehange(CHA) communication(COMM)  cognition(COG) competition(COMP) ", "acronyms": [[32, 36], [13, 16], [49, 52], [66, 70]], "long-forms": [[18, 30], [6, 12], [39, 48], [54, 65]]}, {"text": "during this period: Carpetbagger (CB),1 Daily Kos (DK),2 Matthew Yglesias (MY),3 Red State (RS),4 and Right Wing News (RWN).5 CB and MY ceased as independent bloggers in August 2008.6 Because", "acronyms": [[119, 122], [34, 36], [51, 53], [75, 77], [92, 94], [133, 135], [126, 128]], "long-forms": [[102, 117], [20, 32], [40, 49], [57, 73], [81, 90]]}, {"text": "computed from the rewrite rules by the examination of the interdependencies of the rules with the help of  KIT = Ktinsdiche lntelligenz und Textverstehen  (artificial intelligence and text understanding), FAST = ", "acronyms": [[107, 110], [205, 209]], "long-forms": [[113, 135]]}, {"text": "morphologically very rich. Different suffixes  may be attached to a Light Verb (LVs) (in this  case [YYY]) depending on the various features ", "acronyms": [[80, 83]], "long-forms": [[68, 78]]}, {"text": "Economics neighborhood fbank  bank  Subject Code EC = Economies  account cheque money by ", "acronyms": [[49, 51]], "long-forms": [[54, 63]]}, {"text": "Since many responses in ETLA are expected to  follow certain patterns, it is intuitive to construct  limited regular expressions (RegEx) to match gold  standard responses for candidates with high profi-", "acronyms": [[130, 135], [24, 28]], "long-forms": [[109, 128]]}, {"text": "Results on final test sets. LAS = labeled attachment score. UAS = unlabeled attachment score. ", "acronyms": [[60, 63], [28, 31]], "long-forms": [[66, 92], [34, 58]]}, {"text": "Given an input pair (q,a), where q is a question and a is a candidate answer, first we retrieve the word embeddings (WEs) of both q and a. Then, we separately apply a", "acronyms": [[117, 120]], "long-forms": [[100, 115]]}, {"text": " 1 Introduction Automatic evaluation of machine translation (MT) quality is essential to developing high-quality ma-", "acronyms": [[61, 63]], "long-forms": [[40, 59]]}, {"text": "tical finite-state transducer (SFST) as a generative model and a support vector machine (SVM) and conditional random fields (CRF) as discriminative models.", "acronyms": [[125, 128], [31, 35], [89, 92]], "long-forms": [[98, 123], [0, 29], [65, 87]]}, {"text": "term t appears in position i around the entity.  Bigram Context (BCON): The bigram-based  context model was built in a similar way to UCON, ", "acronyms": [[65, 69], [134, 138]], "long-forms": [[49, 63]]}, {"text": "3.5 Classification   For our task of classifying ALI patients, we  picked the Maximum Entropy (MaxEnt) algorithm due to its good performance in text classi-", "acronyms": [[95, 101], [49, 52]], "long-forms": [[78, 93]]}, {"text": "navigation instruction to guide the IF to a convenient location at which she can then use a simple referring expression (RE). That is, there is an inter-", "acronyms": [[121, 123], [36, 38]], "long-forms": [[99, 119]]}, {"text": " 2.5 Semantic Textual Similarity Semantic Textual Similarity (STS) is the task of judging the similarity of a pair of sentences on", "acronyms": [[62, 65]], "long-forms": [[33, 60]]}, {"text": "The effectiveness of customer care in the email channel is measured using two competing metrics: Average Handling Time (AHT) and Customer Experience Evaluation (CEE).", "acronyms": [[120, 123], [161, 164]], "long-forms": [[97, 118], [129, 159]]}, {"text": "Universitat Polit`ecnica de Catalunya (UPC), Barcelona 2 Centro de Investigaci?on en Computaci?on (CIC), Instituto Polit?ecnico Nacional (IPN), Mexico 1", "acronyms": [[99, 102], [138, 141], [39, 42]], "long-forms": [[57, 97], [105, 136], [0, 37]]}, {"text": " Acknowledgments This work has been funded in part by a research grant from Science Foundation Ireland (SFI) under Grant Number SFI/12/RC/2289 (INSIGHT) and by the EU FP7 program in the context of the project LIDER", "acronyms": [[104, 107], [209, 214], [164, 166], [167, 170]], "long-forms": [[76, 102]]}, {"text": "main line of the narrative. This move is signaled  by the temporal focus (TF), and the entire deictic  center, returning to an established node in the ", "acronyms": [[74, 76]], "long-forms": [[58, 72]]}, {"text": "istic conversational systems. In Proceedings of Intelligent User Interfaces 2001 (IUI-01), pages 1?8, Santa Fe, NM, January.", "acronyms": [[82, 88], [112, 114], [108, 110]], "long-forms": [[48, 80]]}, {"text": "Disco-En-Gold consists of 349 expressions divided into training (TrainD), validation (ValD), and test data (TestD) manually assigned scores from 0 to 100, indicating the level of compositionality (the", "acronyms": [[108, 113], [86, 90], [65, 71]], "long-forms": [[97, 106], [74, 84], [42, 63]]}, {"text": "In  Proceedings of the 16th International Conference on  Computational Linguistics (COLING-96), Copenhagen,  Denmark, pp 459-465.", "acronyms": [[84, 93]], "long-forms": [[57, 82]]}, {"text": "R5   95 7 Antecedent Contained Deletion(ACD)  Further evidence for the proposed analysis comes ", "acronyms": [[40, 43]], "long-forms": [[10, 39]]}, {"text": " 3.2 Matching a review to an object Given the above review language model (RLM), we now state how to match a given review to an", "acronyms": [[75, 78]], "long-forms": [[52, 73]]}, {"text": " 3.1 Annotating message-level data Amazon?s Mechanical Turk (MTurk) was used to annotate the 5,000 random English (American)", "acronyms": [[61, 66]], "long-forms": [[44, 59]]}, {"text": "2012) for our experiment. It consists of 12 common tags: NOUN, VERB, ADJ (adjective), ADV (adverb), PRON (pronoun), DET (deter-", "acronyms": [[69, 72], [86, 89], [100, 104], [116, 119]], "long-forms": [[74, 83], [91, 97], [106, 113], [121, 126]]}, {"text": "LOC(at. IN) The ACT (Actor) can be any noun in the subjective case (the abbreviation n), the PAT (Patient)", "acronyms": [[16, 19], [0, 3], [93, 96]], "long-forms": [[21, 26], [98, 105]]}, {"text": "ity. We presented an evaluation of these parameters for preposition sense disambiguation (PSD). ", "acronyms": [[90, 93]], "long-forms": [[56, 88]]}, {"text": "tation for extracting entities from w. In our system, we let an extraction predicate be a simplified XML path (XPath) such as /html[1]/body[1]/table[2]/tr/td[1]", "acronyms": [[111, 116]], "long-forms": [[101, 109]]}, {"text": "state%1:03:00; ? AB = abstraction%1:03:00 \\ (event%1:03:00 ? state%1:03:00).", "acronyms": [[17, 19]], "long-forms": [[22, 41]]}, {"text": "planes, the \"READ\"-units by AND-planes. The flip-  flops (FF) are simple register units and the shift  register is a simple PLA network of well  known ", "acronyms": [[58, 60], [124, 127]], "long-forms": [[44, 56]]}, {"text": " Table 10: Average value of the mutual infor-  mation (MI) of compound noun seeds  .Number of elements \\[ 2 I 3 ", "acronyms": [[55, 57]], "long-forms": [[47, 53]]}, {"text": "2 Textual Entailment for MT Evaluation 2.1 Textual Entailment vs. MT Evaluation Textual entailment (TE) was introduced by Dagan et al. (", "acronyms": [[100, 102], [25, 27], [66, 68]], "long-forms": [[80, 98]]}, {"text": "Computational Linguistics Volume 21, Number 4  Table 6  Growth of Hypothesis Space: S = sentence; TL = Total number of links; RL= Relevant Links;  AC = Number of Active Chains; G = Growth rate ", "acronyms": [[98, 100], [126, 128], [147, 149]], "long-forms": [[103, 108], [88, 96], [130, 144], [162, 174], [181, 192]]}, {"text": "- meaningful expression (ME): Any physical act  carrying a non-contextual meaning;  - communicative act (CAct): An instance of ME  issued by a specific \"issuer\" and received by a ", "acronyms": [[105, 109], [25, 27], [127, 129]], "long-forms": [[86, 103], [2, 23]]}, {"text": "Daniele Vannella, 2013). The two system types are WSI (Word Sense Induction) and WSD (Word Sense Disambiguation).", "acronyms": [[50, 53], [81, 84]], "long-forms": [[55, 75], [86, 111]]}, {"text": " 1 Introduction Referring Expression Generation (REG) is a keytask in NLG, and the topic of the REG 2008 Chal-", "acronyms": [[49, 52], [70, 73], [96, 99]], "long-forms": [[16, 47]]}, {"text": "We use three classes of features? Crowd Grades (CG), Force Alignment features (FA) and Natural Language Processing features (NLP).", "acronyms": [[79, 81], [48, 50], [125, 128]], "long-forms": [[53, 68], [34, 46], [87, 114]]}, {"text": "monly used tasks: small vocabulary recognition (TI-digits), read and spontaneous text dictation (WSJ), and goal-oriented spoken dialog (ATIS). The broadcast news task is quite general, covering a", "acronyms": [[136, 140], [48, 57], [97, 100]], "long-forms": []}, {"text": " 1 Introduction Electroencephalography (EEG) and magnetoencephalography (MEG) are similar methods for", "acronyms": [[40, 43], [73, 76]], "long-forms": [[16, 38], [49, 71]]}, {"text": "NER model was shown in Table 4. We use the Peking University (PKU) named entity corpus to train the models.", "acronyms": [[62, 65], [0, 3]], "long-forms": [[43, 60]]}, {"text": "describing each video. We then clustered these verbs using Hierarchical Agglomerative Clustering (HAC) using the res metric from WordNet::Similarity by", "acronyms": [[98, 101]], "long-forms": [[59, 96]]}, {"text": "In this paper we show how the extraction process can be scaled to the complete Wall Street Journal (WSJ) section of the Penn-II treebank, with about 1 mil-", "acronyms": [[100, 103]], "long-forms": [[79, 98]]}, {"text": "and Chinese (ZH). The second section gives the result for the English (EN) test set, PTB Section 23. ", "acronyms": [[71, 73], [13, 15], [85, 88]], "long-forms": [[62, 69], [4, 11]]}, {"text": "concept, BLESS contains several relata,  connected to it through one relation, such as cohyponymy (COORD), hypernymy (HYPER),  meronymy (MERO) or no-relation (RANDOM-N).2 ", "acronyms": [[118, 123]], "long-forms": [[107, 116]]}, {"text": "supervised labels to train our user model.  We used Amazon Mechanical Turk (MTurk) to collect data.", "acronyms": [[76, 81]], "long-forms": [[59, 74]]}, {"text": "Winnows software package.  Maximum Entropy Model (MEM) is  especially suited for integrating evidences from ", "acronyms": [[50, 53]], "long-forms": [[27, 48]]}, {"text": "The model consists of two subtasks of boundary identification(BI) and semantic role classification(SRC). ", "acronyms": [[99, 102], [62, 64]], "long-forms": [[70, 97], [38, 61]]}, {"text": "value (Krippendorf, 2004; Artstein and Poesio, 2008) scores are 60.6 (AUTO), 72.1 (TABLETS) for the sentiment task and 64.1 (AUTO), 79.3 (TABLETS) for", "acronyms": [[70, 74], [125, 129], [138, 145], [83, 90]], "long-forms": []}, {"text": " 260 SentiWordNet(SWN) (Baccianella et al., ", "acronyms": [[18, 21]], "long-forms": [[5, 16]]}, {"text": "cial type of MWEs, for which we are mainly interested in its type, rather than individual lexias, during the annotation: named entities (NE).3 Treatment of NEs together with other MWEs is important, be-", "acronyms": [[137, 139]], "long-forms": [[121, 135]]}, {"text": "2 BP Neural Network  At the moment, there are about more than 30 kinds of  artificial neural network (ANN) in the domain of  research and application.", "acronyms": [[102, 105], [2, 4]], "long-forms": [[75, 100]]}, {"text": "   Figure 2. Tutor's Priming Ratio aggregated by task set (TS = Task Set)     Figure 3.", "acronyms": [[59, 61]], "long-forms": [[64, 72]]}, {"text": "gls: the definition of the verb  They also defined two alternate search protocols: rich hierarchy exploration (RHE) with no  more than six links and shallow hierarchy explo-", "acronyms": [[111, 114]], "long-forms": [[83, 109]]}, {"text": "The metrics Precision (P), Recall (R),  F-score (F) (F=2PR/(P+R)), Recall of OOV  (ROOV) and Recall of IV (RIV) are used to  evaluate the results.", "acronyms": [[107, 110], [83, 87]], "long-forms": [[93, 105], [12, 21], [27, 33], [40, 47], [67, 80]]}, {"text": "NC 91.0 99.1 89.5 92.1 99.7 90.7 Table 2: Attachment score for Java and the lexical feature set, where CO = convertible and NC = nonconvertible dependency trees.", "acronyms": [[103, 105], [124, 126]], "long-forms": [[108, 119], [129, 143]]}, {"text": "~21   Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 10?18, Sofia, Bulgaria, August 9, 2013.", "acronyms": [[71, 78]], "long-forms": [[37, 69]]}, {"text": "the affect projection rules are useful. However, when we use automated coreference (ACoref), recall goes down and precision goes up.", "acronyms": [[84, 90]], "long-forms": [[61, 82]]}, {"text": "The TRIANGLE application  (TRIANGLE) and a new Windows 95  Accessible Graphing Calculator (ACG) both  developed by the SAP uses tone plots to ", "acronyms": [[91, 94], [27, 35], [119, 122]], "long-forms": [[59, 78], [4, 12]]}, {"text": "tion algorithm to chase after undecidable cases. For example, consider prepositional phrases (PPs) with in as the head. These PPs occur frequently, and about half of them", "acronyms": [[94, 97], [126, 129]], "long-forms": [[85, 92]]}, {"text": "namely, the set {? ( D)d |ad = a}, where ad is the author of document d. An alternative approach is LDA-S (LDA with a single document per author), where each author?s documents are concatenated into a single document in a preprocessing step, LDA is run", "acronyms": [[100, 105], [242, 245]], "long-forms": [[107, 124]]}, {"text": "H and T . This set of features is later used by two support vector machine (SVM) classifiers for detecting CLTE separately in both directions (T ?", "acronyms": [[76, 79], [107, 111]], "long-forms": [[52, 74], [81, 106]]}, {"text": "size ? is fixed to 0.0001. We refer to this model as Orthogonal Matrix Factorization (OrMF). ", "acronyms": [[86, 90]], "long-forms": [[53, 84]]}, {"text": "The initial translation outputs from Google Translate (GT) and the results of the targeted paraphrasing translation process (TP) were evaluated according to widely used critera of fluency and adequacy.", "acronyms": [[125, 127]], "long-forms": [[104, 123]]}, {"text": "stable functional definition across languages. These categories include NOUN, VERB, ADJ = adjective, ADV = adverb, NUM = number, ADP = adposition,", "acronyms": [[84, 87], [101, 104], [115, 118], [129, 132]], "long-forms": [[90, 99], [107, 113], [121, 127], [135, 145]]}, {"text": "degree of semantic equivalence between a pair of texts. Natural Language Processing (NLP) applications such as Question Answering (Lin and", "acronyms": [[85, 88]], "long-forms": [[56, 83]]}, {"text": "we sample polysemous words from wide-domain {French,Chinese}-English corpora, and use Amazon?s Mechanical Turk (MTurk) to annotate word sense on the English side.", "acronyms": [[112, 117]], "long-forms": [[95, 110]]}, {"text": "Discourse Relations (DR) 48.04 Entity Grid (EG) 67.74 Lexical Cohesion (LC) 61.63 Document Length 69.40", "acronyms": [[72, 74], [21, 23], [44, 46]], "long-forms": [[54, 70], [0, 19], [31, 42]]}, {"text": "Free word associations are the words people spontaneously come up with in re-sponse to a stimulus word. Such informa-tion has been collected from test persons and stored in databases.  A well known example is the Edinburgh Associative Thesaurus (EAT). We will show in this paper that this kind of knowledge can be acquired automatically from corpora, en-abling the computer to produce similar associative responses as people do.", "acronyms": [[246, 249]], "long-forms": [[213, 244]]}, {"text": "A Named Entity Labeler for German: Exploiting Wikipedia and Distributional Clusters. In Proceedings of the Conference on Language Resources and Evaluation (LREC), pages 552?556, La Valletta, Malta.", "acronyms": [[156, 160]], "long-forms": [[121, 139]]}, {"text": "The data are packaged as the payload of incremental units (IU) which are passed between modules. The IUs themselves are also interconnected via so-called same level links (SLL) and groundedin links (GRIN), the former allowing the linking of IUs as a growing sequence, the latter allowing that", "acronyms": [[172, 175], [59, 61], [101, 104], [199, 203], [241, 244]], "long-forms": [[154, 170], [40, 57], [181, 197]]}, {"text": "Topic: Short, usually controversial statement that defines the subject of interest.   Context Dependent Claim (CDC): General, and concise statement, that directly supports or contests  the given Topic.", "acronyms": [[111, 114]], "long-forms": [[86, 109]]}, {"text": "Center who will send the artillery fire when given the appropriate information.  In line 1, G19?s utterance is interpreted as a Warning Order - Method of Fire (WO-MOF), describing the kind of artillery fire requested, whose value is ?", "acronyms": [[160, 166]], "long-forms": [[128, 158]]}, {"text": "them as \"LIG-equivalent formalisms\". LIG is a vari-  ant of index grammar (IG) (Aho, 1968). Like CFG, IG ", "acronyms": [[75, 77], [37, 40], [9, 12], [97, 100], [102, 104]], "long-forms": [[60, 73]]}, {"text": "Using the observation that LL is correlated with MRR on the same data set, we expect that optimizing LL on a development set (LLdev) will also improve MRR on an evaluation set (MRReval).", "acronyms": [[126, 131], [27, 29], [49, 52], [151, 154], [177, 184]], "long-forms": [[101, 120]]}, {"text": "2.4.1 English Gigaword We created large-scale n-gram language models using English Gigaword Second Edition6 (EGW). ", "acronyms": [[109, 112]], "long-forms": [[75, 91]]}, {"text": "The next most confident 600 tuples (i.e., those numbered 1201?1800) were used to build a development set (DEV1) and the next most confident 600 (those numbered 1801?2400) were used", "acronyms": [[106, 110]], "long-forms": [[89, 104]]}, {"text": "SVO = Subject-Verb-Object GE = General Event PE = Predefined Event Grammar Module", "acronyms": [[45, 47], [0, 3], [26, 28]], "long-forms": [[50, 66], [6, 25], [31, 44]]}, {"text": "proach to automatically recognize predicate  heads of Chinese sentences based on a preprocessing step for maximal noun phrases 1(MNPs). ", "acronyms": [[129, 133]], "long-forms": [[106, 126]]}, {"text": " NPHIL = Stray NP: Volume I: Syntax,  SUBJ = Subject: H__~e reads., ", "acronyms": [[38, 42]], "long-forms": [[45, 52]]}, {"text": "Beth Bryson). In addition, Robert Moore and Eric Jack-  son (SRI) provided critical help in designing and debug-  ging the code to support the minimal/maximal nswer ", "acronyms": [[61, 64]], "long-forms": []}, {"text": " In addition, NE alignment can be very useful for  Statistical Machine Translation (SMT) and CrossLanguage Information Retrieval (CLIR).", "acronyms": [[84, 87], [14, 16], [130, 134]], "long-forms": [[51, 82], [93, 128]]}, {"text": "4 Experiments In this section, we evaluate performance of different methods on the Relation Schema Induction (RSI) task.", "acronyms": [[110, 113]], "long-forms": [[83, 108]]}, {"text": "EOPAS (PARADISEC tool) for text interlinear text and media analysis  2. NLTK (Natural Language Toolkit) for text analytics with linguistic data (Bird, Klein, & Loper, 2009)  3.", "acronyms": [[72, 76], [0, 5], [7, 16]], "long-forms": [[78, 102]]}, {"text": "New in three aspects. First, the basic units of their model are elementary discourse units (EDUs) from Rhetorical Structure Theory (RST) (Mann", "acronyms": [[92, 96], [132, 135]], "long-forms": [[64, 90], [103, 130]]}, {"text": "step of segmentation is presented in Section 3 with two variants: stochastic word alignment (GIZA) and integer linear programming (ILP). Then evaluations", "acronyms": [[131, 134], [93, 97]], "long-forms": [[103, 129]]}, {"text": "726  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 657?669, October 25-29, 2014, Doha, Qatar.", "acronyms": [[93, 98]], "long-forms": [[43, 91]]}, {"text": "corpora (section 2.2).  The workflow for named entity (NE) and  terminology extraction and mapping from ", "acronyms": [[55, 57]], "long-forms": [[41, 53]]}, {"text": "This work investigated four well-known specifications created by four different organizations: Academia Sinica (AS), City University of Hong Kong (CITYU), Microsoft Research (Beijing)", "acronyms": [[112, 114], [147, 152]], "long-forms": [[95, 110], [117, 132]]}, {"text": "Tables 79 show, for each emotion classification, the mean accuracy (%correct) and standard error (SE) for our 10 feature sets.", "acronyms": [[98, 100]], "long-forms": [[82, 96]]}, {"text": "CTexT. 2011. Afrikaans WordNet. Centre for Text Technology (CTexT), North-West University, Potchefstroom, South Africa.", "acronyms": [[60, 65], [0, 5]], "long-forms": [[32, 58]]}, {"text": "capability [and t o  go] interregional without involving the private sector.  The General Services Administratioq (GSA) l a s t  month amended its M v a o y  Gu--&de-  Zines adding privacy a d  security considerations for use i n  ADP o r  tqlecom- ", "acronyms": [[115, 118], [231, 234]], "long-forms": [[82, 113]]}, {"text": "The big blue door.?  In this case, the GrM asks  the Response Planner (RP) to provide an elaboration for the current UU; the RP generates this ", "acronyms": [[71, 73], [39, 42], [117, 119], [125, 127]], "long-forms": [[53, 69]]}, {"text": "We use the following label set: S-O (not in maze); S-M (single word maze); B-M (beginning of multi-word 72", "acronyms": [[75, 78], [32, 35], [51, 54]], "long-forms": [[80, 98], [56, 72]]}, {"text": " c?2015 Association for Computational Linguistics Building a Scientific Concept Hierarchy Database (SCHBASE) Eytan Adar", "acronyms": [[100, 107]], "long-forms": [[61, 98]]}, {"text": "and answer sentences that emphasizes three types  of metadata:   (i) Main Verbs (MVerb), identified by the link  parser (Sleator and Temperley 1993);  ", "acronyms": [[81, 86]], "long-forms": [[69, 79]]}, {"text": " In Proceedings of the 16th International Conference on Computational Linguistics (COLING), volume I, pages 466?471.", "acronyms": [[83, 89]], "long-forms": [[56, 81]]}, {"text": "Sellers algorithms  2.1 Algorithm Principle  The Wagner & Fischer (W&F) dynamic  programming algorithm in Figure 3 gives tile ", "acronyms": [[67, 70]], "long-forms": [[49, 65]]}, {"text": "of which are limited in scope. We here restrict inferables to the particular subset de-  fined by Hahn, Markert, and Strube (1996), which we call functional anaphora (FA). ", "acronyms": [[167, 169]], "long-forms": [[146, 165]]}, {"text": "and the neural language model (NLM), for each phrase combination: adjective noun (Adj-N), nounnoun (N-N) and verb object (V-Obj). For each", "acronyms": [[100, 103], [122, 127], [31, 34], [82, 87]], "long-forms": [[90, 98], [109, 120], [8, 29], [66, 80]]}, {"text": "The most common approach to document classification is to fit a linear model (e.g., Logistic Regression) over bag of words (BoW) features. To", "acronyms": [[124, 127]], "long-forms": [[110, 122]]}, {"text": "Re-moving PHI from these free text portions requires application of techniques from natural language processing that are capable of identifying phrases of specific types based on the lexical content (the words that make up the phrases) and the surround-ing words.  3 Current Methods and Metrics Fortunately, the problem of identifying types of information in free text is a well-studied problem in the natural language processing community. We can leverage several decades of research on infor-mation extraction and the named entity identifica-tion problem in particular, including multiple community evaluations such as the Message Un-derstanding Conferences (MUC) (Grishman & Sundheim, 1996) and the subsequent Automated Content Extraction (ACE) evaluations1 ? both fo-cused on extraction from newswire -- as well as evaluations of biomedical entity extraction from the published literature e.g., in the BioCreative evaluations (Krallinger, et al, 2008).", "acronyms": [[743, 746]], "long-forms": [[713, 741]]}, {"text": "method of ADN. ADN is constructed by  Restricted Boltzmann Machines (RBM)  with unsupervised learning using labeled ", "acronyms": [[69, 72], [10, 13], [15, 18]], "long-forms": [[38, 67]]}, {"text": "Verb classification performance (precision, recall, and F for MS are macro-averaged). Global accuracy supplemented by 95% binomial confidence intervals (CI). ", "acronyms": [[153, 155], [62, 64]], "long-forms": [[131, 151]]}, {"text": "The subword-based tagging was implemented using the maximum entropy (MaxEnt) and the conditional random fields (CRF)", "acronyms": [[69, 75], [112, 115]], "long-forms": [[52, 67], [85, 110]]}, {"text": " 5.2 Named Entities As standard named entity recognition (NER) systems do not capture categories that are relevant to", "acronyms": [[58, 61]], "long-forms": [[32, 56]]}, {"text": "take et al (2005)) for the representation of meaning.  LXGram is developed in the Linguistic Knowledge Builder (LKB) system (Copestake, 2002), a development environment for constraint-based grammars.", "acronyms": [[112, 115], [55, 61]], "long-forms": [[82, 110]]}, {"text": " A stack based extraction Algorithm 1 was designed to extract a context free grammar (CFG) from the URDU.KON-TB treebank.", "acronyms": [[86, 89], [100, 111]], "long-forms": [[64, 84]]}, {"text": "chanical Turk service. Two classifiers, Na??ve Bayes (NB) and a support vector machine (SVM), were applied on the tokenized and stemmed state-", "acronyms": [[88, 91], [54, 56]], "long-forms": [[64, 86], [40, 52]]}, {"text": "1 Introduction Kernel methods are considered the most effective techniques for various relation extraction (RE) tasks on both general (e.g. newspaper text) and", "acronyms": [[108, 110]], "long-forms": [[87, 106]]}, {"text": "Table 2: The evaluation for each combination of agents. LB = ListenerBot; DB = DialogBot. ", "acronyms": [[56, 58], [74, 76]], "long-forms": [[61, 72], [79, 88]]}, {"text": "ALL X X X 0.614 0.186 0.706 0314 0.509 Table 2: Pearson?s ? for each feature set (FSet), as well as combinations of feature sets and adap-", "acronyms": [[82, 86]], "long-forms": [[69, 80]]}, {"text": "3 CLaC Methodology Preprocessing consists of tokenizing, lemmatizing, sentence splitting, and part of speech (POS) tagging. ", "acronyms": [[110, 113], [2, 6]], "long-forms": [[94, 108]]}, {"text": "rent participation week (Curr) and the second using data from the beginning participation week till the current week (TCurr). For the second setup,", "acronyms": [[118, 123]], "long-forms": [[100, 111]]}, {"text": "Figure 8: Alternative English lexical entry for *WORK-  FUNCIONAR  (GENDER and NUMBER) count/mass (COUNT) and  a trinary distinction of ANIMACY (human, animal, ", "acronyms": [[79, 85], [56, 65], [99, 104], [136, 143], [68, 74]], "long-forms": [[87, 92]]}, {"text": "974   Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 875?879, October 25-29, 2014, Doha, Qatar.", "acronyms": [[94, 99]], "long-forms": [[44, 92]]}, {"text": " School of Information Science Japan Advanced Institute of Science and Technology (JAIST), Japan nthnhung@jaist.ac.jp", "acronyms": [[83, 88]], "long-forms": [[31, 81]]}, {"text": "2.3.3 Name List Generated using Double Propagation We implement the Double Propagation (DP) algorithm described in Qiu et al. (", "acronyms": [[88, 90]], "long-forms": [[68, 86]]}, {"text": "Inference rules for predicates have been identified as an important component in semantic applications, such as Question Answering (QA) (Ravichandran and Hovy, 2002) and Information", "acronyms": [[132, 134]], "long-forms": [[112, 130]]}, {"text": "5.1 Alternative Models To test LUX?s representations, we built a brute-force histogram model (HM) that discretizes HSV space and tracks frequency distributions of labels directly", "acronyms": [[94, 96], [31, 36], [115, 118]], "long-forms": [[77, 92]]}, {"text": "CoTrain vs. LEX(CN) 6.09E-29 3.72E-21 1.61E-24 CoTrain vs. LEX(EN) 0.0018 0.0276 0.00329 CoTrain vs. SVM(CN) 1.26E-13 6.45E-10 2.7E-14 CoTrain vs. SVM(EN) 2.15E-18 1.1E-17 3.46E-13", "acronyms": [[105, 107]], "long-forms": [[89, 96]]}, {"text": " FERGUS was originally trained on the Penn Tree Bank corpus consisting of Wall Street Journal text (WSJ). The results on", "acronyms": [[100, 103], [1, 7]], "long-forms": [[74, 93]]}, {"text": "has been discussed extensively in various formulations in the NLP literature, notably in PP attachment, semantic role labeling (SRL) and subcategorization acquisition.", "acronyms": [[128, 131], [62, 65], [89, 91]], "long-forms": [[104, 126]]}, {"text": "3.2 Graph-based Approaches Laparra et al(2010) utilize the SSI-Dijkstra+ algorithm to align FN lexical units (LUs) with WN synsets.", "acronyms": [[110, 113], [59, 72], [92, 94], [120, 122]], "long-forms": [[95, 108]]}, {"text": "tities e1, e2, ei,.., eE on translated English documents through aforementioned step, meanwhile, we consider all noun phrases(NP) in original Chinese documents and generate mention candidates", "acronyms": [[126, 128]], "long-forms": [[113, 124]]}, {"text": "veloped for machine learning and data mining, to  determine the data classification performance of  support vector machine (SVM) learning on the                                                   ", "acronyms": [[124, 127]], "long-forms": [[100, 122]]}, {"text": "Table 4: Evaluation results. Abbreviations: TVN (Tone & Vowel Normalization); N-LM (N-order Language Modelling); DS (Dataset); PK (Prior Knowledge); WC (Weighting-based Corrector). ", "acronyms": [[113, 115], [127, 129], [44, 47], [78, 82], [149, 151]], "long-forms": [[117, 124], [131, 146], [84, 110], [153, 178]]}, {"text": "argument facet inducer. We introduce a new task of ARGUMENT FACET SIMILARITY (AFS). We discuss", "acronyms": [[78, 81]], "long-forms": [[51, 76]]}, {"text": "There were four data sources used in the  training set: the Wall Street Journal, Associated  Press, Federal Register (FR), and Department of  215 ", "acronyms": [[118, 120]], "long-forms": [[100, 116]]}, {"text": "Recall all the methods rely on the wrapped classifier. We select two classic but very different classifiers: the Maximum Entropy model (MaxEnt) and the Decision Tree C4.5 (Tree). We implement these", "acronyms": [[136, 142]], "long-forms": [[113, 128]]}, {"text": "insertion operator for combining subtrees as in tree adjoining grammars (TAG) (Joshi, 1985) or tree insertion grammars (TIG) (Schabes and Waters, 1995).", "acronyms": [[120, 123], [73, 76]], "long-forms": [[95, 118], [48, 70]]}, {"text": "BOEING CO(BA) OTC  UTL USA  UTL CORP(UTLC)  BOEING'S ARGOSYSTEMS SUBSIDIARY TO MAKE TENDER OFFER FOR ALL UTL CORE SHARES ", "acronyms": [[37, 41], [105, 108], [14, 17], [19, 22], [23, 26], [7, 13]], "long-forms": [[28, 36]]}, {"text": "2008).  The semantic role labeler (SRL) consists of a pipeline of independent, local classifiers that iden-", "acronyms": [[35, 38]], "long-forms": [[12, 33]]}, {"text": "In order to test the classification rules for the extraction of part?whole relations, we selected two different text collections: the LA Times news articles from TREC 9 and the Wall Street Journal (WSJ) articles from Treebank2.10 From each collection we randomly selected 10,000 sentences that formed two distinct test corpora.", "acronyms": [[198, 201], [162, 166], [134, 136]], "long-forms": [[177, 196]]}, {"text": "can develop after exposure to a terrifying event.  Q-based Union PTSD (posttraumatic stress disorder) is a psychological disorder caused by a mental trauma (also called psychotrauma) that can develop after exposure to a terrifying event.", "acronyms": [[65, 69]], "long-forms": [[71, 100]]}, {"text": " Conf. on Language Resources and Evaluation (LREC), pages 147?152, Las Palmas, Spain, May.", "acronyms": [[45, 49]], "long-forms": [[10, 28]]}, {"text": "The current state of the art within the comment summarisation field is to cluster comments using Latent Dirichlet Allocation (LDA) topic modelling (Khabiri et al, 2011; Ma et al, 2012;", "acronyms": [[126, 129]], "long-forms": [[97, 124]]}, {"text": "End point SIP user agents: These are the SIP end points that exchange SIP signaling messages with the SIP Application server (AS) for call control.", "acronyms": [[126, 128], [41, 44], [70, 73], [102, 105]], "long-forms": [[106, 124], [10, 13]]}, {"text": "Concerning the second objective, we will devise our new measure, known as the Odds of Unithood (OU), which are derived using Bayes Theorem and founded on a few elementary probabil-", "acronyms": [[96, 98]], "long-forms": [[83, 94]]}, {"text": "that symbol?). The categories are:  1) Words as Words (WW): Within the context of  the sentence, the candidate phrase is used to ", "acronyms": [[55, 57]], "long-forms": [[39, 53]]}, {"text": "A List of POS-tags ADJ (adjectives), ADV (adverbs), CJ (conjunctions), CL (clitics), CN (common nouns), DA (definite articles), DEM (demonstratives),", "acronyms": [[71, 73], [85, 87], [10, 13], [19, 22], [37, 40], [52, 54], [104, 106], [128, 131]], "long-forms": [[75, 82], [89, 101], [24, 34], [42, 49], [56, 68], [108, 125], [133, 147]]}, {"text": "of Machine Translation and present an implemetation of a morphological analyser for Amharic using Xerox Finite State Tools (XFST). The different", "acronyms": [[124, 128]], "long-forms": [[98, 122]]}, {"text": "approach.  The Minimum Token Margin (MTM) strategy is a variant of the margin sampling strategy introduced", "acronyms": [[37, 40]], "long-forms": [[15, 35]]}, {"text": "This method is much simpler than the ILP method, while it can achieve comparable result on the CLANG (Coach Language) and Query corpus. ", "acronyms": [[95, 100], [37, 40]], "long-forms": [[102, 116]]}, {"text": "systematic way.  The MIME (Managing Information in Medical Emergencies)1 project is developing technology to", "acronyms": [[21, 25]], "long-forms": [[27, 70]]}, {"text": "distance (EDIT), which is the Levenshtein distance between generated word string and human reference output, and string accuracy (S-A), which is the proportion of times the word string was identical to the", "acronyms": [[130, 133], [10, 14]], "long-forms": [[113, 128]]}, {"text": "halcea and Nataste (2012)). In our framework, we train a Neural Language Model (NLM) on yearly corpora to obtain word vectors for each year", "acronyms": [[80, 83]], "long-forms": [[57, 78]]}, {"text": "sampling the outputs at random locations.  INTENSITY: HOG (histogram of gradients) (Dalal and Triggs, 2005) describes the direction", "acronyms": [[54, 57]], "long-forms": [[59, 81]]}, {"text": "Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), page 89, Beijing, August 2010 Multi-Word Expressions as Discourse Relation Markers (DRMs) Aravind K. Joshi", "acronyms": [[166, 170], [71, 74]], "long-forms": [[138, 164], [19, 39], [112, 133]]}, {"text": "Instead to measure topic coherence we follow (Newman et al, 2009) to compute the Pointwise Mutual Information (PMI) of topic words w.r.t wikipedia articles.", "acronyms": [[111, 114]], "long-forms": [[81, 109]]}, {"text": "the reference than the rest. Considering this, we use a Longest Common Subsequence(LCS) based criterion to calculate s(x, y).", "acronyms": [[83, 86]], "long-forms": [[56, 81]]}, {"text": "2 As a matter of fact, Figure 1 only shows 8 columns, although  the CoNLL-X format includes two additional columns for the  projective head (PHEAD) and projective dependency relation  (PDEPREL), which have not been used in our work.", "acronyms": [[141, 146], [68, 75], [185, 192]], "long-forms": [[124, 139], [152, 182]]}, {"text": " Conf. on Language Resources and Evaluation (LREC). ", "acronyms": [[45, 49]], "long-forms": [[10, 28]]}, {"text": "that together with the BOW it yields higher accuracy. Their results show a significant 1 The reciprocal rank (RR) for a question is 1 divided by the rank ordinal of the highest ranked relevant answer.", "acronyms": [[110, 112], [23, 26]], "long-forms": [[93, 108]]}, {"text": "cal markedness constraints directly from the distribution of input-output mappings in an Optimality Theory (OT) setting. The", "acronyms": [[108, 110]], "long-forms": [[89, 106]]}, {"text": "creation (CR)  emotion (EM)  motion (MO)  perception (PC) ", "acronyms": [[37, 39], [10, 12], [24, 26], [54, 56]], "long-forms": [[29, 35], [0, 8], [15, 22], [42, 52]]}, {"text": "Using either method of uncertainty sampling,  the computational cost of picking an example from  T candidates is: O(TD) where D is the number of  model parameters.", "acronyms": [[116, 118]], "long-forms": [[97, 109]]}, {"text": "ply it on substrings of names. In the English to Russian task, we report ACC (Accuracy in top-1) of 0.545,  Mean F-score of 0.917, and MRR (Mean Reciprocal  ", "acronyms": [[73, 76], [135, 138]], "long-forms": [[78, 86], [140, 155]]}, {"text": "class. Among these are: L (Larsen, 1999), D (Van Dongen, 2000), misclassification index (MI) (Zeng et al, 2002), H (Meila, 2001), clustering F-measure", "acronyms": [[89, 91]], "long-forms": [[64, 87], [27, 33]]}, {"text": "ferent levels. For each text pair on four cross levels, i.e., Paragraph to Sentence (P-S), Sentence to Phrase (S-Ph), Phrase to Word (Ph-W) and Word", "acronyms": [[85, 88], [111, 115], [134, 138]], "long-forms": [[62, 83], [91, 109], [118, 132]]}, {"text": "any parser; the third requirement is not easily met  in all languages, but even in those languages where  nonrestrictives are not easily identifiable, (II)  works reasonable well.", "acronyms": [[152, 154]], "long-forms": [[137, 149]]}, {"text": "(reduced dimensions). The general idea behind the  Pseudo Relevance Feedback (PRF) (Croft &  Harper, 1979) or its more recent variation called ", "acronyms": [[78, 81]], "long-forms": [[51, 76]]}, {"text": " For this reason, NIST assessors not only marked  the segments shared between system units (SU)  and model units (MU), they also indicated the ", "acronyms": [[92, 94], [18, 22], [114, 116]], "long-forms": [[78, 90], [101, 112]]}, {"text": "In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96). ", "acronyms": [[82, 91]], "long-forms": [[55, 80]]}, {"text": "DUC 2007. In Proceedings of the Seventh Document Understanding Conference (DUC), Rochester, NY.", "acronyms": [[75, 78], [0, 3], [92, 94]], "long-forms": [[40, 73]]}, {"text": "guages: British sign language (BSL), Danish (DSL), French Belgian (FBSL), Flemish (FSL), Greek (GSL), and Dutch (NGT). The data for the", "acronyms": [[96, 99], [31, 34], [45, 48], [67, 71], [83, 86], [113, 116]], "long-forms": [[89, 94], [8, 29], [37, 43], [51, 65], [74, 81], [106, 111]]}, {"text": "The s t ruc ture  11ke a combinat ion of  a verb (V) and  an adverb ia l  par t tc le  (ADVPART) tn th ts  sequence  wtth or w i thout  a pronoun (PRON) tn between tn  Engltsh t swr t t ten  as fo l lows .", "acronyms": [[147, 151], [88, 95]], "long-forms": [[138, 145], [44, 48], [61, 85]]}, {"text": "mensions. The counts were then transformed into Local Mutual Information (LMI) scores, an association measure that closely approximates the com-", "acronyms": [[74, 77]], "long-forms": [[48, 72]]}, {"text": "PROBING QUESTION (QP) Do you think that looks correct? 4.99% 4.76% 0.731 QUESTION PROMPT (QQ) Any questions? 2.49% 2.24% 0.978", "acronyms": [[18, 20], [90, 92]], "long-forms": [[73, 88], [0, 16]]}, {"text": "Figure 4: Change of global network properties with incremental addition of edges to the directed network of news genre. SCC = Strongly Connected Component, CC = Connected Component. By ?", "acronyms": [[120, 123], [156, 158]], "long-forms": [[126, 154], [161, 180]]}, {"text": "tion.   In our decoders, language model(LM) is used  for translating edus in Formula(5),(6),(7),(8), but ", "acronyms": [[40, 42]], "long-forms": [[25, 38]]}, {"text": "FF-AUTO-NONE Fullform Auto None FF-DEFAULT-GRAM Fullform Default Auto (GRAM) FF-AUTO-GRAM Fullform Auto Auto (GRAM) FF-DEFAULT-SAO* Fullform Default Auto (SAO)", "acronyms": [[80, 84], [155, 158], [110, 114], [71, 75], [32, 47], [0, 12], [116, 130]], "long-forms": [[85, 98]]}, {"text": " ? Domain communicat ion knowledge (DCK). This is knowledge about how to communi- ", "acronyms": [[36, 39]], "long-forms": [[3, 34]]}, {"text": "(O?Shaughnessy, 2000), lip aperture (LA) is the normalized Euclidean distance between the lips, and lip protrusion (LP) is the normalized 2nd principal component of the midpoint between the lips.", "acronyms": [[116, 118], [36, 39]], "long-forms": [[100, 114], [23, 35]]}, {"text": "sentence pairs can be automatically extracted from comparable corpora, and used to improve the performance of machine translation (MT) systems. ", "acronyms": [[131, 133]], "long-forms": [[110, 129]]}, {"text": "In this paper, I present a lexical representation  of the light  verb  ha  'do'  used in two types of  Korean light verb constructions (LVCs). These ", "acronyms": [[136, 140]], "long-forms": [[110, 134]]}, {"text": " 4 Corpus description The GRN corpus is a set of 201 sentences selected from PubMed abstracts, which are  mainly about the sporulation phenomenon in Bacillus subtilis. This corpus is an extended version of the LLL and BI (BioNLP-ST?11) corpora. The additional sentences ensure a better coverage of the description of the sporulation.", "acronyms": [[218, 220], [210, 213], [26, 29], [77, 83]], "long-forms": [[222, 228]]}, {"text": "  *COMPLEXITY: avoid semantic complexity  BC (BE CONCRETE): have a concrete meaning   ", "acronyms": [[42, 44]], "long-forms": [[46, 57]]}, {"text": "2 GT  and  Move-c~  The central operations of the Minimalist Program  are Generalized Transformation (GT) and Move-  ~. GT is a structure-building operation that builds ", "acronyms": [[102, 104], [2, 4], [120, 122]], "long-forms": [[74, 100]]}, {"text": "The classification step currently supports three machine learning algorithms from the Python scikit-learn4 package: Na??ve Bayes (NB), Maximum Entropy (MaxEnt), and Support Vector", "acronyms": [[130, 132], [152, 158]], "long-forms": [[116, 128], [135, 150]]}, {"text": "(Pierce and Cardie, 2001). A related idea is to use Expectation Maximization (EM) to impute labels.", "acronyms": [[78, 80]], "long-forms": [[52, 76]]}, {"text": "Intersection (I), Union (U), (Koehn et al, 2003) Grow Diagonal Final (GDF), (Och and Ney, 2003) H refined heuristics and Power Mean (PMn) alignment sets where n = 5.", "acronyms": [[133, 136], [70, 73]], "long-forms": [[121, 131], [0, 12], [18, 23], [49, 68]]}, {"text": "every lost arc translates to a set of lost parts, we can avoid repeating computations by storing the partial loss of every arc in a data structure (DS): e ?? ", "acronyms": [[148, 150]], "long-forms": [[132, 146]]}, {"text": "on the SMTnews dataset, with an increase in the Pearson correlation of over 0.10. MSRpar (MPar) is the only dataset in which TLsim (S?aric?", "acronyms": [[90, 94], [125, 130]], "long-forms": [[82, 88], [7, 10]]}, {"text": " ? System integration, through SGML (the Standard Generalized Markup Language), both at the leve l of meaning analysis and at the overall application level .", "acronyms": [[31, 35]], "long-forms": [[41, 77]]}, {"text": "We show that hierarchies of this type can be  automatical!y constructed, by using the semantic ategory codes and the subject codes of the  Longman Dictionary of Contemporary English (LDOCE) to disambiguate the genus terms in  noun definitkms.", "acronyms": [[183, 188]], "long-forms": [[139, 181]]}, {"text": " OOV Handling Techniques and their Combination We compare our baseline system (BASELINE) to each of our basic techniques and their full combi-", "acronyms": [[79, 87], [1, 4]], "long-forms": [[62, 77]]}, {"text": "augmented by a set of PRIDES-specific Common  Gateway Interfaces (CGIs), communicates with the  client via Hypertext Transport Protocol (HTTP). A ", "acronyms": [[137, 141], [22, 37], [66, 70]], "long-forms": [[107, 135], [38, 64]]}, {"text": " In Proceedings of Natural Language Processing in Biomedicine (BioNLP) NAACL 2009 Workshop, pages 1?9.", "acronyms": [[63, 69], [71, 76]], "long-forms": [[50, 61]]}, {"text": "e-maih ide@cs,  vassar ,  edu   Abstract. The Text Encoding Initiative (TEl) is an  international project established in 1988 to develop ", "acronyms": [[72, 75]], "long-forms": [[42, 70]]}, {"text": "Frame representat ion ( for  mapping 4):  \\[agent/an\\] (i/PRP)  5PO$ abbreviations: PRP=personal pro-  noun, AUX=auxiliary verb, VB=main verb (non-inflected), ", "acronyms": [[84, 87], [109, 112], [129, 131]], "long-forms": [[88, 101], [113, 122], [137, 141]]}, {"text": "tiguous correspondence. The Structure Reordering Rules (SRR) and Discontiguous Phrase Rules (DPR) mentioned by (Zhang et al, 2008a) can be regarded", "acronyms": [[93, 96], [56, 59]], "long-forms": [[65, 91], [28, 54]]}, {"text": " 1 Introduction Massive Open Online Courses (MOOCs), run by organizations such as Coursera, have been among", "acronyms": [[45, 50]], "long-forms": [[16, 43]]}, {"text": "Sparse Lexicalised features and Topic Adaptation for SMT. In Proceedings of the seventh International Workshop on Spoken Language Translation (IWSLT), pages 268?275.", "acronyms": [[143, 148], [53, 56]], "long-forms": [[88, 141]]}, {"text": "We use the same evaluation metrics as in (McDonald et al, 2005). Dependency accuracy (DA) is the proportion of non-root words that are assigned the", "acronyms": [[86, 88]], "long-forms": [[65, 84]]}, {"text": " 4KEY: E1S=singular first person ergative, INC=incompletive, PART=particle, PREP=preposition, PRON=pronoun, NEG=negation, 37", "acronyms": [[61, 65], [76, 80], [94, 98], [108, 111], [7, 10], [43, 46]], "long-forms": [[66, 74], [81, 92], [99, 106], [112, 120], [47, 59], [11, 41]]}, {"text": " Its data-driven approach learns a sub-word lexicon from a training corpus of words by using a Minimum Description Length (MDL) algorithm (Creutz et Lagus, 2005). It has been used with", "acronyms": [[123, 126]], "long-forms": [[95, 121]]}, {"text": " 3.4 MAP Inference Maximum a posteriori (MAP) inference seeks the solution to", "acronyms": [[41, 44], [5, 8]], "long-forms": [[19, 39]]}, {"text": "data. In International Conference on Machine Learning (ICML). ", "acronyms": [[55, 59]], "long-forms": [[9, 53]]}, {"text": "X:?  TypeChanging (TCR) X:? ? Y:?(?)", "acronyms": [[19, 22]], "long-forms": [[5, 17]]}, {"text": "tence is assigned a Sense_Weight_Score (SWS)  for each emotion tag which is calculated by dividing the total Sense_Tag_Weight (STW)of all  occurrences of an emotion tag in the sentence by ", "acronyms": [[127, 130], [40, 43]], "long-forms": [[109, 125], [20, 38]]}, {"text": "knowledge about the structuf.e of the world into account.  - The Data Base Language ( DBL ) , which contains conatants that correspond  to data base primitives . (", "acronyms": [[86, 89]], "long-forms": [[65, 83]]}, {"text": "Semantic Computing Group Cognitive Interaction Technology ? Center of Excellence (CITEC), Bielefeld University, Germany", "acronyms": [[82, 87]], "long-forms": [[60, 80]]}, {"text": "Abstract We present the first provably optimal polynomial time dynamic programming (DP) algorithm for best-first shift-reduce parsing, which", "acronyms": [[84, 86]], "long-forms": [[63, 82]]}, {"text": "Finally, some Wikipages are redirections to other pages, e.g. SODA (SODIUM CARBONATE) redirects to SODIUM CARBONATE.", "acronyms": [[62, 66]], "long-forms": [[68, 84], [99, 115]]}, {"text": "guistics to guide the solution of locality of arguments. In particular, Maximal Projection (MP) which dominates", "acronyms": [[92, 94]], "long-forms": [[72, 90]]}, {"text": "  The ungrammatical distracter, e.g., are in Figure 1,  has a different part of speech (POS) than the correct answer germs.", "acronyms": [[88, 91]], "long-forms": [[72, 86]]}, {"text": " 3.2 Query by Committee  Query by Committee (QBC) was introduced by  Seung, Opper, and Sompolinsky (1992).", "acronyms": [[45, 48]], "long-forms": [[25, 43]]}, {"text": "is also significant that this model?s paraphraser can be employed not only for MT but also for most natural language processing (NLP) applications.", "acronyms": [[129, 132], [79, 81]], "long-forms": [[100, 127]]}, {"text": "for PTB III data evaluated by label accuracy system test additional resources JESS-CM (CRF/HMM) 95.15 1G-word unlabeled data 94.67 15M-word unlabeled data", "acronyms": [[87, 94], [4, 7], [78, 85], [102, 109]], "long-forms": []}, {"text": "ing different methods: The methods respectively without prediction(NP), with prediction(P),  with prediction and feedback(PF) only using term  frequency (TM), and with prediction and feed-", "acronyms": [[122, 124], [67, 69], [154, 156]], "long-forms": [[98, 120], [77, 87], [137, 152]]}, {"text": "dictionary (viz. /hu:pana-taNa/ and /Fi:tiki-RaNa/), I also searched the Ma?ori Broadcast Corpus (MBC) for words ending as if they had gerundial suffixes", "acronyms": [[98, 101]], "long-forms": [[73, 96]]}, {"text": "advP Adverb phrase(ADVP)  punct Punctuation(,)  adjP Adjective phrase(ADJP)  OP  advP, np and/or pp ", "acronyms": [[70, 74], [19, 23], [48, 52], [77, 79], [81, 85], [97, 99], [87, 89]], "long-forms": [[53, 68], [5, 18]]}, {"text": "procedures\" (ReP). The RePs work on a memory structure which is adequate for the  representation of knowledge about objects, the \"referential net\" (RefN) 4*. A RefN ", "acronyms": [[148, 152], [13, 16], [23, 27], [160, 164]], "long-forms": [[130, 145]]}, {"text": "Rule-Based Machine Translation(MT)(Hutchins and Somers, 1992) requires large-scale knowledge to analyze both source language(SL) sentences and target language(TL) sentences.", "acronyms": [[125, 127], [31, 33], [159, 161]], "long-forms": [[109, 123], [11, 30], [143, 158]]}, {"text": "easily inspectable. The generalizing ability of the evolutionary reinforcement learning (RL) algorithm, XCS, can dramatically reduce the size of the opti-", "acronyms": [[89, 91], [104, 107]], "long-forms": [[65, 87]]}, {"text": " First, the matching score of the matching two nodes, NMS (Node Match Score) is calculated with their node scores, NS1 and NS2,", "acronyms": [[54, 57], [115, 118], [123, 126]], "long-forms": [[59, 75]]}, {"text": "Some researchers rely on generic planners (e.g., (Dale, 1988)) for this task, while others use plans based on Rhetorical Structure Theory (RST) (e.g., (Bouayad-Aga et al, 2000; Moore and Paris,", "acronyms": [[139, 142]], "long-forms": [[110, 137]]}, {"text": "Computing Center ,  Academy of Sc iences ,  Hosoow, USSR  1.  Personal  Computer Systems (POS) represent  nowadays a  s ign i f teaut  t rend  in  the professiona~, and amateur use of  ", "acronyms": [[90, 93], [52, 56]], "long-forms": []}, {"text": "1979). Most tools and resources developed for natural language processing (NLP) of Arabic are designed for MSA.", "acronyms": [[75, 78], [107, 110]], "long-forms": [[46, 73]]}, {"text": "search excellence program Landes-Offensive zur Entwicklung Wissenschaftlich-o?konomischer Exzellenz (LOEWE) as part of the research center Digital Humanities.", "acronyms": [[101, 106]], "long-forms": [[26, 99]]}, {"text": "Table 6 shows the number of true positive (TP), true negative (TN), false positive (FP) and false negative (FN) of models for the stocks. ", "acronyms": [[108, 110], [43, 45], [63, 65], [84, 86]], "long-forms": [[92, 106], [33, 41], [48, 61], [68, 82]]}, {"text": "that first contains TOOV and given by the search  engine. Average_Rank (A_Rank) is the average position of TOOV in the returned snippets.", "acronyms": [[72, 78], [20, 24], [107, 111]], "long-forms": [[58, 70]]}, {"text": " NONHUMAN (animals), DNA, RNA, PROTEIN, CONTROL (control measures to contain the disease), BACTERIA, CHEMICAL and SYMPTOM.", "acronyms": [[40, 47], [21, 24], [26, 29], [31, 38], [91, 99], [101, 109], [114, 121], [1, 9]], "long-forms": [[49, 56], [11, 18]]}, {"text": "the Internet (Colbath, 2012). Social media poses three major computational challenges, dubbed by Gartner the 3Vs of big data: volume, velocity, and variety1. Natural Language Processing (NLP) methods, in particular, face further difficulties arising from the short, noisy, and strongly contextualised nature of social media. In order to address the 3Vs of social media, new language technologies have emerged, such as the identification and definition of users' language varieties and the translation to a different language, than the source.", "acronyms": [[187, 190]], "long-forms": [[158, 185]]}, {"text": " 2.2 Hierarchical Softmax Hierarchical Softmax (HSM) organizes the output vocabulary into a tree where the leaves are", "acronyms": [[48, 51]], "long-forms": [[26, 46]]}, {"text": "Feature F1,344 d Automated Readability Index (ARI) 0.187 0.047 Average Sentence Length (ASL) 3.870 0.213 Sentence Complexity (COM) 10.93 0.357", "acronyms": [[88, 91], [46, 49], [126, 129]], "long-forms": [[63, 86], [17, 44], [114, 124]]}, {"text": "3.3 Aspect term extraction Our approach for aspect term extraction is based on Conditional Random Fields (CRF). The choice", "acronyms": [[106, 109]], "long-forms": [[79, 104]]}, {"text": " In unvocalised text, the standard written form of Modern Standard Arabic (MSA), it may happen that the stem and the root of a word form are one and the", "acronyms": [[75, 78]], "long-forms": [[51, 73]]}, {"text": "This paper presents the UNL graph matching method for the Semantic Textual Similarity(STS) task. ", "acronyms": [[86, 89], [24, 27]], "long-forms": [[58, 84]]}, {"text": " We use LibSVM (Chang and Lin, 2011), an implementation of Support Vector Machines (SVM) (Cortes and Vapnik, 1995), as the underlying tech-", "acronyms": [[84, 87], [8, 14]], "long-forms": [[59, 82]]}, {"text": "L&L is suggestive of a particular approach to supervised learning ? maximum entropy (MaxEnt) ? in", "acronyms": [[85, 91], [0, 3]], "long-forms": [[68, 83]]}, {"text": "Two-level rules are generally of the form CP OP LC RC where CP = Correspondence Part; OP = Operator; LC = Left Context; RC = Right Context", "acronyms": [[60, 62], [86, 88], [42, 44], [45, 47], [48, 50], [51, 53], [101, 103], [120, 122]], "long-forms": [[65, 84], [91, 99], [106, 118], [125, 138]]}, {"text": "  Machine Translation (prototype phase)  The machine translation (MT) sub-component  implements the hybrid MT paradigm, combining ", "acronyms": [[66, 68], [107, 109]], "long-forms": [[45, 64]]}, {"text": "Given query Q = (q1, ? ? ? , qL), for each document D, expected term frequencies (ETF) of all sub-strings Q[i,j] = (qi, ? ? ? ,", "acronyms": [[82, 85]], "long-forms": [[55, 80]]}, {"text": "put language context to bias translation choices is in some sense a neural network analogy to the PSD (phrase sense disambiguation) approach for context-dependent translation probabilities of", "acronyms": [[98, 101]], "long-forms": [[103, 130]]}, {"text": "thesauri: Macquarie, Moby, Oxford and Roget?s.  The inverse rank (InvR) metric allows a comparison to be made between the extracted rank list", "acronyms": [[66, 70]], "long-forms": [[52, 64]]}, {"text": "5 Conclusion In this pilot experiment, we explore the possibility of using Amazon Mechanical Turk (MTurk) to collect bilingual word alignment data to assist automatic word align-", "acronyms": [[99, 104]], "long-forms": [[82, 97]]}, {"text": "vide a significant degree of control. Perhaps nowhere is this observation more keenly  felt than in weak lexical ontologies like Princeton WordNet (PWN). In PWN [1], ", "acronyms": [[148, 151], [157, 160]], "long-forms": [[129, 146]]}, {"text": "Features representing syntax (a) Phrase structure (PS) rules (b) Grammatical relation (GR) distance measures", "acronyms": [[87, 89], [51, 53]], "long-forms": [[65, 85], [33, 49]]}, {"text": " Bidirectional CLSTM Graves and Schmidhuber (2005) proposed a Bidirectional LSTM (B-LSTM) model, which utilizes additional backward informa-", "acronyms": [[82, 88], [15, 20]], "long-forms": [[62, 80]]}, {"text": "bbai@nec-labs.com Abstract We develop a recursive neural network (RNN) to extract answers to arbitrary natural language", "acronyms": [[66, 69]], "long-forms": [[40, 64]]}, {"text": "these 153,014 verb-noun collocations.  We used 'Bunrui Goi Hyou'(BGH) (NLRI, 1993)  as the Japanese thesaurus.", "acronyms": [[65, 68], [71, 75]], "long-forms": [[48, 63]]}, {"text": "patterns indicative of SLI. In this work, we use Language Models (LMs) for this task since they are a powerful statistical measure of language usage", "acronyms": [[66, 69], [23, 26]], "long-forms": [[49, 64]]}, {"text": "4 Hierarchic Autoepistemic  Logic  Autoepistemic (AE) logic was developed by Moore  \\[I0\\] as a reconstruction of McDermott's nonmono- ", "acronyms": [[50, 52]], "long-forms": [[35, 48]]}, {"text": "and a search procedure. For example, we can build a n-gram word language model (LM)?itself a large weighted FSA.", "acronyms": [[80, 82], [108, 111]], "long-forms": [[64, 78]]}, {"text": "The results of dependency (ZPar-eager, Ours-standard, Ours-PS and Mate-tools) and constituent parsers (BerkeleyParser and ZPar-con) are measured by the unlabeled accuracy score (UAS), labeled accuracy score (LAS) and bracketing f-measure (BF), respectively. ", "acronyms": [[208, 211], [239, 241], [54, 61], [178, 181], [122, 130], [27, 37]], "long-forms": [[184, 206], [217, 229], [152, 176]]}, {"text": "(Bikel et al, 1997), Decision Trees (Sekine, 1998), Maximum Entropy Models (Borthwick and Sterling, 1998), Support Vector Machines (SVM) (Asahara and Matsumoto, 2003), and also semi-supervised", "acronyms": [[132, 135]], "long-forms": [[107, 130]]}, {"text": "i' SRI - text extraction  ~\" TRW - document detection output  i' University of Massachusetts (UMass) -  document detection ", "acronyms": [[94, 99], [29, 32], [3, 6]], "long-forms": [[65, 92]]}, {"text": " 3 Objective SDS (Spoken dialogue system) researchers have addressed several practical challenges of apply-", "acronyms": [[13, 16]], "long-forms": [[18, 40]]}, {"text": "the divergence of their distributions in the targets and backgrounds. A support vector machine (SVM) was used to learn to classify between the targets and", "acronyms": [[96, 99]], "long-forms": [[72, 94]]}, {"text": "nodes  where  the re lat ion cor responds  to a verb .   Verb  nodes  (VERBSTR)  conta in  a po in ter  to the  RE-  LATION represented  by  the  verb ?", "acronyms": [[71, 78]], "long-forms": [[57, 61]]}, {"text": "a wordbreak (WB). In other words, we model Chinese word segmentation as wordbreak (WB) identification which takes all CB?s as candidates and", "acronyms": [[83, 85], [13, 15], [118, 122]], "long-forms": [[72, 81], [2, 11]]}, {"text": "(2014c): ? Italian - Romanian (IT-RO); ?", "acronyms": [[31, 36]], "long-forms": [[11, 29]]}, {"text": "In this paper, we describe an initial  implementation of a general spoken language interface, the  Carnegie Mellon Spoken Language Shell (CM-SLS) which  provides voice interface services to a variable number of applica- ", "acronyms": [[138, 144]], "long-forms": [[99, 136]]}, {"text": " 2.2 CoSeC CoSeC (Comparing Semantics in Context) performs meaning comparison on the basis of an underspec-", "acronyms": [[11, 16]], "long-forms": [[18, 37]]}, {"text": " We used Moses (Koehn et al 2007) with lexicalized reordering and a 6-gram language model (LM) trained using SRILM (Stolcke et al 2011) to trans-", "acronyms": [[91, 93], [109, 114]], "long-forms": [[75, 89]]}, {"text": " In Proceedings of the 22nd International Conference on Computational Linguistics (COLING), pages 865? ", "acronyms": [[83, 89]], "long-forms": [[56, 81]]}, {"text": "and normalizing it with a view to discriminate the importance of words across documents and then approximating it using singular value decomposition(SVD) in R dimensions (Bellegarda, 2000).", "acronyms": [[149, 152]], "long-forms": [[120, 147]]}, {"text": "ken varieties of Arabic, are still lacking. We present ELISSA, a machine translation (MT) system for DA to MSA.", "acronyms": [[86, 88]], "long-forms": [[65, 84]]}, {"text": "Semitic languages (in which vowels are not written), etc.  The problem of word sense disambiguation (WSD) has been described as \"AI-complete,\"  that is, a problem which can be solved only by first resolving all the difficult problems ", "acronyms": [[101, 104]], "long-forms": [[74, 99]]}, {"text": "provide an exhaustive list of connectives in the                                                    4 S=Subject; IO=Indirect Object; DO=Direct Object;  V=Verb; ERG=Ergative; DAT=Dative ", "acronyms": [[113, 115], [133, 135], [160, 163], [174, 177]], "long-forms": [[116, 131], [136, 149], [104, 111], [154, 158], [164, 172], [178, 184]]}, {"text": "  Parallel corpora Size of English texts (in  million words (MB))  Size of Chinese texts (in ", "acronyms": [[61, 63]], "long-forms": [[46, 59]]}, {"text": "(disharmonic) combinators to increase the expressive power of the model.  \u0001 KZGS10 (Kwiatkowski et al2010) uses a restricted higher-order unification procedure, which iteratively breaks up a logical form into", "acronyms": [[76, 82]], "long-forms": [[84, 105]]}, {"text": "(approx. 68,000 sentences, 1.4 million tokens), (2) Brown Corpus (BROWN) (approx. 60,000", "acronyms": [[66, 71]], "long-forms": [[52, 57]]}, {"text": "2007. CRFsuite: A fast implementation of Conditional Random Fields (CRFs), http://www.chokkan.org/software/crfsuite/.", "acronyms": [[68, 72], [6, 14]], "long-forms": [[41, 66]]}, {"text": "? ( S (NP (DT the) (NN man)) (VP (VBZ plays) (NP (DT the) (NN piano)))", "acronyms": [[34, 37], [7, 9], [11, 13], [20, 22], [30, 32], [46, 48], [50, 52], [59, 61]], "long-forms": [[38, 43]]}, {"text": "EUROTYP + + + + + + Leipzig Glossing Rules + + + + + + + + Penn Treebank (POS) + + + + + + + + STTS + + + + + + +", "acronyms": [[74, 77], [0, 7], [95, 99]], "long-forms": [[59, 72]]}, {"text": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI?09), pages 1,058?1,064, Pasadena, CA.", "acronyms": [[81, 89], [121, 123]], "long-forms": [[22, 79]]}, {"text": "of units. '  i Note that unlike RST, Veins Theory (VT) is not  concerned with the type of relations which hold ", "acronyms": [[51, 53], [32, 35]], "long-forms": [[37, 49]]}, {"text": "For our experiments, we collect debate posts from four popular domains, Abortion (ABO), Gay Rights (GAY), Obama (OBA), and Marijuana (MAR), from an online debate forum1.", "acronyms": [[100, 103], [113, 116], [82, 85], [134, 137]], "long-forms": [[88, 91], [106, 111], [72, 80], [123, 132]]}, {"text": "2011) created a corpus of posts from several online forums about breast cancer, which later was used to extract potential adverse reactions from the most commonly used drugs to treat this disease: tamoxifen, anastrozole, letrozole and axemestane. The authors collected a lexicon of lay medical terms from websites and databases about drugs and adverse events. The lexicon was extended with the Consumer Health Vocabulary (CHV)5, a vocabulary closer to the lay terms, which patients usually use to describe their medical experiences. Then, pairs of terms co-occurring within a window of 20 tokens were considered.", "acronyms": [[422, 425]], "long-forms": [[394, 420]]}, {"text": "2011.  Icelandic Parsed Historical Corpus (IcePaHC). ", "acronyms": [[43, 50]], "long-forms": [[7, 41]]}, {"text": "and Rozovskaya and Roth (2011). The article system is trained using the Averaged Perceptron (AP) algorithm (Freund and Schapire, 1999), imple-", "acronyms": [[93, 95]], "long-forms": [[72, 91]]}, {"text": "response- and reference-based scoring methods. All models use support vector regression (SVR) (Smola and Sch?olkopf, 2004), with the complexity parame-", "acronyms": [[89, 92]], "long-forms": [[62, 87]]}, {"text": "For example, an infinitival clause  (INFCL) may contain a noun phrase with an  embedded relative clause (RELCL). Elimination ", "acronyms": [[105, 110], [37, 42]], "long-forms": [[88, 103], [16, 34]]}, {"text": "alignment. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 215?222.", "acronyms": [[103, 106]], "long-forms": [[60, 101]]}, {"text": "Suppose that the feature f2 is an agreement feature and that a local  tree t which is a projection of this ID rule has been constructed, then  the Agreement Principle (AP) forces X = Y = Z and therefore the  AP has to consider three cases 6: ", "acronyms": [[168, 170], [107, 109], [208, 210]], "long-forms": [[147, 166]]}, {"text": "(#classes) with respect o each part of speech.  Table 1 Outline of Bunruigoihy3 (BGH)  POS noun I verb adj other total ", "acronyms": [[81, 84], [87, 90]], "long-forms": [[67, 79]]}, {"text": "evaluating work in speech recognition (SR), but until  recently no community-wide methodology existed for either  natural language (NL) researchers or speech understanding  (SU) researchers for evaluating the systems they developed.", "acronyms": [[132, 134], [39, 41], [174, 176]], "long-forms": [[114, 130], [19, 37], [151, 171]]}, {"text": "In NAACL Workshop on Syntax and Structure in Statistical Translation (SSST), pages 25?32, Rochester, NY.", "acronyms": [[70, 74], [3, 8], [101, 103]], "long-forms": [[45, 68]]}, {"text": "al., 2013), containing essays written by students at the National University of Singapore (NUS) which have been manually corrected by English instruc-", "acronyms": [[91, 94]], "long-forms": [[57, 89]]}, {"text": "1998) as the reference. In Chinese FrameNet, the predicates, called lexical units (LU), evoke frames which roughly correspond to different", "acronyms": [[83, 85]], "long-forms": [[68, 81]]}, {"text": "work of KH and FG was supported by the Academy of Finland, and of SVL by the Research Foundation Flanders (FWO). YVdP and SVL ac-", "acronyms": [[107, 110], [8, 10], [15, 17], [66, 69], [113, 117], [122, 125]], "long-forms": [[86, 96]]}, {"text": "Multi-document person name resolution, Proceedings of 42nd Annual Meeting of the Association for Computational Linguistics (ACL), Reference Resolution Workshop.", "acronyms": [[124, 127]], "long-forms": [[81, 122]]}, {"text": "ZC05 (Zettlemoyer and Collins 2005) 79.3 ?  ZC07 (Zettlemoyer and Collins 2007) 86.1 ? ", "acronyms": [[44, 48], [0, 4]], "long-forms": [[50, 78]]}, {"text": "All words are labeled as basic or not basic according to Ogden?s Basic English 850 (BE850) list (Ogden, 1930).3 In order to measure the lexical complexity", "acronyms": [[84, 89]], "long-forms": [[65, 82]]}, {"text": "The implementations of the oracles described in the first part of this work (sections 3 and 4) use the common formalism of finite state acceptors (FSA) over different semirings and are implemented us-", "acronyms": [[147, 150]], "long-forms": [[123, 145]]}, {"text": "sided brevity penalty (C = 0.01). Table 2 shows the average compression rates (CompR) for McDonald (2006) and our model (STSG) as well as their perfor-", "acronyms": [[79, 84], [121, 125]], "long-forms": [[60, 77]]}, {"text": "the MACH-III expert system, we should begin with  a brief description. Functional hierarchy (FH) is a  new paradigm for organizing expert system ", "acronyms": [[93, 95], [4, 12]], "long-forms": [[71, 91]]}, {"text": " 1 Introduction  Word sense disambiguation (WSD) is perhaps the  great open problem at the lexical level of natural ", "acronyms": [[44, 47]], "long-forms": [[17, 42]]}, {"text": "three things:  (1) a new formalism for logic grammars, which we  call modifier structure grammars (MSGs),  (2) an interpreter (or parser) for MSGs that takes all ", "acronyms": [[99, 103], [142, 146]], "long-forms": [[70, 97]]}, {"text": "1 In t roduct ion   The main goal of the proposed project is to develop  a language model(LM) that uses syntactic structure. ", "acronyms": [[90, 92]], "long-forms": [[75, 88]]}, {"text": "obtain a bilingual database. The database is  called the ATR Dialogue Database(ADD). ", "acronyms": [[79, 82]], "long-forms": [[57, 77]]}, {"text": "sponding to each of the cluster. Fairly intuitively we computed the Longest Common Subsequence(LCS) between the sentences in each cluster which we then", "acronyms": [[95, 98]], "long-forms": [[68, 93]]}, {"text": "In Proceedings of the 2005 International conference on Intelligent User Interfaces (IUI), pages 137?144. ACM Press.", "acronyms": [[84, 87], [105, 108]], "long-forms": [[55, 82]]}, {"text": "Adaptation of discriminative learning methods for these types of features to statistical machine translation (MT) systems, which have historically used idiosyncratic learning tech-", "acronyms": [[110, 112]], "long-forms": [[89, 108]]}, {"text": "For each  model sentence MSij,, the model builder selects  the Required Lexicon (RLijk), a set of the most  essential lexical entities required to appear in a ", "acronyms": [[81, 86], [25, 29]], "long-forms": [[63, 79]]}, {"text": "To classify the NPs according to their type in biomedical terms, we have adopted the Sequence Ontology (SO)2 (Eilbeck and Lewis, 2004).", "acronyms": [[104, 106], [16, 19]], "long-forms": [[85, 102]]}, {"text": "In our particular application, access to Getty?s Art and Architecture Thesaurus (AAT), to other museum and collection databases or online auction cata-", "acronyms": [[81, 84]], "long-forms": [[49, 79]]}, {"text": "2Although independently-developed implementations of  essentially the same algorithm can be found in the source code  of The Attribute Logic Engine (ALE) version 3.2 (Carpenter  & Penn, 1999) and the SICStus Prolog term utilities library ", "acronyms": [[149, 152]], "long-forms": [[125, 147]]}, {"text": "models use a word embedding size of 200, whereas the hidden layer(s) size is fixed at 400, with all hidden units using the Rectified Linear Unit (ReLu) i.e., f(x) = max(0, x) as activation function.", "acronyms": [[146, 150], [165, 168]], "long-forms": [[123, 144]]}, {"text": "onomy using a Japanese-English bilingual dictionary as  a \"bridge\", in order to support semantic processing in a  knowledge-based machine translation (MT) system. ", "acronyms": [[151, 153]], "long-forms": [[130, 149]]}, {"text": " 3 Data The RST Discourse Treebank (RST-DT) (Carlson et al, 2002) was used for training and testing.", "acronyms": [[36, 42]], "long-forms": [[12, 34]]}, {"text": "The computation of associative responses to multiword stimuli. In  Proceedings of the  Workshop on Cognitive Aspects of the Lexicon (COGALEX) at COLING-2008, p.102?109. Manchester, UK", "acronyms": [[133, 140], [181, 183]], "long-forms": [[99, 131]]}, {"text": " 1 Introduction Grammatical Framework (GF) (Ranta, 2004) is a grammar formalism designed in particular to serve", "acronyms": [[39, 41]], "long-forms": [[16, 37]]}, {"text": " Definition  Default Unification (first version) AU!B = A ~ U B, where A ~ is the maximal (i.e. most  specific) element in the subsumption ordering such that A' r- A and A ~ U B is defined.", "acronyms": [[49, 53]], "long-forms": [[56, 63]]}, {"text": "use the two cluster class features. The other selected features and the chosen algorithms (CL) are displayed in Table 1.", "acronyms": [[91, 93]], "long-forms": [[72, 89]]}, {"text": "ing in the non-realizable case. In Advances in Neural Information Processing Systems (NIPS), 2010.", "acronyms": [[86, 90]], "long-forms": [[47, 84]]}, {"text": "coord dep coord (c) Previous conjunct headed (PH) Je vois Jean , Paul et Marie", "acronyms": [[46, 48]], "long-forms": [[20, 44]]}, {"text": "subcategorisation information in the form of a Y in col-  umn 8, then we can assign the label for wh-pronou,  head (HWH). An exception list is used to map to the ", "acronyms": [[116, 119]], "long-forms": [[110, 114]]}, {"text": "guese to Swedish via different pivot language.  RW=Random Walk. * indicates the results are signifi-", "acronyms": [[48, 50]], "long-forms": [[51, 62]]}, {"text": "The major categories of components included in these capabilities include: Sentence Splitter, Phrase Chunker, Tokenizer, Part-of-Speech (POS) Tagger, Shallow Parser, Name Entity Recognizer (NER), Coreference Solution, etc.", "acronyms": [[190, 193], [137, 140]], "long-forms": [[166, 188], [121, 135]]}, {"text": "The columns in the first section of the table represent different settings of the p# parameter, with highest performance for each adjusted count model shown in bold. p# values were selected to show a representative range of performance. P = phoneme model; OR = onset-rhyme model; S = syllable model; IR = iterative re-estimation; LM = local minimum strategy. The best performing local minimum model is shaded.", "acronyms": [[300, 302], [330, 332], [256, 258]], "long-forms": [[305, 317], [335, 348], [241, 248], [261, 272], [284, 292]]}, {"text": "5 Experiments and Results 5.1 Data We use the British National Corpus (BNC),3 which contains 100M words, because it draws its", "acronyms": [[71, 74]], "long-forms": [[46, 69]]}, {"text": "comparison with SMO-n) 6 Conclusions Automatic Text Simplification (ATS) aims to convert complex texts into a simpler form, which is more accessible to a wider audience.", "acronyms": [[68, 71], [16, 21]], "long-forms": [[37, 66]]}, {"text": "as the World Wide Web. Various traditional  information retrieval(IR) techniques combined  with natural language processing(NLP) tech- ", "acronyms": [[66, 68], [124, 127]], "long-forms": [[44, 64], [96, 123]]}, {"text": "Such vectors can be used to perform all standard linear algebra operations applied in vector-based semantics: Measuring the cosine of the angle between vectors, applying singular value decomposition (SVD) to the whole matrix, and so on.", "acronyms": [[200, 203]], "long-forms": [[170, 198]]}, {"text": "Certain CT+ (factual) CT? ( counterfactual) CTu (certain but unknown output) Probable PR+ (probable) PR? ( not probable) [NA]", "acronyms": [[86, 89], [8, 11], [22, 24], [44, 47], [101, 104], [122, 125]], "long-forms": [[91, 99], [111, 119], [49, 75], [28, 42]]}, {"text": "tence All the indexes dove ., in which All should be tagged as a predeterminer (PDT).10 Most occurrences of All, however, are as a determiner (DT, 106/135 vs", "acronyms": [[80, 83], [143, 145]], "long-forms": [[65, 78], [131, 141]]}, {"text": "Score(E), where E is an example of Pat To improve ranking, we also try to find the longest similar subsequence (LSS) between the user input, Sent and retrieved example, Exm", "acronyms": [[112, 115]], "long-forms": [[83, 110]]}, {"text": " ? Term Base eXchange (TBX): XML Terminology Exchange Standard.", "acronyms": [[23, 26]], "long-forms": [[3, 21]]}, {"text": "ation for Computational Linguistics (NAACL) from 2011?2013, and he has served on the editorial boards of the journals Transactions of the ACL (TACL) and Computational Linguistics.", "acronyms": [[143, 147]], "long-forms": [[118, 141]]}, {"text": "results training on Multi-Domain Sentiment Dataset and testing on citation dataset (CITD). The horizontal line", "acronyms": [[84, 88]], "long-forms": [[66, 82]]}, {"text": " 2. Effort of Association (EA): a mc~sure of the effort  required to associate some entity with lira description ", "acronyms": [[27, 29]], "long-forms": [[4, 25]]}, {"text": "The full TBCNN-pair model outperforms all existing sentence encoding-based approaches, including a 1024d gated recurrent unit (GRU)-based RNN with ?", "acronyms": [[127, 130], [9, 14], [138, 141]], "long-forms": [[105, 125]]}, {"text": "full PTB, using 1st sense information. All results  are shown as labelled attachment score (LAS). ", "acronyms": [[92, 95], [5, 8]], "long-forms": [[65, 90]]}, {"text": "Abstract We consider the problem of correcting errors made by English as a Second Language (ESL) writers and address two issues that are essen-", "acronyms": [[92, 95]], "long-forms": [[62, 90]]}, {"text": "Cui et al experimented with two approaches to rank the candidate answers, called Bigram Model and Profile Hidden Markov Model (PHMM). Both", "acronyms": [[127, 131]], "long-forms": [[98, 125]]}, {"text": "On the other hand, multi-lingual  ontology is very important for natural language  processing, such as machine translation (MT), web  mining (Oyama et al 2004) and cross language ", "acronyms": [[124, 126]], "long-forms": [[103, 122]]}, {"text": "Table 5: Participating teams and references to system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, CS=Computer Scientist, LI=Linguist, ML=Machine Learning researcher.", "acronyms": [[104, 107], [148, 150], [171, 173], [83, 85], [184, 186]], "long-forms": [[108, 135], [151, 169], [174, 182], [86, 102], [187, 203]]}, {"text": "Electronic Text Encoding and Interchange were first published in April 1994 and were initially based on Standard Generalized Markup Language (SGML).  The", "acronyms": [[142, 146]], "long-forms": [[104, 140]]}, {"text": "Direction, Manner, and Purpose are Prop-Bank adjunctive argument labels (Palmer et al, 2005). Quantifier, Means, Cause-to-Know and copulas were added to the preceding roles. Finally, anything that did not fit into the above categories retained its dependency parse type: VMod (Verb Modifier), NMod (Noun Modifier), AMod (Adjec-tive or Adverb Modifier), and Root (Root was used when a single word in the answer, typically yes, no, agree, disagree, A-D, etc., stood alone without a significant relation to the remainder of the refer-ence answer; this occurred only 21 times, account-ing for fewer than 1% of the reference answer facets).", "acronyms": [[271, 275], [293, 297], [315, 319]], "long-forms": [[277, 290], [299, 312], [321, 350]]}, {"text": "reranking step works on top of the generative model.  \u0001 ZC05 (Zettlemoyer and Collins 2005) learns a discriminative log-linear model over CCG derivations.", "acronyms": [[56, 60], [138, 141]], "long-forms": [[62, 90]]}, {"text": "Approach for Arabic-English Named Entity Translation, Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages (ACL),  University of Michigan, Ann Arbor", "acronyms": [[136, 139], [73, 76]], "long-forms": [[103, 134]]}, {"text": "approach and extract features from the names.  They use Maximum Entropy (MaxEnt) model and a number of features based on n-grams,", "acronyms": [[73, 79]], "long-forms": [[56, 71]]}, {"text": "We note there also exist various multilingual or cross-lingual semantic processing works. Most of such works focus on semantic role labeling(SRL), the task of recovery of shallow meaning. Examples", "acronyms": [[141, 144]], "long-forms": [[118, 140]]}, {"text": "participant Japanese systems were developed in a four-  month period of time and output results comparable to the Message Understanding Conference-6 (MUC-6) \\[1\\]  English language systems with F-Measures between 70 - ", "acronyms": [[150, 155]], "long-forms": [[114, 148]]}, {"text": "against three baselines. The first baseline was based on the minimum overlap (MinOv) of characters in consecutive scenes and corresponds closely to the", "acronyms": [[78, 83]], "long-forms": [[61, 76]]}, {"text": "We use the publicly available runs of the two best systems from the CoNLL 2003 shared task, namely FLORIAN (Florian et al., ", "acronyms": [[99, 106], [68, 73]], "long-forms": [[108, 115]]}, {"text": "dialogues categorized into multiple domains, we create a particular type of hidden Markov model (HMM) called Class Speaker HMM (CSHMM) to model operator/caller utterance sequences.", "acronyms": [[128, 133]], "long-forms": [[109, 126]]}, {"text": "robust and the failure of matching produces no results.  On the other hand, statistical learning model (SLM) can  deal with unexpected cases during designing and ", "acronyms": [[104, 107]], "long-forms": [[76, 102]]}, {"text": " As stated earlier, our unlabeled data consists of email (EMAIL) and online forum (FORUM) data.", "acronyms": [[58, 63], [83, 88]], "long-forms": [[51, 56], [76, 81]]}, {"text": "of Translation Studies SI - 1000 Ljubljana, A?ker?eva 2 aljosav@gmail.com     Abstract  We report on a series of experiments aimed at improving the machine translation of ambig-uous lexical items by using wordnet-based unsupervised Word Sense Disambiguation (WSD) and comparing its results to three MT systems. Our experiments are performed for the English-Slovene language pair using UKB, a freely available graph-based word sense disambiguation system.", "acronyms": [[259, 262], [299, 301], [385, 388]], "long-forms": [[232, 257]]}, {"text": "Computational Linguistics Volume 40, Number 2 Because of their prevalence and irregularity, MWEs must be stored in lexicons of natural language processing (NLP) applications. Awareness of MWEs was proven", "acronyms": [[156, 159], [92, 96], [188, 192]], "long-forms": [[127, 154]]}, {"text": "Multiword Expressions (MWEs) are one of the stumbling blocks for more precise Natural Language Processing (NLP) systems.", "acronyms": [[107, 110], [23, 27]], "long-forms": [[78, 105], [0, 21]]}, {"text": "We tested two differing algorithms on text from the Wall Street  Journal (WSJ). Using BBN's part of speech tagger (POST), tagged  text was parsed using the full unification grammar of Delphi to fred ", "acronyms": [[115, 119], [74, 77]], "long-forms": [[92, 113], [52, 72]]}, {"text": "Abstract The quality of a sentence translated by a machine translation (MT) system is difficult to evaluate.", "acronyms": [[72, 74]], "long-forms": [[51, 70]]}, {"text": "MusicalArtist:album or Book:genre. Therefore, in addition to recognising entities with Stanford NERC, we also implement our own named entity recogniser (NER), which only recognises entity boundaries, but does not classify them.", "acronyms": [[153, 156], [96, 100]], "long-forms": [[128, 151]]}, {"text": "Japanese Translated SemEval 2007 Test Corpus (in %)  Before Morphology [After Morphology]  Emotion Score (ES) ? 0 Emotion Score (ES) ?", "acronyms": [[106, 108], [129, 131]], "long-forms": [[91, 104], [114, 127]]}, {"text": "  Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 120?125, Boulder, Colorado, June 2009.", "acronyms": [[87, 92]], "long-forms": [[46, 85]]}, {"text": "Our Chinese  word segmentation system is based on three models: (a) word boundary token (WBT) model and (b)  triple context matching model for unknown word ", "acronyms": [[89, 92]], "long-forms": [[68, 87]]}, {"text": "As further evidence of the effectiveness of our framework, we have recently adapted our phrase-structure parser in Section 6 to parsing with a lexicalized grammar formalism, Combinatory Categorial Grammar (CCG), and achieved higher F-scores than the state-of-the-art C&C CCG parser (Clark and Curran 2007).", "acronyms": [[206, 209], [267, 270], [271, 274]], "long-forms": [[174, 204]]}, {"text": "Abstract  This paper describes a heuristic algorithm capable of automatically assigning a label to  each of the senses in a machine readable dictionary (MRD) for the purpose of acquiring a com-  putational-semantic lexicon for treatment of lexical ambiguity.", "acronyms": [[153, 156]], "long-forms": [[124, 151]]}, {"text": " 2 Related Work Locality sensitive hashing (LSH) (Indyk and Motwani, 1998) is an example of an approximate", "acronyms": [[44, 47]], "long-forms": [[16, 42]]}, {"text": "example, we have defined that all the subclasses of #COMMUNICATION-EVENTS (e.g.  #REPORT#,  #CONFIRM#, etc.) map their sentential complements (SENT-COMP)  to THEME, as shown below.", "acronyms": [[143, 152], [158, 163]], "long-forms": [[119, 141]]}, {"text": " Association for Computational Linguistics.                       ACL Special Interest Group on the Lexicon (SIGLEX), Philadelphia,                   Unsupervised Lexical Acquisition: Proceedings of the Workshop of the", "acronyms": [[109, 115], [66, 69]], "long-forms": [[70, 107]]}, {"text": "1 Introduction Recent research shows that it is possible, using current natural language processing (NLP) and machine learning technology, to automatically induce lex-", "acronyms": [[101, 104]], "long-forms": [[72, 99]]}, {"text": "Hodellng Temporal Knowledge  Hodellng time, dasoite its olovlous importance, has  proved an elusive goal for artificial Intelligence (AI). ", "acronyms": [[134, 136]], "long-forms": [[109, 132]]}, {"text": "and stochastic optimization. In Proceedings of the Conference on Learning Theory (COLT), pages 257?269.", "acronyms": [[82, 86]], "long-forms": [[51, 80]]}, {"text": "Table 3: The effect of new features on the development set for English. UAS = unlabeled attachment score; UEM = unlabeled exact match.", "acronyms": [[72, 75], [106, 109]], "long-forms": [[78, 104], [112, 133]]}, {"text": "Abstract In this paper, we address the problem of converting Dialectal Arabic (DA) text that is written in the Latin script (called", "acronyms": [[79, 81]], "long-forms": [[61, 77]]}, {"text": "Hyderabad, India Abstract Named Entity Recognition(NER) is the task of identifying and classifying tokens in a", "acronyms": [[51, 54]], "long-forms": [[26, 49]]}, {"text": "4.3 Experiments with the QA data In the first set of experiments we focus on the Question Answering (QA) domain (CLEF corpus). ", "acronyms": [[101, 103], [25, 27], [113, 117]], "long-forms": [[81, 99]]}, {"text": "But, it is observed that the identification of  lexical scopes of compound verbs (CompVs)  and conjunct verbs (ConjVs) from long sequence of successive Complex Predicates ", "acronyms": [[111, 117], [82, 88]], "long-forms": [[95, 109], [66, 80]]}, {"text": " 1 Introduction  Spoken language translation (SLT) has become  more important due to globalization.", "acronyms": [[46, 49]], "long-forms": [[17, 44]]}, {"text": " Acknowledgments This research was supported by the Deutsche Forschungsgemeinschaft (DFG) in the Center of Excellence in ?", "acronyms": [[85, 88]], "long-forms": [[52, 83]]}, {"text": "z that maps sentences x to logical expressions z. We learn this function by inducing a probabilistic CCG (PCCG) grammar from a training set {(xi, zi)|i = 1 . . .", "acronyms": [[106, 110]], "long-forms": [[87, 104]]}, {"text": " 2.1 Modeling Votes Ideal point (IP) models are a mainstay in quantitative political science, often applied to voting records to", "acronyms": [[33, 35]], "long-forms": [[20, 31]]}, {"text": "ysis incorporating social networks. In Proceedings of Knowledge Discovery and Data Mining (KDD). ", "acronyms": [[91, 94]], "long-forms": [[54, 82]]}, {"text": "non-terminals as leaves. Later, Moschitti (2006) introduced the Partial Tree Kernels (PTK), by allowing fragments with partial rule expansions.", "acronyms": [[86, 89]], "long-forms": [[64, 84]]}, {"text": "The lattice representing a union of several confusion networks can then be directly rescored with an n-gram language model (LM). A transforma-", "acronyms": [[124, 126]], "long-forms": [[108, 122]]}, {"text": " First we used the C&C Combinatory Categorial Grammar (CCG) parser5 (C&C) by Clark and Curran (2004) using the biomedical model described in", "acronyms": [[69, 72], [19, 22], [55, 58]], "long-forms": [[23, 53], [77, 93]]}, {"text": "translations: ovc~iflow in the Data Processing  category (DPR,) and out-o\\[-./lushnc.ss in the Air-  m'M't Structure category (STR). As shown in the ", "acronyms": [[127, 130], [58, 61]], "long-forms": [[107, 125], [31, 56]]}, {"text": "Performing proper Arabic dialect identification may positively impact many Natural Language Processing (NLP) application.", "acronyms": [[104, 107]], "long-forms": [[75, 102]]}, {"text": "We experimented with the following four machine learning algorithms: Support Vector Machine (SVM), Multilayer Perceptron(MLP),  Decision Trees(DT) and AdaBoost(AB).", "acronyms": [[121, 124], [93, 96], [143, 145], [160, 162]], "long-forms": [[99, 119], [69, 91], [128, 141], [151, 159]]}, {"text": "In Modern Standard Arabic (MSA), all nouns and adjectives have one of three cases: nominative (NOM), accusative (ACC), or genitive (GEN). What", "acronyms": [[113, 116], [132, 135], [27, 30], [95, 98]], "long-forms": [[101, 111], [122, 130], [3, 25], [83, 93]]}, {"text": "sets used in the fast Tree Kernel.  2.3 A Fast Tree Kernel (FTK) To compute the kernels defined in the previous", "acronyms": [[60, 63]], "long-forms": [[42, 58]]}, {"text": "4 = 1, 440 items) (ADD=additive, MUL=multiplicative, PLSR=Partial Least Squares Regression, OBS=observed vectors) . ", "acronyms": [[92, 95], [19, 22], [33, 36], [53, 57]], "long-forms": [[96, 104], [23, 31], [37, 51], [58, 90]]}, {"text": " (Undecided) Meronym(MER)  (a) IF x=ANT ", "acronyms": [[21, 24], [36, 39]], "long-forms": [[13, 20]]}, {"text": "derived from these MDPs: (1) Diff?s: the number of states whose policy differs from the Baseline 2 policy, (2) Percent Policy change (P.C.): the weighted amount of change between the two policies (100%", "acronyms": [[134, 138], [19, 23]], "long-forms": [[119, 132]]}, {"text": ", with different projection and SRL training methods. SP=Supplement; OW=Overwrite. ", "acronyms": [[54, 56], [32, 35], [69, 71]], "long-forms": [[72, 81], [57, 67]]}, {"text": "NEDcost = EDcost/length (4) ? The Match Number(MN): The match number is the number of words", "acronyms": [[47, 49], [0, 7], [10, 16]], "long-forms": [[34, 45]]}, {"text": " 2 Related Work Sentiment analysis (SA) and related topics have been extensively studied in recent years.", "acronyms": [[36, 38]], "long-forms": [[16, 34]]}, {"text": "tic attachment. Eight categories of syntactic onstituent were used: sentence (S), noun  phrase (NP), verb phrase (VP), prepositional phrase (PP), wh-noun phrase (WHNP),  adjective or adverbial phrase (AP), any other constituent (O), and both words in the ", "acronyms": [[114, 116], [141, 143], [96, 98], [162, 166], [201, 203]], "long-forms": [[101, 112], [119, 139], [68, 76], [82, 94], [146, 160], [170, 199], [206, 227]]}, {"text": "32  Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 169?178, Seoul, South Korea, 5-6 July 2012.", "acronyms": [[100, 107]], "long-forms": [[50, 98]]}, {"text": " With basic CG there are just two rules for combining categories: the forward (FA) and backward (BA) functional application rules.", "acronyms": [[79, 81], [12, 14], [97, 99]], "long-forms": [[70, 77], [87, 95]]}, {"text": "At the semantic level, we have included three different families which operate using named entities (NE), semantic roles (SR), and discourse representations (DR).", "acronyms": [[101, 103], [122, 124], [158, 160]], "long-forms": [[85, 99], [106, 120], [131, 156]]}, {"text": "our proposed STRAIN approach. The results of using sentence training (STr) and sentence testing (STe) are shown in the STR/STE row of Table 5.", "acronyms": [[70, 73], [13, 19], [97, 100], [119, 126]], "long-forms": [[51, 68], [79, 95]]}, {"text": "The Chinese text is segmented with a segmenter trained on CTB data using conditional random fields (CRF). ", "acronyms": [[100, 103], [58, 61]], "long-forms": [[73, 98]]}, {"text": "Abbreviations NE = Named Entity CE = Correlated Entity EP = Entity Profile", "acronyms": [[32, 34], [14, 16], [55, 57]], "long-forms": [[37, 54], [19, 31], [60, 74]]}, {"text": "set of pivots from a given pair of domains such as the minimum frequency of occurrence of a feature in the two domains, mutual information (MI), and the entropy of the feature distribution over the", "acronyms": [[140, 142]], "long-forms": [[120, 138]]}, {"text": " 1 Introduction Todays natural user interfaces (NUI) for applications running on smart devices, e.g, phones (SIRI,", "acronyms": [[48, 51], [109, 113]], "long-forms": [[23, 46]]}, {"text": "Furthermore, if we can rank preferred verbs by domains, inferred verbs can be more useful to applications that focus on specific domains. Hence we defined Domain Verb Association (DVA) to measure how frequently inferred verbs are used with domain instances that can be used as subjects or", "acronyms": [[180, 183]], "long-forms": [[155, 178]]}, {"text": "In this part, we introduce how to make use of the  original and opposite training/test data together  for dual training and dual prediction (DTDP). ", "acronyms": [[141, 145]], "long-forms": [[106, 139]]}, {"text": "If we look at the permutations, we have in 2. to-  picalization, with OBJect NP in focus structure (FS) I in I. the grammatical relations of 25 are preserved ", "acronyms": [[100, 102], [77, 79]], "long-forms": [[83, 98]]}, {"text": "to generate these features from the training data.  In the NE (named entities) feature ? PERSON?", "acronyms": [[59, 61], [89, 96]], "long-forms": [[63, 77]]}, {"text": "formation retrieval resulted in creation of reusable test collections in large-scale evaluations such as the Text REtrieval Conference (TREC)1. Researchers in", "acronyms": [[136, 140]], "long-forms": [[109, 134]]}, {"text": "1992. Proceedings of the Fourth  Message Understanding Conference (MUC-$). Mor- ", "acronyms": [[67, 72]], "long-forms": [[33, 65]]}, {"text": "mosque, . . .   Detai l izat ion (DET) - a subst i tut ion of a  detai led description Y1 of a thing, s i tuat ion ", "acronyms": [[34, 37]], "long-forms": [[16, 32]]}, {"text": "It is particularly interesting to see that when hypotheses selection is applied, oracle error rate (OER) drops of 2% points from an already accurate OER", "acronyms": [[100, 103], [149, 152]], "long-forms": [[81, 98]]}, {"text": "(Joachims, 1999) software). In it, we implemented: the String Kernel (SK), the Syntactic Tree Kernel (STK), the Shallow Semantic Tree Kernel", "acronyms": [[70, 72]], "long-forms": [[55, 68]]}, {"text": "provided for the slots over the course of the dialog.  These are our String Consistency (SC) features. ", "acronyms": [[89, 91]], "long-forms": [[69, 87]]}, {"text": " In this paper, we introduce a novel method called Random Manhattan Indexing (RMI). RMI", "acronyms": [[78, 81], [84, 87]], "long-forms": [[51, 76]]}, {"text": " 1 Introduction Referring expressions (REs) are expressions intended by speakers to identify entities to hearers.", "acronyms": [[39, 42]], "long-forms": [[16, 37]]}, {"text": "a r e  the fo l lowing  -- Performer,  Object, Goal, Source,  Locat ion,   Means, Cause, and Enabler  -- and (2) s t r u c t u r a l  c a s e s ,  which a r e   R E E L  ( r e l a t i v e  c l a u s e )  and COMP (compound). I w i l l  not  e x p l a i n  ", "acronyms": [[208, 212]], "long-forms": [[214, 222]]}, {"text": "x?D(X) P (X = x|W1 = w1, . . . , WN = wN ). ( 1)", "acronyms": [[33, 35]], "long-forms": [[38, 40]]}, {"text": "is still room for improvement.  2 The Index of Productive Syntax (IPSyn) The Index of Productive Syntax (Scarborough,", "acronyms": [[66, 71]], "long-forms": [[38, 64]]}, {"text": "1 Introduction In the past few years, a number of studies have focused on verbal semantic role labeling (SRL). ", "acronyms": [[105, 108]], "long-forms": [[81, 103]]}, {"text": "We experiment with multiple ways to select a snippet: the first 50 words of the summary (START), the last 50 words (END) and 50 words starting at a randomly chosen sentence", "acronyms": [[89, 94], [116, 119]], "long-forms": [[80, 87]]}, {"text": "In particular, we use transition probability and emission probability in Hidden Markov Model (HMM) (Leek, 1997) to capture this dependency.", "acronyms": [[94, 97]], "long-forms": [[73, 92]]}, {"text": "from dictionaries and hand-tailored heuristics. It applies statistical named entity recognition (NER) methods to the more challenging task of deidenti-", "acronyms": [[97, 100]], "long-forms": [[71, 95]]}, {"text": "Fazly and Stevenson, 2007), our approach is to compare the context vector of a VNC with the composed vector of the verb and noun (V-N) component units of the VNC when they occur in iso-", "acronyms": [[130, 133]], "long-forms": [[115, 128]]}, {"text": "Domains: HT = human transcription factors in blood cells, TCS = two-component systems, BB = bacteria biology, BS = Bacillus subtilis", "acronyms": [[87, 89], [9, 11], [58, 61], [110, 112]], "long-forms": [[92, 108], [14, 33], [64, 85], [115, 132]]}, {"text": "cause de la limite des outils informatiques li?s ? son traitement  automatique,  ce  qui  rend  difcile  son  adh?sion  ?  ses  cons?urs  dans  le domaine des nouvelles technologies de l'information et de la communication (NTIC). Par cons?quent, un ensemble de recherches scientifques et linguistiques sont lanc?es pour rem?dier ?", "acronyms": [[223, 227]], "long-forms": [[159, 221]]}, {"text": "redefined  While politicians all over the world want to  make Information Society Technologies (IST)  available and accessible in the language and locale ", "acronyms": [[96, 99]], "long-forms": [[62, 94]]}, {"text": "Apart from  other features, each modifier should be anno/atecl  with a pragmatic function feature (PRAGM), which  specifies why a modifier is used it: an NP.", "acronyms": [[99, 104], [154, 156]], "long-forms": [[71, 80]]}, {"text": "C = connector  TR = terse reply  FS = false start  E = echo ", "acronyms": [[33, 35], [15, 17]], "long-forms": [[38, 49], [4, 13], [20, 31], [55, 59]]}, {"text": "to inspect and easily modify discourse-planning specifications for rapid  iterative refinement. The Explanation Design Package (EDP) formalism  is a convenient, schema-like (McKeown 1985; Paris 1988) programming ", "acronyms": [[128, 131]], "long-forms": [[100, 126]]}, {"text": "Above all, our goal is to integrate cross-media inference and create the linkage among the information extracted from those heterogenous data. Our novel Multi-media Information Networks (MiNets) representation initializes our idea about a basic ontology of the ranking system.", "acronyms": [[187, 193]], "long-forms": [[159, 185]]}, {"text": " Below we focus on a special case of the latter problem: noun compound (NC) coordination. Con-", "acronyms": [[72, 74]], "long-forms": [[57, 70]]}, {"text": " (e.g., hand, heart, blood, DNA) Diseases and Symptoms (DisSym): Diseases and symptoms.", "acronyms": [[56, 62], [28, 31]], "long-forms": [[33, 54]]}, {"text": "In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI-07), pages 2670?2676. ", "acronyms": [[86, 94]], "long-forms": [[27, 84]]}, {"text": "same time, Intelligent Computer-Assisted Language Learning (ICALL) and Intelligent Language Tutoring (ILT) systems (e.g., Heift and Schulze, 2007; Meurers, 2012) also tend to focus more on gram-", "acronyms": [[102, 105], [60, 65]], "long-forms": [[71, 100], [11, 58]]}, {"text": " 1 Introduction Among many natural language processing (NLP) tasks, such as text classification, question answer-", "acronyms": [[56, 59]], "long-forms": [[27, 54]]}, {"text": " 1 Introduction The Uniform Information Density (UID) hypothesis holds that speakers tend to maintain a relatively", "acronyms": [[49, 52]], "long-forms": [[20, 47]]}, {"text": " 5 Clustering Methods Spectral clustering (SPEC) has proved promising in previous verb clustering experiments (Brew", "acronyms": [[43, 47]], "long-forms": [[22, 41]]}, {"text": "2 Preposition Semantic Role Disambiguation in Penn Treebank Significant numbers of prepositional phrases (PPs) in the Penn treebank [1] are tagged with their semantic role relative to the governing verb.", "acronyms": [[106, 109]], "long-forms": [[83, 104]]}, {"text": "linear chain, CRFs make a first-order Markov independence assumption, and thus can be understood as conditionally-trained finite state machines(FSMs). ", "acronyms": [[144, 148], [14, 18]], "long-forms": [[122, 142]]}, {"text": "for unsupervised learning. In this paper, we are interested in partitioning words into several clusters without any label priori using unsupervised LP (Un-LP) algorithm. Firstly we randomly select K (K ?", "acronyms": [[152, 157]], "long-forms": [[135, 150]]}, {"text": "3.2 Coordination Structures Among the most controversial annotation schemes are those of coordination structures (CS), which are groups of two or more tokens that are in coordina-", "acronyms": [[114, 116]], "long-forms": [[89, 112]]}, {"text": "POS Entropy (PosH) 0.55 0.02 0.21 -0.20 0.18 -0.11 0.22 1.00 0.16 -0.11 Derivation steps (Step) -0.05 0.11 0.38 -0.35 0.31 -0.16 0.32 0.16 1.00 -0.24 Word Length (WLen) 0.18 -0.29 -0.03 0.64 -0.72 0.56 0.02 -0.11 -0.24 1.00 Table 1: Correlations between (mean-centered) predictors.", "acronyms": [[163, 167], [13, 17], [90, 94]], "long-forms": [[150, 161], [0, 11], [83, 88]]}, {"text": " 2 Data Kinyarwanda (KIN) and Malagasy (MLG) are lowresource, KIN is morphologically rich, and English", "acronyms": [[21, 24], [40, 43], [62, 65]], "long-forms": [[8, 19], [30, 38]]}, {"text": "defined linguistic context, the task is to predict the class of a token. Support Vector Machines (SVMs) (Vapnik, 1995) are one class of such model.", "acronyms": [[98, 102]], "long-forms": [[73, 96]]}, {"text": "Italian - Romanian (IT-RO); ? Portuguese - Romanian (PT-RO); ?", "acronyms": [[53, 58], [20, 25]], "long-forms": [[30, 51], [0, 18]]}, {"text": "1 Introduction RWTH?s main approach to System Combination (SC) for Machine Translation (MT) is a refined version of the ROVER approach in Automatic", "acronyms": [[88, 90], [15, 21], [59, 61], [120, 125]], "long-forms": [[67, 86], [39, 57]]}, {"text": "five folds and evaluate them on the fifth 29 Table 1: Results for passage retrieval for TREC-QA using disjoint windows (DW) and sliding windows (SW). ??", "acronyms": [[120, 122], [88, 95], [145, 147]], "long-forms": [[102, 118]]}, {"text": "semantic processing component. A detailed descrip-  tion of the lexical conccplual structure (LCS) which  serves as the interlingua is not given here, but see ", "acronyms": [[94, 97]], "long-forms": [[64, 92]]}, {"text": "segmentable candidates, and picks a correct segmentation candidate from the list by using a value of LEF (Likelihood Evaluation Function, Section 2.1) and so on.", "acronyms": [[101, 104]], "long-forms": [[106, 136]]}, {"text": "Artola Xo (1993)o \"ilIZTSUA: lIiztegi-sistema urDrt.lc  a(lime~dunaren sorkuntza eta eraikuntza /Conccption  d'un syst~,me intelligent d'aide dictionnarialc (SIAl))\"  Ph.D. Thesis.", "acronyms": [[158, 162]], "long-forms": [[114, 156]]}, {"text": "1 Introduction  Scalability in dialog systems is, of course, not only a  matter of the natural language understanding (NLU)  component, but also of the NLG part of the system.2 We ", "acronyms": [[119, 122], [152, 155]], "long-forms": [[87, 117]]}, {"text": "(Schubert 1987; Maxwell & Schubert 1989), and fig-  ure 1 shows the dependency trees for this example,  cross-coded for translation units (TUs). Each ellipse ", "acronyms": [[139, 142]], "long-forms": [[120, 137]]}, {"text": " On the other hand, the final, \"concrete\", level  of semantic representation (SemRep) is more  like a fully-fledged logical form and it is no ", "acronyms": [[78, 84]], "long-forms": [[53, 76]]}, {"text": "  2.1. The behavior of manner adverbs (MA) and sentence  adverbs (SA) in the sentence is widely different: ", "acronyms": [[39, 41], [66, 68]], "long-forms": [[23, 37], [47, 64]]}, {"text": "Rule 3: Question word followed immediately by a verb (Example (3)).   Qp = question word + headword in the following Verb Phrase(VP) or NP chunk  Rule 4: Question word followed by a passive VP (Example (4)).", "acronyms": [[129, 131], [136, 138], [190, 192]], "long-forms": [[117, 127]]}, {"text": "2.4 Dictionaries of  Bahasa Nusantara, Indonesian Linguistics Association (MLI)   Masyarakat Linguistik Indonesia (MLI) is a group  of institutions, organizations and corporation, ", "acronyms": [[115, 118], [75, 78]], "long-forms": [[82, 113]]}, {"text": "Instead of using graph-based consensus  confidence as features in the log-linear model, we  perform structured label propagation (Struct-LP) to  re-rank the n-best list directly, and the similarity ", "acronyms": [[130, 139]], "long-forms": [[100, 128]]}, {"text": "verbs, adject ives,  and others. Then a  separate  Keyword In Context  (KWIC) Index  was made for each part of speech.", "acronyms": [[72, 76]], "long-forms": [[51, 69]]}, {"text": "former networks for image recognition. Bulletin of the International Statistical Institute (ISI). ", "acronyms": [[92, 95]], "long-forms": [[55, 90]]}, {"text": " 2.1 Tree Substitution Grammars A tree substitution grammar (TSG) is a 4-tuple ?", "acronyms": [[61, 64]], "long-forms": [[34, 59]]}, {"text": "date translations. While the traditional Maximum A Posteriori (MAP) decision rule can be optimized as a piecewise lin-", "acronyms": [[63, 66]], "long-forms": [[41, 61]]}, {"text": "This paper describes a set of experiments on two sub-tasks of Quality Estimation of Machine Translation (MT) output.", "acronyms": [[105, 107]], "long-forms": [[84, 103]]}, {"text": "1 Introduction As they are normally conceived, many tasks relevant to Computational Linguistics (CL), such as text categorization, clustering, and information retrieval, ignore the con-", "acronyms": [[97, 99]], "long-forms": [[70, 95]]}, {"text": "Translate has achieved very good results on the  Chinese-to-English translation tracks of NIST open  machine translation test (MT)5 and it ranks the first  on most tracks.", "acronyms": [[127, 129], [90, 94]], "long-forms": [[101, 125]]}, {"text": "In Proceedings of the 15th International Conference on  Computational Linguistics (COLING'94),  Kyoto, Japan, August.", "acronyms": [[83, 92]], "long-forms": [[56, 81]]}, {"text": "The dataset used in the CIPS-ParsEval-2010 evaluation is converted from the Tsinghua Chinese Treebank (TCT). There are two subtasks: (1)", "acronyms": [[103, 106], [24, 42]], "long-forms": [[93, 101]]}, {"text": "Gambling neighborhood f bank  bank  Subject Code GB = Gambling  person use money piece ", "acronyms": [[49, 51]], "long-forms": [[54, 62]]}, {"text": "umn.  Log frequency (LF) and global entropy (GE) are correlated.", "acronyms": [[21, 23], [45, 47]], "long-forms": [[6, 19], [29, 43]]}, {"text": "information nuggets?, called Summary Content Units (SCUs), which are short, atomic statements of facts con-", "acronyms": [[52, 56]], "long-forms": [[29, 50]]}, {"text": " Since this is a binary classification task, we have 5 different tags: B-L (Beginning of a literal chunk), I-L (Inside of a literal chunk), B-I (Beginning an", "acronyms": [[71, 74], [107, 110], [140, 143]], "long-forms": [[76, 98], [112, 131], [145, 157]]}, {"text": "This is called empirical Bayesian estimation. Our approach differs from maximum a posteriori (MAP) estimation, since we re-estimate the parameters of", "acronyms": [[94, 97]], "long-forms": [[72, 92]]}, {"text": "semantically interpreted.  We apply conditional random fields (CRFs) to the task of SRL proposed by the CoNLL shared", "acronyms": [[63, 67]], "long-forms": [[36, 61]]}, {"text": "corpora for our experiments. The first is a new corpus of 70 articles from New York Times (NYT) LDC corpus, each describing one or more terrorist events", "acronyms": [[91, 94], [96, 99]], "long-forms": [[75, 89]]}, {"text": "functions. The latter three correspond to the three Gene Ontology (GO) (Ashburner et al, 2000) toplevel sub-ontologies, and terms of these types were", "acronyms": [[67, 69]], "long-forms": [[52, 65]]}, {"text": "The first step is the identification of the presence of a graphical image in the web page by a  Browser Helper Object (BHO) (Elzer et al., 2007).", "acronyms": [[119, 122]], "long-forms": [[96, 117]]}, {"text": "He con~iciers them foolish.  2) ASTG (adicctive string), including  adjectival Vens and Vings (see VENDADJ I found it well-dcsigned.", "acronyms": [[32, 36], [100, 106]], "long-forms": [[38, 54]]}, {"text": "Figure 1. Annotated Syntax Tree  (AST) and Phrase Levels (PL). ", "acronyms": [[58, 60], [34, 37]], "long-forms": [[43, 56], [10, 31]]}, {"text": "hierarchical phrase-based model, but constrained so that the English part of the right-hand side is restricted to a Greibach Normal Form (GNF)like structure: A contiguous sequence of termi-", "acronyms": [[138, 141]], "long-forms": [[116, 136]]}, {"text": "This makes it hard to find particular information of in-terest (say, a mention of a particular company in a set of thousands of YouTube comments), or to un-derstand the gist of the discussion at a high-level. Our goal in this work was to create a simple tool which would allow people to rapidly ingest useful information contained in large community-created comment threads, where the volume of data precludes manual inspection. To this end, we created CoFi (Comment Filter), a language-independent, web-based interactive browser for single comment threads. 2 How CoFi works For a given set of comments, we create a distinct CoFi instance.", "acronyms": [[453, 457], [625, 629], [564, 568]], "long-forms": [[459, 473]]}, {"text": "(PERS), organization (ORG), geo-political entity (GPE), weapon (WEA), vehicle (VEH), location (LOC), and facility (FAC). Since the person type", "acronyms": [[115, 118], [1, 5], [22, 25], [50, 53], [64, 67], [79, 82], [95, 98]], "long-forms": [[105, 113], [8, 20], [28, 48], [56, 62], [70, 77], [85, 93]]}, {"text": "measure specifically their performance, a selection of them is also given: WH-Subject (WHS), WH-Object (WHO), passive Subject (PSubj), control Subject (CSubj), and the anaphor of the", "acronyms": [[127, 132], [87, 90], [104, 107], [152, 157]], "long-forms": [[110, 125], [75, 85], [93, 102], [135, 150]]}, {"text": "m } using standard support vector machine (SVM) training (holding A fixed), and then make a simple", "acronyms": [[43, 46]], "long-forms": [[19, 41]]}, {"text": "3 Results  The experiments were completed using the revised  RTE3 development set (RTE3Devmt) before the  RTE3Test results were released.", "acronyms": [[83, 92], [106, 114]], "long-forms": [[61, 81]]}, {"text": " 2.2 DIRT data The DIRT (Discovering Inference Rules from Text) method is based on extending Harris Distributional", "acronyms": [[19, 23], [5, 9]], "long-forms": [[25, 62]]}, {"text": "validation. This is carried out for the tweet text (TEXT), user-declared location (MB-LOC) and user-declared time zone (MB-TZ).", "acronyms": [[52, 56], [83, 89], [120, 125]], "long-forms": [[46, 50], [59, 81], [95, 118]]}, {"text": "3 HCMUS 6L OpenNLP OpenNLP Dict Rules - Table 2: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, ML=Machine Learning researcher, L=Linguist, Porter=Porter stemmer,", "acronyms": [[113, 115]], "long-forms": [[116, 132]]}, {"text": "A closer, more detailed, look at the  LOCATION data suggests that he high payoff indicated  by the average REC and precision (PRE) scores was  achieved because most of the data were listable.", "acronyms": [[126, 129], [107, 110]], "long-forms": [[115, 124]]}, {"text": "  For example, the s t ruc ture  tn whtch  ad jec t ives  (ADJ) repeat  a rb i t ra ry  ttmes and a noun  (N) fo l lows  them tn Engl lsh ts expressed as ", "acronyms": [[59, 62]], "long-forms": [[43, 56], [100, 104]]}, {"text": " 1 Introduction Many problems in natural language processing (NLP) involve optimizing some objective function over a set of", "acronyms": [[62, 65]], "long-forms": [[33, 60]]}, {"text": "These 67? 30 candidate claims were annotated using Amazon?s Mechanical Turk (AMT). In each", "acronyms": [[77, 80]], "long-forms": [[51, 75]]}, {"text": "PoS tagF5. Lemma (L)F6. Inflection (INFL)F7. Main verb of main clause (MV)F8.", "acronyms": [[36, 40], [0, 3], [71, 73]], "long-forms": [[24, 34], [11, 16], [45, 54]]}, {"text": " First, we employ a multiple output GP based on the Intrinsic Coregionalization Model (ICM) (", "acronyms": [[87, 90], [36, 38]], "long-forms": [[52, 85]]}, {"text": "We use the two representative corpora mentioned above, Penn Chinese Treebank (CTB) and PKU?s People?s Daily (PPD) in our experiments.", "acronyms": [[109, 112], [78, 81], [87, 92]], "long-forms": [[93, 107], [60, 76]]}, {"text": "TC 59% 59% 79% 85% BTC 86% 86% 86% 92% Table 1: Task Completion (TC) and Binary Task Completion (BTC) prediction results, using auto-", "acronyms": [[65, 67], [0, 2], [19, 22], [97, 100]], "long-forms": [[48, 63], [73, 95]]}, {"text": "In order to normalize Thai input character  sequences to a canonical Unicode form, we developed a finite state transducer (FST) which  detects and repairs a number of sequencing er-", "acronyms": [[123, 126]], "long-forms": [[98, 121]]}, {"text": "stantin, Evan Herbst, Moses: Open Source Toolkit for Statistical Machine Translation, Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session, Prague, Czech Republic, June", "acronyms": [[151, 154]], "long-forms": [[108, 149]]}, {"text": " 3.3 Prosodic Model Training We choose to use a support vector machine (SVM) classifier1 for the prosodic model based on previous", "acronyms": [[72, 75]], "long-forms": [[48, 70]]}, {"text": "successful method presented by Bendersky and Croft (2008) for selection and weighting of query noun phrases (NPs). It also extends work for deter-", "acronyms": [[109, 112]], "long-forms": [[95, 107]]}, {"text": "dependency tree.  3.1 Naive Approach (NA)  In this approach we first run a parser on the input ", "acronyms": [[38, 40]], "long-forms": [[22, 36]]}, {"text": "Probabilistic topic models (PTM), such as probabilistic latent semantic indexing(PLSI) (Hofmann, 1999) and latent Dirichlet alocation(LDA) (Blei et al.,", "acronyms": [[134, 137], [28, 31], [81, 85]], "long-forms": [[107, 132], [0, 26], [42, 80]]}, {"text": " 1 Introduction Predicate argument structure (PAS) analysis is a shallow semantic parsing task that identifies ba-", "acronyms": [[46, 49]], "long-forms": [[16, 44]]}, {"text": "evaluation metrics. Legend: d = dependency f-score, _pr =  predicate-only f-score, M = METEOR, WN = WordNet,  H_FL = human fluency score, H_AC = human accuracy ", "acronyms": [[95, 97], [53, 55], [110, 114], [138, 142]], "long-forms": [[100, 107], [32, 42], [59, 73], [87, 93], [117, 136], [145, 159]]}, {"text": "referred to as Maximum Mutual Information Estimation (MMIE) and the second component Maximum Likelihood Estimation (MLE), therefore in this paper we use a brief notation for (1) just for conve-", "acronyms": [[116, 119]], "long-forms": [[89, 114]]}, {"text": "A Combinatory Categorial Grammar parsing (CCG) (Steedman, 2000) tool and a Tree Kernel (TK) classifier constitute the core of the system.", "acronyms": [[88, 90], [42, 45]], "long-forms": [[75, 86], [2, 32]]}, {"text": "Abstract  This paper provides a description of the Hong  Kong Polytechnic University (PolyU) System  that participated in the task #5 of SemEval-2, ", "acronyms": [[86, 91]], "long-forms": [[62, 84]]}, {"text": "observed in Dutch. Dutch shows a pattern in which  an arbitrary number of noun phrases (NP's) may be  followed by a finite verb and an arbitrary number ", "acronyms": [[88, 92]], "long-forms": [[74, 86]]}, {"text": "rejected by the space-saving algorithm.  Least Recently Used (LRU) When the volume of flow in a text stream rapidly increases, it is likely to relate to a burst of a certain topic.", "acronyms": [[62, 65]], "long-forms": [[41, 60]]}, {"text": "Marcu (2007) note that none of the tens of papers published over the last five years has shown that significant decreases in alignment error rate (AER) result in significant increases in translation perfor-", "acronyms": [[147, 150]], "long-forms": [[125, 145]]}, {"text": "10http://rapid-i.com/ classification problems, we were unable to achieve results with a Support Vector Machine (SVM) learner (libSVMLearner) using the Radial Base", "acronyms": [[112, 115], [126, 139]], "long-forms": [[88, 110]]}, {"text": "1  Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 42?47, Gothenburg, Sweden, April 27, 2014.", "acronyms": [[72, 77], [81, 85]], "long-forms": [[38, 70]]}, {"text": "3.2 Structural model We go beyond traditional feature vectors by employing structural models (STRUCT), which encode each comment into a shallow syntactic tree.", "acronyms": [[94, 100]], "long-forms": [[75, 85]]}, {"text": "It takes an examplebased approach to recognize IV words and follows description length gain (DLG) to infer OOV words in terms of their text compression effect.", "acronyms": [[93, 96], [47, 49], [107, 110]], "long-forms": [[68, 91]]}, {"text": "collection; however, to facilitate comparisons with prior work (e.g., McCarthy et al 2004a), all our experiments use the British National Corpus (BNC). In", "acronyms": [[146, 149]], "long-forms": [[121, 144]]}, {"text": "larger segments.  Speech Systems Incorporated (SSI) has been using a  version of this two-stage cascade of the MMI encoders in the ", "acronyms": [[47, 50], [111, 114]], "long-forms": [[18, 45]]}, {"text": "ing to their different degree of specification. In the hierarchy of relations, Arguments (ARG) include Subject (SUBJ), Object (OBJ), Indirect", "acronyms": [[90, 93], [112, 116], [127, 130]], "long-forms": [[79, 88], [103, 110], [119, 125]]}, {"text": "terns for them. In the terminology of Frame Semantics, the roles are called frame elements (FEs), and the words which evoke the frame are referred", "acronyms": [[92, 95]], "long-forms": [[76, 90]]}, {"text": " UW = ukWaC; GW = Gigaword; WP = Wikipedia; WN = WordNet; BN = British National Corpus (Aston and Burnard, 1998).", "acronyms": [[44, 46], [58, 60], [1, 3], [13, 15], [28, 30]], "long-forms": [[49, 56], [63, 79], [6, 11], [18, 26], [33, 42]]}, {"text": " 2 System Overview Our system, named PML Tree Query (PML-TQ), consists of three main components (discussed fur-", "acronyms": [[53, 59]], "long-forms": [[37, 51]]}, {"text": "The parsers are: the Berkeley parser with gold POS tags as input (Berk-G), the Berkeley product parser with two grammars (Berk-2), the Berkeley parser (Berk-1), the parser of Zhang and Clark (2009) (ZPAR), the Bikel parser (Bikel), the Stanford Factored parser (Stan-F), and the Stanford Unlexicalized PCFG parser (Stan-P). ", "acronyms": [[262, 268], [315, 321], [47, 50], [199, 203]], "long-forms": [[236, 253], [279, 313], [165, 180]]}, {"text": "Hypernym Hyponyms Co-Hyponyms Figure 2: The proposed semantic word embedding (SWE) learning framework (The left part denotes the state-of-the-art skip-gram model; The right part represents the semantic constraints).", "acronyms": [[78, 81]], "long-forms": [[53, 76]]}, {"text": "consider in (14) five salient phases of the passage: at the beginning of the process, the parts of river are localized to the exterior EXT(LOC), then to the boundary FRO(LOC), they arrive in", "acronyms": [[139, 142], [135, 138], [166, 169], [170, 173]], "long-forms": [[109, 118]]}, {"text": "Norm = Normalisation of input prior to tagging. SUC = Subset of Stockholm-Umea? ", "acronyms": [[48, 51]], "long-forms": [[54, 73]]}, {"text": "In contrast to standard 357 multi-class Word Sense Disambiguation (WSD), it uses a coarse-grained sense inventory that allows to", "acronyms": [[67, 70]], "long-forms": [[40, 65]]}, {"text": "In ? Proceedings of  the Eighth Text REtrieval Conference (TREC-9)?, ", "acronyms": [[59, 65]], "long-forms": [[25, 57]]}, {"text": "ifications) to be the first on the COMPS list, and further assigns a positive value for an additional feature INV (inverted) on verbs. This feature may", "acronyms": [[110, 113], [35, 40]], "long-forms": [[115, 123]]}, {"text": "and van Zaanen, 2006).  A Logical Graph (LG) is a directed, bipartite graph with two types of vertices, concepts and re-", "acronyms": [[41, 43]], "long-forms": [[26, 39]]}, {"text": "ferent setups with this parameter. We compare the following setups: (1) The majority baseline (BL) i.e., choosing the most frequent label (SR). (", "acronyms": [[95, 97], [139, 141]], "long-forms": [[85, 93]]}, {"text": "approaches (Gasic and Young, 2011; Lee and  Eskenazi, 2012; Williams, 2010; Young et al  2010) and Bayesian network (BN)-based  methods (Raux and Ma, 2011; Thomson and ", "acronyms": [[117, 119]], "long-forms": [[99, 115]]}, {"text": "puterization, Technical Report 6-CICC-MT55 (1995)  Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 174?182, Boulder, Colorado, June 2009.", "acronyms": [[136, 141], [33, 42]], "long-forms": [[95, 134]]}, {"text": "and reranking for the statistical parsing of spanish. In Proceedings of Human Language Technology (HLT) and the Conference on Empirical Methods in Natural", "acronyms": [[99, 102]], "long-forms": [[72, 97]]}, {"text": "performance\" (MOPs) presented here with  results we still need from system-external  \"measures of effectiveness\" (MOEs)25 MOE-  based methods evaluate (i) baseline unaided ", "acronyms": [[114, 118], [14, 18], [122, 125]], "long-forms": [[86, 111]]}, {"text": "Currently a large proportion of languageindependent MT approaches are based on the  statistical machine translation (SMT) paradigm  (Koehn, 2010).", "acronyms": [[117, 120], [52, 54]], "long-forms": [[84, 115]]}, {"text": "exp (14)    Short word difference penalty (SWDP): a  good translation should have roughly the same ", "acronyms": [[43, 47]], "long-forms": [[12, 41]]}, {"text": "al., 2008; NIST, 2008). We evaluate name (NAM) mentions for cross-lingual person (PER) and organi-", "acronyms": [[42, 45], [11, 15], [82, 85]], "long-forms": [[36, 40], [74, 80]]}, {"text": "\u0003\u0003\t\f\u0006\u0011\u000b\u0006\b strategies(Lewis, 1992).  We use probability threshold(PT) strategy where each document is assigned to the categories above a thresh-", "acronyms": [[65, 67]], "long-forms": [[43, 64]]}, {"text": "2002. The concaveconvex procedure (CCCP). In Proc.", "acronyms": [[35, 39]], "long-forms": [[10, 33]]}, {"text": "we used dialog features derived from manual annotations ? dialog acts (DA) and overt displays of power (ODP) ?", "acronyms": [[71, 73], [104, 107]], "long-forms": [[58, 69], [79, 102]]}, {"text": "labeled DGs.  (C3) Projectivity constraint(PJC): No arc crosses another arc5", "acronyms": [[43, 46], [8, 11]], "long-forms": [[19, 41]]}, {"text": "that combining additional knowledge sources, including lexical features (LX1) and the non-verbal features, prosody (PROS), motion (MOT), and context (CTXT), yields a further improvement (of 8.8%", "acronyms": [[116, 120], [131, 134], [73, 75], [150, 154]], "long-forms": [[107, 114], [123, 129], [55, 70], [141, 148]]}, {"text": " 3.2 Structure Mapping Theory French (2002) cites Structure Mapping Theory (SMT) (Gentner 1983) and its implementation in the Structure Mapping Engine (SME) (Falkenhainer, Forbus, and Gentner", "acronyms": [[76, 79], [152, 155]], "long-forms": [[50, 74], [126, 150]]}, {"text": "  For all the reasons listed above, a dictionary of  Turkish Language Association (TLA) is used in  this study.", "acronyms": [[83, 86]], "long-forms": [[53, 81]]}, {"text": "documents. Thus, HTMM can be seen both as a variation of Hidden Markov Model (HMM) and a variation of LDA.", "acronyms": [[78, 81], [17, 21], [102, 105]], "long-forms": [[57, 76]]}, {"text": "segmentation While the model structure is reminiscent of a factorial hidden Markov model (HMM), there are important differences that prevent the direct application of", "acronyms": [[90, 93]], "long-forms": [[69, 88]]}, {"text": "other models, such as vector space model (VSM), Okapi model (Robertson et al, 1994) or language model (LM). The pipeline meth-", "acronyms": [[103, 105], [42, 45]], "long-forms": [[87, 101], [22, 40]]}, {"text": "factfinding? technology, Information Extraction (IE), to determine exactly what happened in each article:", "acronyms": [[49, 51]], "long-forms": [[25, 47]]}, {"text": "ond accusative object, DA = dative, OG = genitive object, OP = prepositional object, PD = predicate, OC = clausal object, EP = expletive es 9AG = genitive adjunct", "acronyms": [[122, 124], [23, 25], [36, 38], [58, 60], [85, 87], [101, 103], [140, 143]], "long-forms": [[127, 136], [28, 34], [41, 56], [63, 83], [90, 99], [106, 120], [146, 162]]}, {"text": "order to adapt them to process dialects. This paper adopts this general framework: we propose a method to build a lexicon of deverbal nouns for Tunisian (TUN) using MSA tools and resources as starting material.", "acronyms": [[154, 157], [165, 168]], "long-forms": [[144, 152]]}, {"text": "episodes in lexical processing. In Proceedings of SWAP (Spoken Word Access Processes), A. Cutler, J. M McQueen, and R. Zondervan, ed.,", "acronyms": [[50, 54]], "long-forms": [[56, 84]]}, {"text": "the Natural Language Generation (NLG) component to create the textual form of the output and last, the Text To Speech (TTS) component to convert the text to spoken output.", "acronyms": [[119, 122], [33, 36]], "long-forms": [[103, 117], [4, 31]]}, {"text": "3.2 Feature Space An essential aspect of our approach below is the word sense disambiguation (WSD) of the noun. Us-", "acronyms": [[94, 97]], "long-forms": [[67, 92]]}, {"text": "coding-related concepts that appear in the EHR.  We use General Equivalence Mappings (GEMs) between ICD-9 and ICD-10 codes (CMS, 2014)", "acronyms": [[86, 90], [43, 46], [100, 105], [110, 116], [124, 127]], "long-forms": [[56, 84]]}, {"text": " The meaning of complex phrases is represented as  a composed LCS (CLCS). This is constructed \"com- ", "acronyms": [[67, 71]], "long-forms": [[53, 65]]}, {"text": "son. One is based on chi-square value and the other is based on Pointwise Mutual Information (PMI). ", "acronyms": [[94, 97]], "long-forms": [[64, 92]]}, {"text": "string is a false positive (FP). Each gold standard gene mention is counted as a false negative (FN) if it is not identified by the approach.", "acronyms": [[97, 99], [28, 30]], "long-forms": [[81, 95], [12, 26]]}, {"text": "shared task, namely FLORIAN (Florian et al.,  2003) and CHIEU-NG (Chieu and Ng, 2003). ", "acronyms": [[56, 64], [20, 27]], "long-forms": [[66, 78], [29, 36]]}, {"text": " Consider, for example, the tags DT (determiner) and NN (noun), and the four possible ordered tagpairs.", "acronyms": [[53, 55], [33, 35]], "long-forms": [[57, 61], [37, 47]]}, {"text": "languages studied differ widely, there is a quasistandard for presenting the material, in the form of interlinearized glossed text (IGT). IGT typically", "acronyms": [[132, 135], [138, 141]], "long-forms": [[102, 130]]}, {"text": "respect o silence and noise words are removed from  the Nbest lists 7, next the word stream is tagged with  Brill's part of speech (POS) tagger (Brill, 1994),  Version 1.14, adapted to the SWITCHBOARD Cor- ", "acronyms": [[132, 135]], "long-forms": [[116, 130]]}, {"text": "In a spoken dialog system that can handle natural conversation between a human and a machine, spoken language understanding (SLU) is a crucial component aiming at capturing", "acronyms": [[125, 128]], "long-forms": [[94, 123]]}, {"text": "ing to its current beliefs concerning the state of the dialogue. Reinforcement Learning (RL) has been more and more used for the optimisa-", "acronyms": [[89, 91]], "long-forms": [[65, 87]]}, {"text": "used as the seed to build a reliable hedge cue set. Maximum Entropy (MaxEnt) model is used as the learning technique to", "acronyms": [[69, 75]], "long-forms": [[52, 67]]}, {"text": " Support Vector Machine Support Vector Machines (SVMs) have been shown to be an effective classifier in text", "acronyms": [[49, 53]], "long-forms": [[24, 47]]}, {"text": "possession (PO)  process (PR)  quantity (QU)  relation (RE) ", "acronyms": [[41, 43], [12, 14], [26, 28], [56, 58]], "long-forms": [[31, 39], [0, 10], [17, 24], [46, 54]]}, {"text": "man::n a::d Figure 2: Lexical Only Centered Tree (LOCT) be::v", "acronyms": [[50, 54]], "long-forms": [[22, 48]]}, {"text": "7 8  Figure 2: The Sense Distribution  the help of a graphical user intefface(GUI) scans a  parsed sample article and indicates a series of se- ", "acronyms": [[78, 81]], "long-forms": [[53, 76]]}, {"text": "morpheme omitted.   We adopt Support Vector Machines(SVM) as  the device by which a given adnoun clause is ", "acronyms": [[53, 56]], "long-forms": [[29, 51]]}, {"text": "to efficiently implement their computation.  In Natural Language Processing (NLP), the typical dimensionality of databases, which are made", "acronyms": [[77, 80]], "long-forms": [[48, 75]]}, {"text": "are defined:    (1)  VSM-based (Vector Space Model based)  trigger word similarity: the trigger words ", "acronyms": [[21, 30]], "long-forms": [[32, 50]]}, {"text": "for many NLP applications including machine translation. In fact, Google Translate (GT)3 translates Examples (1) and (3) as ?", "acronyms": [[84, 86], [9, 12]], "long-forms": [[66, 82]]}, {"text": "II: irrelevant input due to ASR errors or noise.  We adopt logistic regression (LR)-based dialogue act tagging approach (Tur et al.,", "acronyms": [[80, 82], [28, 31]], "long-forms": [[59, 78]]}, {"text": "tionary. In (Zingarelli, 2008), we found 33 different types of prepositional phrases (PPs), which we grouped into 21 classes (for instance, all of the 48", "acronyms": [[86, 89]], "long-forms": [[63, 84]]}, {"text": " 1 Introduction A Chinese natural language processing (NLP) platform always includes lexical analysis (word", "acronyms": [[55, 58]], "long-forms": [[26, 53]]}, {"text": "work first arose out of a broader family of approaches to pattern classifier design known as Generalized Probabilistic Descent (GPD) (Katagiri et al, 1991).", "acronyms": [[128, 131]], "long-forms": [[93, 126]]}, {"text": "Specifically, the groups include children with ASD with language impairment (ALI); ASD with no language impairment (ALN); SLI alone; and typically developing (TD), which is", "acronyms": [[116, 119], [47, 50], [77, 80], [122, 125], [159, 161]], "long-forms": [[83, 114], [56, 75], [137, 157]]}, {"text": "2 Relation Extraction System In this section, we describe the features used in our basic relation extraction (RE) system. Given", "acronyms": [[110, 112]], "long-forms": [[89, 108]]}, {"text": "A decade ago, students interested in natural language processing arrived at universities having been exposed to the idea of machine translation (MT) primarily through science fiction.", "acronyms": [[145, 147]], "long-forms": [[124, 143]]}, {"text": "vided for training data.  the use of well-motivated Lexical Structures (LS's)  to capture the presuppositional nd anaphoric as- ", "acronyms": [[72, 76]], "long-forms": [[52, 70]]}, {"text": "The project ? Reference Corpus Middle Low German/ Low Rhenish (1200?1650)?2 transliterates and grammatically annotates the Middle Low German (GML) texts from which we take our examples. Be-", "acronyms": [[142, 145]], "long-forms": [[95, 133]]}, {"text": "ning of ORG (B-O). Many of them are mislabeled as O and beginning of location (B-L), resulting low recall and low precision for ORG.", "acronyms": [[79, 82], [8, 11], [13, 16], [128, 131]], "long-forms": [[56, 77]]}, {"text": "6 Related Work Two most prevalent discourse parsing treebanks are RST Discourse Treebank (RST-DT) (Carlson et al.,", "acronyms": [[90, 96]], "long-forms": [[66, 88]]}, {"text": "10-fold open test 62.80-58.54 59.15 66.46-65.55 65.55 65.55-64.63 Table 5: Comparison of Optimizers (Opinions in KNB Corpus) Batch Training (BFGS) Online Training (SD) Simulated parameter initialization chunked data selection Annealing", "acronyms": [[141, 145], [113, 116], [164, 166]], "long-forms": [[125, 139]]}, {"text": " 2.2 Thread-level analysis Next, we perform named entity recognition (NER) over each thread to identify entities such as package", "acronyms": [[70, 73]], "long-forms": [[44, 68]]}, {"text": "2https://www.mturk.com/mturk/. 3http://tartarus.org/martin/PorterStemmer/ 4Reviews with NDr = NTr are regarded as incorrectly classified by TopicSpam.", "acronyms": [[94, 97], [88, 91]], "long-forms": [[98, 125]]}, {"text": " In order to overcome these limitations, some  techniques like word sense induction (WSI) have  been proposed for discovering words?", "acronyms": [[85, 88]], "long-forms": [[63, 83]]}, {"text": "  TGTM P=p,pk ,b   TGTM PR=pr ,  pkr ,  b r   TGTM PL =p l ,  ph l ,  b l  ", "acronyms": [[24, 26], [2, 6], [19, 23], [46, 50], [51, 53]], "long-forms": [[27, 29], [55, 58]]}, {"text": "the text. Our proposed metric is called Sentiment Annotation Complexity (SAC). ", "acronyms": [[73, 76]], "long-forms": [[40, 71]]}, {"text": "three modules: (1) a question processing (QP) module; (2) a passage retrieval (PR) module; and (3) an answer processing (AP) module. Questions", "acronyms": [[121, 123]], "long-forms": [[102, 119]]}, {"text": "not observable from the sentence.  The dynamic nature of named entities (NEs) makes it difficult to enumerate all of their evolv-", "acronyms": [[73, 76]], "long-forms": [[57, 71]]}, {"text": "ical functions. Apart from commonly accepted grammatical functions, such as SB (subject) or OA (accusative object), Negra grammatical func-", "acronyms": [[76, 78], [92, 94]], "long-forms": [[80, 87], [96, 113]]}, {"text": "This examination can be held by plotting values of recall, precision and F-measure during each step  of merging process. Figure 5 shows the fluctuation of positive recall(PR), positive preclsion(AP),  averaged recall(AR), averaged precision and F-measure (FM).", "acronyms": [[171, 173]], "long-forms": [[155, 169]]}, {"text": "automatique, GDR I3 ATALA, Paris, November 1999.  Tang E.K., Natural languages Analysis in machine translation (MT) based on the STCG, PhD thesis, Sains Malaysia University, Penang, March 1994", "acronyms": [[112, 114], [13, 16], [20, 25], [129, 133], [135, 138], [55, 58]], "long-forms": [[91, 110]]}, {"text": "We also mark conjunct clauses with the feature nosubj if they are neither headed by an imperative nor contain a child node with the grammatical function SB (subject) or EP (expletive). This is useful in order to correctly parse", "acronyms": [[153, 155], [169, 171]], "long-forms": [[157, 164], [173, 182]]}, {"text": "the same discourse relation annotation style over different domain corpora: PDTB is annotated on top of Wall Street Journal (WSJ) corpus (financial news-wire domain); and it is aligned with Penn", "acronyms": [[125, 128], [76, 80]], "long-forms": [[104, 123]]}, {"text": "2007 task into four sub-tasks: (1) target word frame disambiguation (TWFD); (2) FE boundary detection (FEBD); (3) GF label classification (GFLC) and (4) FE label classification (FELC).", "acronyms": [[139, 143], [69, 73], [103, 107], [178, 182]], "long-forms": [[114, 137], [153, 176], [80, 101]]}, {"text": "Each word is considered as an  instance. Maximum Entropy (MaxEnt) is used in  this paper.", "acronyms": [[58, 64]], "long-forms": [[41, 56]]}, {"text": "Note: in genera\\], the resultant segments,  such as Declarative Sentence(SDEC),  Noun Phrase(NP), Inf init ive  Phrase(INF), and Verb Phrase(VP), ", "acronyms": [[93, 95], [73, 77], [119, 122], [141, 143]], "long-forms": [[81, 91], [52, 72], [98, 110], [129, 140]]}, {"text": "As an extension, Zhang et al (2008a) proposed two more categories: Structure Reordering Rules (SRR) and Discontiguous Phrase Rules (DPR).", "acronyms": [[95, 98], [132, 135]], "long-forms": [[67, 93], [104, 130]]}, {"text": "one of German, English or Japanese. The system has been designed  around the task of conference r gistration (CR). It has initially been ", "acronyms": [[110, 112]], "long-forms": [[85, 108]]}, {"text": " SYSTEM ARCHITECTURE The TIA used for MUC-3 was developed from the AD-TIA (Alternate Domain TIA) . This system, shown", "acronyms": [[67, 73], [38, 43], [25, 28]], "long-forms": [[75, 95]]}, {"text": "ton (within the Perseus Digital Library) based on  texts of the Classical era (Bamman, 2006), and  the Index Thomisticus Treebank (IT-TB) at the  Catholic University of the Sacred Heart in Milan, ", "acronyms": [[131, 136]], "long-forms": [[103, 129]]}, {"text": "constituent boundary prediction algorithm, the  followiug measures were used:  1) The cost time(CT) of the kernal  functions(CPU: Celeron TM 366, RAM: 64M).", "acronyms": [[96, 98], [125, 128], [138, 140], [146, 149]], "long-forms": [[86, 94]]}, {"text": "(selected expansion  terms are in italic)  OR(locator, finder, location,  directory) ", "acronyms": [[43, 45]], "long-forms": [[47, 53]]}, {"text": " 2 Related Work Reference resolution (RR), which is the task of resolving referring expressions (REs) to what they are", "acronyms": [[38, 40], [97, 100]], "long-forms": [[16, 36], [74, 95]]}, {"text": "Table 8: A comparison of syntactic SMT methods (part 1). FST=Finite State Transducer; SCFG=Synchronous Context-Free Grammar; TT=Tree Transducer. ", "acronyms": [[125, 127], [35, 38], [57, 60], [86, 90]], "long-forms": [[128, 143], [61, 84], [91, 123]]}, {"text": " The set of all homonyms built for a sentence is  called its morphological structure (MorphS). ", "acronyms": [[86, 92]], "long-forms": [[61, 84]]}, {"text": "parser on merged development PTB/PRBK data (section 24). Legend of models: ST=Split Tags; EC=enhanced connectivity.", "acronyms": [[75, 77], [29, 37], [90, 92]], "long-forms": [[78, 88], [93, 114]]}, {"text": "probabilities. Analysis showed that the correct tag most fre-  quently missing from the lattice was the DT (determiner)  tag.", "acronyms": [[104, 106]], "long-forms": [[108, 118]]}, {"text": "C5 Compound Analyser for Robust Morphological Analysis]. Centre for Text Technology (CTexT), North-West University, Potchefstroom, South Africa.", "acronyms": [[85, 90]], "long-forms": [[57, 83]]}, {"text": "source yes better Table 8: A comparison of syntactic SMT methods (part 1). FST=Finite State Transducer; SCFG=Synchronous Context-Free Grammar; TT=Tree Transducer.", "acronyms": [[75, 78], [53, 56], [104, 108], [143, 145]], "long-forms": [[79, 102], [109, 141], [146, 161]]}, {"text": " Rank Group Lexical Features 1 HM HM1 (head of M1) HM2 (head of M2)", "acronyms": [[34, 37]], "long-forms": [[39, 49]]}, {"text": "2 Related Work There have been several studies on supervised dialogue act (DA) modeling. To the best of", "acronyms": [[75, 77]], "long-forms": [[61, 73]]}, {"text": " In Proceedings of the 14th International Conference on World Wide Web (WWW), pages 342?351, Chiba.", "acronyms": [[72, 75]], "long-forms": [[56, 70]]}, {"text": "with one object sentences (IMP_VNP), V_NP_PP  agentless passive sentences (PAS_VNPP), V_NP bypassives (BYPAS_VN), and N_PP clauses (NPP) and  these are all decisions that happen in the realiser, ", "acronyms": [[132, 135], [27, 34], [37, 44], [75, 83], [103, 111]], "long-forms": [[118, 122], [86, 101], [46, 73]]}, {"text": "Draw Team (DT_DT); Team ? Competition (TM_CP); Team ? City / Province / Country ", "acronyms": [[39, 44], [11, 16]], "long-forms": [[33, 37], [0, 9]]}, {"text": "We focus on predicting an absolute indication of quality rather than only ranking the sentences by quality; this is why we use the Mean Absolute Error (MAE) as the main evaluation measure rather than Spearman?s correlation or DeltaAvg (Callison-Burch et al.,", "acronyms": [[152, 155], [226, 234]], "long-forms": [[131, 150]]}, {"text": "due to French proper names, which are left untranslated in the English parallel text.  15 CLEF = Cross Language Evaluation Forum, ? www.clef-campaign.org?.", "acronyms": [[90, 94]], "long-forms": [[97, 128]]}, {"text": "2010). Domain event extraction has been advanced in particular by the BioNLP Shared Task (ST) events (Kim et al, 2011a; Kim et al, 2011b), which have", "acronyms": [[90, 92], [70, 76]], "long-forms": [[77, 88]]}, {"text": " 4.1.7 Doctors? Prescriptions (PRESC) Some of our food-health relations are also men-", "acronyms": [[31, 36]], "long-forms": [[16, 29]]}, {"text": "DO: parent:number := node:number; parent:gender := node:gender; 3.1.5 Preposition without children (PrepNoCh) In our dependency trees, the preposition is the", "acronyms": [[100, 108], [0, 2]], "long-forms": [[70, 98]]}, {"text": " Chapter 1 has the lowest pi?S score in the table, and also the highest bias (BS). One of the reasons for", "acronyms": [[78, 80]], "long-forms": [[72, 76]]}, {"text": "To standardize the measures to have fixed bounds, (Strehl and Ghosh, 2003) defined the normalized Mutual Information (NMI) as: NMI(Cr,Cg) =", "acronyms": [[118, 121], [127, 130]], "long-forms": [[87, 116]]}, {"text": "pendencies is only context-free (section 2.1). Our argument is based on our desire to use a discourse grammar in natural language generation (NLG). It is well-known that", "acronyms": [[142, 145]], "long-forms": [[113, 140]]}, {"text": "An entity has  three types of mention: NAM (proper name), NOM  (nominal) or PRO (pronoun). A relation was ", "acronyms": [[76, 79], [39, 42], [58, 61]], "long-forms": [[81, 88], [51, 55], [64, 71]]}, {"text": " select_id_schema(Sign,Sit,Phrase,NewSit) :-  id_schema(ID),  extend~sit (Sit,NewS\\]l), ", "acronyms": [[56, 58]], "long-forms": [[46, 55]]}, {"text": "Table 3: Example of retrieved Wikipedia pages from the four different methods tested in this paper.  Results of diverse merging (DivM) appear to cover more topics relevant to the conversation fragment than other methods.", "acronyms": [[129, 133]], "long-forms": [[112, 127]]}, {"text": "tion string in discourse: PER, GPE, ORG, LOC,  FAC, NPER (NOMINAL PER), NGPE, NORG,  NLOC, NFAC, PPER (PROUNOUN PER),  PGPE, PORG, PLOC, and PFAC.", "acronyms": [[97, 101], [26, 29], [31, 34], [36, 39], [41, 44], [47, 50], [52, 56], [72, 76], [78, 82], [85, 89], [91, 95], [119, 123], [125, 129], [131, 135], [141, 145]], "long-forms": [[103, 115], [58, 69]]}, {"text": "wards a Shared Task for Multiword Expressions. ACL Special Interest Group on the Lexicon (SIGLEX), Marrakech.", "acronyms": [[90, 96], [47, 50]], "long-forms": [[51, 88]]}, {"text": "Eparl+NC no 29.28 (0.11) 55.28 (0.13) Eparl+NC yes 29.26 (0.10) 55.44 (0.29) Table 1: Results of the study on number translation (NT) from English to French", "acronyms": [[130, 132], [44, 46], [6, 8]], "long-forms": [[110, 128]]}, {"text": "The unspecified role filler is not 'bound'  to a complement (i.e. any item on the SUBCAT list)  but is existentially quantified (EX-Q). The ergative ", "acronyms": [[129, 133], [82, 88]], "long-forms": [[103, 127]]}, {"text": " 66 adopt a minimum Bayes risk (MBR) approach, with the goal of finding the graph with the lowest", "acronyms": [[32, 35]], "long-forms": [[12, 30]]}, {"text": "Table 1). CC = coordinating conjunction; CD = cardinal number; JJ = adjective; MD = modal; NN = singular noun; NNP = proper noun; NNPS = plural proper noun; NNS = plural noun; RB = adverb; TO = to; VB =", "acronyms": [[41, 43], [79, 81], [10, 12], [63, 65], [91, 93], [111, 114], [130, 134], [189, 191], [198, 200], [176, 178], [157, 160]], "long-forms": [[46, 54], [84, 89], [15, 39], [68, 77], [105, 109], [117, 128], [137, 155], [163, 174], [181, 187]]}, {"text": "means, correct  sentences could then be  computat iona l ly  generated from the lo-  g ical  patters  ment ioned  in (II). ", "acronyms": [], "long-forms": []}, {"text": "He et al (2010) measure the similarity between hypothesis and reference translation in terms of the Lexical Functional Grammar (LFG) representation.", "acronyms": [[128, 131]], "long-forms": [[100, 126]]}, {"text": "tends the comparison set to players of AS Roma.  Prepositional phrases (PPs), gerunds, and relative clauses introduce additional complexity.", "acronyms": [[72, 75], [39, 41]], "long-forms": [[49, 70]]}, {"text": "recursive noun phrases (NPs), main verb groups (MVs), and a common annotation for adjectival and adverbial phrases (APs). Example (3) be-", "acronyms": [[116, 119], [24, 27], [48, 51]], "long-forms": [[97, 114], [10, 22], [30, 46]]}, {"text": " 2.2 Human Intelligence Tasks A Human Intelligence Task (HIT) is a short paid task on MTurk.", "acronyms": [[57, 60]], "long-forms": [[32, 55]]}, {"text": "2 Data In this study, we use a collection of blog posts from five blogs: Carpetbagger(CB)1, Daily Kos(DK)2, Matthew Yglesias(MY)3, Red State(RS)4, and Right", "acronyms": [[86, 88], [102, 104], [125, 127], [141, 143]], "long-forms": [[73, 84], [92, 100], [108, 124], [131, 140]]}, {"text": "logical subject/object and its verb governor, General  Event (GE) on who did what when and where and  Predefined Event (PE) such as Management  Succession and Company Acquisition.", "acronyms": [[120, 122], [62, 64]], "long-forms": [[102, 118], [46, 60]]}, {"text": "navigation3  SCAN was developed initially for the TREC-6  Spoken Document Retrieval (SDR) task, which em-  ploys the NIST/DARPA HUB4 Broadcast News cor- ", "acronyms": [[85, 88], [117, 127], [128, 132]], "long-forms": [[58, 83], [50, 54]]}, {"text": " One application area of increasing interest is  information extraction (IE) (see, e.g., Cowie and  Lehnert (1996)).", "acronyms": [[73, 75]], "long-forms": [[49, 71]]}, {"text": "and Darooneh, 2011).  Recurrent neural networks(RNNs) (Elman, 1990) has been applied to many sequential prediction", "acronyms": [[48, 52]], "long-forms": [[22, 46]]}, {"text": "77 (a) README.txt file (d) RPM Spec PACKAGE section (metadata) Bean Scripting Framework (BSF) is a set of Java classes which provides an easy to use scripting language support", "acronyms": [[89, 92], [27, 30]], "long-forms": [[63, 87]]}, {"text": "annotations of sentiment values for individual syntactic phrases in a binarized tree, and an approach based on recursive neural tensor networks (RNTN) which yields significant improvements over the ear-", "acronyms": [[145, 149]], "long-forms": [[111, 143]]}, {"text": "edges. The NEs includes personal name(PRE), location name(LOC) and organization name(ORG). ", "acronyms": [[85, 88], [11, 14], [38, 41], [58, 61]], "long-forms": [[67, 79], [24, 32], [44, 52]]}, {"text": "following formulas.  PPe = Pe(Se)? ", "acronyms": [[21, 24]], "long-forms": [[27, 32]]}, {"text": "Model of Argumentation. Proceedings of American Association .for  Artificial Intelligence (AAAI) Conference: 313-315. ", "acronyms": [[91, 95]], "long-forms": [[39, 89]]}, {"text": " ? Template Element (TE) -- Extract  basic information related to organization and ", "acronyms": [[21, 23]], "long-forms": [[3, 19]]}, {"text": "Specifically, we investigate dialectal language in publicly available Twitter data, focusing on AfricanAmerican English (AAE), a dialect of Standard American English (SAE) spoken by millions of peo-", "acronyms": [[121, 124], [167, 170]], "long-forms": [[96, 119], [140, 165]]}, {"text": "(Roelofs, 2004), experiments on priming (Schvaneveldt et al., 1976) or the tip of the tongue problem (TOT) (Brown and McNeill, 1996).", "acronyms": [[102, 105]], "long-forms": [[75, 92]]}, {"text": "roles they typically enter: ACT (Actor), PAT (Patient), ADDR (Addressee), ORIG (Origin) and EFF (Effect). Syntactic criteria are used to identify", "acronyms": [[92, 95], [28, 31], [41, 44], [56, 60], [74, 78]], "long-forms": [[97, 103], [33, 38], [46, 53], [62, 71], [80, 86]]}, {"text": "Secondly, there is the group of speech particles which are not part of the core sentence construction,  yet pragmatically cannot stand on their own. These 'sentence external' (SE) elements can be subclassified into two classes.", "acronyms": [[176, 178]], "long-forms": [[156, 173]]}, {"text": "The evaluation strategy follows the global standard as  Text Retrieval Conference (TREC)8 metrics. It ", "acronyms": [[83, 87]], "long-forms": [[56, 81]]}, {"text": "sentence length. This gives us five metrics of complexity: sentence length (SL), tree depth (TD), branching factor (BF), normalized tree depth", "acronyms": [[76, 78], [93, 95], [116, 118]], "long-forms": [[59, 74], [81, 91], [98, 114]]}, {"text": "J = Japanese ????? S = Spanish  JV = Joint Venture ?????????? ME = Microelectronics ", "acronyms": [[32, 34], [62, 64]], "long-forms": [[37, 50], [4, 12], [67, 83]]}, {"text": "{xiaoluo,hraghav,vittorio,smaskey,raduf}@us.ibm.com Abstract In natural language question answering (QA) systems, questions often contain terms and", "acronyms": [[101, 103]], "long-forms": [[81, 99]]}, {"text": "curacy of an automatic classifier means to compare its output with the correct semantic tags on a Gold Standard (GS) dataset. Within our formal", "acronyms": [[113, 115]], "long-forms": [[98, 111]]}, {"text": " First of all, we now first formally introduce DUDES: Definition 1 (DUDES) A DUDES is a 7-tuple (m, l, t, U,A, S,C) consisting of", "acronyms": [[68, 73], [77, 82]], "long-forms": [[54, 66]]}, {"text": "Var. 47.9 60.7 67.9 70.8 75.0 77.3 Pronunciation (PHL) with Pron. Var.", "acronyms": [[50, 53], [66, 69], [60, 64]], "long-forms": [[35, 48]]}, {"text": "tion using a method similar to FOIL (Quin-  lan, 1990) and bottom-up generalization using  Least General Generalizations (LGG's). Ad- ", "acronyms": [[122, 127], [31, 35]], "long-forms": [[91, 120]]}, {"text": "rada@cs.unt.edu Abstract Amazon Mechanical Turk (MTurk) is a marketplace for so-called ?", "acronyms": [[49, 54]], "long-forms": [[32, 47]]}, {"text": "tation from a user?s speech. That is, it consists of automatic speech recognition (ASR) and language understanding (LU).", "acronyms": [[83, 86], [116, 118]], "long-forms": [[53, 81], [92, 114]]}, {"text": " ? Modifier substitution (M-Sub) :  t2 is a substitution of t~ if and only if : ", "acronyms": [[26, 31]], "long-forms": [[3, 24]]}, {"text": "at meeting the needs of CSR research, and at serving in  a complementary ole to the corpora being collected in  the interactive Air Travel Information System (ATIS) do-  main.", "acronyms": [[159, 163], [24, 27]], "long-forms": [[128, 157]]}, {"text": " (Markov) that significantly differed from the output of the noisy channel model (NoisyC), which confirms our finding that Markovized models can pro-", "acronyms": [[82, 88]], "long-forms": [[61, 74]]}, {"text": "229 2 Participation in STS-SEM2013  The Semantic Textual Similarity (STS) task consists of estimated the value of semantic similarity ", "acronyms": [[69, 72], [23, 34]], "long-forms": [[40, 67]]}, {"text": "In Proceedings of the Eighteenth International Conference on Machine Learning (ICML), pages 282?289. ", "acronyms": [[79, 83]], "long-forms": [[33, 77]]}, {"text": " 3.2 Swedish Constructicon The Swedish Constructicon (SweCcn) 4", "acronyms": [[54, 60]], "long-forms": [[31, 52]]}, {"text": "Statistical model (S) O O O O O O O O  Cooperative(CPR)  O   O O  O  Corrective(COR)   O  O  O O  Self-directing(SFD)    O  O O O ", "acronyms": [[80, 83], [19, 21], [51, 54], [113, 116]], "long-forms": [[69, 79], [0, 11], [39, 50], [98, 112]]}, {"text": "dimensionality reduction. NG = ngrams, E = emoticon replacement, IR = informal register replacement, TL = tweet length, RT = retweet count, SVO = subject-verb-", "acronyms": [[65, 67]], "long-forms": [[70, 87]]}, {"text": "We performed a 10-fold cross-validation on each dataset and experimented with three feature sets by using a Support Vector Machine (SVM) classifier (Cortes and Vapnik, 1995).", "acronyms": [[132, 135]], "long-forms": [[108, 130]]}, {"text": " They solve this by formulating the problem as a quadratic assignment problem (QAP). But, even", "acronyms": [[79, 82]], "long-forms": [[49, 77]]}, {"text": "PCFG score (SP ) 49.5 50.0 TSG score (ST ) 49.5 49.7 Charniak score (SC) 50.0 50.0 l + S3 61.0 64.3", "acronyms": [[69, 71], [0, 4], [12, 14], [27, 30], [38, 40]], "long-forms": [[62, 67]]}, {"text": "to systems that rely on brittle features is that many texts are not well-formed. One  such class of texts are those that are the output of optical character recognition (OCR);  typically these texts contain many extraneous or incorrect characters.", "acronyms": [[170, 173]], "long-forms": [[139, 168]]}, {"text": "fn is tfi, and foov is fq in Feature (1).  v. Df_Rank (D-Rank): It is similar to SRank and computed based on Rank(i)= ", "acronyms": [[55, 61], [81, 86]], "long-forms": [[46, 53]]}, {"text": "The development of efficient estimation procedures for context-dependent acoustic models revolutionised the field of Automatic Speech Recognition (ASR) (Young et al.,", "acronyms": [[147, 150]], "long-forms": [[117, 145]]}, {"text": " The graph in figure 2 shows that as the number of relevant documents increases, average precision (AveP) after feedback increases considerably for each extra relevant", "acronyms": [[100, 104]], "long-forms": [[81, 98]]}, {"text": "sisting of analyses automatically created by systems participating in the recent BioNLP Shared Task (ST) 2011. In providing for the", "acronyms": [[101, 103], [81, 87]], "long-forms": [[88, 99]]}, {"text": "The resulting unit denominates a concept which belongs to the language for special purposes (LSP). ", "acronyms": [[93, 96]], "long-forms": [[62, 91]]}, {"text": "(Marcus et al., 1993) whereas IN = preposition or conjunction, subordinating; CC = Coordinating Conjunction; VBN = Verb, past participle; VBG = verb, gerund or present partici-", "acronyms": [[78, 80], [30, 32], [109, 112], [138, 141]], "long-forms": [[83, 107], [115, 136], [144, 175]]}, {"text": "Sangkeun Jung, Cheongjae Lee, Kyungduk Kim, Gary Geunbae Lee Department of Computer Science and Engineering Pohang University of Computer Science and Technology(POSTECH) San 31, Hyoja-Dong, Pohang, 790-784, Korea", "acronyms": [[161, 168]], "long-forms": [[108, 159]]}, {"text": "helpful in identifying the embedded words. However  some ambiguous segmentation strings(ASSs) and  unregistered words (i.e. the word that is not registered ", "acronyms": [[88, 92]], "long-forms": [[57, 87]]}, {"text": "ers; (ii) to design an initial policy for reinforcement learning of multimodal clarifications.4 We use the Nite XML Toolkit (NXT) (Carletta et al, 2003) to represent and browse the data and to de-", "acronyms": [[125, 128]], "long-forms": [[107, 123]]}, {"text": "The training set consisted of 12,927 texts: News reports (News) about Education (Edu), Editorials (Edit.) about Defense (Def), and Letters to the Editor (LttE) about Medicine (Med). ", "acronyms": [[154, 158], [81, 84], [99, 103], [121, 124], [176, 179]], "long-forms": [[131, 152], [70, 79], [87, 97], [112, 119], [166, 174]]}, {"text": "In Proc. of the Eighth  Text Retrieval Conference (TREC-8), pages 151162.", "acronyms": [[51, 57]], "long-forms": [[16, 49]]}, {"text": "report false positives. This can be quantified by the positive predictive value (PPV), or probability that a research finding is true.", "acronyms": [[81, 84]], "long-forms": [[54, 79]]}, {"text": " 1 Introduction  When a natural language processing (NLP) system  is created in a modular fashion, it can be relatively ", "acronyms": [[53, 56]], "long-forms": [[24, 51]]}, {"text": "SIZE = sizesensorreading85 SHAPE = shapesensorreading62 COLOUR = coloursensorreadning78 ?", "acronyms": [[56, 62], [0, 4], [27, 32]], "long-forms": [[65, 87], [7, 26], [35, 55]]}, {"text": "Association measure Following the aforementioned studies, we implemented these popular measures: pointwise mutual information (PMI), log-likelihood ratio (LL) and chi-square (?", "acronyms": [[127, 130], [155, 157]], "long-forms": [[97, 125], [133, 147]]}, {"text": "The basic aim of Acquilex is the  development of techniques and methods in order to use  Machine Readable Dictionaries (MRD) * for building lexical  components for Natural Language Processing Systems.", "acronyms": [[120, 123]], "long-forms": [[89, 118]]}, {"text": " [and, therefore, so]  Contrastive Connectives (CC)  men den ?", "acronyms": [[48, 50]], "long-forms": [[23, 46]]}, {"text": "currently concerns include Chinese personal  names( CN), transliterated foreign personal names( TFN)  and Chinese place names(CPN). They can not be ", "acronyms": [[126, 129], [52, 54], [96, 99]], "long-forms": [[106, 124], [27, 49], [57, 93]]}, {"text": "Pivot, RHS),  generate all subconstituents  generate _rhs ( RHS ),  generate material on path to root ", "acronyms": [[60, 63], [7, 10]], "long-forms": [[54, 57]]}, {"text": "tend to conflate the distances between all possible sense pairs. Latent semantic analysis (LSA) (Landauer et al, 1998) has also been used to measure dis-", "acronyms": [[91, 94]], "long-forms": [[65, 89]]}, {"text": "is set to 0.95 and threshold_f is set to 1;  Step 3. Use TCT (triple context template) matching  model to extract 2-char, 3-char and 4-char ", "acronyms": [[57, 60]], "long-forms": [[62, 85]]}, {"text": "` and survival variables S`. Languages shown are Latin (LA), Vulgar Latin (VL), Proto-Iberian (PI), Italian (IT), Portuguese (PT), and Spanish (ES). Note that only modern", "acronyms": [[75, 77], [126, 128], [56, 58], [95, 97], [109, 111], [144, 146]], "long-forms": [[61, 73], [114, 124], [49, 54], [80, 93], [100, 107], [135, 142], [6, 24]]}, {"text": "collected as follows: Positive Diccn: 3,730 Chinese positive terms (e.g., /good-looking, / lucky) were collected from the Chinese Vocabulary for Sentiment Analysis (VSA)20 released by HOWNET.", "acronyms": [[165, 168], [184, 190]], "long-forms": [[130, 163]]}, {"text": "an efficient bottom-up algorithm. The asymptotic time complexity of this search is O(SR) where S is the number of source nodes andR is the number", "acronyms": [[85, 87]], "long-forms": [[73, 79]]}, {"text": "lines are published results by Hall and Nivre 2008 (HN08), Maier et al 2012 (M12), van Cranenburgh 2012 (C12), Kallmeyer and Maier 2013 (KM13), van Cranenburgh and Bod 2013 (CB13), and Versley 2014a, 2014b (V14a, V14b).", "acronyms": [[137, 141], [52, 56], [77, 80], [105, 108], [174, 178], [207, 217]], "long-forms": [[111, 135], [31, 50], [60, 75], [87, 103], [148, 172], [185, 205]]}, {"text": "? P5E3N4S3, F W I International Language of Service and Maintenance (ILSAM) (Pym 1990) is an influential language similar to Caterpillar Fundamental English, from which it was derived", "acronyms": [[69, 74], [2, 10]], "long-forms": [[18, 67]]}, {"text": "Abstract In this paper, we explore the possibility of leveraging Residual Networks (ResNet), a powerful structure in constructing extremely", "acronyms": [[84, 90]], "long-forms": [[65, 82]]}, {"text": "One is manually typing the text transcriptions which we regarded as the Correct Recognition Result (CRR) transcription, and another is the ASR result which", "acronyms": [[100, 103], [139, 142]], "long-forms": [[72, 98]]}, {"text": "descriptions 3800 4247 Table 2: Properties of the annotated two subcorpora, genetics (GEN) and computational linguistics (CL)", "acronyms": [[86, 89], [122, 124]], "long-forms": [[76, 84], [95, 120]]}, {"text": "  Figure 1: Example of a BDT sentence in the CoNLL-X format  (V = main verb, AUXV = auxiliary verb, CONJ = conjunction, REL = subordinated clause, CMP = completive, ccomp_obj =  clausal complement object, ERG = ergative, SUBJ:3S: subject in 3rd person sing.,", "acronyms": [[77, 81], [100, 104], [147, 150]], "long-forms": [[84, 98], [107, 118], [153, 163]]}, {"text": "CoTrain vs. TSVM(EN) 1.41E-05 0.00311 2.17E-08 CoTrain vs. TSVM(ENCN) 1.37E-08 0.0113 0.0396 CoTrain vs. SelfTrain(CN) 7.07E-18 2.79E-11 6.53E-07 CoTrain vs. SelfTrain(EN) 1.01E-07 0.0192 1.35E-07", "acronyms": [[115, 117], [12, 16], [17, 19], [59, 63], [64, 68], [168, 170]], "long-forms": [[93, 100]]}, {"text": "wk} be its vocabulary. In the monolingual settings, the Vector Space Model (VSM) is a k-dimensional space Rk, in which the text tj ?", "acronyms": [[76, 79], [106, 108]], "long-forms": [[56, 74]]}, {"text": "document-level CLOA tasks, respectively. The evaluations on simplified Chinese (SC) opinion analysis by using small SC training data and large", "acronyms": [[80, 82], [15, 19], [116, 118]], "long-forms": [[60, 78]]}, {"text": "5.1 Data  We have two kinds of training data from general  domain: Labeled Data (LD) and Unlabeled Data  (UD).", "acronyms": [[81, 83], [106, 108]], "long-forms": [[67, 79], [89, 103]]}, {"text": "HowNet and Its Computation of Meaning. In Actes de COLING-2010, Beijing, 4 p. Francopoulo, G., Bel, N., George, M., Calzolari, N., Monachini, M., Pet, M. and Soria, C. (2009). Multilingual resources for NLP in the lexical markup framework (LMF). In journal de Language Resources and Evaluation, March 2009, Volume 43, pp.", "acronyms": [[240, 243]], "long-forms": [[214, 238]]}, {"text": "3.1 Overview   Graph-based Representation  Attribute Relation Graph (ARG) (Tsai and Fu, 1979)  is used to represent information in our approach.", "acronyms": [[69, 72]], "long-forms": [[43, 67]]}, {"text": " 4 Dimensionality Reduction In this section, the Sparse Projection (SP) algorithm is described (see also Algorithm 1). SP is the core", "acronyms": [[68, 70]], "long-forms": [[49, 66]]}, {"text": " minimizes the multiway normalized cut(MNCut): MNCut(I) = K ?", "acronyms": [[39, 44], [47, 52]], "long-forms": [[15, 37]]}, {"text": " (d) The word?s position in the sentence (e) The word?s Part of speech (POS) tag, based on the Stanford POS tagger2", "acronyms": [[72, 75], [104, 107]], "long-forms": [[56, 70]]}, {"text": "(Figure 2). Argviz is a web-based application, built using Google Web Toolkit (GWT),4 which allows users to visualize and manipulate SITS?s outputs en-", "acronyms": [[79, 82], [133, 138]], "long-forms": [[59, 77]]}, {"text": " ) are based on the pairwise mutual information (PMI) between two phrases.", "acronyms": [[49, 52]], "long-forms": [[20, 47]]}, {"text": "20M Lattice Y 9.0 3.1 1.0 13.1 2801 20M List Y 9.0 3.3 0.9 13.3 16030 Table 2: Results for parsing HUB-1 n-best word lattices and lists: OP = overparsing, S = substutitions (%), D = deletions (%), I = insertions (%), T = total WER (%).", "acronyms": [[137, 139], [99, 104], [227, 230]], "long-forms": [[142, 153], [182, 191], [201, 211], [221, 226]]}, {"text": "whole of MARY = KMary>.  referent of MARY = Mary. ", "acronyms": [[37, 41], [9, 13]], "long-forms": [[44, 48], [17, 21]]}, {"text": "Swedish 83.01 (82.44) 88.53 (87.36) 81.20 (81.10) 86.50 (85.86) 82.95 (82.66*) 88.29 (87.45*) 82.89 (82.44) 88.61 (87.55) Turkish 62.70 (71.27) 73.67 (78.57) 59.83 (68.31) 70.15 (75.17) 63.27* (71.63*) 73.93* (78.72*) 62.58 (70.96) 73.09 (77.95) Table 1: Parsing accuracy of the undirected planar parser with naive (UPlanarN) and label-based (UPlanarL) postprocessing in comparison to the directed planar (Planar) and the MaltParser arc-eager projective (MaltP)", "acronyms": [[316, 324], [343, 351], [406, 412], [455, 460]], "long-forms": [[279, 314], [398, 404], [422, 432]]}, {"text": "sion with LSA and filtering according to the ET.  Further on, we apply sentiment analysis (SA)  using the approach described in Section 5.3 and ", "acronyms": [[91, 93], [10, 13], [45, 47]], "long-forms": [[71, 89]]}, {"text": "for the task: a training dataset (TrainSet) with 9675 messages directly retrieved from Twitter; a development dataset (DevSet), with 1654 messages; the testing dataset from 2013 run, which", "acronyms": [[119, 125], [34, 42]], "long-forms": [[98, 117], [16, 32]]}, {"text": "semantic tree setups are depicted as follows:  TP2TP1 (a) Bag Of Features(BOF) ENT", "acronyms": [[74, 77], [47, 53], [79, 82]], "long-forms": [[58, 72]]}, {"text": "languages.  Mutual Information (MI)  For the purpose of this experiment we use a ", "acronyms": [[32, 34]], "long-forms": [[12, 30]]}, {"text": "OWL DL is a logical language that combines the expressivity of OWL2 with the favourable computational properties of Description Logics (DL), notably decidability and monotonicity (Baader et al, 2003).", "acronyms": [[136, 138], [0, 3], [4, 6], [63, 67]], "long-forms": [[116, 134]]}, {"text": "We annotate the relation node in the path with the exact relation word (as a lexical constraint) and the POS (postag constraint). We create a re-", "acronyms": [[105, 108]], "long-forms": [[110, 116]]}, {"text": "junct verbs (ConjVs), the Non-MonoClausal  Verbs (NMCV) and Auxiliary Construction  (AC) occur as conjunct verbs (ConjVs).  The ", "acronyms": [[114, 120], [13, 19], [50, 54], [85, 87]], "long-forms": [[98, 112], [0, 11], [26, 48], [60, 82]]}, {"text": "should not be allowed?.  Gay Marriage (GM) 5", "acronyms": [[39, 41]], "long-forms": [[25, 37]]}, {"text": "? This material is based on research supported in part by the U.S. National Science Foundation (NSF) under Grant No.", "acronyms": [[96, 99], [62, 66]], "long-forms": [[67, 94]]}, {"text": "sulting matrices be M1 and M2, respectively. In step (3), SentIDs (sentences where the two words appear with the specified relation) are obtained by", "acronyms": [[58, 65]], "long-forms": [[67, 96]]}, {"text": "plex knowledge discovery and applications, including but not limited to Question Answering (QA), Machine Translation (MT), and Information Retrieval (IR).", "acronyms": [[118, 120], [92, 94], [150, 152]], "long-forms": [[97, 116], [72, 90], [127, 148]]}, {"text": "1 Introduction Large-scale open-domain question answering from structured Knowledge Base (KB) provides a good balance of precision and recall in everyday QA", "acronyms": [[90, 92], [154, 156]], "long-forms": [[74, 88]]}, {"text": " 4.3 MORPHOTACT1C MODEL  An associative Morphotactic Model (MTModel) is a pair  <{MRi},<*>, where {MRi} is a set of morphotactic rules ", "acronyms": [[60, 67], [82, 85], [99, 102]], "long-forms": [[40, 58]]}, {"text": "Peter Robinson; Philip Tuddenham; 3 Visualisation Scalable Vector Graphics (SVG)1 is a language for describing two-dimensional graphics and graphical", "acronyms": [[76, 79]], "long-forms": [[50, 74]]}, {"text": "A model-theoretic coreference scoring scheme. In Proceedings of Message Understanding Conference 6 (MUC-6), pages 45?52. ", "acronyms": [[100, 105]], "long-forms": [[64, 98]]}, {"text": "data are classified manually (Human) into three  stability classes. Decision Tree (DT) automatic  algorithm C4.5 (Quinlan, 1993; Weiss & Kulikowski, ", "acronyms": [[83, 85]], "long-forms": [[68, 81]]}, {"text": "In all other tests, including all closed  tests, City University of Hong Kong (CityU)  open test and Microsoft Research (MSR) open  test, we trained our system using the relevant ", "acronyms": [[121, 124], [79, 84]], "long-forms": [[101, 119], [49, 64]]}, {"text": " 5.2 Corpus Benchmark Tool The Corpus Benchmark Tool(CBT) is one of the components in GATE which enables automatic evaluation of an", "acronyms": [[53, 56]], "long-forms": [[31, 51]]}, {"text": "The starting point for the approach followed here was a dissatisfaction with certain  aspects of the theory of quasi-logical form as described in Alshawi (1990, 1992), and  implemented in SRI's Core Language Engine (CLE). In the CLE-QLF approach, as ra- ", "acronyms": [[216, 219], [188, 192], [229, 236]], "long-forms": [[194, 214]]}, {"text": "suffix and prefix information, as well as information about the sorrounding words and their tags are used to develop a Maximum Entropy (MaxEnt) based Hindi NER system.", "acronyms": [[136, 142], [156, 159]], "long-forms": [[119, 134]]}, {"text": "automatic speech recognition (ASR), machine translation (MT), text-to-speech synthesis (TTS), as well as technology for language resource and fundamental tool de-", "acronyms": [[88, 91], [30, 33], [57, 59]], "long-forms": [[62, 86], [0, 28], [36, 55]]}, {"text": "tion of predicate signs. Ramchand divides events into a maximum of three hierarchical phrases: an initiation phrase (InitP), a process phrase (ProcP), and a result phrase (ResP).", "acronyms": [[117, 122], [143, 148]], "long-forms": [[98, 115], [127, 141]]}, {"text": "375 that...). Extreme case formulations (ECF) are lexical patterns emphasizing extremeness (e.g., This is", "acronyms": [[41, 44]], "long-forms": [[14, 39]]}, {"text": " Conditional Random Field  A conditional random field (CRF)[5] can be seen  as an undirected graph model in which the nodes ", "acronyms": [[55, 58]], "long-forms": [[29, 53]]}, {"text": "chine learning models based on three different well known techniques, decision trees (C4.5), rule induction (RIPPER) and maximum entropy (MaxEnt), in order to find out which approach is the most suitable", "acronyms": [[138, 144], [109, 115]], "long-forms": [[121, 136]]}, {"text": "(Koehn, 2004a). Furthermore, they extendedWSD to phrase sense disambiguation (PSD) (Carpuat and Wu, 2007a).", "acronyms": [[78, 81]], "long-forms": [[49, 76]]}, {"text": "We think, based on the explicit sentences, several Support Vector Machine (SVM) classifiers can be established to do this task.", "acronyms": [[75, 78]], "long-forms": [[51, 73]]}, {"text": "demonstrate such dependencies.  The Maximum Entropy (MaxEnt) model (Berger et al, 1996) estimates the probability of a time-bin", "acronyms": [[53, 59]], "long-forms": [[36, 51]]}, {"text": "Abstract This paper reports about the development of a Named Entity Recognition (NER) system for Bengali using the statistical Conditional", "acronyms": [[81, 84]], "long-forms": [[55, 79]]}, {"text": "pris VPE (participe assE)  la AR  TD  par PREP (prEposition)  main SUBS (substamif) ", "acronyms": [[42, 46]], "long-forms": [[48, 59]]}, {"text": "In Proceedings of The 52nd Annual Meeting of the Association for Computational Linguistics(ACL). ", "acronyms": [[91, 94]], "long-forms": [[49, 89]]}, {"text": " In this paper, we propose a new, structured vector space model for word meaning (SVS) that addresses these problems.", "acronyms": [[82, 85]], "long-forms": [[34, 57]]}, {"text": "Main verb of main clause (MV)F8. Boolean feature for MV (BMV)F9. Previous sentence feature (PREV)Additional feature used only for Arg1F10. Arg2 Labels", "acronyms": [[92, 96], [26, 28], [57, 60], [130, 137], [139, 143]], "long-forms": [[65, 73], [0, 9], [33, 55]]}, {"text": "word penalty The 8 features have weights adjusted on the tuning data using minimum error rate training (MERT) (Och, 2003).", "acronyms": [[104, 108]], "long-forms": [[75, 102]]}, {"text": "After applying the linguistic phenomena  resolution algorithm we obtain a new slot  structure (SS) that will store both the anaphora  and their antecedents.", "acronyms": [[95, 97]], "long-forms": [[84, 93]]}, {"text": "2 ? Lemma, PoS, and Dependency relation (DepRel) for the node itself, the parent, and the left and right sibling", "acronyms": [[41, 47], [11, 14], [4, 9]], "long-forms": [[20, 39]]}, {"text": "servations.  Partial Least Squares Regression (PLSR) is a multivariate regression technique that has been de-", "acronyms": [[47, 51]], "long-forms": [[13, 45]]}, {"text": " 1 Introduction Machine translation (MT) by statistical modeling of bilingual phrases is one of the most successful ap-", "acronyms": [[37, 39]], "long-forms": [[16, 35]]}, {"text": " ? Word translation features (WT): ?", "acronyms": [[30, 32]], "long-forms": [[3, 28]]}, {"text": "We also have investigated our two-step solution on two existing treebanks, the Penn Chinese Treebank (CTB) (Xue et al.,", "acronyms": [[102, 105]], "long-forms": [[84, 100]]}, {"text": "There are four goodness algorithms reviewed by Zhao and Kit (2008a). The algorithms, including Description Length Gain (DLG) (Kit and Wilks 1999), Accessor Variety (Feng et al 2004a, 2004b), and Branching Entropy (Tanaka-Ishii", "acronyms": [[120, 123]], "long-forms": [[95, 118]]}, {"text": "the style of Shriberg (1994) and the Switchboard corpus. FP=Filled Pause, RM=Reparandum, IM=Interregnum, RP=Repair.", "acronyms": [[57, 59], [74, 76], [89, 91]], "long-forms": [[60, 72], [77, 87], [92, 103]]}, {"text": "for test year 2010 (train on 2009), polarity task.  SemTree combined with FWD (SemTreeFWD) generally gives the best performance in both", "acronyms": [[79, 89]], "long-forms": [[52, 77]]}, {"text": "that these heuristics have much effect not only in  the inductive inference (regular SVM) but also in  transductive inference (TSVM), especially when  the untagged data is large.", "acronyms": [[127, 131], [85, 88]], "long-forms": [[103, 125]]}, {"text": "Extraction Abbreviations NE = Named Entity CE = Correlated Entity", "acronyms": [[25, 27], [43, 45]], "long-forms": [[30, 42], [48, 65]]}, {"text": "{zhaosq,xlan,tliu,lisheng}@ir.hit.edu.cn Abstract Paraphrase generation (PG) is important in plenty of NLP applications.", "acronyms": [[73, 75], [103, 106]], "long-forms": [[50, 71]]}, {"text": "Figure 3: A Graphical Representation of the Infinite Tree Model than a simple Dirichlet process (DP)2 (Ferguson, 1973) is that we have to introduce coupling across", "acronyms": [[97, 99]], "long-forms": [[78, 95]]}, {"text": "To address this problem, Xiong et al (2006) enhance the BTG with a maximum entropy (MaxEnt) based reordering model which uses boundary words of bilingual", "acronyms": [[84, 90], [56, 59]], "long-forms": [[67, 82]]}, {"text": "    Two additional general features were used.  The preposition feature (PREP) captures the  most indicative preposition among connected ", "acronyms": [[73, 77]], "long-forms": [[52, 63]]}, {"text": "This section describes the two evaluation methods we employed ? average precision (AP) and correlation coefficient (CC).", "acronyms": [[83, 85], [116, 118]], "long-forms": [[64, 81], [91, 114]]}, {"text": "traction) consists of two steps: keyphrase candidate extraction and the genetic programming of keyphrase scoring measures (KSMs).1 3.1 Step 1: Keyphrase candidate extraction", "acronyms": [[123, 127]], "long-forms": [[95, 121]]}, {"text": "and the speech. The SU detection task is evaluated on both the reference human transcriptions (REF) and speech recognition outputs (STT).", "acronyms": [[95, 98], [20, 22], [132, 135]], "long-forms": [[63, 72], [104, 130]]}, {"text": "6 BC = Broadcast Conversations; BN = Broadcast News; CTS = Conversational Telephone Speech; NW = Newswire; UN = Usenet Newsgroups; and WL = Weblogs.", "acronyms": [[53, 56], [92, 94], [2, 4], [32, 34], [107, 109], [135, 137]], "long-forms": [[59, 90], [97, 105], [7, 30], [37, 51], [112, 129], [140, 147]]}, {"text": " 1 Introduction Natural Language Processing (NLP) systems often consist of a series of NLP components, each trained", "acronyms": [[45, 48], [87, 90]], "long-forms": [[16, 43]]}, {"text": "represents the UTB statistics. For Telugu, the Telugu Treebank (TTB) released for ICON 2010 Shared Task (Husain et al. ( 2010)) was used for evaluation.", "acronyms": [[64, 67], [15, 18], [82, 86]], "long-forms": [[54, 62]]}, {"text": "They found that using a combination of all the features in a Support Vector Machine (SVM), they can obtain an accuracy of 80% in the classification of 5 differ-", "acronyms": [[85, 88]], "long-forms": [[61, 83]]}, {"text": "ISREM 1 iff the candidate occurs 2 or more sentences before the anaphor POSITION 1 iff the antecedent occurs before anaphor SEMANTIC ROLE LABELLING (SR) IVERB 1 iff the governing verb of the given candidate is an issue verb", "acronyms": [[149, 151], [0, 5], [72, 80], [153, 158]], "long-forms": [[124, 137]]}, {"text": "sented by the S node) are extracted. ( 2) VPs (NPs) in a path on which all the nodes are VPs (NPs) are also recursively extracted and regarded as hav-", "acronyms": [[94, 97], [42, 45], [47, 50], [89, 92]], "long-forms": []}, {"text": "CoTrain vs. LEX(CN) 9.53E-10 7.15E-11 1.17E-09 CoTrain vs. LEX(EN) 1.87E-05 1.64E-05 8.92E-07 CoTrain vs. SVM(CN) 5.7E-08 2.91E-09 2.27E-11 CoTrain vs. SVM(EN) 3.74E-15 5.77E-17 1.18E-20", "acronyms": [[110, 112], [12, 15], [16, 18], [59, 62], [63, 65], [152, 155], [156, 158]], "long-forms": [[94, 101]]}, {"text": "ple need access to information anywhere, anytime. The  Adaptive Information Management (AIM) service in the  FASiL VPA seeks to automatically prioritise and pre-", "acronyms": [[88, 91], [109, 114], [115, 118]], "long-forms": [[55, 86]]}, {"text": "Text5 holiday(0.432) humor(0.23) 0.099 blues(0.15) Table 2: Percent Agreement(PA) to manually extracted index terms", "acronyms": [[78, 80]], "long-forms": [[60, 76]]}, {"text": "For 1http://maltparser.org/ English?Chinese (EN?ZH) word alignment, we observe that 75.62% of the consecutive Chinese", "acronyms": [[45, 50]], "long-forms": [[28, 43]]}, {"text": "any hypotheses between frames and events.  (2) SameFrame (SF) is the second baseline system, which applies H1 over the results from AN-", "acronyms": [[58, 60]], "long-forms": [[47, 56]]}, {"text": "For the bilingual corpus, we  used the BTEC and PIVOT data of IWSLT 2008,  HIT corpus 5  and other Chinese LDC (CLDC)                                                            ", "acronyms": [[112, 116], [39, 43], [48, 53], [62, 67], [75, 78]], "long-forms": [[99, 110]]}, {"text": "twelve NE tags. The NE tagged corpus has been  used to develop Named Entity Recognition (NER)  system in Bengali using pattern directed shallow ", "acronyms": [[89, 92], [7, 9], [20, 22]], "long-forms": [[63, 87]]}, {"text": "special right category before COO > (5) the common left coordination category > (6) the other special right category > (7) the free cross-clause clausal category (IC) > (8) the common left cross-clause category > (9) the free cross-clause punctuations (PUS). ", "acronyms": [[253, 256], [30, 33], [163, 165]], "long-forms": [[239, 251], [56, 68]]}, {"text": "We present experiments using counts of three types of ngrams: lemma ngrams (LN), POS ngrams (PN) and mixed ngrams (MN).2 Mixed ngram is a restricted formulation of lemma ngram where open-", "acronyms": [[115, 117], [76, 78], [93, 95]], "long-forms": [[101, 113], [62, 74], [81, 91]]}, {"text": "   Additionally, Mean Reciprocal Rank (MRR) is  also reported.", "acronyms": [[39, 42]], "long-forms": [[17, 37]]}, {"text": "er positions less than the penalty of reordering the first ranks.  iii):  Weighted Normalized Discounted Cumulative Gain (WNDCG): NDCG (Moffat and Zobel,  2008) normally compares the rankings of two lists.", "acronyms": [[122, 127], [130, 134]], "long-forms": [[74, 120]]}, {"text": "tical problems in class. It might also be useful in massive open online courses (MOOCs). In this for-", "acronyms": [[81, 86]], "long-forms": [[52, 79]]}, {"text": " 1 Introduction Approaches to Machine Translation (MT) using Data-Oriented Parsing (DOP: (Bod, 1998; Bod et", "acronyms": [[51, 53], [84, 87]], "long-forms": [[30, 49], [61, 82]]}, {"text": " Undoubtedly, Web 2.0 and the constant increase of User Generated Content (UGC) lead to a  higher demand for translation.", "acronyms": [[75, 78]], "long-forms": [[51, 73]]}, {"text": "Table 4: Human expert evaluated accuracy (Acc.)  and full cluster accuracy (FAcc.) of models on", "acronyms": [[76, 81], [42, 45]], "long-forms": [[53, 74], [32, 40]]}, {"text": "corporates agreement features is superior to CB models that treat morphosyntax as statesplits (SP), and that the RR model benefits more from inflectional features.", "acronyms": [[95, 97], [45, 47], [113, 115]], "long-forms": [[87, 93]]}, {"text": "FEDERAL DATA ENCRYPTION STANDARD APPROVED BY COMMERCE DEPARTMENT  A data encryption algorithm, designed to protect digital information, was  approved in November ad a Federal .Information Processing Standard (FIPS)  by the Department of Commerce.", "acronyms": [[209, 213]], "long-forms": [[167, 207]]}, {"text": "processing beyond keyword indexing, typically supported by Natural Language Processing (NLP)  and Information Extraction (IE) (Chinchor and Marsh 1998, Hovy, Hermjakob and Lin 2001, Li ", "acronyms": [[122, 124], [88, 91]], "long-forms": [[98, 120], [59, 86]]}, {"text": "2 tMi The two parameter classes for generating modifying nonterminals that are children of base NPs (NPB nodes), PM,NPB and PMw,NPB, have the following back-off structures. ", "acronyms": [[96, 99], [113, 115], [116, 119], [124, 127], [128, 131]], "long-forms": [[101, 110]]}, {"text": "similar to how Iida et al (2011) computed features to present to their classifier: namely Ling (linguistic features), TaskSp (task specific features), and Gaze (from SV only).", "acronyms": [[118, 124], [166, 168]], "long-forms": [[126, 139]]}, {"text": " We first examined three randomly selected portions of the listing  in the American Heritage Word Frequency Book (AHWFB).side by side  with the corresponding entry lists of the American Heritage School Dic- ", "acronyms": [[114, 119]], "long-forms": [[75, 112]]}, {"text": "Errors are italicized and marked in red.  LDA with phrases (LDA-P): As aspect-sentiment phrases are often noun phrases, a basic approach", "acronyms": [[60, 65]], "long-forms": [[42, 58]]}, {"text": "Text REtrieval Conference (TREC)1. The TREC 1The Text REtrieval Conference (TREC) is a series of evaluations of fully automatic Q/A systems", "acronyms": [[76, 80], [27, 31], [39, 43], [128, 131]], "long-forms": [[49, 74]]}, {"text": "belief updating model. In Proc American Association for Artificial Intelligence (AAAI) Workshop on Statistical and Empirical Approaches", "acronyms": [[81, 85]], "long-forms": [[40, 79]]}, {"text": "that provides a good compression rate of the text.  3.2 Byte Pair Encoding (BPE) Byte Pair Encoding (BPE) (Gage, 1994) is a sim-", "acronyms": [[76, 79], [101, 104]], "long-forms": [[56, 74], [81, 99]]}, {"text": "1 Introduction Resolving the ambiguity of person names in web search results is a challenging problem becoming an area of interest for Natural Language Processing (NLP) and Information Retrieval (IR) communities. ", "acronyms": [[164, 167], [196, 198]], "long-forms": [[135, 162], [173, 194]]}, {"text": " English For English dataset, we follow the standard splits of Penn Treebank (PTB), using sections 2-21 for training, section 22 as de-", "acronyms": [[78, 81]], "long-forms": [[63, 76]]}, {"text": "{afader,soderlan,etzioni}@cs.washington.edu Abstract Open Information Extraction (IE) is the task of extracting assertions from massive corpora", "acronyms": [[82, 84]], "long-forms": [[58, 80]]}, {"text": "calizations.  Direct responses (DS) are essentially characterized by introductory markers like yes/no/this is pos-", "acronyms": [[32, 34]], "long-forms": [[14, 30]]}, {"text": "These two representations are associated in an abstract type map, called AAM (Abstract Associative Map). This", "acronyms": [[73, 76]], "long-forms": [[78, 102]]}, {"text": "n of  PSP Positive?sentence percentage (PSP) statistics  ", "acronyms": [[40, 43], [6, 9]], "long-forms": [[10, 38]]}, {"text": "VBL (Light Verb) is used in complex predicates (Butt 1995), but its syntactic similarity with  VB (Verb) is a major source of confusion in automatic tagging.", "acronyms": [[95, 97], [0, 3]], "long-forms": [[99, 103], [5, 15]]}, {"text": "or fictional) world. These discourse ntities,  called reference objects (RefOs), are stored  and processed ina net-like structure, called a ", "acronyms": [[73, 78]], "long-forms": [[54, 71]]}, {"text": "rately hand-designing a large set of features (feature engineering) and utilizing the existing supervised natural language processing (NLP) toolkits and resources (i.e name tagger, parsers, gazetteers", "acronyms": [[135, 138]], "long-forms": [[106, 133]]}, {"text": "connective label?. The results are reported for Same Sentence (SS) and Previous Sentence (PS) models, and the joined results for each of the argu-", "acronyms": [[63, 65], [90, 92]], "long-forms": [[48, 61], [71, 88]]}, {"text": "ZZ initial optional verb complements  statement(Q) -...  verb_complementsO(VC). ", "acronyms": [[75, 77], [0, 2]], "long-forms": [[57, 73]]}, {"text": "outer: the perceived concrete or abstract source, goal, or  location of the action,event, or state  Correspondent (CAR):  inner: the entity perceived as being in correspondence with ", "acronyms": [[115, 118]], "long-forms": [[100, 113]]}, {"text": "3.1 Semantic Types In the present task, we use a subset of semantic types from the Brandeis Shallow Ontology (BSO), which is a shallow hierarchy of types developed as a part", "acronyms": [[110, 113]], "long-forms": [[83, 108]]}, {"text": " We observe the following: First, pre-enrollment reviews have noun phrases(NP) that contain fewer leaf nodes than in the post-enrollment reviews.", "acronyms": [[75, 77]], "long-forms": [[62, 73]]}, {"text": "of Reuters newswire articles annotated with four entity types: person (PER), location (LOC), organization (ORG), and miscellaneous (MISC). The data", "acronyms": [[132, 136], [71, 74], [87, 90], [107, 110]], "long-forms": [[117, 130], [63, 69], [77, 85], [93, 105]]}, {"text": "minimal set of defaults.  A Preferential Default Description Logic (PDDL)  based on weigthed defaults has been developed in ", "acronyms": [[68, 72]], "long-forms": [[28, 66]]}, {"text": "Machine learning in automated text categorization. In ACM computing surveys (CSUR). ", "acronyms": [[77, 81], [54, 57]], "long-forms": [[58, 75]]}, {"text": "it as a model for compiling their own corpora.  The Russian National Corpus (RNC) has been released by the group of specialists from different organi-", "acronyms": [[77, 80]], "long-forms": [[52, 75]]}, {"text": "PLC = partition left context  (has been done)  PRC = partition right context  (yet to be done) ", "acronyms": [[47, 50], [0, 3]], "long-forms": [[53, 76], [6, 28]]}, {"text": "References TREC (Text REtrieval Conference) : http://trec.nist.gov/ NTCIR (NII-NACSIS Test Collection for IR Systems) project: http://research.nii.ac.jp/ntcir/index-en.html", "acronyms": [[75, 85], [11, 15], [68, 73], [106, 108]], "long-forms": [[17, 42]]}, {"text": "Schafer and Graham, 2002) discussed several approaches such as case deletion, mean substitution, and recommended maximum likelihood (ML) and Bayesian multiple imputation (MI).", "acronyms": [[133, 135], [171, 173]], "long-forms": [[113, 131], [150, 169]]}, {"text": "Measuring and estimating post-editing effort is therefore a growing concern addressed by Confidence Estimation (CE) (Specia, 2011). ", "acronyms": [[112, 114]], "long-forms": [[89, 110]]}, {"text": "also recorded in the miscellaneous information field of the lexeme. Similarly, Gene Ontology (GO) (Consortium.,", "acronyms": [[94, 96]], "long-forms": [[79, 92]]}, {"text": "ANTEST R E T U R N S  ** 1**  CHANGT, HAVE CSEXCE1 FOR HESGEF IN  ARTEST CALLEC FOR 18\"REGVO I C E u  (AACC)  ANTEST E T U E N S  ** l** ", "acronyms": [[103, 107], [43, 50], [51, 54], [55, 61], [0, 6]], "long-forms": [[66, 96]]}, {"text": "tion. So we developed a method to optimize the CRFs towards the alignment error rate (AER) or the F-score with sure and possible links as introduced", "acronyms": [[86, 89]], "long-forms": [[64, 84]]}, {"text": "Other formats have been suggested for dictionary sharing,  notably those developed under the Text Encoding Initiative  using SGML (Standard Generalized Markup Language). We ", "acronyms": [[125, 129]], "long-forms": [[131, 167]]}, {"text": "erature for further details.  Semantic Role Labeling (SRL) Our first task is that of identifying arguments of verbs in a sen-", "acronyms": [[54, 57]], "long-forms": [[30, 52]]}, {"text": "as ht, ct = LSTM(xt, ht?1, ct?1).  Residual Networks (ResNet) are among the pioneering works (Szegedy et al, 2015; Srivastava et", "acronyms": [[54, 60], [12, 16]], "long-forms": [[35, 52]]}, {"text": "One of  the most commonly used methods is the  Latent Semantic Analysis (LSA). In this ", "acronyms": [[73, 76]], "long-forms": [[47, 71]]}, {"text": "and include them in the training data for the SMT.  Corpus Combination (CComb) The easiest method is to use these n newly created paral-", "acronyms": [[72, 77]], "long-forms": [[52, 70]]}, {"text": "gathered training data from parallel texts for the set of most frequently occurring noun, adjective, and verb types in the Brown Corpus (BC). These word", "acronyms": [[137, 139]], "long-forms": [[123, 135]]}, {"text": "ing is combined with dictionary-based (e.g.,  WordNet) reranking, which leads to a 25% increase in mean reciprocal rank (MRR). Xu et al ", "acronyms": [[121, 124]], "long-forms": [[99, 119]]}, {"text": "cerd,jurafsky,manning@stanford.edu Abstract Minimum error rate training (MERT) is a widely used learning procedure for statistical", "acronyms": [[73, 77]], "long-forms": [[44, 71]]}, {"text": "Sofa. The viewer makes use the open-source library Java Speech Toolkit (JSTK)5. ", "acronyms": [[72, 76]], "long-forms": [[51, 70]]}, {"text": "clue words characteristic to the nine relation types.  In order to measure the semantic relatedness (SR) of targets and clues, we used the Explicit Seman-", "acronyms": [[101, 103]], "long-forms": [[79, 99]]}, {"text": "2010). Alternatively, iteratively optimized embeddings such as Skip Gram (SG) model (Mikolov et al.,", "acronyms": [[74, 76]], "long-forms": [[63, 72]]}, {"text": "text corpus, to be made available without royalties for scientific research. The text will  be formatted using SGML (the Standard Generalized Markup Language). To date ", "acronyms": [[111, 115]], "long-forms": [[121, 157]]}, {"text": "We propose a method to solve this problem, which also results in a new topic model, called AKL (Automated Knowledge LDA), whose inference can exploit the automatically learned", "acronyms": [[91, 94]], "long-forms": [[96, 119]]}, {"text": "Several numerical algorithms, such as Generalized Iterative Scaling (GIS) (Darroch and Ratcliff 1972), Improved Iterative Scaling (IIS) (Della Pietra, Della Pietra, and Lafferty 1997), and the Limitedmemory Broyden-Fletcher-Goldfarb-Shanno method (L-BFGS) (Nocedal and Wright", "acronyms": [[131, 134]], "long-forms": [[112, 129]]}, {"text": "The focus of the robust CSR techniques  on SLS applications is being facilitated by development and implementation of a well-structured  interface between a CSR and a natural language processor (NLP), allowing collaboration with other  groups developing NLPs for SLS applications.", "acronyms": [[195, 198], [24, 27], [43, 46], [157, 160], [254, 258], [263, 266]], "long-forms": [[167, 193]]}, {"text": "Department of Linguistics, ? Center for the Preservation of Ancient Religious Texts (CPART) Brigham Young University", "acronyms": [[85, 90]], "long-forms": [[29, 83]]}, {"text": "Schauder 91). The grammar is divided into an LD  (linear dominance) and an LP (linear precedence) part  so that the piecewise construction of syntactic ", "acronyms": [[75, 77], [45, 47]], "long-forms": [[79, 96], [50, 67]]}, {"text": "project.  In section 2 we provide an overview of the automatic compound processing (AuCoPro) project, which forms the background of this research.", "acronyms": [[84, 91]], "long-forms": [[53, 82]]}, {"text": "appficability o new tasks, such as indications/warn-  ings, text tagging, and document detection support  \\[1\\] The Text REtrieval Conferences (TREC's) are described  in the Document Detecfien section.", "acronyms": [[144, 150]], "long-forms": [[116, 142]]}, {"text": " 4.1. Document Input (DI)  The DI process is the interface between ADEPT ", "acronyms": [[22, 24], [67, 72], [31, 33]], "long-forms": [[6, 20]]}, {"text": " 3.2 Taboo Constraint Taboo constraint (TABOO) requires that the substitute word is a taboo word or frequently used", "acronyms": [[40, 45]], "long-forms": [[22, 38]]}, {"text": "vided within scientific articles. In addition, image Regions of Interest (ROIs) are commonly referred to within the image caption.", "acronyms": [[74, 78]], "long-forms": [[53, 72]]}, {"text": "marn et al 2007). The training procedure usually employs an expectation maximization (EM) procedure and the resulting transducer can be used to", "acronyms": [[86, 88]], "long-forms": [[60, 84]]}, {"text": "Translation Equivalents and Semantic  Relations   Note that two translation equivalents (TE)  in a pair of languages stand in a lexical semantic ", "acronyms": [[89, 91]], "long-forms": [[64, 87]]}, {"text": "Frustration Frustrated (F), Neutral (N), Correctness Correct (C), Incorrect (I) Partially Correct (PC) Percent Correct 50-100% (High), 0-50% (Low)", "acronyms": [[99, 101]], "long-forms": [[80, 97], [12, 22], [28, 35], [41, 60], [66, 75]]}, {"text": " Relations between function words and content words (e.g. specifier (SPR), marker complement (CMP), infinitival zu marker (PM)) are frequent and", "acronyms": [[69, 72], [94, 97], [123, 125]], "long-forms": [[58, 67], [82, 92]]}, {"text": "\u0011\u000f \u0019 \u0019 \u0019 \u0019 \u0019 \u0018 Figure 3: Scored dependency forest 2.5 Semantic Dependency Graph (SDG) The SDG is a semantic-label word DG designed", "acronyms": [[81, 84], [90, 93], [119, 121]], "long-forms": [[54, 79]]}, {"text": "VIOLATED EXPECTATION (Ho) NONVOLITIONAL-RESULT (M&T) EXPLANATION (Ho) ( CAUSAL \u0004 ADDITIVE ) - RESULT (A&L) ( SEMANTIC \u0004 PRAGMATIC ) - EXPLANATION (A&L)", "acronyms": [[102, 105], [48, 51], [22, 24], [66, 68], [147, 150]], "long-forms": [[81, 100]]}, {"text": "In this paper we present methods for reducing the compu-  tation time of joint segmentation a d recognition of phones  using the Stochastic Segment Model (SSM). Our approach ", "acronyms": [[155, 158]], "long-forms": [[129, 153]]}, {"text": "In Table 1, we show the precision, recall, and F1 measures of our domain-aware method (DOM) and the baseline method (BL) in all three sets of experiments.", "acronyms": [[117, 119], [87, 90]], "long-forms": [[100, 108], [66, 85]]}, {"text": " 3.1 Ng and Cardie (2002a) Ng and Cardie (N&C) do not attempt to improve PA, simply using the anaphoricity information it pro-", "acronyms": [[42, 45], [73, 75]], "long-forms": [[27, 40]]}, {"text": "phrases (NPs) (representing 49.6% of the total number of phrases), verb phrases (VPs), prepositional phrases (PPs), adjectival phrases (ADJPs), and quantity phrases (QPs), representing 99.1% of", "acronyms": [[136, 141]], "long-forms": [[116, 134]]}, {"text": "5 Tools for the development of the prototype experiment For the practical development of our prototype experiments we are considering to use the upper cate-gories of the NIFSTD ontology and wikis as a collaborative tool. The availability and suitability for our research of the former has been considered in Maroto (2013).  NIFSTD (NIF Standard) ontology stands out as the most comprehensive ontology of the neurosci-ences available on the web. Its wide coverage and its degree of normalisation and reusability make this ontology particularly suitable for our research purposes.", "acronyms": [[324, 330], [170, 176]], "long-forms": [[332, 344]]}, {"text": "3 MaxEnt Model and Features  3.1 MaxEnt Model for NOR  The principle of maximum entropy (MaxEnt)  model is that given a collection of facts, choose a ", "acronyms": [[89, 95], [2, 8], [33, 39], [50, 53]], "long-forms": [[72, 87]]}, {"text": "terial with relevant events will be done along the 1MUMIS is an on-going EU-funded project within the Information Society Program (IST) of the European Union, section Human Language Technology (HLT).", "acronyms": [[131, 134]], "long-forms": [[102, 121]]}, {"text": "ture. Later, AVG were enriched with a statistical component (Abney, 1997): stochastic AVG (SAVG). ", "acronyms": [[91, 95], [13, 16]], "long-forms": [[75, 89]]}, {"text": " As an example, consider a user who is looking for information on digital video recorders (DVR), in particular, on how she can use a DVR with a", "acronyms": [[91, 94], [133, 136]], "long-forms": [[66, 89]]}, {"text": "In Addition to the visualhaptic interface, iDrive includes a speech dialogue system (SDS) as well. The SDS allows the driver", "acronyms": [[85, 88]], "long-forms": [[77, 83]]}, {"text": "In Proc. of IEEE/ACL workshop on Spoken Language Technology (SLT). ", "acronyms": [[61, 64], [12, 20]], "long-forms": [[33, 59]]}, {"text": "In  * This work has been sponsored by the Fonds zur  FSrderung der wissenschaftlichen Forschung (FWF),  Grant No.", "acronyms": [[97, 100]], "long-forms": [[53, 95]]}, {"text": "methods.  For example, consider the ways in which evaluation of machine translation (MT) systems is carried out.", "acronyms": [[85, 87]], "long-forms": [[64, 83]]}, {"text": "Other language technology applications, such as Question Answering (QA) systems or information retrieval (IR) systems, also suffer from the poor contextual disambiguation of word senses.", "acronyms": [[106, 108], [68, 70]], "long-forms": [[83, 104], [48, 66]]}, {"text": "tating full-text passages that describe the functional relationships between bio-entities summarised in a Molecular Interaction Map (MIM). Our corpus", "acronyms": [[133, 136]], "long-forms": [[106, 131]]}, {"text": "Supertagging involves assigning words lexical entries based on a lexicalized grammatical theory, such as Combinatory Categorial Grammar (CCG) (Steedman, 2000) Tree-adjoining Grammar (Joshi,", "acronyms": [[137, 140]], "long-forms": [[105, 135]]}, {"text": "Question is defined as a Question term (QTerm).  The Answer Term (ATerm) is the Answer given by the KM corpus.", "acronyms": [[66, 71], [40, 45], [100, 102]], "long-forms": [[53, 64], [25, 38]]}, {"text": "versational participants. This type of HMM is called a speaker HMM (SHMM) and has been successfully utilized to model two-party conversa-", "acronyms": [[68, 72], [39, 42]], "long-forms": [[55, 66]]}, {"text": " I. Introduction  SABA (\"Semantic Analyser , Backward Ap-  proach\") is an automatic parser of French ", "acronyms": [[18, 22]], "long-forms": [[25, 65]]}, {"text": "Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, ML=Machine Learning researcher, L=Linguist, Porter=Porter stemmer, McCCJ=McClosky-Charniak-Johnson parser, SD=Stanford Dependency conversion, Dict=Dictionary UTurku VIBGhent ConcordU HCMUS", "acronyms": [[187, 189], [15, 17], [36, 39], [80, 82], [124, 130], [147, 152], [222, 226]], "long-forms": [[190, 209], [18, 34], [40, 67], [83, 99], [114, 122], [131, 137], [153, 178], [227, 237]]}, {"text": "cies and percentages of which are given in Table 1 (where the letters in example (3)  correspond to the letters in the table). Example (3a) uses a to infinitive form (TNF). ", "acronyms": [[167, 170]], "long-forms": [[147, 165]]}, {"text": " In this definition, WHEN has two formal parameters x and y; each of them refers to a  situation that occurs at the same point in time (PTIM). Any occurrence of the relation ", "acronyms": [[136, 140]], "long-forms": [[121, 134]]}, {"text": "So, for example, the preposition in addition to (krom?) appears altogether in 309 instances in PDT,  within which there are 44 instances in the function of AltLex (automatically looked up). All ", "acronyms": [[156, 162], [95, 98]], "long-forms": [[164, 184]]}, {"text": "Here, we describe a naive baseline approach to arrange nearest neighbors next to each other by using Independent Random Projections (IRP). In this", "acronyms": [[133, 136]], "long-forms": [[101, 131]]}, {"text": "tegrating more linguistic and structural knowledge with modern statistical techniques, and in particular, for syntax-based machine translation (MT) systems. ", "acronyms": [[144, 146]], "long-forms": [[123, 142]]}, {"text": "legislatures, councils, \"other government bodies , I 1  and the private sector  should withhold action implementing major proposals for EFTS until the  National Commission on Electronic Fund transfers (NCEFT) has completed its  studies.", "acronyms": [[202, 207], [136, 140]], "long-forms": [[152, 200]]}, {"text": "KEY: Number of discussions and posts on the topic (Discs, Posts).  Number of authors (NumA). Posts per author (P/A).", "acronyms": [[86, 90], [111, 114]], "long-forms": [[67, 84], [93, 109]]}, {"text": "Available for SRL tasks are efforts such as PropBank (Palmer et al, 2005) and FrameNet (Fillmore et al, 2003) that have developed semantic role labels (based on differing approaches) and have labeled large corpora for training and testing of SRL systems. PropBank (PB) identifies and labels the semantic arguments of the verb on a verb-by-verb basis, creating a separate frameset that includes verb specific semantic roles to account for each subcategorization frame of the verb. Much like PB, FrameNet (FN) identifies and labels semantic roles, known as Frame Elements, around a relational target, usually a verb.2 But unlike PB, Frame Elements less verb specific, but rather are defined in terms of semantic structures called frames evoked by the verb. That is, one or more verbs can be associated with a single semantic frame.", "acronyms": [[504, 506], [14, 17], [242, 245], [265, 267]], "long-forms": [[494, 502], [255, 263]]}, {"text": "TGTM PR=pr ,  pkr ,  b r   TGTM PL =p l ,  ph l ,  b l   TGTM PW=pw, pkw, bw  Figure 26 ", "acronyms": [[62, 64], [0, 4], [5, 7], [27, 31], [32, 34], [57, 61]], "long-forms": [[65, 67], [8, 10], [36, 39]]}, {"text": " 8SB = subject, OA = accusative object, OA2 = second accusative object, DA = dative, OG = genitive object, OP = prepositional object, PD = predicate, OC = clausal ob-", "acronyms": [[72, 74], [1, 4], [16, 18], [40, 43], [85, 87], [107, 109], [134, 136], [150, 152]], "long-forms": [[77, 83], [7, 14], [21, 38], [46, 70], [90, 105], [112, 132], [139, 148], [155, 165]]}, {"text": "complementary features ( Section 3.3).  3.2 Mining Labeled Sequential Patterns ( LSP ) Labeled Sequential Patterns (LSP).", "acronyms": [[81, 84], [115, 119]], "long-forms": [[51, 78], [87, 114]]}, {"text": "them, and finally generating and displaying them.  The Input Analyzer (IA) of the system is the  most stable end experimented component and it is ", "acronyms": [[71, 73]], "long-forms": [[55, 69]]}, {"text": " 3.2 Convolutional Neural Network model The Convolutional Neural Network (CNN) model using raw audio as input is shown in Figure 1.", "acronyms": [[74, 77]], "long-forms": [[44, 72]]}, {"text": "sentence, but many equally good translation options.  Often, machine translation (MT) systems are only evaluated quantitatively, e.g. by the use of automatic", "acronyms": [[82, 84]], "long-forms": [[61, 80]]}, {"text": "which can handle the non-projective trees present in the Irish data. In each case we report Labelled Attachment Score (LAS) and Unlabelled Attachment Score (UAS). ", "acronyms": [[157, 160], [119, 122]], "long-forms": [[128, 155], [92, 117]]}, {"text": "248   Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1284?1295, October 25-29, 2014, Doha, Qatar.", "acronyms": [[94, 99]], "long-forms": [[44, 92]]}, {"text": "the following.  The Basic Additive model (BA) (introduced in (Mitchell and Lapata, 2008)) computes the disti-", "acronyms": [[42, 44]], "long-forms": [[20, 34]]}, {"text": "snippets with a frequency higher than three. Then we calculate the inverse sentence frequency (ISF) for these phrases using the entire ICSI meeting corpus.", "acronyms": [[95, 98], [135, 139]], "long-forms": [[67, 93]]}, {"text": "4} is not a most frequent token  and will reach at bi-gram queue manager only  after passing  through all forms generator (AFG).  ", "acronyms": [[123, 126]], "long-forms": [[102, 121]]}, {"text": "Gimenez and Marquez (2008) measure overlapping grammatical dependency relationships (DP), semantic roles (SR), and discourse representations (DR).", "acronyms": [[106, 108], [85, 87], [142, 144]], "long-forms": [[90, 104], [59, 83], [115, 140]]}, {"text": "(1992). Grammars  are defined over typed fea-  twre .structures (TFSs) which can be viewed as  generalizations of first-order terms (Carpenter, ", "acronyms": [[65, 69]], "long-forms": [[35, 63]]}, {"text": "course structure. In Proceedings of the International Conference in Computational Linguistics (COLING), pages 43?49. ", "acronyms": [[95, 101]], "long-forms": [[68, 93]]}, {"text": "z and a segmental grammar g, compute the sur-  face form y : g(z) of z.  The phonological recognition problem (PRP) is:  Given a (partially specified) surface form y, a dic- ", "acronyms": [[111, 114]], "long-forms": [[77, 109]]}, {"text": "For example, both the terms chiaroscuro and collage are classified under picture, image, icon in WordNet, but in the Art & Architecture Thesaurus (AA&T)16 chiaroscuro is categorized under perspective and shading techniques whereas collage is classified under image-making processes and", "acronyms": [[147, 151]], "long-forms": [[117, 145]]}, {"text": "kitchen cabinet and will hardly be able to win the elections]. The parse tree contains phrase labels NP (Noun Phrase), PP (Prepositional Phrase), VP (Verb Phrase), S (Sentence), and CS (Coordinated Sentence).", "acronyms": [[119, 121], [146, 148]], "long-forms": [[123, 143], [150, 161]]}, {"text": "A simple solution to this problem is  to compute the probability of words in the target  language as maximum likelihood estimates (MLE)  over a large corpus and reformulate the general ", "acronyms": [[131, 134]], "long-forms": [[101, 129]]}, {"text": " 4.3 Counting and Calculation The SRI Language Modelling Toolkit (SRILM) (Stolcke and others, 2002) is used to count the frequencies in our work.", "acronyms": [[66, 71]], "long-forms": [[34, 56]]}, {"text": " 1 Introduction Traditionally, Information Retrieval (IR) and Statistical Natural Language Processing (NLP) applica-", "acronyms": [[54, 56], [103, 106]], "long-forms": [[31, 52], [74, 101]]}, {"text": "Abstract This paper reports on the participation of the TALP Research Center of the UPC (Universitat Polit?cnica de Catalunya) to the ACL WMT 2008 evaluation", "acronyms": [[84, 87], [56, 60], [134, 137], [138, 141]], "long-forms": [[89, 112]]}, {"text": "tion, Generation, Question Answering (QA), etc.  STS is related to both Textual Entailment (TE) and Paraphrasing, but differs in a number of ways", "acronyms": [[92, 94], [38, 40], [49, 52]], "long-forms": [[72, 90], [18, 36]]}, {"text": " 2.3 Tree Insertion Grammar Tree Insertion Grammars (TIGs) are a longstanding compromise between the intuitive expressivity", "acronyms": [[53, 57]], "long-forms": [[28, 51]]}, {"text": "these instances. We treat the language ID task as a coreference resolution (CoRef) problem: a mention is an IGT or a language name appearing in a", "acronyms": [[76, 81], [39, 41], [108, 111]], "long-forms": [[52, 74]]}, {"text": "{EVENT 2 {AND {SUBTYPE DIE} {PERSON  $foo}}}  2.4 Graphical User Interface (GUI)  For some applications such as database ", "acronyms": [[76, 79]], "long-forms": [[50, 74]]}, {"text": "Another dictionary device deals wlth  unrecognized elements - the so-called  transducing dictionary (TD). TD re- ", "acronyms": [[101, 103]], "long-forms": [[77, 99]]}, {"text": "  Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143?147, October 25, 2014, Doha, Qatar.", "acronyms": [[80, 84], [21, 26]], "long-forms": [[44, 78]]}, {"text": "and above 95% for determiners (DT). In addition, subjects (SS) have a score above 90%. In all these", "acronyms": [[59, 61], [31, 33]], "long-forms": [[49, 57], [18, 28]]}, {"text": "these paths. This corresponds to the Viterbi approximation i speech recognition or in  other related areas for which hidden Markov models (HMM's) are used. In all such ", "acronyms": [[139, 144]], "long-forms": [[117, 137]]}, {"text": "2.2 Hierarchical Agglomerative Clustering After discovering sense clusters of paths, we employ hierarchical agglomerative clustering (HAC) to discover semantic relations from these sense clusters.", "acronyms": [[134, 137]], "long-forms": [[95, 132]]}, {"text": "The GALE manual WA corpus and the Chinese to English corpus from the shared task of the NIST open machine translation (OpenMT) 2006 evaluation 6 were employed as the experimental corpus", "acronyms": [[119, 125], [4, 8], [16, 18], [88, 92]], "long-forms": [[93, 117]]}, {"text": "Figure 1: Sample transcript from a TD child 3 Narrative Topic Analysis Using LDA Latent Dirichlet Allocation (LDA) (Blei et al 2003) has been used in NLP to model topics within", "acronyms": [[110, 113]], "long-forms": [[81, 108]]}, {"text": "The central components of our non-parametric Bayesian models are the Chinese Restaurant Processes (CRPs) and the closely related Dirichlet Processes (DPs) (Ferguson, 1973).", "acronyms": [[99, 103], [150, 153]], "long-forms": [[69, 97], [129, 148]]}, {"text": " 5.4 Nonshared Concept Activation with  No Identif ication Intention (NSNI). ", "acronyms": [[70, 74]], "long-forms": [[40, 68]]}, {"text": "Section 2 discusses related work. Section 3 introduces the Condition Random Fields(CRFs)  and the defined Long-Dependency CRFs ", "acronyms": [[83, 87], [122, 126]], "long-forms": [[59, 82]]}, {"text": "the increase is.  Table 2 shows the average solve time (ST) for sentences with respect to the number of tokens in", "acronyms": [[56, 58]], "long-forms": [[44, 54]]}, {"text": " In our experiments, we have applied the COLLINS (Collins, 1999) parser to generate the syntactic tree of both pieces of text.", "acronyms": [[41, 48]], "long-forms": [[50, 57]]}, {"text": " : : , .  :~..~. NAT =nat iona =ty .:~:~',,~,.~ . .:.-,~.~;~ SRC~.;ob I .~concrete-:,~ ", "acronyms": [[17, 20], [61, 64]], "long-forms": [[22, 25]]}, {"text": " 3 The Discourse Model Informally, a DiscourseModel (DM)may be described as the set of entities \"specified\" in a discourse, linked together by the relations they participate in.", "acronyms": [[53, 55]], "long-forms": [[37, 51]]}, {"text": "In addition, adding the soft joint-inference formula results in further gain, and our full system (FULL) attained an F1 of 55.5. ", "acronyms": [[99, 103]], "long-forms": [[86, 90]]}, {"text": "2013. Overview of the pathway curation (PC) task of bioNLP shared task 2013.", "acronyms": [[40, 42]], "long-forms": [[22, 38]]}, {"text": "known that Figure 1(a) can be represented by an equivalent hierarchical Chinese Restaurant Process (CRP) (Aldous, 1985) as in Figure 1(b). ", "acronyms": [[100, 103]], "long-forms": [[72, 98]]}, {"text": "RH = Random House dictionary; WSJ = Wall Street Journal; BN = Broadcast News; SWB = Switchboard. ", "acronyms": [[78, 81], [0, 2], [30, 33], [57, 59]], "long-forms": [[84, 95], [5, 17], [36, 55], [62, 76]]}, {"text": "appear although ModP and FocP are optional.  projections such as NegP (negation phrase) will  not be discussed although we assume there must ", "acronyms": [[65, 69], [16, 20], [25, 29]], "long-forms": [[71, 86]]}, {"text": "phrase markers or words. For simplicity of manipulation but without loss of general-  ity, we will limit the productions to the Chomsky Normal Form (CNF). That is, only ", "acronyms": [[149, 152]], "long-forms": [[128, 147]]}, {"text": "First, we investigate how laypeople intuitively recognize metaphor by conducting Amazon Mechanical Turk (MTurk) experiments.", "acronyms": [[105, 110]], "long-forms": [[88, 103]]}, {"text": "vp?np?pp .83 .80 .83 .80 .83 .80 vp?pp?pp .75 .74 .75 .74 .75 .74 Lexical association (LAsim) Sequences PrEC PrPGR RecEC RecPGR F-SRV F-SPGR", "acronyms": [[87, 92]], "long-forms": [[66, 85]]}, {"text": "In recent decades, this idea appears in (Curry, 1961) where the interlingua is called tectogrammar, in the Rosetta project (Rosetta, 1994), building on the semantic models of (Montague, 1974), and in the UNL (Universal Networking Language) project. ", "acronyms": [[204, 207]], "long-forms": [[209, 238]]}, {"text": "( NN?? ) speech 1:1 ( NP ( NR ) ( NN ) ) X1 | X2 1:2 2:1 ( NP ( NR?? ) (", "acronyms": [[34, 36], [2, 6], [59, 61], [64, 68]], "long-forms": [[22, 29]]}, {"text": "tell verb base (VB), tell VB tell told verb past tense (VBD), tell VBD,VBN tell verb past participle (VBN), tell tells verb present 3rd person sing (VBZ), tell VBZ tell", "acronyms": [[102, 105], [16, 18], [26, 28], [56, 59], [67, 70], [71, 74], [149, 152], [160, 163]], "long-forms": [[80, 100], [5, 14], [39, 54], [119, 142]]}, {"text": "words. In Proceedings of the International Conference on Computational Linguistics (COLING). ", "acronyms": [[84, 90]], "long-forms": [[57, 82]]}, {"text": "AJCL = AmericanJournal of Computational  Linguistics (1974-present)  SNLP = Studies in Natural Language Processin~  (Cambridge University Press Monograph ", "acronyms": [[69, 73], [0, 4]], "long-forms": [[76, 114], [7, 52]]}, {"text": "tion database (OID) and provides the corresponding interface;  - Knowledge Retriever (KR) ? retrieves KSs from ", "acronyms": [[86, 88], [15, 18], [102, 105]], "long-forms": [[65, 84]]}, {"text": " 1 Introduction Statistical machine translation (SMT) starts from sequence-based models.", "acronyms": [[49, 52]], "long-forms": [[16, 47]]}, {"text": "The dependency inductions were evaluated on 3 metrics: directed accuracy, undirected accuracy and Neutral Edge Detection (NED) (Schwartz et al.,", "acronyms": [[122, 125]], "long-forms": [[98, 120]]}, {"text": "Name Discrimination by Clustering Similar Contexts, Proceedings of the World Wide Web Conference (WWW). ", "acronyms": [[98, 101]], "long-forms": [[71, 85]]}, {"text": "1977).  The parameters of the IDCLM model are computed using the variational Bayes EM (VB-EM) procedure by maximizing the marginal distribution of the training data that contains a set of n-gram events", "acronyms": [[87, 92], [30, 35]], "long-forms": [[65, 85]]}, {"text": "cation and domain in question, can provide an effective means to deal with a number of natural language processing (NLP) tasks.", "acronyms": [[116, 119]], "long-forms": [[87, 114]]}, {"text": "Their by-country breakdown is as follows: 3.99M (61%) from Saudi Arabia (SA), 880K (13%) from Egypt (EG), 707K (11%) from Kuwait (KW), 302K (5%) from United Arab Emi-", "acronyms": [[101, 103], [73, 75], [130, 132]], "long-forms": [[94, 99], [59, 71], [122, 128]]}, {"text": "Noun I Nominalized verb(NIO  Determinative modifier ::= Adjective I Differentiable Adjective(DA) I Verb I Noun I  Location I String l Numeral + Classifier ", "acronyms": [[93, 95], [24, 27]], "long-forms": [[68, 91]]}, {"text": " One example of this would be in providing support for the curation of the Gene Expression Database (GXD).4 This support could come in the form of a named entity recog-", "acronyms": [[101, 104]], "long-forms": [[75, 99]]}, {"text": "from the output of the parser we adopt a uniform meaning representation which is a structured Logical Form(LF). In other words we map our f-", "acronyms": [[107, 109]], "long-forms": [[94, 106]]}, {"text": "e.g. Microsoft 2. Candidate Definition Features (CDs) : These consist of the two following feature classes.", "acronyms": [[49, 52]], "long-forms": [[18, 47]]}, {"text": "spectively. Each of these sets is further divided into three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews).", "acronyms": [[80, 85], [128, 133]], "long-forms": [[70, 78], [112, 126]]}, {"text": "Abstract  Most machine transliteration systems  transliterate out of vocabulary (OOV)  words through intermediate phonemic ", "acronyms": [[81, 84]], "long-forms": [[62, 79]]}, {"text": "1 Introduction  Turkish Discourse Bank (TDB) is the first discourse-annotated corpus of Turkish, which follows the  principles of Penn Discourse Tree Bank (PDTB) (Prasad et al., 2008) and includes annotations for dis-", "acronyms": [[156, 160], [40, 43]], "long-forms": [[130, 154], [16, 38]]}, {"text": " 1 Introduction Machine Translation (MT) can be addressed as a structured prediction task (Brown et al.,", "acronyms": [[37, 39]], "long-forms": [[16, 35]]}, {"text": "Suffixes (S): able, est, ful, ic, ing, ive, ness etc.  Word Sentiment Polarity (SP): POS, NEG, NEU Pivoting on the head aspect, we look forward and", "acronyms": [[80, 82]], "long-forms": [[60, 78]]}, {"text": "In Proc. of the Conference on Computational Natural Language Learning (CoNLL), 7.", "acronyms": [[71, 76]], "long-forms": [[30, 69]]}, {"text": "neighboring phrases serially or inversely. They built a maximum entropy (MaxEnt) classifier based on boundary words to predict the order of neighboring", "acronyms": [[73, 79]], "long-forms": [[56, 71]]}, {"text": " To adapt for Chinese phonetic rule, we divide the  continuous CLs into independent CLs(IC) and  divide structure of CL+VL+CL into CL+VL and ", "acronyms": [[88, 90], [63, 66], [117, 119], [120, 122], [123, 125], [131, 133], [134, 136]], "long-forms": [[72, 86]]}, {"text": "For comparison, the graphs in Figures 1 and 2 also show the curves corresponding to the evaluation of Pointwise Mutual Information (PMI).8 The cooccurrence statistics of the expressions in Disco-En-", "acronyms": [[132, 135]], "long-forms": [[102, 130]]}, {"text": "non-interactions   Y They are widely distributed and mediate all of the known biologic effects of  angiotensin II (AngII) through a variety of signal transduction systems, including activation of phospholipases C and A2, inhibition of adenylate cyc-", "acronyms": [[115, 120]], "long-forms": [[99, 113]]}, {"text": " Like most of the successful AQUAINT QA systems,  LCC?s system uses an answer type (AT) ontology for  the classification of AT categories.", "acronyms": [[84, 86], [29, 36], [37, 39], [50, 53], [124, 126]], "long-forms": [[71, 82]]}, {"text": " Another syntactic phenomena crucial to the parser is known as the complex NP  Constraint (CNPC) (Radford 1981); i.e., no transformation rule can move any element  out of a complex NP, where a complex NP (CNP) is an NP containing a relative clause.", "acronyms": [[91, 95], [181, 183], [201, 203], [205, 208], [216, 218], [75, 77]], "long-forms": [[79, 89]]}, {"text": "following table shows the results of U-DOP on the WSJ40 using 10 different 90-10 splits, compared to a  supervised binarized PCFG (S-PCFG) and a supervised binarized DOP model (S-DOP) on the", "acronyms": [[131, 137], [37, 42], [50, 55], [177, 182]], "long-forms": [[104, 129], [145, 169]]}, {"text": " Association for Computational Linguistics.          ACL Special Interest Group in Computational Phonology (SIGPHON), Philadelphia,        Morphological and Phonological Learning: Proceedings of the 6th Workshop of the", "acronyms": [[108, 115]], "long-forms": [[57, 106]]}, {"text": "4-gram + LSA using linear interpolation  with ? LSA = 0.11 (LI). ", "acronyms": [[60, 62], [9, 12]], "long-forms": [[48, 51], [19, 39]]}, {"text": "lected randomly from some reference corpus.  Active Learning (AL) has recently shaped as a much more efficient alternative for the creation of", "acronyms": [[62, 64]], "long-forms": [[45, 60]]}, {"text": "actual object and \\[AI is the word that represents A. CS : = speaking A;yes refers A \\[A\\] ; yes  (111) Resource Situation(RS)  A resource situation is defined for each individual in a discourse; it ", "acronyms": [[123, 125], [54, 56]], "long-forms": [[104, 122]]}, {"text": "Extraction (from now on AVE) is performed with two approaches: a) Rule-based approaches apply Regular Expressions (RE) to map the words realizing a concept into a normalized value.", "acronyms": [[115, 117], [24, 27]], "long-forms": [[94, 113]]}, {"text": "We describe two classifiers we have built for relevance. A Naive Bayes classifier (NB) was used as the baseline.", "acronyms": [[83, 85]], "long-forms": [[59, 70]]}, {"text": " 1 Introduction  Statistical Machine Translation (SMT) is attracting more attentions than rule-based and example-", "acronyms": [[50, 53]], "long-forms": [[17, 48]]}, {"text": "(perhaps maller than traditional linguistic units) out of  component words: 1. noun group (NG), which consists  of a noun and its immediately preceding words (e.g., ", "acronyms": [[91, 93]], "long-forms": [[79, 89]]}, {"text": "transitions, depending on whether the backward-looking center of Ui?1 is maintained or not in Ui and on whether CB(Ui) is also the most highly ranked entity (CP) of Ui: Center Continuation (CON): CB(Ui) = CB(Ui?1), and CB(Ui) is the most highly ranked CF (CP) of Ui (i.e., CP(Ui) = CB(Ui))", "acronyms": [[190, 193], [112, 114], [94, 96], [65, 67], [158, 160], [196, 198], [252, 254], [256, 258], [282, 284], [273, 275]], "long-forms": [[176, 188], [199, 201]]}, {"text": "induction algorithm (Bisk and Hockenmaier, 2012), which induces a language-specific Combinatory Categorial grammar (CCG) and lexicon based on a small number of linguistic", "acronyms": [[116, 119]], "long-forms": [[84, 114]]}, {"text": "F6: \"TO PRODUCE GOLF CLUBS\"  (VP (AUX (TO \"TO\"))  (VP (V \"PRODUCE\")  (NP (N \"GOLF\") (N \"CLUBS\")))) ", "acronyms": [[51, 53], [30, 32], [34, 37], [70, 72]], "long-forms": [[55, 58]]}, {"text": "computational devices for natural language processing.  called active production networks (APNs), and explore  how certain kinds of movement are handled.", "acronyms": [[91, 95]], "long-forms": [[63, 89]]}, {"text": "ceedin.qs, IEEE-1ECEJ-ASJ htternational Con-  ference on Acoustics, Speech, and Signal Process-  ing (ICASSP), 2bkyo, April 1986. ", "acronyms": [[102, 108], [11, 25]], "long-forms": [[26, 100]]}, {"text": "cognition(COG) feeling(FEEL)  motivation(MOT) abstraction(ABS)  time(TIME) space(SPA) attribute(ATT)  relation(REL) social_relation(SREL) ", "acronyms": [[96, 99], [10, 13], [23, 27], [41, 44], [58, 61], [69, 73], [81, 84], [111, 114], [132, 136]], "long-forms": [[86, 94], [0, 9], [15, 22], [30, 40], [46, 57], [64, 68], [75, 80], [102, 110], [116, 131]]}, {"text": "Parse tree of tagged sentence in Box 1  3 Geographic Information Retrieval  3.1 Propositional logic of context (PLC)  As previously discussed, candidate named entities ", "acronyms": [[112, 115]], "long-forms": [[80, 110]]}, {"text": "basic word-level edit operations (insertion, deletion and substitution) to transform one text into the other: Levenshtein with substitution penalty (LEV2): This feature is a variant of LEV1 in which substi-", "acronyms": [[149, 153], [185, 189]], "long-forms": [[110, 147]]}, {"text": "potential can be fully exploited by our convolution partial tree kernel: - Dependency Words (DW) tree is similar to PET adapted for dependency tree constituted", "acronyms": [[93, 95], [116, 119]], "long-forms": [[75, 91]]}, {"text": "Processing, Hong Kong, Apr. HTK, 2004. Hidden Markov Model Toolkit (HTK) 3.2.", "acronyms": [[68, 71], [28, 31]], "long-forms": [[39, 66]]}, {"text": "The contextual information about social status and  sentence-external individuals can bc included in the  attribute CONTEXT (CONX). Ill order to see values the ", "acronyms": [[125, 129]], "long-forms": [[116, 123]]}, {"text": " 1 Introduction The use of Support Vector Machines (SVMs) in supervised learning frameworks is spreading", "acronyms": [[52, 56]], "long-forms": [[27, 50]]}, {"text": "The pair of speakers KI-KA is in the top quin-tile (>13.6%). Based on this evidence we can conclude the following:   ExpDisagreementDRX (KI,KA, 5, dialogue-1) which may be read as follows: speakers KI and KA have the highest level of expressive disagreement in dialogue-1. This measure is complemented by a Cumulative Disagreement Index (CDX), which is computed for each speaker as a percentage of all Disagree-Reject utterances in the discourse that are made by this speaker. Unlike DRX, which is computed for pairs of speakers, the CDX values are as-signed to each group participant and indicate the degree of disagreement that each person generates.", "acronyms": [[338, 341], [21, 26], [198, 200], [205, 207], [484, 487], [534, 537]], "long-forms": [[307, 336]]}, {"text": "sets for Chinese and English. For Chinese, this is the Penn Chinese Treebank 5.1 (CTB5), converted 2For replicability, a complete description of all features can", "acronyms": [[82, 86]], "long-forms": [[60, 80]]}, {"text": "by adapting the baseline model to four adaptation domains. In particular, we attempt to interpret the results given in terms of the character error rate (CER) by  correlating them with the characteristics of the adaptation domain measured us-", "acronyms": [[154, 157]], "long-forms": [[132, 152]]}, {"text": "gree (TTCD) 1, tongue body constriction location (TBCL) and degree (TBCD), lower tooth height (LTH), and glottal vibration (GLO). For example,", "acronyms": [[124, 127], [6, 10], [50, 54], [68, 72], [95, 98]], "long-forms": [[105, 122], [15, 48], [75, 93]]}, {"text": "Introduction  The pro jec t  note  presents  the  computer  program  GECO (GEometry COnsu l te r ) ,  wh ich  generates   exp lanat ions  (descr ip t ions )  o f  geometr i ca l  ", "acronyms": [[69, 73]], "long-forms": [[75, 96]]}, {"text": "WI = wide; NA = narrow; CR = critical; CL = closed; ALV = alveolar; P-A = palato-alveolar; RET = retroflex. ", "acronyms": [[91, 94], [0, 2], [11, 13], [24, 26], [39, 41], [52, 55], [68, 71]], "long-forms": [[97, 106], [5, 9], [16, 22], [29, 37], [44, 50], [58, 66], [74, 89]]}, {"text": "The last column lists the Spearman rank order correlation (?) of the rankings with the Berlin and Kay (B&K) ranks. ", "acronyms": [[103, 106]], "long-forms": [[87, 101]]}, {"text": " 1 Introduction Question Answering (QA) is a challenging task that draws upon many aspects of NLP.", "acronyms": [[36, 38], [94, 97]], "long-forms": [[16, 34]]}, {"text": "Program. It is intended that this interface be coupled to the battle management system being  developed under DARPA's Fleet Command Center Battle Management Program(FCCBMP). In the ", "acronyms": [[165, 171], [110, 115]], "long-forms": [[118, 163]]}, {"text": "SELF = talking to oneself  TQ = terse question  TI = terse information  INT = interrupted ", "acronyms": [[48, 50], [0, 4], [27, 29], [72, 75]], "long-forms": [[53, 70], [7, 25], [32, 46], [78, 89]]}, {"text": "? similar count? score (SC) is calculated as the number of characters that match between two", "acronyms": [[24, 26]], "long-forms": [[17, 22]]}, {"text": "to do the testing on real emotions. The Berlin Emotional Database (EMO-DB) contains the set of emotions from the MPEG-4 standard (anger,", "acronyms": [[67, 73], [113, 119]], "long-forms": [[47, 65]]}, {"text": " The non-standard words in text are referred to as Out of Vocabulary (OOV) words. The nor-", "acronyms": [[70, 73]], "long-forms": [[51, 68]]}, {"text": "I .  INTRODUCTION  Preliminary research on machine translat ion (MT) started soon af ter  computers  became avai lable.", "acronyms": [[65, 67]], "long-forms": [[43, 59]]}, {"text": "PIQ(Fy;R) or not.  z Predictive Information Redundancy(PIR) Based on the above two definitions, we can", "acronyms": [[55, 58], [0, 3], [4, 8]], "long-forms": [[21, 53]]}, {"text": "Tokens (T) .72 / .77 .83 / .84 .72 / .76 .85 / .84 .82 / .84 .88 / .86 Named Entities (NE) .75 / .80 .84 / .79 .75 / .77 .85 / .78 .89 / .78 .89 / .73 NE targeted (NE-T) .54 / .55 .49 / .47 .66 / .64 .60 / .57 .64 / .64 .57 / .58 Host (H) .72 / .57 .64 / .48 .67 / .51 .58 / .41 .67 / .63 .59 / .55", "acronyms": [[164, 168]], "long-forms": [[151, 162]]}, {"text": "1.1 A System Exhibiting Reinforcement Learning The central motivation for building this dialogue system is as a platform for Reinforcement Learning (RL) experiments.", "acronyms": [[149, 151]], "long-forms": [[125, 147]]}, {"text": "Having presented the sequent parser, we now show its embedding in the learning algorithm GraSp (Grammar of Speech). ", "acronyms": [[89, 94]], "long-forms": [[96, 113]]}, {"text": "Exact  match rate(EMR), violate match rate(VMR), and  inside match rate(IMR) denote the ratio of three  types of bracketing numbers in all bracketing ", "acronyms": [[72, 75], [18, 21], [43, 46]], "long-forms": [[54, 70], [0, 17], [24, 42]]}, {"text": "email: adam@itri.bton.ac.uk  People have been writing programs for auto-  matic Word Sense Disambiguation (WSD) for  forty years now, yet the validity of the task has ", "acronyms": [[107, 110]], "long-forms": [[80, 105]]}, {"text": "From raw text extract the temporal entities (events and timexes), identify the pairs of temporal entities that have a temporal link (TLINK) and classify the temporal relation between them.", "acronyms": [[133, 138]], "long-forms": [[118, 131]]}, {"text": "pairs. Transactions of the Association for Computational Linguistics (TACL), 2(10):377?392. ", "acronyms": [[70, 74]], "long-forms": [[7, 68]]}, {"text": " ? Target types per Source type (TpS), i.e. the number of target types a specific source type", "acronyms": [[33, 36]], "long-forms": [[10, 26]]}, {"text": "eling approaches. Table 3 shows the corresponding letter error rates (LER). LERs are more compa-", "acronyms": [[70, 73], [76, 80]], "long-forms": [[50, 68]]}, {"text": " Our correction model makes use of a minimum divergence (MD) model (Berger et al., 1996),", "acronyms": [[57, 59]], "long-forms": [[37, 55]]}, {"text": "In Proc. IEEE Automatic Speech Recognition and Understanding (ASRU), Merano, Italy, December. ", "acronyms": [[62, 66], [9, 13]], "long-forms": [[14, 60]]}, {"text": "Finally, the intention  translates into a call to UC's expression mechanism,  UCExpress (UCexpressl in the trace), which eventu-  ally calls UCGen to produce the answer.", "acronyms": [[78, 87], [50, 52], [141, 146]], "long-forms": [[89, 99]]}, {"text": "Langman dictionary.  Maximum Entropy (MaxEnt) principle has been successfully applied in many classification and tagging tasks (Rat-", "acronyms": [[38, 44]], "long-forms": [[21, 36]]}, {"text": "ment data time constraints, we were not able to test which of our modules leads to false negative (FN) instances. ", "acronyms": [[99, 101]], "long-forms": [[83, 97]]}, {"text": " The SU detection task is conducted on two corpora: Broadcast News (BN) and Conversational Telephone Speech (CTS).", "acronyms": [[68, 70]], "long-forms": [[52, 66]]}, {"text": "recognized cue phrase. Five systems followed a pure token classification approach (TC) for cue detection while others used sequential labeling tech-", "acronyms": [[83, 85]], "long-forms": [[52, 81]]}, {"text": "NE translation.   Although NE translation is less sophisticated than machine translation (MT) in general, to some extent, the issues in NE translation are similar to those in MT.", "acronyms": [[90, 92], [0, 2], [27, 29], [136, 138], [175, 177]], "long-forms": [[69, 88]]}, {"text": "and Innovation action). This research is part of the Interactive sYstems for Answer Search (IYAS) project, conducted by the Arabic Language Tech-", "acronyms": [[92, 96]], "long-forms": [[53, 90]]}, {"text": "attributes of the observation vectors and a  specific label).we can represent the input-output  pairs via joint feature map (JFM)  1", "acronyms": [[125, 128]], "long-forms": [[106, 123]]}, {"text": "eigenvalues are not zero, then I? minimizes the multiway normalized cut(MNCut): MNCut(I) = K ??", "acronyms": [[72, 77], [80, 85]], "long-forms": [[48, 71]]}, {"text": "trigger in the Trigger Rule Factbase.  Consistency Checkers ( CC' s): Report  inconsistencies within and between factbases and, ", "acronyms": [[62, 67]], "long-forms": [[39, 59]]}, {"text": "its right neighbour. Hence, the tree in Figure 2 is assumed to have the structure ((AB)C). ", "acronyms": [[84, 88]], "long-forms": [[52, 81]]}, {"text": "Cross-lingual textual entailment (CLTE) (Mehdad et al., 2010) is an extension of textual entailment (TE) (Dagan and Glickman, 2004).", "acronyms": [[101, 103], [34, 38]], "long-forms": [[81, 99], [0, 32]]}, {"text": "The IXM2 is the first massively parallel associative  processor that clearly demonstrates the computing  power of a large Associative Memory (AM). The AM ", "acronyms": [[142, 144], [4, 8], [151, 153]], "long-forms": [[122, 140]]}, {"text": "this corpus is labelled with a set of seven classes: beneficial (BNF), direction (DIR), extent (EXT), location (LOC), manner (MNR), purpose (PRP), and temporal (TMP).", "acronyms": [[112, 115], [141, 144], [65, 68], [82, 85], [96, 99], [126, 129], [161, 164]], "long-forms": [[102, 110], [132, 139], [53, 63], [71, 80], [88, 94], [118, 124], [151, 159]]}, {"text": "6.1 Corpus The training and test data sets were derived from the EventCorefBank (ECB) corpus5 created by Bejan and Harabagiu (2010) to study event coreference", "acronyms": [[81, 84]], "long-forms": [[65, 79]]}, {"text": "city. City and state can then be used to select a local area language model (LM) for recognizing listing names.", "acronyms": [[77, 79]], "long-forms": [[61, 75]]}, {"text": "notation for real-world applications. In Machine Translation (MT) Quality Estimation (QE), for instance, using human-", "acronyms": [[62, 64], [86, 88]], "long-forms": [[41, 60], [66, 84]]}, {"text": "In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 75? ", "acronyms": [[92, 95]], "long-forms": [[49, 89]]}, {"text": " ? Backward Looking (BL)/Forward Looking (FL) features (14 to 22) are mostly extracted from ut-", "acronyms": [[42, 44], [21, 23]], "long-forms": [[25, 40], [3, 19]]}, {"text": "  To address the issues in transliteration, we  propose a direct orthographic mapping (DOM)  framework through a joint source-channel model ", "acronyms": [[87, 90]], "long-forms": [[58, 85]]}, {"text": "For instance, in (def4) a polar interrogative clauses  (I'olS) is detined as a verb-first clause (V1S), which  in (def3) is deiined as a main clause (MainS), which  in turn is defined as a clause (S).", "acronyms": [[150, 155], [18, 22], [56, 61], [98, 101]], "long-forms": [[137, 148], [79, 96], [32, 53], [189, 195]]}, {"text": "formation from non-expert bilingual speakers. The  Translation Correction Tool (TCTool) is a userfriendly online tool that allows users to add, delete ", "acronyms": [[80, 86]], "long-forms": [[51, 78]]}, {"text": "In support to the on going project of Multilingual  Machine Translation Sytem for Asian Language organized by  Center for International Cooperaliou inComputerization (CICC)-  Japan and other Asian cotmtries (China.", "acronyms": [[167, 171]], "long-forms": [[111, 165]]}, {"text": "the percentage of words that were placed in a segment perfectly identical to that in the reference. The dialogue act based metric (DER) was proposed in Zimmermann et al (2005). In this metric a word is", "acronyms": [[131, 134]], "long-forms": [[104, 129]]}, {"text": "we use three categories for the identically spelled words: (a) we use the term true equivalents (TE) to refer to the pairs that have the same", "acronyms": [[97, 99]], "long-forms": [[79, 95]]}, {"text": "the end we build two NGCMs: NGCMP  (NGCM according to preceding context) and  NGCMS (NGCM according to succeeding  context).", "acronyms": [[78, 83], [21, 26], [28, 33], [36, 40]], "long-forms": [[85, 113]]}, {"text": "TO-DEATH).  VAg and related NPs/PPs (VAgRel) This is similar to VPa above, but for VAg.", "acronyms": [[37, 43], [64, 67], [83, 86]], "long-forms": [[12, 27]]}, {"text": "Sotelo, 2007).  4.3 Polarity Lexicon (LEX) We have built a polarity lexicon with both Positive", "acronyms": [[38, 41]], "long-forms": [[29, 36]]}, {"text": "information. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), pages 317?325, Columbus, USA.", "acronyms": [[100, 103], [131, 134]], "long-forms": [[57, 98]]}, {"text": "a. the 1000-headlines text (target domain) 1,181 40.2 32.1 35.7 b. the TEC (source domain) 32,954 29.9 26.1 27.9 c. the 1000-headlines text and the TEC (target and source) c.1.", "acronyms": [[148, 151], [71, 74]], "long-forms": [[153, 170]]}, {"text": " Single-tokenization of compound verbs  and named entities (NE) provides significant gains over the baseline PB-SMT ", "acronyms": [[60, 62], [109, 115]], "long-forms": [[44, 58]]}, {"text": "volved. We show that efficient training is feasible, using a Tree Adjoining Grammar (TAG) based parsing formalism.", "acronyms": [[85, 88]], "long-forms": [[61, 83]]}, {"text": "In order to solve idiomatic expressions as well as  collocations and frozen compound nouns, we  have developed the compound unit(CU)  recognizer (Jung et.", "acronyms": [[129, 131]], "long-forms": [[115, 127]]}, {"text": "158  I. CONSTRUCT THE PROPOSED ANCHORS for Un  (a) Create set of referring expressions (RE's). ", "acronyms": [[88, 92]], "long-forms": [[65, 86]]}, {"text": "English using the frequency dictionary of Arabic (Buckwalter and Parkinson, 2011) and the Corpus of Contemporary American English (COCA) top 5,000 words (Davies, 2010).", "acronyms": [[131, 135]], "long-forms": [[100, 121]]}, {"text": "by using multiple learners and a label integrator.  We have developed a forward (FR) and a backward relationship (BR) learner to learn relation-", "acronyms": [[81, 83], [114, 116]], "long-forms": [[72, 79], [91, 112]]}, {"text": "local  cons t i tuents .  These i n c l u d e  Hsimplem noun phrases (NPs) and  prepositional phrases (PPs), (\"simplen meaning 'up to the head noun but  not including any modifying clauses or phrases\"),  and verb groups (VGs) ", "acronyms": [[103, 106], [70, 73], [221, 224]], "long-forms": [[80, 101], [56, 68], [208, 219]]}, {"text": "5http://wordnet.princeton.edu/. 58 that, as in Informtion Retrieval (IR), multiple occurrences in the same document count as just one", "acronyms": [[69, 71]], "long-forms": [[47, 67]]}, {"text": "there are usually three kinds of named entities (NEs) to be dealt with: names of persons (PER) , locations (LOC) and organizations (ORG).", "acronyms": [[108, 111], [49, 52], [90, 93], [132, 135]], "long-forms": [[97, 106], [33, 47], [81, 87], [117, 129]]}, {"text": " 4.3 The Limited-Memory BFGS Algorithm The limited memory BFGS (L-BFGS) algorithm is a general purpose numerical optimization algorithm (Nocedal and Wright 1999).", "acronyms": [[64, 70], [24, 28]], "long-forms": [[43, 62]]}, {"text": "mark concept are sent to the kernel-based location belief tracker, while all other concepts are sent to a Dynamic Probabilistic Ontology Trees (DPOT) semantic belief tracker, whose structure is shown in", "acronyms": [[144, 148]], "long-forms": [[106, 142]]}, {"text": "  4.1 Speech recognition   The automatic speech recognition module (ASR)  is based on the Sphinx 4 system (Lamere et al, ", "acronyms": [[68, 71]], "long-forms": [[31, 59]]}, {"text": "Given these restrictions the DAR problem becomes to find that value da of DA that maximises P ( DA = da | f1 = v1, . . . , fn = vn,", "acronyms": [[96, 98], [29, 32], [74, 76]], "long-forms": [[101, 103]]}, {"text": "Table 1). Firstly, each term candidate is mapped to  a specific canonical representative (CR) by  semantically isomorphic transformations.", "acronyms": [[90, 92]], "long-forms": [[64, 88]]}, {"text": "entire search process.  (b) EPN for the first optimum solution (EPN-F): The number of the expanded problems when", "acronyms": [[64, 69]], "long-forms": [[28, 45]]}, {"text": "email: {firstname.lastname} @itri.bton.ac.uk  Introduction ~,  WYSIWYM (What You See Is What You Meant) is a user interface technique which allows anauthor to create  and edit in a natural and simple way the knowledge contained in a generated document.", "acronyms": [[63, 70]], "long-forms": [[72, 102]]}, {"text": "3 Polylingual Topic Model The polylingual topic model (PLTM) is an extension of latent Dirichlet alocation (LDA) (Blei et al.,", "acronyms": [[108, 111], [55, 59]], "long-forms": [[80, 106]]}, {"text": "The input to the first block are the words of the TEXTCHUNK, represented by CW (Collobert and Weston, 2008) embeddings.", "acronyms": [[76, 78], [50, 59]], "long-forms": [[80, 100]]}, {"text": "it can therefore mean ? prostrated on the threshold  and respectfully (AD) paid visits three times? or ", "acronyms": [[71, 73]], "long-forms": [[53, 56]]}, {"text": "  2. PrecisionCorrectTransliteration  (PTrans)  The precision is going to be computed using the ", "acronyms": [[39, 45]], "long-forms": [[5, 36]]}, {"text": " ? Argument Similarity (ArgSim): This baseline computes the cosine similarity of the vectors for", "acronyms": [[24, 30]], "long-forms": [[3, 22]]}, {"text": "In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC), pages 417?422.", "acronyms": [[89, 93]], "long-forms": [[54, 72]]}, {"text": "storing our storage. We built a pattern matching  system based on Finite State Automata(FSA). After ", "acronyms": [[88, 91]], "long-forms": [[66, 87]]}, {"text": " The obtained Spanish scores as compared to the  scores from the initial English experiment (E-E-E)  are shown in figure 5.", "acronyms": [[93, 98]], "long-forms": [[73, 91]]}, {"text": "generative models which are respectively estimated  on their corresponding named entity lists using  maximum likelihood estimation (MLE), together  with smoothing methods4.", "acronyms": [[132, 135]], "long-forms": [[101, 130]]}, {"text": "th fo frture representations abstracts (AbT), titles (ArT),  authors (Aut), Journals (Jou), and Mesh Headings", "acronyms": [[40, 43], [54, 57], [70, 73], [86, 89]], "long-forms": [[29, 38], [46, 52], [61, 68], [76, 84]]}, {"text": "ceedings of the 10th International Conference on Text, Speech, and Dialogue (TSD-2007), Lecture Notes in Computer Science (LNCS), Springer-Verlag.", "acronyms": [[123, 127], [77, 80]], "long-forms": [[88, 121]]}, {"text": "There have been p,'evious VCl'sions of I,'1\" (l,cpage 1986)  The I,T llSed ill our wo!'k has been implemented on  MacilLtosh with CLOS (Common Lisp Oh.jeer System)  (l,afeurcade 1993) The realizalion is lmscd mainly on ", "acronyms": [[130, 134], [26, 29]], "long-forms": [[136, 162]]}, {"text": "person, mood, voice and case, CATiB uses 6 POS tags: NOM (non-proper nominals including nouns, pronouns, adjectives and adverbs), PROP (proper nouns), VRB (verbs), VRB-PASS (passive-voice", "acronyms": [[130, 134], [30, 35], [43, 46], [53, 56], [151, 154], [164, 172]], "long-forms": [[136, 142], [156, 161]]}, {"text": "follow-up study, Le Calvez (2007) compared KL to other indicators, namely the Jensen?Shannon divergence (JS) and the Bhattacharyya coefficient (BC).3 2.2 Lexical indicators", "acronyms": [[144, 146], [43, 45], [105, 107]], "long-forms": [[117, 142]]}, {"text": "We suppose that the possessor of a noun phrase is  the subject or the noun phrase's nearest opic that  has a semantic mark,er HUM (human) or a seman-  tic marker AN I (animal).", "acronyms": [[126, 129], [162, 164]], "long-forms": [[131, 136]]}, {"text": "In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC), pages 1262?1267, Genoa, Italy, May.", "acronyms": [[89, 93]], "long-forms": [[54, 87]]}, {"text": "2002. DAML agent semantic communications service (ASCS) http://oak.teknowledge.com:8080/daml/damlquery.jsp", "acronyms": [[50, 54], [6, 10]], "long-forms": [[11, 48]]}, {"text": "We introduce a  exible history reference mechanism called an ACT (arboreal context tree; an extension of the context tree to tree-shaped his-", "acronyms": [[61, 64]], "long-forms": [[66, 87]]}, {"text": "120 compared to approximate maximum likelihood estimation (MLE). However, this method has not been", "acronyms": [[59, 62]], "long-forms": [[28, 57]]}, {"text": "determines the nature of such space.  For example, Syntactic Tree Kernel (STK) are used to model complete context free rules as in (Collins", "acronyms": [[74, 77]], "long-forms": [[51, 72]]}, {"text": "C-NOUN: Nouns with POS NN that are not marked O-NOUN or PER-NOUN.  Verbs Only ING-VERBs (VBG) and ED-VERBs (VBN and VBD) are needed for this task (other verbs trigger state O).", "acronyms": [[89, 92], [0, 6], [19, 22], [23, 25], [46, 52], [56, 64], [98, 106], [108, 111], [116, 119]], "long-forms": [[67, 81]]}, {"text": "tent both in their living rooms and on their mobile devices. Digital video recorders (DVRs) allow people to record TV programs from hundreds of chan-", "acronyms": [[86, 90], [115, 117]], "long-forms": [[61, 84]]}, {"text": "+ ??????????)  random Markov Clustering Algorithm (MCL)  (Dongen, 2000) ", "acronyms": [[51, 54]], "long-forms": [[22, 49]]}, {"text": " Figure 5 also gives a speed comparison of our method to a linear programming (LP) solver that solves the LP relaxation defined by constraints D0?", "acronyms": [[79, 81]], "long-forms": [[59, 77]]}, {"text": "There are two machine learning tasks in our problem. The first is Dialogue Act (DA) Tagging, in which we assign DAs to every Dialogue Func-", "acronyms": [[80, 82], [112, 115]], "long-forms": [[66, 78]]}, {"text": "system architecture  The data is stored in one central Resource  Repository (RR). As training data may change (for ", "acronyms": [[77, 79]], "long-forms": [[55, 75]]}, {"text": "NN = Noun, NN-PL = Plural Noun  DET = Determiner, PREP = Preposition  POS = Possessive, J J = Adjective  Table h Patterns for partOf(basement,building) ", "acronyms": [[70, 73], [0, 2], [11, 16], [32, 35], [50, 54], [88, 91]], "long-forms": [[76, 86], [5, 9], [19, 30], [38, 48], [57, 68], [94, 103]]}, {"text": "  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1181?1191, October 25-29, 2014, Doha, Qatar.", "acronyms": [[90, 95]], "long-forms": [[40, 88]]}, {"text": "For the nouns, 31 basic types are selected from  WordNet top categories (unique beginners): 2  entity(ENT) life~orm(LIF)  causal_agent(AGT) human(HUN) ", "acronyms": [[102, 105]], "long-forms": [[95, 100]]}, {"text": "(see also Sima?an, 1999, 2003). We haven?t implemented the max rule product (MRP) where posteriors are multiplied instead of added (Petrov and", "acronyms": [[77, 80]], "long-forms": [[59, 75]]}, {"text": "Engineering neighborhood of bank  bank  Subject Code EG = Engineering  river wall flood thick ", "acronyms": [[53, 55]], "long-forms": [[58, 69]]}, {"text": " ? Conditional Random Fields (CRF) is the state  of art for named entity extraction, in the ", "acronyms": [[30, 33]], "long-forms": [[3, 28]]}, {"text": "Accept? validations for reliably deliberate (Rel) and unreliable (URel) subsets of the metaphor production data, given that the", "acronyms": [[66, 70], [45, 48]], "long-forms": [[54, 64], [24, 32]]}, {"text": " In line 4, G91 provides an Acknowledge type of evidence, and Moves On to the next task item: identifying the Target Location - Grid (TL-GR) of the CFF. The Acknowledge and Move On, referring to the CGU", "acronyms": [[134, 139], [12, 15], [148, 151]], "long-forms": [[110, 132]]}, {"text": "two aspects: how well the generated text reflects the source data, whether it be text in another language for machine translation (MT), a natural language generation (NLG) input representation, a doc-", "acronyms": [[131, 133], [167, 170]], "long-forms": [[110, 129], [138, 165]]}, {"text": "3.2 Graph-based Label Propagation Graph-based label propagation, a critical subclass of semi-supervised learning (SSL), has been widely used and shown to outperform other SSL meth-", "acronyms": [[114, 117], [171, 174]], "long-forms": [[88, 112]]}, {"text": "mostly context-free, with some context-sensit ive and  some transformational  rules, written in a modif ied  Backus Normal Form (BNF). Each rule contains the ", "acronyms": [[129, 132]], "long-forms": [[109, 127]]}, {"text": "guages: German, French and Italian, with German  usually serving as the source language (SL),  French and Italian as the target language (TL). ", "acronyms": [[138, 140], [89, 91]], "long-forms": [[121, 136], [72, 87]]}, {"text": "Common error measures are the Word Error Rate (WER) and the Position Independent Word Error Rate (PER) as well as evaluation metric on the n-gram level like the BLEU and", "acronyms": [[98, 101], [47, 50], [161, 165]], "long-forms": [[60, 96], [30, 45]]}, {"text": "ing instance is created as during training, and then presented to the decision tree, which returns a confidence value (CF)2 indicating the likelihood that NPi is coreferential to NPj .", "acronyms": [[119, 121], [155, 158], [179, 182]], "long-forms": [[101, 111]]}, {"text": "dresses such conflicting constraints. In this method, the owner of the TM generates a Phrase Table (PT) from it, and makes it accessible to the user following", "acronyms": [[100, 102], [71, 73]], "long-forms": [[86, 98]]}, {"text": "Hyungjong Noh* Jeong-Won Cha** Gary Geunbae Lee*  *Department of Computer Science and Engineering  Pohang University of Science & Technology (POSTECH)  San 31, Hyoja-Dong, Pohang, 790-784, Republic of Korea ", "acronyms": [[142, 149]], "long-forms": [[99, 140]]}, {"text": " Temporal Types Possible Values (tags) Timeline (TL) past, present, future Day of Week (DOW) Mon, Tue, . . . ,", "acronyms": [[49, 51], [88, 91]], "long-forms": [[39, 47], [75, 86]]}, {"text": "for re-ranking in the context of name tagging.  Maximum Entropy modeling (MaxEnt) has  been extremely successful for many NLP classifi-", "acronyms": [[74, 80], [122, 125]], "long-forms": [[48, 63]]}, {"text": "Background (BKG) the background of the study Problem (PROB) the research problem Method (METH) the methods used Result (RES) the results achieved", "acronyms": [[89, 93], [12, 15], [54, 58], [120, 123]], "long-forms": [[81, 87], [0, 10], [45, 52], [112, 118]]}, {"text": "mental state labels that are highly similar to the context of the scene in a latent, conceptual vector space; and an information retrieval (IR) model that identifies labels commonly appearing in sentences", "acronyms": [[140, 142]], "long-forms": [[117, 138]]}, {"text": "contributions to sentence similarity. In most cases, the longer common sequence (LCS) the two sentences have, the higher similarity score the sentences", "acronyms": [[81, 84]], "long-forms": [[57, 79]]}, {"text": "restriction to do top-down filtering.  1986 Kameyama (1986) proposed a fourth transition type, Center Establishment (EST), for utterances E.g., in Bruno was the bully of the neighborhood.", "acronyms": [[117, 120]], "long-forms": [[102, 115]]}, {"text": "rlt*s*rle TR AN SFORHATIONS *S***   SCAN CALLED AT 1 I  ANTEST CALLED FOR 4l'I NG l1 (AACC) ,SD= 5. RES= 0.", "acronyms": [[70, 73], [86, 90], [93, 95], [100, 103]], "long-forms": [[56, 69]]}, {"text": "Collins et al. ( 2008) proposed simple exponentiated gradient (EG) algorithm for Conditional Random Feild (CRF).", "acronyms": [[63, 65], [107, 110]], "long-forms": [[39, 61], [81, 105]]}, {"text": "2.4 Longest Common Substring  Given two strings, T of length n and H of length m,  the Longest Common Sub-string (LCS) problem  (Dan, 1999) will find the longest string that is a ", "acronyms": [[114, 117]], "long-forms": [[87, 105]]}, {"text": "Dialogues were recorded and system and user behavior were logged automatically. The concept accuracy (CA) of each turn was manually labeled. If the", "acronyms": [[102, 104]], "long-forms": [[84, 100]]}, {"text": "WSD, which rely on knowledge represented as  attribute-value vectors: C4.5 (decision-trees),  Naive Bayes and Support Vector Machine (SVM)1. ", "acronyms": [[134, 137], [0, 3]], "long-forms": [[110, 132]]}, {"text": "josefr@coli.uni-sb.de Abstract Active Learning (AL) has been proposed as a technique to reduce the amount of annotated", "acronyms": [[48, 50]], "long-forms": [[31, 46]]}, {"text": "we can use these annotations to measure an average precision across the precision-recall curve, and an aggregate mean average precision (MAP) across all relations.", "acronyms": [[137, 140]], "long-forms": [[113, 135]]}, {"text": "in the lexicon to the following categories: protesters : NP seized : (S\\NP )/NP several : NP/NP", "acronyms": [[70, 74], [57, 59], [77, 79], [90, 95]], "long-forms": [[60, 68]]}, {"text": "autism. In Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR), pages 131?140, Gothenburg, Sweden, April. Association for Computational Linguistics.", "acronyms": [[119, 123]], "long-forms": [[46, 117]]}, {"text": "Concerned about this inflation of the grammar constant, (DeNero et al, 2009) consider a superset of CNF called Lexical Normal Form (LNF). A rule is", "acronyms": [[132, 135], [100, 103]], "long-forms": [[111, 130]]}, {"text": "Next we consider the recurrent neural network (RNN) based architecture called the Dual Encoder (DE) model (Lowe et al, 2015). The", "acronyms": [[96, 98], [47, 50]], "long-forms": [[82, 94], [21, 45]]}, {"text": " Table 1: Classifier features in predicate disambiguation (PredDis), argument identification (ArgId), and argument labeling (ArgLab).", "acronyms": [[94, 99], [59, 66], [125, 131]], "long-forms": [[69, 92], [33, 57], [106, 123]]}, {"text": "2004). Accordingly, we define in-NE probability  to help delete and create named entities (NE). ", "acronyms": [[91, 93], [30, 35]], "long-forms": [[75, 89]]}, {"text": " University of Texas at Austin Word sense disambiguation (WSD) is an old and important task in computational linguistics that still remains challenging, to machines as well as to human annotators.", "acronyms": [[58, 61]], "long-forms": [[31, 56]]}, {"text": "l (CAUSER sally-l)  (OBJECT paint-l)  (PATH (path-1 (DESTINATION wall-l))))  Sally sprayed the wall with paint.", "acronyms": [[39, 43], [10, 17], [28, 35]], "long-forms": [[45, 51]]}, {"text": "for 4 of the 9 classes, and was usually competitive on the remaining 5 classes. WordNet (W.Net) consistently produced high precision, but with compar-", "acronyms": [[89, 94]], "long-forms": [[80, 87]]}, {"text": " We integrate two sets of linguistic features into a maximum entropy (MaxEnt) model and develop aMaxEnt-based binary classifier to predict the cat-", "acronyms": [[70, 76], [97, 103]], "long-forms": [[53, 68]]}, {"text": "LL; it is calculated from contingency table information as follows: LO = log (O11 + 0.5)(O22 + 0.5)", "acronyms": [[68, 70]], "long-forms": [[73, 76]]}, {"text": "construct such a treebank from scratch. Fortunately, RST Discourse Treebank (RST-DT)  (Carlson et al, 2001) is an available resource to ", "acronyms": [[77, 83]], "long-forms": [[53, 75]]}, {"text": "Topic 1 Other modules Greeting(GR) Keep silence(KS) Figure 2: Overview of the information navigation", "acronyms": [[31, 33], [48, 50]], "long-forms": [[22, 29], [35, 46]]}, {"text": " 2.1 Random Indexing Our first method is based on Random Indexing (RI), introduced by Kanerva (Kanerva, 1988).", "acronyms": [[67, 69]], "long-forms": [[50, 65]]}, {"text": "composition process.  4.1 Tag Guided RNN (TG-RNN) We propose Tag Guided RNN (TG-RNN) to re-", "acronyms": [[42, 48], [77, 83]], "long-forms": [[26, 40], [61, 75]]}, {"text": "document is different from the question. Also, in  Information Extraction (IE), in which the system  tries to extract elements of some events (e.g. ", "acronyms": [[75, 77]], "long-forms": [[51, 73]]}, {"text": "Step 1  Tagging using Global Distribution (NEIG) Trained Model Statistical System (MEMM) Step 2 MEMM Based Statistical System(S-MEMM)Final Tagged DataSet Added    as a feature", "acronyms": [[126, 132], [43, 47], [83, 87], [146, 153]], "long-forms": [[89, 100]]}, {"text": "While named entity recognition (NER) and relation or event extraction are regarded as standard tasks of information extraction (IE), coreference resolution (Ng, 2010; Bejan and Harabagiu, 2010) is more", "acronyms": [[128, 130]], "long-forms": [[104, 126]]}, {"text": "cke et al, 1997). The only attempt to use Minimum Bayes Risk (MBR) decoding in parsing was made in (Goodman, 1996), where a parsing al-", "acronyms": [[62, 65]], "long-forms": [[42, 60]]}, {"text": " ? HybFSum (Hybrid Flat Summarizer): To investigate the performance of hierarchical topic", "acronyms": [[3, 10]], "long-forms": [[12, 34]]}, {"text": "Abbreviations: Trig./Arg./Group./Modif.=event trigger detection/argument detection/argument grouping/modification detection, BI=Bioinformatician, NLP=Natural Language Processing researcher, CS=Computer scientist, CoreNLP=Stanford CoreNLP, Porter=Porter stemmer, Snowball=Snowball stemmer McCCJ=McClosky-Charniak-Johnson parser, LGP=Link Grammar Parser, SD=Stanford De-", "acronyms": [[190, 192], [353, 355], [328, 331], [288, 293], [213, 220], [230, 237]], "long-forms": [[193, 211], [356, 364], [332, 351], [294, 319]]}, {"text": "\\[ Class (Tag) Kernel Nouns  act (AC)  an~ (AN)  art~fact (AR) ", "acronyms": [[44, 46]], "long-forms": [[39, 42]]}, {"text": "Symbol Descriptor Example  If. I Simple connection between (IMPEDANCE) GA TAF~I  I|.2 ", "acronyms": [[60, 69]], "long-forms": [[31, 58]]}, {"text": "sists of given entities and their relation expression.  Here, we use a Salient Referent List (SRL) to obtain contextual structure.", "acronyms": [[94, 97]], "long-forms": [[71, 92]]}, {"text": "77 .73  Problem 2nd 1.45 3.00  GS = Group significant cannot pool by individual  DISCUSSION OF THE RESULTS ", "acronyms": [[31, 33]], "long-forms": [[36, 53]]}, {"text": "word-level features described in Section 5.  4.1 Ranking by regression (RR) The first ranking strategy is based on training a re-", "acronyms": [[72, 74]], "long-forms": [[49, 70]]}, {"text": "Given an OOV word a and its IV version b we have extracted character transformation rules from a to b using the longest common substring (LCS) algorithm (See Table 5).", "acronyms": [[138, 141], [9, 12], [28, 30]], "long-forms": [[112, 136]]}, {"text": "hedge words Table 3: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, SDE=Software Development Engineer, CoreNLP=Stanford CoreNLP, Porter=Porter", "acronyms": [[85, 87], [106, 109], [150, 153], [185, 192], [211, 217]], "long-forms": [[88, 104], [110, 137], [154, 183], [218, 224], [193, 209]]}, {"text": "tically justified.  Tree adjoining grammars (TAGs) are also a tree-based  system, ltowever, the major composition operation in ", "acronyms": [[45, 49]], "long-forms": [[20, 43]]}, {"text": "of the above three neural classifiers.  Recursive Autoencoder (RAE) has proven to be an effective model to compose words vectors in", "acronyms": [[63, 66]], "long-forms": [[40, 61]]}, {"text": "also included as features.  Concept Unique Identifiers (CUIs): We follow the approach presented by McInnes et al (2007) to", "acronyms": [[56, 60]], "long-forms": [[28, 54]]}, {"text": "Averaged Reca l l  (AR)  : 2  PP.~.NP ? Averaged Prec is ion  (AP)  : 2  (fl3-1-1)?PPxPR ?", "acronyms": [[63, 65], [20, 22], [30, 32], [35, 37], [83, 85], [86, 88]], "long-forms": [[40, 60], [0, 17]]}, {"text": "Note Table 3: Statistics of training and test corpus for the Canadian Hansards task (PP=perplexity). ", "acronyms": [[85, 87]], "long-forms": [[88, 98]]}, {"text": "  ? suffixes (SUF), such as verb endings, nominal  cases, the nominal feminine ending -at, etc.;", "acronyms": [[14, 17]], "long-forms": [[4, 12]]}, {"text": " 4.4 Bag of Words using Maximum Entropy (MaxEnt) Classifier We include Maximum Entropy classifier using sim-", "acronyms": [[41, 47]], "long-forms": [[24, 39]]}, {"text": "Odijk, and Stelios Piperidis, editors, Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC?14), Reykjavik, Iceland, may. European Language Resources Association (ELRA). ", "acronyms": [[203, 207], [127, 134]], "long-forms": [[162, 201], [92, 125]]}, {"text": "Table 2: Comparison of adaptive supertagging (AST) and a less restrictive setting (Reverse) with Viterbi and oracle F-scores on CCGbank Section 00. The table shows the labelled F-score (LF), precision (LP) and recall (LR) and the the number of lexical categories per word used (from first to last parsing attempt).", "acronyms": [[186, 188], [46, 49], [128, 135], [202, 204], [218, 220]], "long-forms": [[168, 178], [23, 44]]}, {"text": "match with a hypothesis. These weights are  confidence measures: Logical Sufficiency (LS)  and Logical Necessity (LN).", "acronyms": [[86, 88], [114, 116]], "long-forms": [[65, 84], [95, 112]]}, {"text": "518 ? SS = Stanford parser style:5 the first conjunct is the head and the remaining conjuncts (as", "acronyms": [[6, 8]], "long-forms": [[11, 32]]}, {"text": "Evidence for a text?s topic and genre comes, in part, from its lexical and syntactic features?features used in both Automatic Topic Classification and Automatic Genre Classification (AGC). Because an ideal AGC system should", "acronyms": [[183, 186], [206, 209]], "long-forms": [[151, 181]]}, {"text": "     elements; ? |? is used for alternating elements; TOP = topic marker. ", "acronyms": [[54, 57]], "long-forms": [[60, 65]]}, {"text": "for more general audience of users.  Helping our own (HOO) is an initiative that could in future spark a new interest in the re-", "acronyms": [[54, 57]], "long-forms": [[37, 52]]}, {"text": "Ures uniformly (Dadam et al, 1986). Our LDB  rmat and Lexical Query l_anguage (LQL) sup-  port the hierarchical model for dictionary data; ", "acronyms": [[79, 82], [40, 43]], "long-forms": [[54, 77]]}, {"text": " 2 (Durrett and Klein, 2013) call this error false new (FN). ", "acronyms": [[56, 58]], "long-forms": [[45, 54]]}, {"text": "First, we rewrite equation 1 in a more detailed fashion as: A?R = argmax A", "acronyms": [[60, 63]], "long-forms": [[66, 72]]}, {"text": "model organism databases (e.g., for mouse3 and  yeast4) as well as various protein databases (e.g.,  Protein Information Resource5 (PIR) or SWISS-                                                                                           tor), a model organism for genetics research: ", "acronyms": [[132, 135]], "long-forms": [[101, 130]]}, {"text": " 3.1 Sentence Splitting (SS) Sentence Splitting (SS) is the rewriting of a sentence by breaking it into two or more sentences,", "acronyms": [[49, 51], [25, 27]], "long-forms": [[29, 47], [5, 23]]}, {"text": "Holes, 2004). Most tools and resources developed for natural language processing (NLP) of Arabic are designed for MSA.", "acronyms": [[82, 85], [114, 117]], "long-forms": [[53, 80]]}, {"text": "food(FOOD) artifact(AFT) article(ART)  location(LOC) psych_feature(PSY)  cognition(COG) feeling(FEEL)  motivation(MOT) abstraction(ABS) ", "acronyms": [[83, 86], [5, 9], [20, 23], [33, 36], [48, 51], [67, 70], [96, 100], [114, 117], [131, 134]], "long-forms": [[73, 81], [0, 4], [11, 19], [25, 32], [39, 47], [53, 66], [88, 95], [103, 113], [119, 130]]}, {"text": "In addition, results from the machine learning based model are refined by a rule-based postprocessing, which is implemented using a finite state transducer (FST). The", "acronyms": [[157, 160]], "long-forms": [[132, 155]]}, {"text": "  We have also made a preliminary attempt to transfer a thesaurus entry from the Collins Thesaurus (CT) into  Italian by means of the English-Italian and Italian- ", "acronyms": [[100, 102]], "long-forms": [[81, 98]]}, {"text": "= Majority Class, Acc. = Accuracy, SE = Standard Error) ing on 5 \u0000 with 20-fold cross-validation achieves an", "acronyms": [[35, 37], [18, 21]], "long-forms": [[40, 54], [25, 33]]}, {"text": "lines and web-gathered word lists. Theses grammars are represented by Finite State Machines (FSMs) (thanks to the AT&T GRM/FSM toolkit (Allauzen et", "acronyms": [[93, 97], [114, 118], [119, 126]], "long-forms": [[70, 91]]}, {"text": "to cover terms frequently used by students, such as acronyms: E.L.C. (the English Language Center), R.O.C. (Republic of China), and so on. Other", "acronyms": [[100, 106], [62, 67]], "long-forms": [[108, 125], [74, 97]]}, {"text": "wisdom of crowds. Our approach is based on the Latent Mixture of Discriminative Experts (LMDE) model originally introduced for multimodal fu-", "acronyms": [[89, 93]], "long-forms": [[47, 87]]}, {"text": "appropriate.  Terminology Data banks (TD) are the least ambitious  systems because access frequently is not made during a ", "acronyms": [[38, 40]], "long-forms": [[14, 30]]}, {"text": "This representation uses the logical formulation of feature structures  as given by Kasper and Rounds (1986) and Johnson (1988) and is similar in approach  to the logical formulation of Functional Unification Grammar (FUG) given by Rounds  and Manaster-Ramer (1987).", "acronyms": [[218, 221]], "long-forms": [[186, 216]]}, {"text": "pears or no other attribute is included.  Surface Text (ST): To measure the effectiveness of the semantic analysis (attribute labels and ", "acronyms": [[56, 58]], "long-forms": [[42, 54]]}, {"text": "a user interface for the production of wordlevel annotations for an opinion-mining task in the information technology (IT) domain. ", "acronyms": [[119, 121]], "long-forms": [[95, 117]]}, {"text": "1.2 The Binding Module The output of grammatical modules is then fed onto the Binding Module(BM) which activates an algorithm for anaphoric binding in LFG terms", "acronyms": [[93, 95], [151, 154]], "long-forms": [[78, 92]]}, {"text": "The key reason to compute tsim under the equiprobability assumption is that we need not compute the MWBM, but may find just the maximum cardinality bipartite matching (MCBM), since all potential links have the same weight. An O(e", "acronyms": [[168, 172], [100, 104]], "long-forms": [[158, 166]]}, {"text": "Efficient Algorithms for Parsing the DOP  Model\", Proceedings Empirical Methods in Natural Language  Processing, Philadelphia (PA),  J. Goodman, 1998.", "acronyms": [[127, 129], [37, 40]], "long-forms": [[113, 125]]}, {"text": ".  3.4 Stochastic Gradient Descent (SGD) Training With the likelihood gradients, we apply L2-norm regularized SGD training to iteratively learn the feature", "acronyms": [[36, 39], [110, 113]], "long-forms": [[7, 34]]}, {"text": "of National Intelligence (ODNI) and the Intelligence Advanced Research Projects Activity (IARPA) via the Air Force Research Laboratory (AFRL) contract number FA8750-16-C-0114.", "acronyms": [[136, 140], [26, 30], [90, 95]], "long-forms": [[105, 134], [40, 88]]}, {"text": "Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval (IR) system (Choueka, 1990; Ja?ppinen and Niemisto?,", "acronyms": [[121, 123]], "long-forms": [[98, 119]]}, {"text": " We ran three parsing experiments: (i) replacing the value of the surface form (FORM) of pronominal prepositions with their lemma form (LEMMA), for", "acronyms": [[80, 84], [136, 141]], "long-forms": [[74, 78], [124, 129]]}, {"text": "88 lated based on a co-occurrence relationship between i and w. Next, the semantic orientation (SO) of the phrase i is obtained by calculating the difference be-", "acronyms": [[96, 98]], "long-forms": [[74, 94]]}, {"text": "In Proceedings of the 11th International Joint Conference on Artificial Intelligence (IJCAI-89), volume 2, pages 1511?1517.", "acronyms": [[86, 94]], "long-forms": [[27, 84]]}, {"text": "tongues. In Proc. of the Text Encoding Initiative 10th Anniversary User Conference (TEI-10). ", "acronyms": [[84, 90], [12, 16]], "long-forms": [[25, 54]]}, {"text": "  1. PARADISEC (Pacific and Regional Archive for Digital Sources in Endangered Cultures): audio, video,  text and image resources for Australian and Pacific Island languages (Thieberger, Barwick, Billington, & ", "acronyms": [[5, 14]], "long-forms": [[16, 87]]}, {"text": "ayman,R.Gaizauskas@dcs.shef.ac.uk Abstract Disambiguating named entities (NE) in running text to their correct interpretations in a specific knowledge base (KB) is an important problem in NLP.", "acronyms": [[74, 76], [157, 159], [188, 191]], "long-forms": [[58, 72], [141, 155]]}, {"text": "tity in the contrast set until no distractors are left.  Dale & Reiter speaker frequency (DR-sf) uses a different preferred attribute list for each speaker,", "acronyms": [[90, 95]], "long-forms": [[57, 88]]}, {"text": "scheme that includes: (1) a pre-annotation that segments the dialogue into turns which are further segmented into Elementary Discourse Units (EDUs) with the author of each turn automatically given;", "acronyms": [[142, 146]], "long-forms": [[114, 140]]}, {"text": " iii. Simple_Rank (S-Rank): It is computed  based on Rank(i)=tfi*Len(i), which aims ", "acronyms": [[19, 25]], "long-forms": [[6, 17]]}, {"text": " 3 Tools and Component Combination   We use the support vector machine (SVM) multi-class classifier (Crammer and Singer (2002),  ", "acronyms": [[72, 75]], "long-forms": [[48, 70]]}, {"text": " In Table 3 the number of questions that get a higher and lower reciprocal rank (RR) after applying the individual lexico-semantic resources are", "acronyms": [[81, 83]], "long-forms": [[64, 79]]}, {"text": "Table 3 describes the used data sets.  Assault Weapons (AW) 4", "acronyms": [[56, 58]], "long-forms": [[39, 54]]}, {"text": "when reconcilable with Bias 1. Whenever the sentence or query has a verb phrase (VP) spanning roughly half of it, annotators seem to chunk be-", "acronyms": [[81, 83]], "long-forms": [[68, 79]]}, {"text": " Acknowledgements  This work was supported by the Social Sciences and Humanities Research Council (SSHRC) of Canada. We ", "acronyms": [[99, 104]], "long-forms": [[50, 97]]}, {"text": "Tutor's Priming Ratio aggregated by task set (TS = Task Set)     Figure 3. Student's Priming Ratio aggregated by task set (TS = Task Set)  Several significant relationships emerged within the models. We discuss a subset of these here.", "acronyms": [[123, 125], [46, 48]], "long-forms": [[128, 136], [51, 59]]}, {"text": "The underlying learning algorithm has been successfully applied to some other Natural Language Processing (NLP) tasks. ", "acronyms": [[107, 110]], "long-forms": [[78, 105]]}, {"text": " 5 Conclusions The spoken language understanding (SLU) system discussed in this paper is entirely statistically based.", "acronyms": [[50, 53]], "long-forms": [[19, 48]]}, {"text": "92\\]. This selective approach led to significant  results in some restricted applications (ATIS...). ", "acronyms": [[91, 98]], "long-forms": [[77, 89]]}, {"text": "approach to structuring knowledge is based  on:  z automatic term recognition (ATR)  z automatic term clustering (ATC) as an ", "acronyms": [[79, 82], [114, 117]], "long-forms": [[51, 77], [87, 112]]}, {"text": "  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 928?937, October 25-29, 2014, Doha, Qatar.", "acronyms": [[90, 95]], "long-forms": [[40, 88]]}, {"text": " 1 Introduction The Semantic Textual Similarity (STS) shared task consists of several data sets of paired passages of", "acronyms": [[49, 52]], "long-forms": [[20, 47]]}, {"text": "The seed set is compiled from popular mental and emotional state dictionaries, including the Profile of Mood States (POMS) (McNair et al.,", "acronyms": [[117, 121]], "long-forms": [[93, 115]]}, {"text": "Finally, Lampert, Dale, and Paris (2006) describe a statistical classifier trained on text-based features for automatically predicting eight different speech acts derived from a taxonomy called Verbal Response Modes (VRM). The experiments are conducted", "acronyms": [[217, 220]], "long-forms": [[194, 215]]}, {"text": " In Proc. Rich Text 2004 Fall Workshop (RT-04F). ", "acronyms": [[40, 46]], "long-forms": [[10, 29]]}, {"text": "The table shows percentage of phrases that we have to retain. ES=Spanish, EN=English, FR=French, CS=Czech, DE=German. ", "acronyms": [[74, 76], [86, 88], [62, 64], [97, 99], [107, 109]], "long-forms": [[77, 84], [89, 95], [65, 72], [100, 105], [110, 116]]}, {"text": "The word lattices of the HUB-1 corpus are directed acyclic graphs in the HTK Standard Lattice Format (SLF), consisting of a set of vertices and a set of edges.", "acronyms": [[102, 105], [25, 30], [73, 76]], "long-forms": [[77, 100]]}, {"text": "DEPICTION (DPC) TOPIC (TPC) SYNONYMY-NAME (SYN) CAUSALITY (CSL) PART-WHOLE (PW) MANNER (MNR) ANTONYMY (ANT) JUSTIFICATION (JST) HYPERNYMY (ISA) MEANS (MNS) PROBABILITY OF EXISTENCE (PRB) GOAL (GOL) ENTAIL (ENT) ACCOMPANIMENT (ACC) POSSIBILITY (PSB) BELIEF (BLF)", "acronyms": [[182, 185], [43, 46], [11, 14], [23, 26], [193, 196], [206, 209], [226, 229], [244, 247], [257, 260], [59, 62], [76, 78], [88, 91], [103, 106], [123, 126], [151, 154], [139, 142]], "long-forms": [[156, 167], [28, 36], [0, 9], [16, 21], [187, 191], [198, 204], [211, 224], [231, 242], [249, 255], [48, 57], [64, 74], [80, 86], [93, 101], [108, 121], [144, 149]]}, {"text": "Verbs can also involve non-core modifier arguments, such as ArgMTMP (time), ArgM-LOC (location), ArgM-CAU (cause), etc.", "acronyms": [[81, 84], [60, 67], [97, 105]], "long-forms": [[86, 94], [69, 73], [107, 112]]}, {"text": "knowledge. The use of Proposition Stores as  Background Knowledge Bases (BKB) have been  argued to be useful for improving parsing, co-", "acronyms": [[73, 76]], "long-forms": [[45, 71]]}, {"text": "CoTrain vs. SVM(EN) 2.15E-18 1.1E-17 3.46E-13 CoTrain vs. SVM(ENCN) 2.08E-13 8.13E-12 1.05E-12 CoTrain vs. TSVM(CN) 1.2E-19 1.07E-06 0.0624 CoTrain vs. TSVM(EN) 1.41E-05 0.00311 2.17E-08", "acronyms": [[112, 114], [12, 15], [16, 18], [58, 61], [62, 66], [152, 156], [157, 159], [107, 111]], "long-forms": [[95, 102]]}, {"text": "the classification of various verb groups (generic verbs versus specific verbs) based on the semantic distance with Latent Semantic Analysis (LSA) and Cluster Analysis.", "acronyms": [[142, 145]], "long-forms": [[116, 140]]}, {"text": "x, y) where t(x) is the true label of the observation sequence x. We can get a quadratic program (QP) using a standard transformation to eliminate ?", "acronyms": [[98, 100]], "long-forms": [[79, 96]]}, {"text": "4.1 Test Dataset The dataset used in our experiments comes from the Automated Student Assessment Prize (ASAP)1, which is sponsored by the William and Flora", "acronyms": [[104, 108]], "long-forms": [[68, 102]]}, {"text": "James Clark. 1999. XSL transformations (XSLT). W3C Recommendation, 16 November.", "acronyms": [[40, 44]], "long-forms": [[19, 38]]}, {"text": "They are Independent Word Probability (IWP), Anti-Word Pair  (AWP), and Word Formation Analogy (WFA). ", "acronyms": [[96, 99], [39, 42], [62, 65]], "long-forms": [[72, 94], [9, 37], [45, 59]]}, {"text": "cal search. We examine this by using three different parsers in phase 0: (i) MS (Marecek and Straka, 657", "acronyms": [[77, 79]], "long-forms": [[81, 99]]}, {"text": "sLDA is a model that is an extension of Latent Dirichlet Allocation (LDA) (Blei et al, 2003) that models each document as having an output variable in addition to", "acronyms": [[69, 72], [0, 4]], "long-forms": [[40, 67]]}, {"text": " 2Regularized parses (henceforth, \"parse trees\") are  like F-structures of Lexical Ftmction Grammar (LFG),  except, hat a dependency structure is used.\"", "acronyms": [[101, 104]], "long-forms": [[75, 99]]}, {"text": "Results for the Mention-Pair Model 1 Base 56.5 69.7 62.4 54.9 66.3 60.0 50.4 56.7 53.3 48.9 54.5 51.5 2 Base+YAGO Types (YT) 57.3 70.3 63.1 58.7 67.5 62.8 51.7 57.9 54.6 50.3 55.6 52.8 3 Base+YAGO Means (YM) 56.7 70.0 62.7 55.3 66.5 60.4 50.6 57.0 53.6 49.3 54.9 51.9", "acronyms": [[121, 123], [204, 206]], "long-forms": [[104, 119], [192, 202]]}, {"text": "As shown in Table 3, using the transformation of dependency trees, the Dep2Str model implemented in Moses (D2S) is comparable with the standard implementation", "acronyms": [[107, 110]], "long-forms": [[71, 78]]}, {"text": "mantic feature called the latent topic feature, which is extracted by exploiting the Latent Dirichlet Allocation (LDA) algorithm. Unlike syntactic fea-", "acronyms": [[114, 117]], "long-forms": [[85, 112]]}, {"text": "In practice we can find approximate solution using such algorithms as: Loopy Belief Propagation (BP), Mean Field (MF), Gibbs Sampling (Gibbs). ", "acronyms": [[114, 116], [97, 99], [135, 140]], "long-forms": [[102, 112], [77, 95], [119, 124]]}, {"text": "perceptual space between each pair. We can do this with a multidimensional scaling (MDS) algorithm. Let us call", "acronyms": [[84, 87]], "long-forms": [[58, 82]]}, {"text": "Labels Base NP modifier NN (common noun), M (measure word), CD (cardinal number), OD (ordinal number), PN (pronoun), NR (proper noun), NT (temporal noun), JJ (other noun-modifier), or PU (punctuation) Base NP head NN (common noun), M (measure word), CD (cardinal number), OD (ordinal number), PN (pronoun), NR", "acronyms": [[184, 186]], "long-forms": [[188, 199]]}, {"text": "~ '1  procedural component  Q data structure  SSP = SemanticJSyntacticJPhonological  Figl~e 1: The SYNPHONICS Formulator ", "acronyms": [[46, 49], [99, 109]], "long-forms": [[52, 83]]}, {"text": "As the entire sentence is informative to determine the proper conjunction of all roles, a Smoothed Partial Tree Kernel (SPTK) within the classifier that enhances both syntactic and lexical in-", "acronyms": [[120, 124]], "long-forms": [[90, 118]]}, {"text": "  Although we use the same techniques to derive global features (assessor variety (AV) feature with 2~6 grams) from both training and test-", "acronyms": [[83, 85]], "long-forms": [[65, 81]]}, {"text": "Proceedings of  the First International Symposium on Compurers and Chinese  Inpuf/Output Systems, Acadernig Sinico, 983-998  in the FCL (FACOM Composition Language) System, information is punched on paper tape  with a Kanji keyboard.", "acronyms": [[132, 135]], "long-forms": [[137, 163]]}, {"text": "  An Underspecified Segmented Discourse Representation Theory (USDRT)  Frank Schilder ", "acronyms": [[63, 68]], "long-forms": [[5, 61]]}, {"text": "Nevertheless, LSI has known a resurging interest. Supervised Semantic Indexing (SSI) (Bai et al.,", "acronyms": [[80, 83], [14, 17]], "long-forms": [[50, 78]]}, {"text": "Table 1: Labelled attachment score on the two test sets of the best single parse, blended with weights set to PoS labelled attachment score (LAS) and blended with learned weights.", "acronyms": [[141, 144], [110, 113]], "long-forms": [[114, 139]]}, {"text": "have to be induced from parallel corpora.  An inversion transduction grammar (ITG) strikes a good balance between STGs and SDTGs,", "acronyms": [[78, 81], [114, 118], [123, 128]], "long-forms": [[46, 76]]}, {"text": " Snow et al (2008) explored the use of the Amazon Mechanical Turk (MTurk) web service for gathering annotations for a variety of natural lan-", "acronyms": [[67, 72]], "long-forms": [[50, 65]]}, {"text": " 3.1 Underspecified domains An underspecified domain (UD) represents a partially specified reference domain corresponding to the", "acronyms": [[54, 56]], "long-forms": [[31, 52]]}, {"text": "Run 3 100% 18 (9.0%) 38 (19.0%)  Table 7.  Effect of Translation (E-C)   ", "acronyms": [[66, 69]], "long-forms": [[43, 49]]}, {"text": "dominates the other.  Marcu?s Nuclearity Principle (NP) Marcu 1996 provides an alternative to the immediate interpretation and", "acronyms": [[52, 54]], "long-forms": [[30, 50]]}, {"text": "In a second step, unmatched words are converted into stems or synonyms and then matched. A method that uses the concept of maximum matching string (MMS) is presented by Turian, Shen, and Melamed (2003).", "acronyms": [[148, 151]], "long-forms": [[123, 146]]}, {"text": "Figure 2: Algorithm for scope detection by MRS crawling a Formally: If an EP shares its label with the negation cue, or is a quantifier whose restriction (RSTR) is = q", "acronyms": [[155, 159], [43, 46], [74, 76]], "long-forms": [[142, 153]]}, {"text": "Overall recall and precision were 0.80 and 0.87 for drugs, and 0.56 and 0.85 for adverse events. 1 Introduction  It is well-known that adverse drug reactions (ADRs) are an important health problem. Indeed, ADRs are the 4th cause of death in hospitalized patients (Wester et al.,", "acronyms": [[159, 163], [206, 210]], "long-forms": [[135, 157]]}, {"text": "directly from the speech signal. In recent years, a variant of dynamic time warping (DTW) has been proposed to find reoccurring patterns in the speech", "acronyms": [[85, 88]], "long-forms": [[63, 83]]}, {"text": "data are summarized in Table 6. We also report the Wordnet first sense baseline (WFS). ", "acronyms": [[81, 84]], "long-forms": [[51, 79]]}, {"text": "Abstract   This paper describes two algorithms which construct two differ-  ent types of generators for lexical functional grammars (LFGs). The ", "acronyms": [[133, 137]], "long-forms": [[104, 131]]}, {"text": "4.0 release. This was also the training data used in the experiments in the Parsing the Web (PTW) shared task at NAACL 2012.2 In the shared task", "acronyms": [[93, 96], [113, 118]], "long-forms": [[76, 91]]}, {"text": "3.1.1 Directed Acyclic Graph The general SPRITE model can be thought of as a dense directed acyclic graph (DAG), where every document or topic is connected to every compo-", "acronyms": [[107, 110]], "long-forms": [[83, 105]]}, {"text": " 1 In t roduct ion   For most natural language processing (NLP) systems,  thesauri comprise indispensable linguistic knowledge.", "acronyms": [[59, 62]], "long-forms": [[30, 57]]}, {"text": " 3.2 HL-MRFs for Tweet Stance Classification Finding the maximum a posteriori (MAP) state is a difficult discrete optimization problem and, in gen-", "acronyms": [[79, 82], [5, 11]], "long-forms": [[57, 77]]}, {"text": "computational semantics. With the rise of massive and easily-accessible digital corpora, computation of co-occurrence statistics has enabled researchers in NLP to build distributional semantic models (DSMs) that have found relevance in many application areas.", "acronyms": [[201, 205], [156, 159]], "long-forms": [[169, 199]]}, {"text": "1 Introduction ? Language Model (LM) Growing? refers to adding", "acronyms": [[33, 35]], "long-forms": [[17, 31]]}, {"text": "opment and sentence generation. Report, German National Center for Information Technology (GMD),  Institute for integrated publication and information systems (IPSI), Darmstadt, Germany, January 1997. ", "acronyms": [[160, 164], [91, 94]], "long-forms": [[98, 150], [40, 89]]}, {"text": "Linear-chain CRFs correspond to finite state machines, and can be roughly understood as conditionally-trained hidden Markov models (HMMs). This class of CRFs", "acronyms": [[132, 136]], "long-forms": [[110, 130]]}, {"text": "dominated by different Root Nodes. In this table, for each  possible Root Node category (RN), its corresponding Head  Node (HN), Dependent Nods/8 (DN) and Control Features (CF), ", "acronyms": [[89, 91], [124, 126], [147, 149], [173, 175]], "long-forms": [[69, 78], [112, 122], [129, 145], [155, 171]]}, {"text": "(see details below).  pronoun, PUNC = punctuation, PRT = particle, and X = residual (a category for language-specific cat-", "acronyms": [[31, 35], [51, 54]], "long-forms": [[38, 49], [57, 65]]}, {"text": "less than linear is the sample size, m. We formalize  this as a variant of \"Set Cover\" problem which we call  \"Weighted Set Cover~(WSC), and prove the existence of  an approximation algorithm with a performance guar- ", "acronyms": [[131, 134]], "long-forms": [[111, 129]]}, {"text": "larities of MSA. ARET has two subparts tools : the  Arabic Reading Facilitation Tool (ARFT) and the  Arabic Reading Assessment Tool (ARAT).", "acronyms": [[86, 90], [17, 21], [12, 15], [133, 137]], "long-forms": [[52, 84], [101, 131]]}, {"text": "scopes are not necessarily contiguous.  Conditional Random Field (CRF) sequence tag? ", "acronyms": [[66, 69]], "long-forms": [[40, 64]]}, {"text": "where Q(w,w?) is proportional to the integral term in Equation (IX). The term PC(w) corresponds", "acronyms": [[64, 66], [79, 83]], "long-forms": [[51, 62]]}, {"text": " Conf. on Language Resources and Evaluation (LREC), pages 697?702, Genoa, Italy, May.", "acronyms": [[45, 49]], "long-forms": [[10, 28]]}, {"text": "For each IDR triple  all the object grammar triples are generated whose CF-PS rules  conform with the linear precedence(LP) rules, the fourth rule set  of the metagrammar.", "acronyms": [[120, 122], [9, 12], [72, 77]], "long-forms": [[102, 118]]}, {"text": "Abstract We present the design, preparation, results and analysis of the Cancer Genetics (CG) event extraction task, a main task of the", "acronyms": [[90, 92]], "long-forms": [[73, 88]]}, {"text": "LR = Lagrangian relaxation; DP = exhaustive dynamic programming; ILP = integer linear programming; LP = linear programming (LP does not recover an exact solution).", "acronyms": [[65, 68], [0, 2], [28, 30], [99, 101], [124, 126]], "long-forms": [[71, 97], [5, 26], [44, 63], [104, 122]]}, {"text": "and in part by the TerraSwarm Research Center, one of six centers supported by the STARnet phase of the Focus Center Research Program (FCRP) a Semiconductor Research Corporation program sponsored by", "acronyms": [[135, 139], [83, 90]], "long-forms": [[104, 133]]}, {"text": "Clark, 2010; Sun, 2011b; Li, 2011) are usually trained on human-annotated corpora such as the Penn Chinese Treebank (CTB) (Xue et al, 2005), and perform quite well on corresponding test sets.", "acronyms": [[117, 120]], "long-forms": [[99, 115]]}, {"text": "For example, PropBank annotates 8,037 ARGM-MNR relations (10.7%) out of 74,980 adjunct-like arguments (ARGMs). There are verbs", "acronyms": [[103, 108], [38, 46]], "long-forms": [[92, 101]]}, {"text": " REF = obj123 SIZE = sizesensorreading85 SHAPE = shapesensorreading62", "acronyms": [[14, 18], [1, 4], [41, 46]], "long-forms": [[21, 40], [49, 69]]}, {"text": "226  Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 304?313, Seoul, South Korea, 5-6 July 2012.", "acronyms": [[101, 108]], "long-forms": [[51, 99]]}, {"text": "The SCBD structure.  prepositional phrases (PPs), verb phrases (VPs), and adverbial phrases  (APs).", "acronyms": [[44, 47], [64, 67], [4, 8], [94, 97]], "long-forms": [[21, 42], [50, 62], [74, 91]]}, {"text": "7 (Ogren and Bethard, 2009) can be used to design and execute pipelines made up of a sequence of AEs (and potentially some more complex flows), and UIMA-AS 8", "acronyms": [[97, 100], [148, 155]], "long-forms": [[102, 122]]}, {"text": "emoeion(ENO) perception(PER)  possession(POSS) stat ive(STA)  ~eather(WEA) ingestion(ING)  use(USE) social(SOC) body(BOD) ", "acronyms": [[85, 88], [8, 11], [24, 27], [41, 45], [56, 59], [70, 73], [85, 88], [95, 98], [107, 110], [117, 120]], "long-forms": [[75, 84], [0, 7], [13, 23], [30, 40], [47, 56], [63, 69], [91, 94], [100, 106], [112, 116]]}, {"text": "Texts The performance of punctuation prediction on both Chinese (CN) and English (EN) texts in the correctly recognized output of the BTEC and CT datasets are", "acronyms": [[65, 67], [82, 84], [134, 138], [143, 145]], "long-forms": [[56, 63], [73, 80]]}, {"text": "object (J), which is bad for the Jews (the  event is marked by minus), and after that (>) a  Jewish bearer of Sacred Power (J*SP) miracu-  lously (MIR) protects the (above) Jewish object, ", "acronyms": [[124, 128], [147, 150]], "long-forms": [[93, 122], [130, 145]]}, {"text": "+Valency = Adding valency filtering to the setting in the preceding row. SUC = Subset of Stockholm-Umea? ", "acronyms": [[73, 76]], "long-forms": [[79, 98]]}, {"text": "We therefore chose to perform ASR using a statistical language model (LM) and employ CMU?s Sphinx to generate an n-best list of recogni-", "acronyms": [[70, 72], [30, 33], [85, 90]], "long-forms": [[54, 68]]}, {"text": "transduction and matching words approximately.  Unicode (UTF8) is fully supported and is in fact the only encoding accepted by Foma.", "acronyms": [[57, 61]], "long-forms": [[48, 55]]}, {"text": "1. INTRODUCTION  Hidden Markov Models (HMMs) have been used suc-  cessfully in a wide variety of recognition tasks ranging ", "acronyms": [[39, 43]], "long-forms": [[17, 37]]}, {"text": "It has been shown in (Ando and Zhang, 2005a) that the optimization problem (3) has a simple solution using singular value decomposition (SVD) when we choose square regularization: r(f", "acronyms": [[137, 140]], "long-forms": [[107, 135]]}, {"text": "resent horizontal movement of the eyebrows.  2.2 Continuous Profile Models (CPM) Continuous Profile Model (CPM) aligns a set", "acronyms": [[76, 79], [107, 110]], "long-forms": [[49, 74], [81, 105]]}, {"text": "1 Motivation  Question Answering has emerged as a key area in  natural language processing (NLP) to apply question parsing, information extraction, summariza-", "acronyms": [[92, 95]], "long-forms": [[63, 90]]}, {"text": "POL (politics) Belgium elections 2003 16 15107 15.4 SPO (sports) Kim Clijsters 9 9713 11.1 HIS (history) History of Belgium 3 8396 17.9 BUS (business) Belgium Labour Federation 9 4440 11.0", "acronyms": [[91, 94], [0, 3], [52, 55], [136, 139]], "long-forms": [[96, 103], [5, 13], [57, 63], [141, 149]]}, {"text": "sides identity (IDENT) we only marked up three associative relations (Hawkins, 1978): set membership (ELEMENT), subset (SUBSET), and ? gen-", "acronyms": [[120, 126], [16, 21], [102, 109]], "long-forms": [[112, 118], [6, 14]]}, {"text": "2.4 Optimisation and Sampling from a WCFG Optimisation in a weighted CFG (WCFG)3, that is, finding the maximum derivation, is well stud-", "acronyms": [[74, 78], [37, 41]], "long-forms": [[60, 72]]}, {"text": " Abstract Minimum Error Rate Training (MERT) is a method for training the parameters of a log-", "acronyms": [[39, 43]], "long-forms": [[10, 37]]}, {"text": "For each sense s i of the target words, we place a Hierarchical Dirichlet process (HDP) prior on the mixture proportion to latent concepts shown as follows:", "acronyms": [[83, 86]], "long-forms": [[51, 81]]}, {"text": " ? MEA+LexPageRank (MEALR) : This method applies the proposed mixture-event-aspect model to", "acronyms": [[20, 25]], "long-forms": [[3, 18]]}, {"text": "functions to SGML-mark the input.  Fast Partial Parser (FPP) .  The ultimate ", "acronyms": [[56, 59], [13, 17]], "long-forms": [[35, 54]]}, {"text": "second verb in Japanese compound verbs. We  investigate Japanese compound verbs (JCVs) and  extract semantic constraints for the purpose of ", "acronyms": [[81, 85]], "long-forms": [[56, 79]]}, {"text": " ? True Positive (TP), the predicted e was correctly referred to by s.   ", "acronyms": [[18, 20]], "long-forms": [[3, 16]]}, {"text": "ral probabilistic language model. In Advances in Neural Information Processing Systems (NIPS), 2000.", "acronyms": [[88, 92]], "long-forms": [[49, 86]]}, {"text": "Several different learning algorithms have been explored for text classification (Dumais et al 1998) and support vector machines (SVMs) (Vapnik, 1995) were found to be the most computationally ef-", "acronyms": [[130, 134]], "long-forms": [[105, 128]]}, {"text": "Here the construction of the Chinese VP involves joining a prepositional phrase (PP) and a smaller verbal phrase (VP-A), with the preposition at the beginning as a PP marker.", "acronyms": [[114, 118], [37, 39], [81, 83], [164, 166]], "long-forms": [[99, 112], [59, 79]]}, {"text": "the first reference in this study. ( 3) a small dataset of Wikipedia articles (WIKI) to extend our corpus and metric evaluation to topics beyond the", "acronyms": [[79, 83]], "long-forms": [[59, 77]]}, {"text": "swer sequence tagging.  bels: B-ANSWER (beginning of answer), I-ANSWER (inside of answer), O (outside of answer).", "acronyms": [[30, 38], [62, 70]], "long-forms": [[40, 59], [94, 111]]}, {"text": "For example, in (2) we find frames identifying baseform verbs (VB) (2a) and frames identifying cardinal numbers (CD) (2b), despite having a variety of context words.", "acronyms": [[113, 115], [63, 65]], "long-forms": [[95, 103], [56, 60]]}, {"text": "  Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 33?37, Gothenburg, Sweden, April 26-30 2014.", "acronyms": [[70, 72], [28, 32]], "long-forms": [[50, 68]]}, {"text": "We further validate our approach on a large publicly available manipulation action dataset (MANIAC) from (Aksoy et al, 2014), achieving promising ex-", "acronyms": [[92, 98]], "long-forms": [[63, 82]]}, {"text": "nutcracker 155 22 62 312 449 0.0467 0.8342 39.5% (60% w/o B.O.) srl 0 487 437 63 13 0.9740 0.1260 55.0% Table 1: Results of the three systems on the SSI-testsuite ( TN = true negatives, FN = false negatives, TP = true positives, FP = false positives, N = TN + FP, P = TP + FN, Prec = Precision, ERROR: no", "acronyms": [[165, 167], [186, 188], [208, 210], [229, 231], [255, 257], [260, 262], [268, 270], [273, 275], [277, 281]], "long-forms": [[170, 184], [191, 206], [213, 227], [234, 249], [284, 293]]}, {"text": " 2 Graphical Model Framework A Graphical Model (GM) represents a factorization of a family of joint probability distributions over a", "acronyms": [[48, 50]], "long-forms": [[31, 46]]}, {"text": "tions\" as per the gold standard.  D = True Negatives (TN) = Pairs that were identified as \"Incorrect Transliterations\" by the par-", "acronyms": [[54, 56]], "long-forms": [[38, 52]]}, {"text": "Table 10: A=acoustic, P=psycholinguistic, POS=part-of-speech, C=complexity, F=fluency, VR=vocabulary richness, CFG=CFG production rule features.", "acronyms": [[87, 89], [42, 45], [111, 114], [115, 118]], "long-forms": [[90, 109], [12, 20], [24, 40], [46, 60], [64, 74], [78, 85]]}, {"text": "1995. A bi-directional Russian-toEnglish machine translation system (ETAP-3). In", "acronyms": [[69, 75]], "long-forms": [[33, 67]]}, {"text": "(V = main verb, N = noun, AUXV = auxiliary verb, COMPL = completive, ccomp_obj = clausal complement object, ERG =  ergative, S: singular, auxmod = auxiliary, ncsubj = non-clausal subject, B-NP = beginning of NP, I-NP = inside an NP,  &MAINV = main verb, &<AUXMOD = verbal auxiliary modifier). ", "acronyms": [[235, 240], [26, 30], [49, 54], [108, 111], [69, 78], [138, 144], [158, 164], [188, 192], [212, 216], [256, 262]], "long-forms": [[243, 252], [5, 14], [20, 24], [33, 47], [57, 67], [115, 123], [81, 107], [128, 136], [147, 156], [167, 186], [195, 210], [219, 231], [265, 292]]}, {"text": "The prefer-  ence score (PS) for a pair is determined by the ratio  of its local dominance count (LDC)--the total num-  ber of cases in which the pair is locally dominant--to ", "acronyms": [[98, 101], [25, 27]], "long-forms": [[75, 96], [4, 23]]}, {"text": "inference of lexical semantic roles After the training phase, a testing procedure using the Markov Chain Monte Carlo (MCMC) inference engine can be used to infer role labels.", "acronyms": [[118, 122]], "long-forms": [[92, 116]]}, {"text": "context    Chinese Context(CC): ???????? ", "acronyms": [[27, 29]], "long-forms": [[11, 25]]}, {"text": "lion words. From TIPSTER,  we used the Associ-  ated Press (AP), Wall Street Journal (WSJ), and  San Jose Mercury News (SJM) data, yielding 123, ", "acronyms": [[60, 62], [86, 89], [17, 24], [120, 123]], "long-forms": [[39, 58], [65, 84], [97, 113]]}, {"text": " 3.2.6. Candidate word number (WNum)  Because there are candidates that are a multi-", "acronyms": [[31, 35]], "long-forms": [[18, 29]]}, {"text": "To extract the verb?noun combinations that have been used by non-native speakers in practice, we use the Cambridge Learner Corpus (CLC), which is a 52.5 million-word corpus of learner En-", "acronyms": [[131, 134]], "long-forms": [[105, 129]]}, {"text": "the traditional k-nearest neighbor (kNN) algorithm.  Maximum a posteriori (MAP) principle is used to determine which emotion set is related to the giv-", "acronyms": [[75, 78], [36, 39]], "long-forms": [[53, 73], [16, 34]]}, {"text": "3. Formal descriptions about specific games which are classified as formal texts (FoT) 4.", "acronyms": [[82, 85]], "long-forms": [[68, 80]]}, {"text": "being developed as an Apache incubator project.  UIMA?s Common Analysis System (CAS) is used to describe typed objects (annotations) associated", "acronyms": [[80, 83], [49, 53]], "long-forms": [[56, 78]]}, {"text": " ? The Match Rate(MR): The match rate is the match number normalized", "acronyms": [[18, 20]], "long-forms": [[7, 16]]}, {"text": "tice. They found that a domain-specific corpus performs better than a Wall Street Journal (WSJ) corpus for the trigram LM.", "acronyms": [[91, 94]], "long-forms": [[70, 89]]}, {"text": "of not requiring so much copying. On the con-  trary, constraint unification (CU) (Hasida 1986,  Tuda et al 1989), a disjunctive unification ", "acronyms": [[78, 80]], "long-forms": [[54, 76]]}, {"text": "AFIPS Washington Off ice   GAO REPORTS ON FEDERAL MODELING  The General Accounting 0fEic.e (GAO') has released a repor t -  on \"Ways to  Improve  &mug-nt of Federally kcnded ~o@ute r i z ed  ~ o d e Z s I ~  (#-  enc luse $1.00) .", "acronyms": [[92, 96], [0, 5], [27, 30]], "long-forms": [[64, 90]]}, {"text": "categories, as shown in Figure 1. Messages may  involve a request (REQ), provide information  (INF), or fall into the category of interpersonal ", "acronyms": [[67, 70], [95, 98]], "long-forms": [[58, 65], [81, 92]]}, {"text": "{csjxu, csluqin}@comp.polyu.edu.hk Abstract The Semantic Textual Similarity (STS) task aims to exam the degree of semantic", "acronyms": [[77, 80]], "long-forms": [[48, 75]]}, {"text": "Table 5: Final test accuracies for Chinese. UAS = unlabeled attachment score; UEM = unlabeled exact match; LAS = labeled attachment score.", "acronyms": [[78, 81]], "long-forms": [[84, 105]]}, {"text": "volution model (DTCNN). Figure 1 illustrates an example from the Movie Reviews (MR) dataset (Pang and Lee, 2005).", "acronyms": [[80, 82], [16, 21]], "long-forms": [[65, 78]]}, {"text": "mentation in (Zhang et al, 2006) 2.2 OOV Recognition with Accessor Variety Accessor variety (AV) (Feng et al, 2004) is a simple and effective unsupervised method for extrac-", "acronyms": [[93, 95], [37, 40]], "long-forms": [[75, 91]]}, {"text": "CP = Relative Pronoun  +  IP  PP = Preposition  + NP AdjP = Adjective + NP", "acronyms": [[30, 32]], "long-forms": [[35, 46]]}, {"text": "To this end, we employ the  27 Adaptive Hierarchical Density Histograms (AHDH) as visual feature vectors, due to the fact that they  have shown discriminative power between binary complex drawings (Sidiropoulos et al.,", "acronyms": [[73, 77]], "long-forms": [[31, 71]]}, {"text": "Figure 2: Heat map of the relevance scores w s, j between the target domain Usenet (UN) with the other domains on ACE 2004 data set.", "acronyms": [[84, 86], [114, 117]], "long-forms": [[76, 82]]}, {"text": "knowledge that we can get from these examples the required information to parse a new input sentence .  In our  approach, examples are annotated with the Structured String Tree Correspondence (SSTC) annotation schema  where each SSTC describes a sentence, a representation tree as well as the correspondence b tween substrhzgs in ", "acronyms": [[193, 197], [229, 233]], "long-forms": [[154, 191]]}, {"text": " 1 Introduction Tree substitution grammar (TSG) is a promising formalism for modeling language data.", "acronyms": [[43, 46]], "long-forms": [[16, 41]]}, {"text": "that word in a sentence. Another covering  grammar is the so called null grammar (NG), in  which a word can follow any other word.", "acronyms": [[82, 84]], "long-forms": [[68, 80]]}, {"text": "recording  information pertinent to treatment of a patient that consists of a number of subsections such as Chief Complaint (CC), History of Present Illness (HPI),", "acronyms": [[125, 127], [158, 161]], "long-forms": [[108, 123], [130, 156]]}, {"text": "  Figure 2.  Words Correct (WC) scores from Teachers  and Machine scoring at the reader level (n = 87).", "acronyms": [[28, 30]], "long-forms": [[13, 26]]}, {"text": " 2.3 Markov Logic Network Markov Logic Networks (MLN) (Richardson and Domingos, 2006) are a framework for probabilis-", "acronyms": [[49, 52]], "long-forms": [[26, 47]]}, {"text": "analysis. To include more of the corpus, parameters are relaxed: the high group (HH) includes anyone whose score is above .5 SD", "acronyms": [[81, 83], [125, 127]], "long-forms": [[69, 73]]}, {"text": "validity of the large margin method is guaranteed by the theorems of Structural Risk Minimization (SRM) under Probably Approximately Correct (PAC) framework2; test error is related to training data error, number of training", "acronyms": [[142, 145], [99, 102]], "long-forms": [[110, 140], [69, 97]]}, {"text": "These  probabilities could be estimated from training cases  with Maximum Likelihood Estimation (MLE). Let l ", "acronyms": [[97, 100]], "long-forms": [[66, 95]]}, {"text": "as director of Pentagon telecom~~nicntions and commc~nd :~nd control systcms.  Requests for coments on a proposed Federal information processing -t.lndard (PII'S)  for the National Communications System have been requested by .Innuor).", "acronyms": [[156, 161]], "long-forms": [[105, 144]]}, {"text": "modeled as distributed dense vectors of hidden layers. A recurrent neural network (RNN) is one such learner that can operate on sequential data of variable", "acronyms": [[83, 86]], "long-forms": [[57, 81]]}, {"text": " We have three versions of reference summaries based on summarization ratio(SR): 10%, 15% and 20% respectively.", "acronyms": [[76, 78]], "long-forms": [[56, 75]]}, {"text": "average values. Figure 6 shows the average pitch of the phrase do you have in task interruption (INT) and poker-playing (PKR) of each player, with the actual values displayed in the columns below.", "acronyms": [[121, 124], [97, 100]], "long-forms": [[106, 111], [83, 95]]}, {"text": " The third is the confusion between adjective  (JJ) and noun (NN), when the word in question  modifies a noun that immediately follows.", "acronyms": [[62, 64], [48, 50]], "long-forms": [[56, 60], [36, 45]]}, {"text": "of money to perform tasks that are simple for humans but difficult for computers. Examples of these Human Intelligence Tasks (HITs) range from labeling images to moderating blog comments to providing feedback on the relevance of results for a search query.", "acronyms": [[126, 130]], "long-forms": [[100, 124]]}, {"text": "2. We propose a new topic model, Topic Sentiment Latent Dirichlet Allocation (TSLDA), which can capture the topic and sentiment si-", "acronyms": [[78, 83]], "long-forms": [[33, 76]]}, {"text": "Q-based Intersection PTSD stands for posttraumatic stress disorder and is a psychological disorder.  Generic Union Posttraumatic stress disorder (PTSD) is a psychological disorder, which is classified as an anxiety disorder in the DSM-IV, caused by a mental trauma (also called psychotrauma) that", "acronyms": [[146, 150], [21, 25], [231, 237]], "long-forms": [[115, 144]]}, {"text": "There are four basic phrases in Korean: noun phrase (NP), verb phrase (VP), adverb phrase (ADVP), and independent phrase (IP). Thus, chunking by rules is", "acronyms": [[122, 124], [53, 55], [71, 73], [91, 95]], "long-forms": [[102, 120], [40, 51], [58, 69], [76, 89]]}, {"text": "Another important note is that, although the audio sets consist of both broadcast news (BN) and broadcast conversations (BC), we did not perform BN or BC-specific tuning.", "acronyms": [[121, 123], [88, 90], [145, 147], [151, 153]], "long-forms": [[96, 119], [72, 86]]}, {"text": "specifier phrase with one of a set of (usually numeric) specifiers; the specifier phrase typically occurs in apposition or as a genitive modifier (GEN) to the head noun.", "acronyms": [[147, 150]], "long-forms": [[128, 136]]}, {"text": "number, fifteen predefined verbs (Paul, 2010)  are chosen as Light Verbs (LVs) for framing  the compound verbs (CompVs).  A manually ", "acronyms": [[112, 118], [74, 77]], "long-forms": [[96, 110], [61, 72]]}, {"text": "\u0000 EFF (effect): We made her the secretary.  \u0000 ORIG (origin): She made a cake from apples. ", "acronyms": [[46, 50], [2, 5]], "long-forms": [[52, 58], [7, 13]]}, {"text": "hence Srinivas and Joshi, in the context of TAG, refer to supertagging as almost parsing.  The parser is able to parse 20 Wall Street Journal (WSJ) sentences per second on standard hardware, using our best-performing model, which compares very favorably with other", "acronyms": [[143, 146], [44, 47]], "long-forms": [[122, 141]]}, {"text": "passenger vessel.  (5) Multiple mentions (MENTION): These alignments link one word to multiple occur-", "acronyms": [[42, 49]], "long-forms": [[32, 40]]}, {"text": "tributed to idiosyncrasies in the translation. For instance, Emma (EM) seems very difficult to align, which can be attributed to the use of an old transla-", "acronyms": [[67, 69]], "long-forms": [[61, 65]]}, {"text": "maries that are too specific. In this paper, we propose a natural language generation (NLG) model for the automatic creation of indicative multidoc-", "acronyms": [[87, 90]], "long-forms": [[58, 85]]}, {"text": "lined previously, in that its target is entity extraction from raw news wires from the news agency Agence France Presse (AFP), and not only linking relying on gold NER annotations: the input", "acronyms": [[121, 124], [164, 167]], "long-forms": [[99, 119]]}, {"text": "lexical chaining.  4.1 LDA Mode Method (LDA-MM) The LDA-MM approach places all word tokens that", "acronyms": [[40, 46], [52, 58]], "long-forms": [[23, 38]]}, {"text": "of the log-likelihood.     We used the tempered EM (TEM) as described  by Hofmann (1999).", "acronyms": [[52, 55]], "long-forms": [[39, 50]]}, {"text": "three stages. A source-language input string is rewritten to form an information retrieval (IR) query.", "acronyms": [[92, 94]], "long-forms": [[69, 90]]}, {"text": "relative-resource?, i.e.  EuroWordNet (EWN).1   In this paper we start by briefly recalling the ", "acronyms": [[39, 42]], "long-forms": [[26, 37]]}, {"text": "and test splits, and bias the results.  We trained a Support Vector Machine (SVM) for regression with RBF kernel using scikit-learn (Pe-", "acronyms": [[77, 80], [102, 105]], "long-forms": [[53, 75]]}, {"text": "cal patterns and the impacts of different  constraints that are used to identify the  Complex Predicates (CPs). System ", "acronyms": [[106, 109]], "long-forms": [[86, 104]]}, {"text": "Model 3 (Figure 3) illustrates how the source language text and MT component may be replaced by a natural language generation (NLG) system, given a rich enough semantic representation.", "acronyms": [[127, 130], [64, 66]], "long-forms": [[98, 125]]}, {"text": " It is used for many natural language tasks, such as part of speech (POS) and named entity tagging (Toutanova and others, 2003; Carreras et al.,", "acronyms": [[69, 72]], "long-forms": [[53, 67]]}, {"text": "sual scenes. In their seminal work Dale and Reiter (1995) present the Incremental Algorithm (IA) for GRE.", "acronyms": [[93, 95], [101, 104]], "long-forms": [[70, 91]]}, {"text": "Discovery of ambiguous and unambiguous discourse connectives via annotation projection. In Proceedings of Workshop on Annotation and Exploitation of Parallel Corpora (AEPC), pages 83?82, Tartu, Estonia.", "acronyms": [[167, 171]], "long-forms": [[118, 165]]}, {"text": "(CPs) increases the number of Complex Predicates (CPs) entries along with compound verbs  (CompVs) and conjunct verbs (ConjVs). The ", "acronyms": [[119, 125]], "long-forms": [[103, 117]]}, {"text": "an example of a low-pass filter. The concept of recursion is next introduced in order to pave the way for a discussion of IIR (Infinite Impulse Response) filters. High-, low-, and", "acronyms": [[122, 125]], "long-forms": [[127, 152]]}, {"text": " We split annotated data into two parts: the BLOB (Binary Large OBject) and the XML annotations that refer to specific regions of the BLOB.", "acronyms": [[45, 49], [80, 83], [134, 138]], "long-forms": [[51, 70]]}, {"text": "Amongst the various learning algorithms available in QUEST, to make our results comparable we selected SVR with radial basis function (RBF) kernel, which has been shown to perform very well", "acronyms": [[135, 138], [53, 58], [103, 106]], "long-forms": [[112, 133]]}, {"text": "belief from the belief tracker in 6.3% of the dialogs.  The mean Word Error Rate (WER) per worker on the test set is 27.5%.", "acronyms": [[82, 85]], "long-forms": [[65, 80]]}, {"text": "1994). Following (Collins, 2002), we used sections 0-18 of the Wall Street Journal (WSJ) corpus for training, sections 19-21 for development, and", "acronyms": [[84, 87]], "long-forms": [[63, 82]]}, {"text": " Phrasometer ? The phrasometer feature (PM) is the summed log-likelihood of all n-grams the word", "acronyms": [[40, 42]], "long-forms": [[19, 30]]}, {"text": "son to visit Udaipur.  Parse: September to March is [NP (np the  best season) [SBAR [S (dcP to visit Udaipur)]]] .", "acronyms": [[53, 55], [79, 83]], "long-forms": [[57, 59]]}, {"text": "2.3.1 KiF (Knowledge in Frame) The whole system, training and prediction, has been implemented in KiF (Knowledge in Frame), a script language that has been implemented into", "acronyms": [[98, 101], [6, 9]], "long-forms": [[103, 121], [11, 29]]}, {"text": " 2 Named Entity Extraction  Named Entity Recognition (NER) is useful in  NLP applications such as question answering, ", "acronyms": [[54, 57], [73, 76]], "long-forms": [[28, 52]]}, {"text": "translations. Although initially intended for  learners of English as Foreign Language (EFL)  in Taiwan, it is a gold mine of texts in English ", "acronyms": [[88, 91]], "long-forms": [[59, 86]]}, {"text": "apply shallow semantic (selectlonal) constraints, to filter out semantically anomalous parses, in a  second experiment. This procedure used PUNDIT's Selection Pattern Query and Response (SPQR)  component ~Lang1988\\].", "acronyms": [[187, 191]], "long-forms": [[149, 185]]}, {"text": "nym, Instance Hypernym, Part Holonym, Member Holonym, Substance Meronym, Entailment Table 1: Similarity features using WordNet (WN). ", "acronyms": [[128, 130]], "long-forms": [[119, 126]]}, {"text": "disasters or political crises in the media. There are two main approaches to audio hotspotting; one involves speech-to-text (STT), also known as large vocabulary continuous speech recognition (LVCSR),  and the other employs phonetic speech recognition.", "acronyms": [[193, 198], [125, 128]], "long-forms": [[145, 191], [109, 123]]}, {"text": "4.3 Nested Expressions No nested expressions will be marked. Even in cases where LOCATION (ENAMEX) expressions occur within  TIMEX and NUMEX expressions, they are not to be tagged.", "acronyms": [[91, 97], [125, 130], [135, 140]], "long-forms": [[61, 89]]}, {"text": "words words  Fig. 1 Structure of Bunruigoihy6 (BGH)  This paper focuses on classifying only nouns in terms of ", "acronyms": [[47, 50]], "long-forms": [[33, 45]]}, {"text": "In this paper we have systematically studied these complex relations involving SVC and VopC for BP, which constitute a challenge to Natural Language Processing (NLP) systems, and have been often ignored in related work.", "acronyms": [[161, 164], [79, 82], [96, 98], [87, 91]], "long-forms": [[132, 159]]}, {"text": "2008) since it also includes structural information of arguments. It is based on the Argumentation Markup Language (AML) that models argument components in a XML-based tree structure.", "acronyms": [[116, 119], [158, 161]], "long-forms": [[85, 114]]}, {"text": "al., 2005; Vapnik, 1998) based on the Gaussian  Radial Basis kernel function (RBF). We tuned ", "acronyms": [[78, 81]], "long-forms": [[48, 76]]}, {"text": "3.2 Result of Chinese NER We evaluated our named entity recognizer on the SIGHAN Microsoft Research Asia(MSRA) corpus in both closed and open track.", "acronyms": [[105, 109], [22, 25], [74, 80]], "long-forms": [[81, 104]]}, {"text": " 8. Adjacent Variety(AV) of the candidate. We", "acronyms": [[21, 23]], "long-forms": [[4, 19]]}, {"text": "~  = unrecognized input token.)  (ABC) = (A(BC)) = ((AB)C). Tim singletonbidi- ", "acronyms": [[53, 57]], "long-forms": [[42, 46]]}, {"text": "surveys of QA and DP data. The surveys are evaluated using nuggets drawn from QA citation texts (QA?CT), QA abstracts (QA?AB), and DP citation texts (DP?CT).", "acronyms": [[97, 102], [11, 13], [18, 20], [119, 124], [150, 155]], "long-forms": [[78, 95], [105, 117], [131, 148]]}, {"text": " CSIDM-200804 partially funded by a grant from the National Research Foundation (NRF) administered by the Media Development Authority (MDA)", "acronyms": [[81, 84], [1, 6], [135, 138]], "long-forms": [[51, 79], [106, 133]]}, {"text": "present specialized knowledge, since both the writer and readers are experts. Medical texts include the abstracts of all medical articles written in Basque in the Gaceta M?edica de Bilbao (GMB) ? Medical", "acronyms": [[189, 192]], "long-forms": [[163, 187]]}, {"text": "On the source-language side of the  corpus we will automatically generate lists of  frequent multiword expressions (MWEs) and  grammatical constructions using the methodology ", "acronyms": [[116, 120]], "long-forms": [[93, 114]]}, {"text": "computation of distributional thesauri (Lin, 1998) has been around for decades, its full potential has yet to be utilized in Natural Language Processing (NLP) tasks and applications.", "acronyms": [[154, 157]], "long-forms": [[125, 152]]}, {"text": "Improving part-of-speech tagging for context-free parsing. In Proceedings of 5th International Joint Conference on Natural Language Processing (IJCNLP), pages 1260?1268, Chiang Mai, Thailand.", "acronyms": [[144, 150]], "long-forms": [[81, 142]]}, {"text": "will describe our method of automatically creating a training set based on the click-through links and how we build an SVM (Support Vector Machine) classifier with the integration of enriched informa-", "acronyms": [[119, 122]], "long-forms": [[124, 146]]}, {"text": "developing a ser ies of inc reas ing ly  soph is t icated natura l  language unders tand ing   systems which will serve as an in tegrated  in ter face  to severa l  faci l i t ies at the Pacif ic  F leet Command Center:  the In tegrated  Data Base (IDB), which conta ins  information  about  ships, the i r  read iness  s tates ,  the i r  capabi l i t ies,  etc.;", "acronyms": [[249, 252]], "long-forms": [[225, 247]]}, {"text": "229  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1810?1815, October 25-29, 2014, Doha, Qatar.", "acronyms": [[93, 98]], "long-forms": [[43, 91]]}, {"text": "Baselines and Evaluation We compare prediction results with a set of single-task baselines: a Support Vector Machine (SVM) using an RBF kernel with hyperparameters optimised via cross-", "acronyms": [[118, 121], [132, 135]], "long-forms": [[94, 116]]}, {"text": "Pro = percent of the words as pronominals. WPS = Words per sentence. 6LTR = percent of words that are longer than 6 letters.", "acronyms": [[43, 46], [70, 73]], "long-forms": [[49, 67]]}, {"text": "Translation  The first method compared is a transitive  translation using MT (machine translation). The ", "acronyms": [[74, 76]], "long-forms": [[78, 97]]}, {"text": "sented in the graphic. The first strategy can be applied when the data set contains a  functionally independent attribute (FIA) that is used as an organizing device or \"an-  chor\" for the entire graphic.", "acronyms": [[123, 126]], "long-forms": [[87, 121]]}, {"text": "  Abstract  Our previous work focuses on combining translation memory (TM) and statistical machine translation  (SMT) when the TM database and the SMT training set are the same.", "acronyms": [[71, 73], [113, 116], [127, 129], [147, 150]], "long-forms": [[51, 69], [79, 110]]}, {"text": "1 Introduction Despite the advances in natural language processing (NLP), Word Sense Disambiguation (WSD) is still considered one of the most challenging prob-", "acronyms": [[101, 104], [68, 71]], "long-forms": [[74, 99], [39, 66]]}, {"text": "ENT E1 E2 (b) Feature Paired Tree(FPT) ENT", "acronyms": [[34, 37]], "long-forms": [[14, 32]]}, {"text": "making procedures.  Latent semantic analysis (LSA) (Deerwester et al.,", "acronyms": [[46, 49]], "long-forms": [[20, 44]]}, {"text": "(NL) into formal meaning representations (MR), and are applied for both parsing of textual input and in Spoken Language Understanding (SLU). In data-", "acronyms": [[135, 138], [1, 3], [42, 44]], "long-forms": [[104, 133], [17, 40]]}, {"text": "following are the most frequently used ones: ? MS = Mel?c?uk style used in the MeaningText Theory (MTT): the first conjunct is the", "acronyms": [[47, 49]], "long-forms": [[52, 66]]}, {"text": "For the training of the SMT engines, we used two parallel Spanish-English corpora provided by the organizers: the Europarl (EP) corpus (Koehn, 2005), which consists of 1.4M paral-", "acronyms": [[124, 126], [24, 27]], "long-forms": [[114, 122]]}, {"text": "Computational Linguistics, Volume 15, Number 1, March 1989 33  Michael C. McCord \\]Design of LMT: A Prolog-Based Machine Translation System  sions in a logical form language (LFL)  (McCord 1985a,  1987).", "acronyms": [[175, 178], [93, 96]], "long-forms": [[152, 173]]}, {"text": "morphological types and variables.  The Encyclopedia Specialist (ES) is able to access the Encyclo-  pedia for extracting semantic information and world knowledge.", "acronyms": [[65, 67]], "long-forms": [[40, 63]]}, {"text": "+ raising verb - non-raising verb KEYAGR (key agreement) ?", "acronyms": [[34, 40]], "long-forms": [[42, 55]]}, {"text": "4 Discussion We provide a brief introduction to the framework of Linear Categorial Grammar (LinCG). One of", "acronyms": [[92, 97]], "long-forms": [[65, 90]]}, {"text": "tion. Then, we extract expansion terms from these clusters using pseudo relevance feedback (PRF) as implemented in Terrier.", "acronyms": [[92, 95]], "long-forms": [[65, 90]]}, {"text": "Abstract WordNet, a widely used sense inventory for Word Sense Disambiguation(WSD), is often too fine-grained for many Natural Language", "acronyms": [[78, 81], [9, 16]], "long-forms": [[52, 76]]}, {"text": "1 Introduction Many text understanding applications, such as Question Answering (QA) and Information Extraction (IE), need to infer a target textual mean-", "acronyms": [[81, 83], [113, 115]], "long-forms": [[61, 79], [89, 111]]}, {"text": "and beyond, in several AI applications. Neel and Garzon (2010) show that the quality of a knowledge resource like WN affects the performance in recognizing textual entailment (RTE) and word-sense disambiguation (WSD) tasks.", "acronyms": [[176, 179], [114, 116], [212, 215], [23, 25]], "long-forms": [[144, 174], [185, 210]]}, {"text": " Unknown  1976 \"The Lexicography Informati on Sys tern (LEXIS) o f  the Bundeswher  Language Service,\" i n  Machine Assisted \"h-ansl ation i n  West ", "acronyms": [[56, 61]], "long-forms": [[20, 49]]}, {"text": "The e-rater system TM ~ is an operational  automated essay scoring system, developed  at Educational Testing Service (ETS). The ", "acronyms": [[118, 121], [19, 21]], "long-forms": [[89, 116]]}, {"text": "with parts of the annotated logical form.  \u0001 ZC07 (Zettlemoyer and Collins 2007) extends ZC05 with extra (disharmonic) combinators to increase the expressive power of the model.", "acronyms": [[45, 49], [89, 93]], "long-forms": [[51, 79]]}, {"text": "types through various features based on e.g., partof-speech tagging (POS) and named entity recognition (NER). ", "acronyms": [[104, 107], [69, 72]], "long-forms": [[78, 102], [46, 59]]}, {"text": "of Excellence and the Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no.", "acronyms": [[133, 137], [65, 70]], "long-forms": [[102, 131], [22, 63]]}, {"text": "ber of occurrence for this feature per patient narrative is obtained based on the frequency of the coordinating conjunction PoS tag (CC) detected in the parse tree structure.", "acronyms": [[133, 135]], "long-forms": [[112, 123]]}, {"text": "PP Fu?r diese Behauptung has the grammatical function OAMOD, which indicates that it is a modifier (MOD) of a direct object (OA) elsewhere in the structure (in this case keinen", "acronyms": [[100, 103], [125, 127], [0, 2], [54, 59]], "long-forms": [[90, 98], [105, 109]]}, {"text": "training set by cosine-similarity. Precision-recall (P-R) curves and mean average precision (MAP) are two metrics we used for evaluation.", "acronyms": [[93, 96], [53, 56]], "long-forms": [[69, 91], [35, 51]]}, {"text": "CoTrain vs. BaseCN2 0.000144 4.77E-05 0.000247 CoTrain vs. BaseCN3 0.0009 0.000287 0.00139 CoTrain vs. LEX(CN) 9.53E-10 7.15E-11 1.17E-09 CoTrain vs. LEX(EN) 1.87E-05 1.64E-05 8.92E-07", "acronyms": [[107, 109], [150, 153], [154, 156]], "long-forms": [[91, 98]]}, {"text": " Thirdly, most PROLOG implementations include a  version of metamorphosis grammars (MGs), a logic-  based formalism useful in particular for describing NL ", "acronyms": [[84, 87], [15, 21], [152, 154]], "long-forms": [[60, 82]]}, {"text": "11 Figure 4: Variation of Average Information Processing Indices(IPI) for Video 4-6 Figure 5: Variation of Average Information Processing Indices(IPI) for the full course the last week, i.e, students who do not finish the", "acronyms": [[146, 149], [65, 68]], "long-forms": [[115, 144], [34, 64]]}, {"text": "The modifier*\"its\" of TOK188 was converted to a modifier of the form  (POSSBY SCAFFOLD184), which was semantically processed to make TOK188 a  LOCPART (LOCationlPAIiT) SFRAME whwe SEMOBJ (SEMantic ODJect) is  SCAFFOLD1 84; idelltif'ication of the location referents of TOK 188 yieldad the two ", "acronyms": [[143, 150], [22, 28], [71, 77], [78, 89], [133, 139], [168, 174], [180, 186], [188, 196], [197, 203], [209, 218], [269, 272]], "long-forms": [[152, 166]]}, {"text": "(TEMPO1) and YOUTH-TIME (TEMPO2) where the choice is a secor~d  order Pa~t and for the pair YOUTH-TIME (TEMPO2) and BUILDING-  TIME (TEMPO3) where the choice is a third order F~Jture. As a ", "acronyms": [[133, 139]], "long-forms": [[127, 131]]}, {"text": "and its too slowly paced to be a thriller.  Question Classification (QC)What is the temperature at the center of the earth? numberWhat state did the Battle of Bighorn take place in?", "acronyms": [[69, 71]], "long-forms": [[44, 67]]}, {"text": "3http://www.noslang.com 370 are the New York Times (NYT),4 SMS,5 and Twitter.6 The results are presented in Figure 1.", "acronyms": [[52, 55]], "long-forms": [[36, 50]]}, {"text": "This  paper focuses on this problem in the context of  Information Extraction (IE). 2 Many extraction ", "acronyms": [[79, 81]], "long-forms": [[55, 77]]}, {"text": "applied to the sentiment analysis problem. Models such as Na??ve Bayes (NB), Maximum Entropy (ME) and Support Vector Machines (SVM) can determine", "acronyms": [[94, 96], [72, 74], [127, 130]], "long-forms": [[77, 92], [102, 125]]}, {"text": "answers accordingly. Specially, we develop a supervised Maximum Entropy (MaxEnt) based model to rescore the answers from the pipelines,", "acronyms": [[73, 79]], "long-forms": [[56, 71]]}, {"text": "Words/Phrases as Themselves (WD)  Symbols/Nonliteral Marks (SY)  Phonetic/Sound (PH)  Spelling (SP) ", "acronyms": [[81, 83], [29, 31], [60, 62], [96, 98]], "long-forms": [[65, 73], [34, 41], [86, 94]]}, {"text": "RERANKED 56.2 13.5 57.3 12.7 ORACLE 85.0 70.3 80.4 60.0 Table 2: Word accuracies and error rate reductions (ERR) in percentages for English-to-Japanese MTL augmented", "acronyms": [[108, 111], [152, 155]], "long-forms": [[85, 106]]}, {"text": " With the availability of Chinese Gigaword Corpus (CGC) and Word Sketch Engine (WSE) Tools (Kilgarriff, 2004).", "acronyms": [[80, 83], [51, 54]], "long-forms": [[60, 78], [26, 49]]}, {"text": "ture of I end set to 1.  Unique Occurrences and Zone (UNIQ): This group of features indicates whether the word ", "acronyms": [[54, 58]], "long-forms": [[25, 31]]}, {"text": "followed by a verbal suffix\". This is to cover general  verb inflection, for both auxiliaries (AUX +) and main  verbs (AUX -).", "acronyms": [[95, 100], [119, 122]], "long-forms": [[82, 93]]}, {"text": "329 Figure 1: The different structures (left: constituency trees, right: predicate argument structure) derived from Sentence (1) for the opinion holder candidate Malaysia used as input for convolution kernels (CK). ", "acronyms": [[210, 212]], "long-forms": [[189, 208]]}, {"text": "fornls of words. For instance, the rule  \\[ S= ion I=  (NNS VBZ) R= (NN) M=8\\]  says if by deleting the suffix \"ion\" from a word ", "acronyms": [[60, 63], [69, 71]], "long-forms": [[56, 59]]}, {"text": "REPRESENTATION OF INTENSIONAI,  CON'FEXTS  The main extension to the work reported in \\[Di Eugenio &  Lesnro II'/l consists in the introduction of CONTEXT SPACES (CS),  which enable us to treat the intensional contexts along the lines pro.. ", "acronyms": [[163, 165]], "long-forms": [[147, 161]]}, {"text": "Two types of initial parameter configurations were tried for BFGS; initial parameters have the same fixed values, or were chosen randomly. Steepest Descent (SD) was used as online training where some portion (i.e. chunk) of the training data were used during an iteration.", "acronyms": [[157, 159], [61, 65]], "long-forms": [[139, 155]]}, {"text": "different tags: B-L (Beginning of a literal chunk), I-L (Inside of a literal chunk), B-I (Beginning an Idiomatic chunk), I-I (Inside an Idiomatic chunk), O (Outside a chunk).", "acronyms": [[121, 124], [16, 19], [52, 55], [85, 88]], "long-forms": [[126, 145], [21, 43], [57, 76], [90, 112], [157, 164]]}, {"text": "category. The following transfer knowledge involves  sets of three common ouns (CNs):  3A' is the transferred expression of A ", "acronyms": [[80, 83]], "long-forms": [[67, 78]]}, {"text": "11  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1665?1675, October 25-29, 2014, Doha, Qatar.", "acronyms": [[92, 97]], "long-forms": [[42, 90]]}, {"text": "numeroinen se on (UT = Utterance as actually made by the user, UR = Utterance as recognized by the system, SU = System utterance).", "acronyms": [[63, 65], [18, 20], [107, 109]], "long-forms": [[68, 77], [23, 32], [112, 128]]}, {"text": "Concepts across categories Hilke Reckman and Crit Cremers Leiden University Centre for Linguistics (LUCL) Leiden, Netherlands", "acronyms": [[100, 104]], "long-forms": [[58, 98]]}, {"text": "and round corners for processes. Lexical access is applied to the input string to produce  (nondeterministically) the extended lexical item (ELI) of each word. Its output is split ", "acronyms": [[141, 144]], "long-forms": [[118, 139]]}, {"text": "the MDL methods.  ConVote (CONVOTE) Our second dataset is taken from segments of speech from United States", "acronyms": [[27, 34], [4, 7]], "long-forms": [[18, 25]]}, {"text": " 4 Algorithms 4.1 Topic?sentence graph matching (GM) We treat a sentence and a topic as graphs.", "acronyms": [[49, 51]], "long-forms": [[33, 47]]}, {"text": "user gender (GEN), the user identity (UID) (e.g. the user could be a person or an organization), and the source document ID (DID). We also mark the lan-", "acronyms": [[125, 128], [13, 16], [38, 41]], "long-forms": [[112, 123], [5, 11], [23, 36]]}, {"text": "It  is embedded to the C-value approach for  automatic term recognition (ATR), in the  form of weights constructed from statisti- ", "acronyms": [[73, 76], [23, 30]], "long-forms": [[45, 71]]}, {"text": "task: Argumentative Zoning (Teufel and Moens, 2002). Argumentative Zoning (AZ) is the task of applying one of seven discourse level tags (Fig-", "acronyms": [[75, 77]], "long-forms": [[53, 73]]}, {"text": "                                                    2  In our system, we define ten types of factoid: date, time (TIME), percentage, money, number (NUM), measure, e-mail, phone  number, and WWW.", "acronyms": [[148, 151], [114, 118], [190, 193]], "long-forms": [[140, 146], [108, 112]]}, {"text": "words not found in the dictionary, a Markov grammar that  computes the optimal ordering of the possible classes of all  words and a Wild Card Parser (WPC), i.e., a deterministic parser  based on a Context Free Grammar.", "acronyms": [[150, 153]], "long-forms": [[120, 141]]}, {"text": "In this paper, we explore the benefits of semantic features and in particular, evaluate the application of semantic role labeling (SRL) to Open IE. ", "acronyms": [[131, 134], [144, 146]], "long-forms": [[107, 129]]}, {"text": "knowledge resources (e.g., WordNet), and (ii) corpus-based that do not require any external knowledge source. Corpus-based metrics are formalized as Distributional Semantic Models (DSMs) (Baroni and Lenci, 2010) based on the distributional hypothesis of meaning (Harris, 1954).", "acronyms": [[181, 185]], "long-forms": [[149, 179]]}, {"text": "At  the top level, >,sb,,~ denotes the basic relation for the  overall ranking of information structure (IS) patterns. ", "acronyms": [[105, 107]], "long-forms": [[82, 103]]}, {"text": "relates only loosely to the semantics of natural language. The work we present in  this paper differs from all previous work in natural anguage processing (NLP) in at  least two respects.", "acronyms": [[156, 159]], "long-forms": [[128, 154]]}, {"text": "2014).  The RST Discourse Treebank (RST-DT) (Carlson et al.,", "acronyms": [[36, 42]], "long-forms": [[12, 34]]}, {"text": "2007. CRFsuite: a fast implementation of conditional random fields (CRFs). ", "acronyms": [[68, 72], [6, 14]], "long-forms": [[41, 66]]}, {"text": " 2. Na?ve Bayesian approach with full vocabulary (NBF). It", "acronyms": [[50, 53]], "long-forms": [[4, 37]]}, {"text": " 53 Creative Information Retrieval (CIR) can be used as a platform for the design of many Web services that offer linguistic creativity on de-mand. By enabling the flexible retrieval of n-gram data for non-literal queries, CIR allows a wide variety of creative tasks to be reimagined as simple IR tasks (Veale 2013).", "acronyms": [[36, 39], [223, 226]], "long-forms": [[4, 34]]}, {"text": "sentence are not participate in evaluation. Exact  match rate(EMR), violate match rate(VMR), and  inside match rate(IMR) denote the ratio of three ", "acronyms": [[87, 90], [62, 65], [116, 119]], "long-forms": [[68, 85], [44, 61], [98, 115]]}, {"text": " 2. Computer  Aided Wri t ing (CAW)  A computer system for a writer is basically a ", "acronyms": [[31, 34]], "long-forms": [[4, 29]]}, {"text": "pendency and constituency tracks are shown in table 1. The label attachment score (LAS) was used by the organizer for evaluating the dependency versions,", "acronyms": [[83, 86]], "long-forms": [[59, 81]]}, {"text": "Tu?r, Oflazer, and Tu?r 2002; Oflazer 2003; Oflazer et al 2003; Eryig?it and Oflazer 2006) has represented the morphological structure of Turkish words by splitting them into inflectional groups (IGs). The root and derivational elements of a word are represented", "acronyms": [[196, 199]], "long-forms": [[175, 194]]}, {"text": "The proceedings from CoNLL2004 and  CoNLL2005 detail a wide variety of approaches  to Semantic Role Labeling (SRL).  Many re-", "acronyms": [[110, 113], [21, 30], [36, 45]], "long-forms": [[86, 108]]}, {"text": " Introduction The Penn Chinese Treebank (CTB) is an ongoing project, with its objective being to", "acronyms": [[41, 44]], "long-forms": [[23, 39]]}, {"text": "ance improvements in our system.  The OOV recall rates (RRoov) showed in  Table 4 demonstrate that the OOV recognition ", "acronyms": [[56, 61], [38, 41], [103, 106]], "long-forms": [[42, 54]]}, {"text": " In the next sections, we briefly introduce the kernel trick and describe the subtree (ST) kernel devised in Vishwanathan and Smola (2002), the subset tree (SST) kernel defined in Collins and Duffy (2002), and the partial tree (PT) kernel proposed in", "acronyms": [[157, 160], [228, 230], [87, 89]], "long-forms": [[144, 155], [214, 226], [78, 85]]}, {"text": "Scores for PK    Because Academia Sinica corpora (AS) are  provided by us, we are not allowed to participate ", "acronyms": [[50, 52], [11, 13]], "long-forms": [[25, 40]]}, {"text": " 3.3 Question Classification We look next at question classification (QC). ", "acronyms": [[70, 72]], "long-forms": [[45, 68]]}, {"text": "Higher log-likelihood corresponds to improved model fit. However, typi-cally it is desirable to penalize a higher number of hidden states, since increasing the model complexi-ty results in tradeoffs that may not be fully warrant-ed by the improvement in model fit. In this work, we utilize the Akaike Information Criterion (AIC), a standard penalized log-likelihood metric (Akaike, 1976).     ", "acronyms": [[324, 327]], "long-forms": [[294, 322]]}, {"text": "Therefore, the standard metrics widely used in sequential topic segmentation for monologues and dialogs, such as Pk and WindowDiff(WD), are also not applicable.", "acronyms": [[131, 133], [113, 115]], "long-forms": [[120, 129]]}, {"text": "the previous section. We contrast this metric with Normalized Pointwise Mutual Information (NPMI) which uses only the events A = X+a and B = X", "acronyms": [[92, 96]], "long-forms": [[51, 90]]}, {"text": "Dependency-Based Open Information Extraction Pablo Gamallo and Marcos Garcia Centro de Investigac?a?o sobre Tecnologias da Informac?a?o (CITIUS) Universidade de Santiago de Compostela", "acronyms": [[137, 143]], "long-forms": [[77, 119]]}, {"text": "4 Sagan for MT evaluation Sagan for MT evaluation is based on a core devel-opment to approach the Semantic Textual Similari-ty task(STS). The pilot task STS was recently defined in Semeval 2012 (Aguirre et al, 2012) and has as main objective measuring the degree of semantic equivalence between two text fragments. STS is related to both Recognizing Textual En-tailment (RTE) and Paraphrase Recognition, but  54", "acronyms": [[371, 374], [12, 14], [36, 38], [132, 135], [153, 156], [315, 318]], "long-forms": [[338, 369], [98, 126]]}, {"text": "pointing and lacks systematic evaluation.  This paper employs a label propagation (LP)  algorithm for global learning of NP anaphoricity.", "acronyms": [[83, 85], [121, 123]], "long-forms": [[64, 81]]}, {"text": "This paper proposes a contextdependent phrase reordering approach that uses the maximum entropy (MaxEnt) model to help the HPB decoder select appropriate re-", "acronyms": [[97, 103], [123, 126]], "long-forms": [[80, 95]]}, {"text": "274  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1192?1202, October 25-29, 2014, Doha, Qatar.", "acronyms": [[93, 98]], "long-forms": [[43, 91]]}, {"text": "For ex-  ample, temporal PPs, such as \"in 1959\", where  the prepositional object is tagged CD (cardi-  nal), favor attachment to the VP, because tile ", "acronyms": [[91, 93], [133, 135], [25, 28]], "long-forms": [[95, 106]]}, {"text": "we often decompose the global probability of sequences using a directed graphical model (e.g., an HMM (Brants, 2000) or a conditional Markov model (CMM) (Ratnaparkhi, 1996)).", "acronyms": [[148, 151], [98, 101]], "long-forms": [[122, 146]]}, {"text": "(i)(a) If the verb is the last word  of the surface shape of the  sentence (SS), it always be-  longs to the focus.", "acronyms": [[76, 78]], "long-forms": [[44, 74]]}, {"text": "knowledge from a corpus\\[2\\]\\[6\\]\\[91.  Machine translation (MT) systems are no  exception.", "acronyms": [[61, 63]], "long-forms": [[40, 59]]}, {"text": "We present an open source, freely available Java implementation of Align, Disambiguate, and Walk (ADW), a state-of-the-art approach for measuring semantic similarity based on", "acronyms": [[98, 101]], "long-forms": [[67, 96]]}, {"text": "These interfaces stand to play a critical role in the  ongoing migration of interaction fi'oln the desktop  to wireless portable computing devices (PI)As, next-  generation phones) that offer limited screen real es- ", "acronyms": [[148, 150]], "long-forms": [[120, 146]]}, {"text": "amjbara@umich.edu Abstract The ACL Anthology Network (AAN)1 is a comprehensive manually curated networked", "acronyms": [[54, 57]], "long-forms": [[31, 52]]}, {"text": " The LRS representation of (1) is shown in Figure 1, where INCONT (INTERNAL CONTENT) encodes the core semantic contribution of the head, EXCONT", "acronyms": [[59, 65], [5, 8], [137, 143]], "long-forms": [[67, 83]]}, {"text": "words, respectively. We include two versions of this general model; Continuous Bag of Words (CBOW) that predicts a word based on the context, and Skip-", "acronyms": [[93, 97]], "long-forms": [[68, 91]]}, {"text": "demanding.  Latent Semantic Analysis (LSA) (Deerwester et al.,", "acronyms": [[38, 41]], "long-forms": [[12, 36]]}, {"text": "the parameters. We trained our network with stochastic gradient descent (SGD), mini-batches and adagrad updates (Duchi et al, 2011), using", "acronyms": [[73, 76]], "long-forms": [[44, 71]]}, {"text": "of a sentence or phrase, in turn, is necessary for automatic acquisition of important lexical knowledge, such as subcategorization frames and argument structures, which is used in several natural language processing (NLP) tasks and applications, such as parsing, machine translation, and information extraction (Srinivas and Joshi 1999;", "acronyms": [[217, 220]], "long-forms": [[188, 215]]}, {"text": "3  Chinese NER Using CRFs Model Integrating Multiple Features  Besides the text feature(TXT), simplified part-ofspeech (POS) feature, and small-vocabulary-", "acronyms": [[88, 91], [11, 14], [21, 25], [120, 123]], "long-forms": [[75, 87], [105, 118]]}, {"text": "all characters are included as features; full remove (P4), where all special Twitter features like user names, URLs, hashtags, retweet (RT ) tags, and emoticons are stripped; and replacing Twitter fea-", "acronyms": [[136, 138], [54, 56], [111, 115]], "long-forms": [[127, 134]]}, {"text": "However, a study regarding maximal recall shows that we do not remove too many true positives (TPs) (more details in Section 4.1).", "acronyms": [[95, 98]], "long-forms": [[79, 93]]}, {"text": " ? If the key and response do not match, the category is incorrect (INC) ; if interactively assigned, a tall y appears in both the INC and XIC (interactive incorrect) columns .", "acronyms": [[68, 71], [131, 134], [139, 142]], "long-forms": [[57, 66], [144, 165]]}, {"text": "scheme category in the corpus: Results (RES) is by far the most frequent zone (accounting for 40% of the corpus), while Background (BKG), Objective (OBJ), Method (METH) and Conclusion (CON) cover", "acronyms": [[132, 135], [40, 43], [149, 152], [163, 167], [185, 188]], "long-forms": [[120, 130], [31, 37], [138, 147], [155, 161], [173, 183]]}, {"text": "Inspired by the work of web search (Gao et al2010) and question retrieval in community question answer (Q&A) (Zhou et al2011), we assume the following generative", "acronyms": [[104, 107]], "long-forms": [[87, 102]]}, {"text": "5 Conclusions We have presented a sequential semantic role labeling system for the Semeval-2007 task 17 (SRL). ", "acronyms": [[105, 108]], "long-forms": [[68, 95]]}, {"text": " In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC), pages 1698?1703.", "acronyms": [[90, 94]], "long-forms": [[55, 73]]}, {"text": "This model is a multinomial DP model. Under the Chinese restaurant process (CRP) (Aldous, 1985) 394", "acronyms": [[76, 79], [28, 30]], "long-forms": [[48, 74]]}, {"text": "as feature vectors. The model of our choice is the maximum entropy model (MaxEnt), also known as logistic regression (?).", "acronyms": [[74, 80]], "long-forms": [[51, 66]]}, {"text": "Bayesian Networks (Samuelsson, 1993), Neural  Networks (Marques and Lopes, 1996) and  Conditional Random Fields (CRF) (Lafferty et  al.,", "acronyms": [[113, 116]], "long-forms": [[86, 111]]}, {"text": " 3.2 Formal basis: Lexical Resource Semantics Lexical Resource Semantics (LRS) (Richter and Sailer, 2003) is an underspecified semantic formal-", "acronyms": [[74, 77]], "long-forms": [[46, 72]]}, {"text": "Abstract Regardless of language, the standard character set for text messages (SMS) and many other social media platforms is the Roman alphabet.", "acronyms": [[79, 82]], "long-forms": [[56, 77]]}, {"text": "Domains  In this section we compare some characteristics of the  English Travel Domain (ETD) and the English Spon-  taneous Scheduling Task (ESST).", "acronyms": [[88, 91], [141, 145]], "long-forms": [[65, 86], [101, 139]]}, {"text": "result. We have used the symbol Comp in that case (e.g., if  ANTI (A)=B and CONV(B)=C, then the relation result-  ing from the composition is simply ANTI(CONV(A))----C).", "acronyms": [[61, 65], [149, 153], [76, 80]], "long-forms": []}, {"text": "for the annotation process.  Topic models (TMs) are a suite of unsuper992", "acronyms": [[43, 46]], "long-forms": [[29, 41]]}, {"text": "problems. Informally, a CRF bears resemblance to a Hidden Markov Model (HMM) in which, for each input position in a sequence, there is an observed", "acronyms": [[72, 75], [24, 27]], "long-forms": [[51, 70]]}, {"text": "6.7 Presence of  four digits 8 Evaluation  If the token is a four digit number, it is likelier to  be a NETI (Named Entity Time). For example, ", "acronyms": [[104, 108]], "long-forms": [[110, 127]]}, {"text": "chose a method from the second group. We use the Hierarchical Agglomerative Clustering (HAC) algorithm (Jain et al, 1999) for all experiments reported", "acronyms": [[88, 91]], "long-forms": [[49, 86]]}, {"text": "1 N 79.4 80.6 1.89 46.2 74.5 2 Y 80.8 81.4 1.70 44.3 80.4 Table 1: Results for parsing section 0 ( \u0000 40 words) of the WSJ Penn Treebank: OP = overparsing, LP/LR = labelled precision/recall.", "acronyms": [[137, 139], [118, 121], [155, 160]], "long-forms": [[142, 153], [163, 188]]}, {"text": "described as operating within the same three-stage framework as STRAND.  Parallel Text Miner (PTMiner) (Chen and Nie 2000) exploits already-existing Web search engines to locate pages by querying for pages in a given language that contain", "acronyms": [[94, 101], [64, 70]], "long-forms": [[73, 92]]}, {"text": "We encode the target state in the  similar way. Like the Vector Space Model(VSM),  we use a label matrix to represent each class as in ", "acronyms": [[76, 79]], "long-forms": [[57, 74]]}, {"text": "In Proc. of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL). ", "acronyms": [[86, 89]], "long-forms": [[43, 84]]}, {"text": " 1 Introduction  Generation of referring expression (GRE) is an  important task in the field of Natural Language ", "acronyms": [[53, 56]], "long-forms": [[17, 51]]}, {"text": "as given in (6)b, the v-hon type with the -(u)si suffix adds the information that its subject (the first element in the ARG-ST (argument structure)) is [HON +], in addition to the information that the", "acronyms": [[120, 126], [153, 156]], "long-forms": [[128, 146]]}, {"text": "Language Weaver, Inc. This article shows that the structure of bilingual material from standard parsing and alignment tools is not optimal for training syntax-based statistical machine translation (SMT) systems. ", "acronyms": [[198, 201]], "long-forms": [[165, 196]]}, {"text": "more details of this at the end of the next section.  4 Compiling the DiCo (dictionary-like) database into a lexical system", "acronyms": [[70, 74]], "long-forms": [[76, 86]]}, {"text": "s), correlation with error counts (re and ? e), average precision (AP) and pairwise accuracy.", "acronyms": [[67, 69]], "long-forms": [[48, 65]]}, {"text": " VP  Figure 3: A tree with some of its partial trees (PTs). ", "acronyms": [[54, 57]], "long-forms": [[39, 52]]}, {"text": " This work addresses a major bottleneck in the development of Statistical MT (SMT) systems: the lack of sufficiently large parallel corpora for most", "acronyms": [[78, 81]], "long-forms": [[62, 76]]}, {"text": " In this work, we explore n-gram models over Minimal Translation Units (MTUs) to explicitly capture contextual dependencies across", "acronyms": [[72, 76]], "long-forms": [[45, 70]]}, {"text": "In the cross-validation process, Multinomial Naive Bayes (MNB) has shown better results than Support Vector Machines (SVM) as a component for AdaBoost.", "acronyms": [[118, 121], [58, 61]], "long-forms": [[93, 116], [33, 56]]}, {"text": "utterance. The interface default allowing this is called Noun meaning extended (NMExt)13 NMExt: Noun(u), sem(u) is ?", "acronyms": [[80, 85], [89, 94]], "long-forms": [[57, 78]]}, {"text": "future work.1 1 Introduction and Motivation Typically, Information Extraction (IE) systems learn an extractor for each target relation from la-", "acronyms": [[79, 81]], "long-forms": [[55, 77]]}, {"text": "(grammatical knowledge and lexical knowledge respectively). The insights gained from our work  with machine readable dictionaries (MRDs) the Longman Dictionary of Contemporary English,  henceforth LDOCE, and the Van Dale dictionary of contemporary Dutch \"Groot Woordenboek van ", "acronyms": [[131, 135], [197, 202]], "long-forms": [[100, 129]]}, {"text": "We then build three pairwise comparison matrices: one comparing pairs of typically developing (TD) children; one comparing pairs of children with ASD; and a third com-", "acronyms": [[95, 97], [146, 149]], "long-forms": [[73, 93]]}, {"text": "Lack of Orientation (LO). If there is at least one obstacle of the former, more serious kind, we will speak of Dead End (DE). For example, in the case of the DE Exam-", "acronyms": [[121, 123], [20, 23], [158, 160]], "long-forms": [[111, 119], [0, 19]]}, {"text": "   FIGURE 1: Community of Inquiry (CoI) model   (Adapted from: Garrison et al 2000) ", "acronyms": [[35, 38]], "long-forms": [[13, 33]]}, {"text": "eling the sequential nature of the output. The constraint satisfaction inference (CSInf) approach (Bosch and Canisius, 2006) improves the", "acronyms": [[82, 87]], "long-forms": [[47, 80]]}, {"text": "started.  British National Corpus (BNC)4, American  National Corpus (ANC)5 had been referenced ", "acronyms": [[35, 38], [69, 72]], "long-forms": [[10, 33], [42, 67]]}, {"text": "Th~se de l'Universitt~ Joseph  Fourier, Grenoble I, Mars 1990  \\[8\\] TEl (Text Encoding Initiative), Guidelines for the  Encoding and lnterchange of Machine Readable Texts.", "acronyms": [[69, 72]], "long-forms": [[74, 98]]}, {"text": "The final reward is calculated as follows: TaskCompletionReward(TCR) = 1000 TurnCost(TC) = 10 TotalTurnCost(TTC) = #(Turns) ?", "acronyms": [[85, 87], [64, 68], [108, 111]], "long-forms": [[76, 83], [43, 63], [94, 107]]}, {"text": "6. Demonstrative pronoun labels are collapsed to DEM PRON (person and number information is easily recovered)", "acronyms": [[53, 57], [49, 52]], "long-forms": [[59, 65]]}, {"text": "2.85 0.001 8 29. ( VP (VBP ? NEED?) (", "acronyms": [[19, 21]], "long-forms": [[23, 26]]}, {"text": " A related task was explored at the Document Understanding Conference (DUC) in 2007.5 Here the goal was to find new information with respect to a", "acronyms": [[71, 74]], "long-forms": [[36, 69]]}, {"text": " 3.1.3 TBL Transformation based learning(TBL), first introduced by Eric Brill(Brill, 1995), is mainly", "acronyms": [[41, 44], [7, 10]], "long-forms": [[11, 39]]}, {"text": " Rosario and Hearst (2001) and Rosario, Hearst, and Fillmore (2002) classify nounmodifier relations in the medical domain, using Medical Subject Headings (MeSH) and Unified Medical Language System (UMLS) as lexical resources for representing each", "acronyms": [[155, 159], [198, 202]], "long-forms": [[129, 153], [165, 196]]}, {"text": "egories (left side) and with respect to the assessor?s own expertise (right side). ( Key: B=beneficial, LB=likely beneficial, T=tradeoffs, U=unknown, UB=unlikely beneficial, H=harmful, N=not in CE) the assessor had no idea from which condition an", "acronyms": [[150, 152], [104, 106]], "long-forms": [[153, 172], [92, 102], [107, 124], [128, 137], [141, 148], [176, 183], [187, 190]]}, {"text": " Actes de la 13e Confe?rence sur le Traitement Automatique des Langues Naturelles (TALN), pages 20?42.", "acronyms": [[83, 87]], "long-forms": [[36, 81]]}, {"text": "context dependence and mutual information. Yamamoto and Church (2001) experiment with both mutual information and residual inverse document frequency (RIDF)1 as criteria for deciding Japanese words, and their main contribution is in affording", "acronyms": [[151, 155]], "long-forms": [[114, 149]]}, {"text": "In Proceedings of the 19th International Conference on Computational Linguistics (COLING), volume I, pages 267?273.", "acronyms": [[82, 88]], "long-forms": [[55, 80]]}, {"text": " 2. All the named entities(NE) in the question are extracted as NE set.", "acronyms": [[27, 29], [64, 66]], "long-forms": [[12, 25]]}, {"text": " As far as discriminative models are concerned,  the Maximum Entropy (MaxEnt) model has been  applied (Bohus and Rudnicky, 2006).", "acronyms": [[70, 76]], "long-forms": [[53, 68]]}, {"text": "The alignments produced by MEBA were  compared to the ones produced by YAWA and  evaluated against the Gold Standard (GS)1 annotations used in the Word Alignment Shared ", "acronyms": [[118, 120], [27, 31], [71, 75]], "long-forms": [[103, 116]]}, {"text": "   1 Introduction  Named Entities (NEs) play a critical role in many  Natural Language Processing and Information ", "acronyms": [[35, 38]], "long-forms": [[19, 33]]}, {"text": "tions and keying in on student language to promote self-explanation of concepts, and its curriculum is based on the Full Option Science System (FOSS) 1 a proven system for inquiry based learning.", "acronyms": [[144, 148]], "long-forms": [[116, 142]]}, {"text": " 1 Introduction Word Sense Disambiguation (WSD) is a difficult Natural Language Processing task which requires", "acronyms": [[43, 46]], "long-forms": [[16, 41]]}, {"text": "  The project used the Linguamatics Interactive  Information Extraction (I2E) platform. This ", "acronyms": [[73, 76]], "long-forms": [[49, 71]]}, {"text": "Other methods include maximal marginal relevance (MMR) (Carbonell and Goldstein,  1998), latent semantic analysis (LSA) (Gong and  Liu, 2001).", "acronyms": [[115, 118], [50, 53]], "long-forms": [[89, 113], [22, 48]]}, {"text": "segment of a conversation. We will therefore use the  terms initiating conversational participant (ICP) and other  conversational participant(s) (OCP) to distinguish the initi- ", "acronyms": [[99, 102], [146, 149]], "long-forms": [[60, 97], [108, 141]]}, {"text": "MIRA/AROW requires selecting the loss function `(w) so that wt can be solved in closed-form, by a quadratic program (QP), or in some other way that is better than linearizing.", "acronyms": [[117, 119], [0, 9]], "long-forms": [[98, 115]]}, {"text": "propose a new inference method ? collective iterative classification (CIC), to find the maximum a posteriori (MAP) assignments for both entities", "acronyms": [[70, 73], [110, 113]], "long-forms": [[33, 68], [88, 108]]}, {"text": " ? Because Dependency Grammar (DG) directly describes the functional relations between  words, and s dependency tree has not any non-terminal nodes, DG is suitable for our ", "acronyms": [[31, 33], [149, 151]], "long-forms": [[11, 29]]}, {"text": "words in similar context have similar meanings ?  distributed semantic models (DSM)s build vector representations based on corpus-extracted context.", "acronyms": [[79, 82]], "long-forms": [[50, 77]]}, {"text": " 3 Keystroke Data Collection Amazon?s Mechanical Turk (MTurk) is a web service that enables crowdsourcing of tasks that are dif-", "acronyms": [[55, 60]], "long-forms": [[38, 53]]}, {"text": "1 Introduction Semantic Parsing, the process of converting text into a formal meaning representation (MR), is one of the key challenges in natural language process-", "acronyms": [[102, 104]], "long-forms": [[78, 100]]}, {"text": "contrast, L/RMC = left/right-most char,  L/RMW = left/right-most word, VS = vowel  sequences, HYPH = hyphenation, CASE =  case, PM = parenthesized material.", "acronyms": [[94, 98], [10, 15], [41, 46], [71, 73], [114, 118], [128, 130]], "long-forms": [[101, 112], [18, 38], [49, 69], [76, 92], [122, 126], [133, 155]]}, {"text": " 2 Swedish FrameNet Swedish FrameNet (SweFN), which began in 2011, is part of Swedish FrameNet++ (Borin et al.,", "acronyms": [[38, 43]], "long-forms": [[20, 36]]}, {"text": "  The similarity of two words is the least common  ancestor information content(IC), and hence, the  higher the information content is, the more similar ", "acronyms": [[80, 82]], "long-forms": [[60, 78]]}, {"text": "slot-def SN subslot-of SN1 . . . SNn (SN v SN1) . . . ( SN v SNn)", "acronyms": [[33, 36], [9, 11]], "long-forms": [[38, 46]]}, {"text": "However, Turkers are not trained to provide reliable annotations for natural language processing (NLP) tasks, and some Turkers attempt to game the system by submitting", "acronyms": [[98, 101]], "long-forms": [[69, 96]]}, {"text": "ported by Shared Annotated Resources (ShARe) project NIH 5R01GM090187 and Temporal Histories of Your Medical Events (THYME) project (NIH R01LM010090 and U54LM008748).", "acronyms": [[117, 122], [38, 43], [53, 56], [133, 136]], "long-forms": [[74, 115], [10, 36]]}, {"text": "tion algorithm. We use an existing unsupervised method, called Double Propagation (DP) (Qiu et al, 2011), for extraction.", "acronyms": [[83, 85]], "long-forms": [[63, 81]]}, {"text": "In Proceedings of the 15th International Conference on Computational Linguistics (COLING?94), pages 1145?1150, Kyoto, Japan.", "acronyms": [[82, 91]], "long-forms": [[55, 80]]}, {"text": "(Joshi, Vijay?Shanker, and Weir, 1989; Weir and Joshi,  1988) have shown that LIGs, Combinatory Categorial  Grammars (CCG), Tree Adjoinig Grammars (TAGs),  and Head Grammars (HGs) are weakly equivalent.", "acronyms": [[148, 152], [78, 82], [118, 121], [175, 178]], "long-forms": [[124, 146], [84, 116], [160, 173]]}, {"text": "We searched for four conditions: depression, bipolar disorder, post traumatic stress disorder (PTSD) and seasonal affective disorder (SAD).", "acronyms": [[95, 99], [134, 137]], "long-forms": [[63, 93], [105, 132]]}, {"text": "ing via schema matching and lexicon extension. In Association for Computational Linguistics (ACL). ", "acronyms": [[93, 96]], "long-forms": [[50, 91]]}, {"text": "derivation decoding (Best MAX), the best single system minimum Bayes risk decoding (Best MBR) and minimum Bayes risk system combination (MBR-SC) combining three systems.", "acronyms": [[137, 143], [26, 29], [89, 92]], "long-forms": [[98, 135], [55, 73]]}, {"text": "subject and object with the ground truth. ETS/ETO = Emotions towards subject/object, MAS=mean absolute error, and RMSE= root mean square error", "acronyms": [[85, 88], [42, 49], [114, 118]], "long-forms": [[89, 102], [52, 83], [120, 142]]}, {"text": "PROP  VP  I PROP = proposition  These-fragments would match a locative object use of a p r epos~ .~ lu r~  arlu L H ~ .", "acronyms": [[12, 16]], "long-forms": [[19, 30]]}, {"text": "ROBUST04 WT10G GOV2MAP R-Pr MAP R-Pr MAP R-PrSF-12 27.03 30.20 21.62 24.81 28.57 34.01SF-123 26.83 30.34 21.34 24.64 28.77 34.24SF-NE 26.51 29.86 21.42 24.55 27.96 33.26SF-GD 26.22 29.48 20.33 23.72 28.30 33.83Gold 27.92 31.15 22.56 25.69 29.65 35.08 Table 5: Results with supervised selection of catenae with specified length (SF-12, SF-123) are more effective than combinations of SFeat with heuristic NomEnd (SF-NE) or GovDep (SF-GD). ", "acronyms": [[412, 417], [430, 435]], "long-forms": [[383, 410]]}, {"text": "contact(CeNT) motion(MOT)  emoeion(ENO) perception(PER)  possession(POSS) stat ive(STA)  ~eather(WEA) ingestion(ING) ", "acronyms": [[68, 72], [83, 86], [8, 12], [21, 24], [35, 38], [51, 54], [97, 100], [112, 115]], "long-forms": [[57, 66], [74, 78], [0, 7], [14, 20], [27, 34], [40, 50], [90, 96], [102, 111]]}, {"text": "@\"' itself is counted. Another way is to count how  many parts of words (PWs) are eontMnmd in the  SA.", "acronyms": [[73, 76], [99, 101]], "long-forms": [[57, 71]]}, {"text": "Semantic Role Labeling (SRL) has been used successfully in several stages of automated Question Answering (QA) systems but its inherent slow procedures make it", "acronyms": [[107, 109], [24, 27]], "long-forms": [[87, 105], [0, 22]]}, {"text": "Generation of Crisp Descriptions Arguably the most fundamental task in the generation of referring expressions (GRE), content determination (CD) requires finding a set of properties that jointly identify the intended referent.", "acronyms": [[141, 143]], "long-forms": [[118, 139]]}, {"text": " 2 Forced Derivation Tree for SMT A forced derivation tree (FDT) of a sentence pair {f, e} can be defined as a pair G =< D,A >:", "acronyms": [[60, 63], [30, 33]], "long-forms": [[36, 58]]}, {"text": "PRN = Pronoun A-FLEX = Adjectival Inflexion  CA = Case CL = Inflsxion Class GD = Gender MD = Mode  PF ~ Predicate Form PS = Person TN = Tense  NU = Number ", "acronyms": [[131, 133], [0, 3], [14, 20], [45, 47], [55, 57], [76, 78], [88, 90], [99, 101], [119, 121], [143, 145]], "long-forms": [[136, 141], [6, 13], [23, 43], [50, 54], [70, 75], [81, 87], [93, 97], [104, 118], [124, 130], [148, 154]]}, {"text": "0.35 0.25 0.50 0.75 1.00 Omission Rate (OR) Co", "acronyms": [[40, 42]], "long-forms": [[25, 38]]}, {"text": "ond, task B referred to as task of normalization involves the mapping of each disorder mention to a  UMLS concept unique identifier (CUI).The mapping was limited to UMLS CUI of SNOMED clin-", "acronyms": [[133, 136]], "long-forms": [[106, 131]]}, {"text": "boundaries. Additionally, a local character-based joint segmentation and tagging solver (SegTagL) is used to provide word boundaries as well as inaccu-", "acronyms": [[89, 96]], "long-forms": [[56, 87]]}, {"text": "the middle (Baxendale, 1958).  Sentence Position Yield (SPY) is obtained separately for both types of documents.", "acronyms": [[56, 59]], "long-forms": [[31, 54]]}, {"text": "2.1 Knowledge Source We employ BabelNet 2.5.1 as our reference knowledge base (KB). BabelNet is a multilingual", "acronyms": [[79, 81]], "long-forms": [[63, 77]]}, {"text": "In Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together (ACL), pages 50?57, Stroudsburg, PA.", "acronyms": [[100, 103], [132, 134]], "long-forms": []}, {"text": "Taalkommissie van die Suid-Afrikaanse Akademie vir Wetenskap en Kuns. Centre for Text Technology (CTexT), North-West University, Potchefstroom, South Africa. ", "acronyms": [[98, 103]], "long-forms": [[70, 96]]}, {"text": "discussed in section 2, are represented.  Evaluation of machine translation (MT) systems has to consider the pre-processing of input and", "acronyms": [[77, 79]], "long-forms": [[56, 75]]}, {"text": "proper textual evidences. We formulate this task as an Integer Linear Programming (ILP). Instead of", "acronyms": [[83, 86]], "long-forms": [[55, 81]]}, {"text": "Hongo 7-3-1, Bunkyo-ku, Tokyo 113-0033 JAPAN ? CREST, JST (Japan Science and Technology Corporation) Honcho 4-1-8, Kawaguchi-shi, Saitama 332-0012 JAPAN", "acronyms": [[54, 57]], "long-forms": [[59, 87]]}, {"text": "construct the desired model in a way that allows efficient inference, even for large datasets, using determinantal point processes (DPPs). We begin", "acronyms": [[132, 136]], "long-forms": [[101, 130]]}, {"text": " CSIDM-200804 partially funded by a grant from the National Research Foundation (NRF) administered by the Media Development Authority", "acronyms": [[81, 84], [1, 6]], "long-forms": [[51, 79]]}, {"text": " 6 Experiments and Results We use the Wall Street Journal (WSJ) section of the Penn Treebank as our labeled source domain", "acronyms": [[59, 62]], "long-forms": [[38, 57]]}, {"text": "scikit-learn python library 3 : Naive Bayes (NB), Nearest Neighbor (NN), Decision Tree (DT), Ran-", "acronyms": [[45, 47], [68, 70], [88, 90]], "long-forms": [[32, 43], [50, 66], [73, 86]]}, {"text": "Subjacency sub-  sumes, as well as other principles, Ross's lO  Complex Noun Phrase Constraint (CNPC), which  prohibits movements out o f~-NpNPS ~ structures, ", "acronyms": [[96, 100], [60, 62], [139, 144]], "long-forms": [[64, 94]]}, {"text": "Deployment management, enabling rapid deployment of locally tested charac-ters to highly available web servers as well as review and data warehousing functions for both analytic and refinement purposes. The information model is implemented in a re-lational database that fully specifies, relates and allows inquiry and validation of authored infor-mation. Additionally, a complete web application programming interface (API) powers the Roundtable application, providing a transactional framework for data operations as well as user privilege enforcement, but which also allows application expansion. The information model also serves to decouple the authoring representation from the data struc-tures necessary to drive dialogue behavior at runtime.", "acronyms": [[420, 423]], "long-forms": [[385, 418]]}, {"text": "tasks or languages.  Amazon?s Mechanical Turk (MTurk) service facilitates inexpensive collection of large amounts of", "acronyms": [[47, 52]], "long-forms": [[30, 45]]}, {"text": "Subsequently, alternative estimation strategies for unsupervised learning have been proposed, such as Contrastive Estimation (CE) by Smith and Eisner (2005).", "acronyms": [[126, 128]], "long-forms": [[102, 124]]}, {"text": "ed AIC   a) Dialogue ActsOnly (DAONLY)    N (number of hidden states) ", "acronyms": [[31, 37], [3, 6]], "long-forms": [[12, 29]]}, {"text": " 2001. Linguistic Inquiry and Word Count (LIWC):  LIWC2001.", "acronyms": [[42, 46]], "long-forms": [[7, 40]]}, {"text": "lowing three metrics are used in this experiment.  (a) EPN in total (EPN-T): The number of the expanded problems which are generated in the", "acronyms": [[69, 74]], "long-forms": [[55, 67]]}, {"text": "Two document collections are used in this study.  CE (Chinese Encyclopedia): This is from the electronic version of the Chinese Encyclopedia.", "acronyms": [[50, 52]], "long-forms": [[54, 74]]}, {"text": "2 Pivot Translation Pivot translation is a translation from a source language (SRC) to a target language (TRG) through an intermediate pivot (or bridging) language (PVT).", "acronyms": [[106, 109], [79, 82], [165, 168]], "long-forms": [[89, 104], [62, 77], [135, 163]]}, {"text": "More  technically, for each syntactic feature {sf1, sf2, ...,  sfn} of the set SF (Syntactic Features) represented  in the lexical typology, we define the goal of our ", "acronyms": [[79, 81]], "long-forms": [[83, 101]]}, {"text": " 1 Introduction Recurrent Neural Network (RNN)-based conditional language models (LM) have been shown to", "acronyms": [[42, 45], [82, 84]], "long-forms": [[16, 40], [65, 80]]}, {"text": "07 a Single 0.71 1.00 0.83 0.00 0.00 0.00 0.42 1.39 9  Table 9  Constituent parsing evaluation results of Task 2-2 (Close Track), ranked with Tot-F1  (S_S=simple sentence, C_S=complex sentence)  ID Sys-ID Model Constituents in S_S C_S constituent Total POS-A Rank", "acronyms": [[151, 154], [172, 175], [253, 258], [227, 234], [198, 204]], "long-forms": [[155, 170], [176, 192]]}, {"text": "Ph i lade lph ia ,  PA  191C4  .ABSTRACT  Tree Adjoining Grammar (TAG) is a formalism for natural  language grammars.", "acronyms": [[66, 69], [20, 22]], "long-forms": [[42, 64], [0, 16]]}, {"text": "640,000 non-empty abstracts were found.  Query Set (QSet): We download from PubMed the abstracts that mention a given gene name and its syn-", "acronyms": [[52, 56]], "long-forms": [[41, 50]]}, {"text": "as in figure 3.  It is parsed as an adverb (AA), whereas it should be a verb group (VG).", "acronyms": [[44, 46], [84, 86]], "long-forms": [[33, 42], [72, 82]]}, {"text": "must be stored at each step of the decoding algorithm.  This information includes: the current score (SCORE),  the pointer to the previous lexical item (BPO) on the best ", "acronyms": [[102, 107], [153, 156]], "long-forms": [[95, 100]]}, {"text": "based Translation. In Proceedings of the 13th International Conference on Computational Linguistics (COLING?90), pages 247?252.", "acronyms": [[101, 110]], "long-forms": [[60, 99]]}, {"text": "Classification, Word Sense Disambiguation, etc. In  Natural Language Processing (NLP), one of the  most used resources for WSD and other tasks is ", "acronyms": [[81, 84], [123, 126]], "long-forms": [[52, 79]]}, {"text": "resource presented here implements formal semantic descriptions of verbs in the Web Ontology Language (OWL) and exploits its reasoning potential based on Description Logics (DL) for the disambiguation of verbs in context, since before the correct sense of a verb can be reliably", "acronyms": [[174, 176], [103, 106]], "long-forms": [[154, 172], [80, 101]]}, {"text": "interested in formalisms which are being  used or have applications in the domain  of machine translation (MT). These can ", "acronyms": [[107, 109]], "long-forms": [[86, 105]]}, {"text": "2014). We note the linguistic rules included in the Lease, Johnson & Charniak (2006) tree adjoining grammar (TAG) noisy-channel model ? lexical,", "acronyms": [[109, 112]], "long-forms": [[85, 107]]}, {"text": " ? New York Times (NYT) archive: a set of around 1.8 million news article from the archives", "acronyms": [[19, 22]], "long-forms": [[3, 17]]}, {"text": "In order to answer this question, we propose a new model called the Recursive Neural Tensor Network (RNTN). The main idea is to use", "acronyms": [[101, 105]], "long-forms": [[68, 99]]}, {"text": "  1 Introduction  INTERA (Integrated European language data  Repository Area, Contract 22076Y2C2DMAL2) is ", "acronyms": [[18, 24]], "long-forms": [[26, 76]]}, {"text": "The ISO 639-3 language codes for our eight languages are as follows: Urdu (URD), Thai (THA), Bengali (BEN), Tamil (TAM), Punjabi (PAN), Tagalog (TGL), Pashto", "acronyms": [[75, 78], [102, 105], [4, 7], [87, 90], [115, 118], [130, 133], [145, 148]], "long-forms": [[69, 73], [93, 100], [81, 85], [108, 113], [121, 128], [136, 143]]}, {"text": "152 Kuhn A Survey and Classification of Controlled Natural Languages Controlled Language for Crisis Management (CLCM) (Temnikova 2010, 2011, 2012) is a language for writing instructions about how to deal with crisis situations.", "acronyms": [[112, 116]], "long-forms": [[69, 110]]}, {"text": "to be explained by a set of unobserved (latent) topics. Hidden Markov Model LDA (HMM-LDA) (Griffiths et al, 2005) is a topic model that simul-", "acronyms": [[81, 88]], "long-forms": [[56, 79]]}, {"text": "\u0000 -movement (mostly wh-movement: WH), empty complementizers (COMP), empty units (UNIT), and traces representing pseudo-attachments", "acronyms": [[61, 65], [33, 35], [81, 85]], "long-forms": [[44, 59], [74, 78]]}, {"text": "not enter into speech recognition. Tillmann, Vogel, Ney, and Zubiaga (1997) proposes a dynamic programming (DP)?based search algorithm for statistical MT that monotonically translates the input sentence from left to right.", "acronyms": [[108, 110], [151, 153]], "long-forms": [[87, 106]]}, {"text": "Since it is costly to compute the partition function over the whole vocabulary, we use noise constrastive estimation (NCE) to estimate the parameters of the model (Mnih and", "acronyms": [[118, 121]], "long-forms": [[87, 116]]}, {"text": "5 Conclusion We have presented an efficient extension of the posterior regularization (PR) framework to a more general class of penalty functions.", "acronyms": [[87, 89]], "long-forms": [[61, 85]]}, {"text": "1 Scope and Prior Work We present minimally supervised methods for training and testing geographic name disambiguation (GND) systems.", "acronyms": [[120, 123]], "long-forms": [[88, 118]]}, {"text": "URL?, excluded utterances with the symbols that indicate the re-posting (RT) or quoting (QT) of others?", "acronyms": [[89, 91], [0, 3], [73, 75]], "long-forms": [[80, 87], [61, 71]]}, {"text": "all levels of syntactic represent-  ation, name\\].y, D-structure,  S-structure, and LF (logical form). ", "acronyms": [[84, 86]], "long-forms": [[88, 100], [55, 64], [69, 78]]}, {"text": "   then  Cast_in_Chain(Antecedent, Anaphor)    then  Cast_in_Chain(Antecedent, Anaphor) RULE-1-Filter-1-Pronoun (R1F1Pron) RULE-1-Filter-1-Nominal (R1F1Nom)", "acronyms": [[113, 121], [148, 155]], "long-forms": [[88, 111], [123, 146]]}, {"text": " Two sorts of recursion can be distinguished: 1)  middle field (MF) recursion, where the embedded  base clause is framed by the left and right verb parts ", "acronyms": [[64, 66]], "long-forms": [[50, 62]]}, {"text": "large and is often simplified.  Because we use belief propagation (BP) as baseline to compare to, and as a subroutine in our pro-", "acronyms": [[67, 69]], "long-forms": [[47, 65]]}, {"text": "processing applications, su ch as larg e-vocab u lary speech recog nition (L V CS R), statistical machine translation (S M T ) and information retrieval (IR), is the morpholog ical analy sis of w ords.", "acronyms": [[154, 156], [119, 124], [75, 83]], "long-forms": [[131, 152], [86, 117], [34, 73]]}, {"text": "the work of language specialists. They often need to perform extensive corpus research, including Natural Language Processing (NLP), statistical modelling and data visualisation. Our ", "acronyms": [[127, 130]], "long-forms": [[98, 125]]}, {"text": "guage model. Instead, with information gathered  from interviews of subject matter experts (SME's),  we developed a handwritten grammar using Gemini ", "acronyms": [[92, 97]], "long-forms": [[68, 90]]}, {"text": "As is common practice for continuous features, we choose this pdf to be a Gaussian mixture model (GMM) since any continuous distribution can be approximated with ar-", "acronyms": [[98, 101]], "long-forms": [[74, 96]]}, {"text": "Learning dependency-based compositional semantics.  In Association for Computational Linguistics (ACL). ", "acronyms": [[98, 101]], "long-forms": [[55, 96]]}, {"text": " 1 Introduction Named Entity Recognition (NER) is usually solved by a supervised learning approach, where", "acronyms": [[42, 45]], "long-forms": [[16, 40]]}, {"text": "smoothness. Before creating a POMDP structure, we used the dynamic Bayesian network (DBN) structure (Fig.", "acronyms": [[85, 88], [30, 35]], "long-forms": [[59, 83]]}, {"text": "srlrr(r** TRANSPORMATIONS IC*S**  SCAN CALLED AT 1 I  ANTEST CALLED F O R  5\"SYLLAB \" (AACC) ,SD= 6. RES= 11.", "acronyms": [[87, 91], [94, 96], [101, 104]], "long-forms": [[54, 67]]}, {"text": "word and sentence level QE. In this work we describe the Fondazione Bruno Kessler (FBK), Universitat Polit`ecnica de Val`encia (UPV) and Uni-", "acronyms": [[83, 86], [24, 26], [128, 131]], "long-forms": [[57, 81], [89, 126]]}, {"text": "(6) health issues (HI) trend other (7) personal issues (PI) trend decreasing (8) lectures attended (LA) trend other (9) revision (R) trend decreasing", "acronyms": [[100, 102], [19, 21], [56, 58]], "long-forms": [[81, 98], [4, 16], [39, 53], [120, 128]]}, {"text": "CrossT values). The regression model predicted  Figure 4: ST alignment crossings (CrossS), as generated  when checking the ST against the TT ", "acronyms": [[82, 88], [0, 6], [58, 60], [123, 125], [138, 140]], "long-forms": [[71, 80]]}, {"text": "3 Attribute Modeling based on LDA 3.1 Controled LDA This section introduces Controled LDA (C-LDA), a weakly supervised variant of LDA.", "acronyms": [[91, 96], [30, 33], [48, 51], [130, 133]], "long-forms": [[76, 89]]}, {"text": " 3 Baseline SMT system The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sen-", "acronyms": [[68, 71], [12, 15]], "long-forms": [[35, 66]]}, {"text": "Semantic Information Retrieval (SIR) AQUA Sentiment Analysis in User Generated Discourse (SentAL) Internet der Dienste (THESEUS) ?", "acronyms": [[90, 96], [32, 35], [37, 41], [120, 127]], "long-forms": [[42, 60], [0, 30]]}, {"text": "proaches, namely Bisecting K-Means (Steinbach et al.,  2000), and Latent Semantic Analysis (LSA)-based document clustering (for short, LSA).", "acronyms": [[92, 95], [135, 138]], "long-forms": [[66, 90]]}, {"text": "We use multiple epochs of minibatch stochastic gradient descent and update all parameters to minimize the negative log likelihood (NLL) of our training set.", "acronyms": [[131, 134]], "long-forms": [[106, 129]]}, {"text": "is the DIAGRAM grammar \\ [9 \\ ] .   It is un for tunate ly  the very power .of APSGs (and ATNs)  that  makes it  d i f f i cu l t  to capture l inguist ic  general izat ions ", "acronyms": [[79, 84], [90, 94]], "long-forms": []}, {"text": "2 Symmetrical Tversky?s Ratio Model In the field of mathematical psychology Tversky proposed the ratio model (TRM) (Tversky, 1977) motivated by the imbalance that humans have on", "acronyms": [[110, 113]], "long-forms": [[93, 108]]}, {"text": " 3 Conditional Random Fields  Conditional Random Fields (CRFs) are a type of  discriminative probabilistic model proposed for ", "acronyms": [[57, 61]], "long-forms": [[30, 55]]}, {"text": "template includes, for each sentence, syntactic Infor-  mation that Is represented in a tree whose nodes are  syntacti~ categories such as S (sentence), CL (clause),  SUBJECT or VERB.", "acronyms": [[153, 155]], "long-forms": [[157, 163], [142, 150]]}, {"text": "the semantics of the head noun of the reference  object. A noun phrase (NP) denoting a place  gives rise to a spatial PP.", "acronyms": [[72, 74], [118, 120]], "long-forms": [[59, 70]]}, {"text": "As expected, the poor performance observed on the sniper text is mainly due to two reasons: the presence of out of vocabulary (OOV) words and the incorrect translations of terminological", "acronyms": [[127, 130]], "long-forms": [[108, 125]]}, {"text": "06 33.3 125 33.1 73 Average: 35.4 216 36.1 125 Table 3: Directed dependency accuracies (DDA) and iteration counts for the 10 (of 23) train/test splits affected by", "acronyms": [[88, 91]], "long-forms": [[56, 86]]}, {"text": "Finite State Automata (FSA) have traditionally been used in speech processing, but they are clearly  inappropriate for spoken language systems. In this section, we contrast unification grammars (UGs) with  Context-Free grammars (CFGs) and discuss extensions needed for spoken language systems.", "acronyms": [[195, 198], [23, 26], [229, 233]], "long-forms": [[173, 193], [0, 21], [206, 227]]}, {"text": "since it appears in the corpus with the six differ-  ent tags: CD (cardinal), DT (determiner), JJ (ad-  jective), NN (noun). NNP (proper noun) and VBP ", "acronyms": [[114, 116], [63, 65], [78, 80], [95, 97], [125, 128], [147, 150]], "long-forms": [[118, 122], [67, 75], [82, 92], [104, 111], [130, 141]]}, {"text": "ules, distributed on two computers.  The graphical user interface (GUI) has a close link to the dialogue manager since it integrates sev-", "acronyms": [[67, 70]], "long-forms": [[41, 65]]}, {"text": "3.1 Vector SpaceModei for Text Catego-  r izat ion  The bulk of the VSM for Information Retrieval (IR) is  representing naturallanguage xpressions as term ", "acronyms": [[99, 101], [68, 71]], "long-forms": [[76, 97]]}, {"text": "as automatic speech recognition (ASR), natural language understanding (NLU), dialogue management (DM), natural language generation (NLG), and speech synthesis (TTS).", "acronyms": [[132, 135], [33, 36], [71, 74], [98, 100], [160, 163]], "long-forms": [[103, 130], [3, 31], [39, 69], [77, 96]]}, {"text": "P i jPMI P i P j=   Equation 2: Pointwise Mutual Information (PMI)  between two terms i and j. ", "acronyms": [[62, 65], [5, 8]], "long-forms": [[32, 60]]}, {"text": "res. In Section 2 we present a structural reformulation of Support Vector Machines (SVMs) that can take similarities between different genres into ac-", "acronyms": [[84, 88]], "long-forms": [[59, 82]]}, {"text": "words. We model semantic relatedness between two words using the Information Content (IC) of the pair in a method similar to the one used by Lin", "acronyms": [[86, 88]], "long-forms": [[65, 84]]}, {"text": "Contextual relationship attributes:  1. Prefix Counted Rule (PRC): The selected  sense is the most commonly appended sense by the ", "acronyms": [[61, 64]], "long-forms": [[40, 54]]}, {"text": "Table 7: Feature template we use for our classification of event types. Feature examples are based on the sentence ta1 (he) bu4 (not) kan4 (read) zhen1tan4 (detective) xiao3shuo1 (novel) le0 (LE) ? he doesn?t", "acronyms": [[192, 194]], "long-forms": [[187, 190]]}, {"text": "method to train large neural networks. We use mini-batch version RPROP (RMSPROP) (Hinton, 2012) to minimize the loss function.", "acronyms": [[65, 70]], "long-forms": [[72, 79]]}, {"text": "If a goal is not accomplished before worst-time  timeout value,  ACCUMVALUE = ACCUM.VALUE - \\[response-  complexity(punishment) * sub-goal(worst-ease timeout punis- ", "acronyms": [[65, 75]], "long-forms": [[78, 89]]}, {"text": "  Abstract  In an attempt to extend Penn Discourse Tree Bank (PDTB) / Turkish Discourse Bank (TDB)  style annotations to spoken Turkish, this paper presents the first attempt at annotating the explicit ", "acronyms": [[62, 66], [94, 97]], "long-forms": [[36, 60], [70, 92]]}, {"text": "A set of the hyponym candidates extracted from a single itemization or list is called a hyponym candidate set (HCS). For the itemization", "acronyms": [[111, 114]], "long-forms": [[88, 109]]}, {"text": " 3.2 Latent Structural SVM We employ the latent structural SVM (LS-SVM) model for learning the discriminative model of query", "acronyms": [[64, 70], [23, 26]], "long-forms": [[41, 62]]}, {"text": "lemma(L)? and ? nonlem(NL)? systems for ran-", "acronyms": [[23, 25]], "long-forms": [[16, 22], [0, 5]]}, {"text": "Chair), Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odjik, Stelios Piperidis, Mike Rosner, & Daniel Tapias, 310?314, Valletta, Malta. European Language Resources Association (ELRA).Ferra?ndez, Oscar, Michael Ellsworth, Rafael Mun?oz, & Collin F. Baker. 2010b.", "acronyms": [[183, 187]], "long-forms": [[142, 181]]}, {"text": "583  Proceedings of the Analyzing Conversations in Text and Speech (ACTS) Workshop at HLT-NAACL 2006, pages 1?7, New York City, New York, June 2006.", "acronyms": [[68, 72], [86, 95]], "long-forms": [[24, 66]]}, {"text": "lists are derived automatically from the training data.  Frequent Word List (FWL) This list consists of words that occur in more than 5 different documents.", "acronyms": [[77, 80]], "long-forms": [[57, 75]]}, {"text": " In a second experiment, we used the original TGRD corpus but added the language variety (LV) (i.e., MSA and DA) features.", "acronyms": [[90, 92], [46, 50], [101, 104], [109, 111]], "long-forms": [[72, 88]]}, {"text": "and Causal Relations. In proceedings of the Association for Computational Linguistics (ACL). ", "acronyms": [[87, 90]], "long-forms": [[50, 85]]}, {"text": " It considers all pronouns (PRP, PRP$), noun phrases (NP) and heads of verb phrases (VP) as potential mentions.", "acronyms": [[85, 87], [28, 31], [54, 56], [33, 37]], "long-forms": [[71, 83], [40, 51]]}, {"text": "are written in the original language.  Direct orthographical mapping (DOM), which performs the transliteration between two lan-", "acronyms": [[70, 73]], "long-forms": [[39, 68]]}, {"text": "(? 2.2), we propose an induction algorithm based on Integer Linear Programming (ILP). Figure 2", "acronyms": [[80, 83]], "long-forms": [[52, 78]]}, {"text": "in sentence level are not combined. That is why  most of the verb phrases(VP) are inside match  (53.28%).", "acronyms": [[74, 76]], "long-forms": [[61, 72]]}, {"text": "ranging from generating weather forecasts to summarizing medical information (Reiter and Dale 2000). Of all the subtasks of NLG, Referring Expression Generation (REG) is among those that have received most scholarly attention.", "acronyms": [[162, 165], [124, 127]], "long-forms": [[129, 160]]}, {"text": " The system includes four main stages: topic classification, named entity recognition (NER), disease/location detection, and visualization.", "acronyms": [[87, 90]], "long-forms": [[61, 85]]}, {"text": "Model level, there is an intermediate stage of analysis , characterized by a  formal language , resp r  - The Engliaboriented Formal Language ( EFL) , which containa  constant^ that  correspond to the terms of English, This language is wed to represent the ", "acronyms": [[144, 147]], "long-forms": [[110, 141]]}, {"text": "Table 1 shows the feature template sets.  For training, we used soft confidence weighted (SCW) (Wang et al., 2012).", "acronyms": [[90, 93]], "long-forms": [[64, 88]]}, {"text": "2115  Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 63?67, Gothenburg, Sweden, April 26-30 2014.", "acronyms": [[74, 76], [32, 36]], "long-forms": [[54, 72]]}, {"text": "al. ( 1997)  and later Harabagiu and Maiorano (HM) (2000)  investigated the acquisition of the lexical concept ", "acronyms": [[47, 49]], "long-forms": [[23, 45]]}, {"text": "(wine) is localized to exterior locus (barrel) and crosses the intermediate locus IME(LOC) to be localized to the interior INT(LOC) (the_bottle). ", "acronyms": [[127, 130], [86, 89], [82, 85], [123, 126]], "long-forms": [[97, 106], [76, 81]]}, {"text": "PCFG = Probabilistic  Context-Free Grammar, LM = Bigram Model with Witten-Bell smoothing,  PM = Priority Model. ", "acronyms": [[91, 93], [0, 4], [44, 46]], "long-forms": [[96, 110], [7, 42], [49, 61]]}, {"text": " Irish students do not receive any instruction in  Modern Foreign Languages (MFL) up until this  point (Irish is not considered a MFL).", "acronyms": [[77, 80], [130, 133]], "long-forms": [[51, 75]]}, {"text": "require. We solve this problem by designing the Shallow Semantic Tree Kernel (SSTK) which allows to match portions of a PAS.", "acronyms": [[78, 82]], "long-forms": [[48, 76]]}, {"text": "lem, and our system adopted a supervised learning approach with Maximum Entropy classifier, which is widely used in natural language processing(NLP). ", "acronyms": [[144, 147]], "long-forms": [[116, 142]]}, {"text": "prove SRL performance.  Template Generation (TG)  Our template generation (TG) algorithm extracts ", "acronyms": [[45, 47], [6, 9], [75, 77]], "long-forms": [[24, 43], [54, 73]]}, {"text": "  Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 53?57, Gothenburg, Sweden, April 26-30 2014.", "acronyms": [[70, 72], [28, 32]], "long-forms": [[50, 68]]}, {"text": "ical relations may be at the head of multiple arcs.  For example, the surface subject (S-SBJ) of a passive verb is also the logical object (L-OBJ).", "acronyms": [[87, 92], [140, 145]], "long-forms": [[70, 85], [124, 138]]}, {"text": "? TFN Bank(TFNB): 38,769 samples  CPN Bank(CPNB): 17,637 samples  The difficulty of identifying unknown words in ", "acronyms": [[43, 47], [11, 15]], "long-forms": [[34, 42], [2, 10]]}, {"text": "2 Classification Algorithms  2.1 Conditional Random Fields  Conditional random field (CRF) was an extension  of both Maximum Entropy Model (MEMs) and ", "acronyms": [[86, 89], [140, 144]], "long-forms": [[60, 84], [117, 138]]}, {"text": "The Text Encoding Initiative (TEI) is a cooperative undertaking of the Association  for Computers and the Humanities (ACH), the Association for Computational Lin-  guistics (ACL), and the Association for Literary and Linguistic Computing (ALLC). ", "acronyms": [[239, 243], [30, 33], [118, 121], [174, 177]], "long-forms": [[188, 237], [4, 28], [71, 116], [128, 172]]}, {"text": "(the concept <food,nutrient>).  The aim of using Selectional Preferences (SP) in SRL is to generalize from the argument heads in", "acronyms": [[74, 76], [81, 84]], "long-forms": [[49, 72]]}, {"text": "NLP-Based  Index ing  in  In fo rmat ion   Ret r ieva l   In information retrieval (IR), a typical task is to  fetch relevant documents from a large archive in ", "acronyms": [[84, 86], [0, 3]], "long-forms": [[61, 82]]}, {"text": "impulses are possibly found. It is realized with very  simple space management transition networks (SMTNs),  in which $EXP, a distinguished symbol on an arc, ", "acronyms": [[100, 105]], "long-forms": [[62, 98]]}, {"text": "Additionally, we have acquired gazetteer lists for Hindi and used these gazetteers in the Maximum Entropy (MaxEnt) based Hindi NER system.", "acronyms": [[107, 113], [127, 130]], "long-forms": [[90, 105]]}, {"text": "Method (METH) the methods used Result (RES) the results achieved Conclusion (CON) the authors? conclusions", "acronyms": [[77, 80], [8, 12], [39, 42]], "long-forms": [[65, 75], [0, 6], [31, 37]]}, {"text": "(3) range, e.g., (age(value(0 100))).  The notion of IMPORTANCE VALUES (IVs) are  introduced here and are used to numerically describe ", "acronyms": [[72, 75]], "long-forms": [[53, 70]]}, {"text": "A similar embedding method, called ? Global Vector (GloVe)?, was", "acronyms": [[52, 57]], "long-forms": [[37, 50]]}, {"text": "Using the alignments from HIER, we created phrase tables using model probabilities (MOD), and heuristic extraction on words (HEUR-W), blocks (HEUR-B), and minimal phrases (HEUR-P) as de-", "acronyms": [[125, 131], [26, 30], [84, 87], [142, 148], [172, 178]], "long-forms": [[94, 123]]}, {"text": "parsed as the specified category.  The 'target condition(TCND)' represents  conditions on variables in tile 'target pattern.'", "acronyms": [[57, 61]], "long-forms": [[40, 56]]}, {"text": "ble. The model makes heavy use of single-category Ambiguity Classes (AC)3, which (being independent on the tagger?s intermediate decisions) can be", "acronyms": [[69, 71]], "long-forms": [[50, 67]]}, {"text": "We used four machine learning algorithms implemented in Mallet (McCallum, 2002): decision tree, Naive Bayes, maximum entropy (MaxEnt), and conditional random field (CRF).5 Table 4 shows the", "acronyms": [[126, 132], [165, 168]], "long-forms": [[109, 124], [139, 163]]}, {"text": "train statistical models that rely on annotated data.8 In this paper, we test automatic annotation using Conditional Random Fields (CRFs) (Lafferty et al, 2001) which have achieved high performance for in-", "acronyms": [[132, 136]], "long-forms": [[105, 130]]}, {"text": "Each of these sets is further divided into three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews). The number of entities", "acronyms": [[116, 121]], "long-forms": [[100, 114]]}, {"text": " Assi, S. (1997). Farsi linguistic database (FLDB). ", "acronyms": [[45, 49]], "long-forms": [[18, 43]]}, {"text": "MT is one of the oldest and most important areas of Natural Language Processing (NLP) / Computational Linguistics (CL).2 From its beginnings we have witnessed some changes in the", "acronyms": [[115, 117], [0, 2], [81, 84]], "long-forms": [[88, 113], [52, 79]]}, {"text": "In t roduct ion   This paper discusses the relationstfip between Tree Adjoin-  ing Grammars (TAG's) and :Head Grammars (HG's). TAG's ", "acronyms": [[120, 124], [93, 98], [127, 132]], "long-forms": [[105, 118], [65, 91]]}, {"text": "tions for this sentence.  Figure 5: The LF (left) and MRS (right) representations for the sentence ?", "acronyms": [[40, 42], [54, 57]], "long-forms": [[44, 48]]}, {"text": "3.5 A Novel Lattice Statistical Language Model Representation Our final statistical language model is a novel latent-variable statistical language model, called a Partial Lattice MRF (PL-MRF), with rich latent structure, shown in Figure 3. The", "acronyms": [[184, 190]], "long-forms": [[163, 182]]}, {"text": "2.1 Processing definitions  Our algorithms are used in an overall system  called \"onomasiological search system\" (OSS),  whose aim is to allow the user to find terms by ", "acronyms": [[114, 117]], "long-forms": [[82, 111]]}, {"text": "In TAC 2008 Summarization track, all submitted runs were scored with the ROUGE (Lin, 2004) and Basic Elements (BE) metrics (Hovy et al.,", "acronyms": [[111, 113], [3, 6]], "long-forms": [[95, 109]]}, {"text": "In the next section we will explain the concep-  tual model of ILMs by means of the KADS Domain  Description Language (DDL) proposed in Schreiber  (Schreiber et al, 1993).", "acronyms": [[119, 122], [63, 67], [84, 88]], "long-forms": [[97, 117]]}, {"text": "They thus attract research from many different and beneficial perspectives. Dialog acts (DAs) (Searle, 1969), which reflect the functions that ut-", "acronyms": [[89, 92]], "long-forms": [[76, 87]]}, {"text": "Branching quantification in DTS has partially been discussed in [7] and [8], in which we compared DTS with First Order Logic (FOL). However, FOL is limited in that it allows to", "acronyms": [[126, 129], [28, 31], [98, 101], [141, 144]], "long-forms": [[107, 124]]}, {"text": "Our translation method performs sense-based translation and pronunciation-based translation on the basis of statistical machine translation (SMT) methods.", "acronyms": [[141, 144]], "long-forms": [[108, 139]]}, {"text": "1 Introduction 1.1 Background Back in 2004, ETV (Eenadu Television), Hyderabad, felt a need for a text editor to prepare news", "acronyms": [[44, 47]], "long-forms": [[49, 66]]}, {"text": "Also,  the dependency framework is arguably closer to  semantics than the phrase structure grammar (PSG)  if the dependency relations are judiciously chosen.", "acronyms": [[100, 103]], "long-forms": [[74, 98]]}, {"text": "Na?ve Bayes (De Sitter and Daelemans, 2003).  Maximum Entropy (ME) conditional models like  ME Markov models (McCallum et al, 2000) and ", "acronyms": [[63, 65], [92, 94]], "long-forms": [[46, 61]]}, {"text": "overall 412 5298 1519 750 Table 1: Corpus statistics: number of sentences (S), words (W), frame elements (FE) and alignments.", "acronyms": [[106, 108]], "long-forms": [[90, 104], [64, 73], [79, 84]]}, {"text": "5.1 Candidate Generation We generate a list of candidate antecedents by first extracting all VPs and ADJPs (and all contiguous combinations of their constituents) from the current", "acronyms": [[101, 106], [93, 96]], "long-forms": [[108, 126]]}, {"text": "NG = ngrams, E = emoticon replacement, IR = informal register replacement, TL = tweet length, RT = retweet count, SVO = subject-verbobject structures. %", "acronyms": [[94, 96], [0, 2], [39, 41], [75, 77], [114, 117]], "long-forms": [[99, 106], [5, 11], [17, 25], [44, 61], [80, 92], [120, 138]]}, {"text": "Keyword 0.168 0.168 0.157 6.3 Table 3: Title quality as compared to the reference for the hierarchical discriminative (HD), flat discriminative (FD), hierarchical generative (HG), flat", "acronyms": [[119, 121], [145, 147], [175, 177]], "long-forms": [[90, 117], [124, 143], [150, 173]]}, {"text": "2 Shared-task evaluation in HLT Over the past twenty years, virtually every field of research in human language technology (HLT) has introduced STECs.", "acronyms": [[124, 127], [28, 31], [144, 149]], "long-forms": [[97, 122]]}, {"text": "As shown in the table, all models perform equally well on identification, which is determined by the frame matcher (FM); i.e., any extracted argument receiving one or more candidate roles is ?", "acronyms": [[116, 118]], "long-forms": [[101, 114]]}, {"text": "4 Learning Algorithms We evaluated four supervised learning algorithms: Support Vector Machines (SVM), AdaBoost with decision stumps (AdB), Naive Bayes (NB), and de-", "acronyms": [[97, 100], [153, 155], [134, 137]], "long-forms": [[72, 95], [140, 150], [103, 111]]}, {"text": " 2 Universal Networking Language Universal Networking Language (UNL) is an interlingua that represents a sentence in a language inde-", "acronyms": [[64, 67]], "long-forms": [[33, 62]]}, {"text": "mance. The query-based selection model utilizes Support Vector Regression (SVR) models to predict the mean average precision (MAP) of each query", "acronyms": [[75, 78], [126, 129]], "long-forms": [[48, 73], [102, 124]]}, {"text": "acoustic ambiguity. We measure performance in  terms of character error rate (CER), which is the  number of characters wrongly converted from the ", "acronyms": [[78, 81]], "long-forms": [[56, 76]]}, {"text": "ing mobile devices. Such an application typically uses a speech recognizer (ASR) for transforming the user?s speech input to text and a search component", "acronyms": [[76, 79]], "long-forms": [[55, 74]]}, {"text": "word lexicon optimized for a given task. We consider the task of out of vocabulary (OOV) word detection, which relies on output from", "acronyms": [[84, 87]], "long-forms": [[65, 82]]}, {"text": "its title  read{ARG0, ARG1}  Figure 2: A sentence parse tree with two predicative tree structures (PAST s) which is equal 1 if the target fi is rooted at node n", "acronyms": [[99, 105], [16, 20], [22, 26]], "long-forms": [[70, 97]]}, {"text": "the source and target sides are lexicons (terminals) 2) Unlexicalized (ULex): all leaf nodes in both the 46", "acronyms": [[71, 75]], "long-forms": [[56, 69]]}, {"text": "were computed for each scenario: bilingual evaluation under study (BLEU), position independent error rate (PER) and word error rate (WER). ", "acronyms": [[133, 136], [67, 71], [107, 110]], "long-forms": [[116, 131], [33, 59], [74, 105]]}, {"text": " 3.3 Cascaded ATN Grammars A Cascaded ATN Grammars (CATN) (Woods 1980) is a cooperating sequence of ATN transducers, each feeding its output to the next stage.", "acronyms": [[52, 56], [14, 17], [100, 103]], "long-forms": [[29, 41]]}, {"text": "assignment for each annotator. We then performed an analysis of variance (ANOVA) on the outcomes of our experiment.", "acronyms": [[74, 79]], "long-forms": [[52, 72]]}, {"text": "Evaluation (LREC?08), Marrakech, Morocco, may.  European Language Resources Association (ELRA). ", "acronyms": [[89, 93], [12, 16]], "long-forms": [[48, 87]]}, {"text": "various evidential features are proposed and  integrated effectively and efficiently through a  Hidden Markov Model (HMM). In addition, a ", "acronyms": [[117, 120]], "long-forms": [[96, 115]]}, {"text": "Clark, 2008). For constituent-based parsing using the Chinese Treebank (CTB), Wang et al (2006) have shown that a shift-reduce parser can give", "acronyms": [[72, 75]], "long-forms": [[54, 70]]}, {"text": "on terrorism in a matter of weeks. Since the terrorism  domain knowledge bases (KB's) were developed for English  for MUC-4 already, and since the KB's can be shared across ", "acronyms": [[80, 84], [118, 123], [147, 151]], "long-forms": [[63, 78]]}, {"text": "As suggested from the tables, the accuracy values of the component classifiers (Ccn and Cen) in CoTrain are almost always higher than those of the corresponding TSVM(CN) and TSVM(EN), based on any machine translation service.", "acronyms": [[166, 168], [161, 165], [174, 178], [179, 181], [80, 83], [88, 91]], "long-forms": []}, {"text": "on a 1,000 TU, EN-IT test set. B=Basic, LI=language identification, QE=quality estimation, WE=word embedding. ", "acronyms": [[68, 70], [91, 93], [11, 13], [15, 20], [33, 38], [40, 42]], "long-forms": [[71, 89], [94, 108], [43, 66]]}, {"text": "Center for Language Technology. After accomplishing the task concerning named entity (NE)  identification, we go on studying identification ", "acronyms": [[86, 88]], "long-forms": [[72, 84]]}, {"text": " 2 Changes to the AZ Scheme Argumentative Zoning II (AZ-II) is a new annotation scheme, which is an elaboration of the orig-", "acronyms": [[53, 58], [18, 20]], "long-forms": [[28, 51]]}, {"text": "UniProt the protein sequence database managed by the Swiss Institute of Bioinformatics (SIB), the European Bioinformatics Institute (EBI) and the Protein Information Resource (PIR)", "acronyms": [[133, 136], [88, 91], [176, 179]], "long-forms": [[98, 131], [53, 85], [146, 174]]}, {"text": "2.2 Singular Value Decomposition Given any matrix S, its singular value decomposition (SVD) is S = U?V T . The matrix Sk =", "acronyms": [[87, 90], [99, 102]], "long-forms": [[57, 85]]}, {"text": "the current work, we used a subset of that corpus consisting of examples whose question types were PRC (procedure), RSN (reason) or ATR (atrans). ", "acronyms": [[99, 102], [116, 119], [132, 135]], "long-forms": [[104, 113], [121, 127], [137, 143]]}, {"text": "fier. We also implemented a simple classifier that relies on the pointwise mutual information (PMI) between the senses of the target and co-occurring", "acronyms": [[95, 98]], "long-forms": [[65, 93]]}, {"text": "However, to the best of our knowledge only the model of Blunsom & Cohn (2006), which is based on a Conditional Random Field (CRF) (Lafferty et al, 2001), can compute word indices pairs?", "acronyms": [[125, 128]], "long-forms": [[99, 123]]}, {"text": "In Processdings of Sixth International Conference on  Language Resources and Evaluation (LREC),  pages 2961-2968, Marrakech, Morocco.", "acronyms": [[89, 93]], "long-forms": [[54, 72]]}, {"text": "MR = MN/length (5) ? The Continuous Match Value(CMV): Continuous match should be better than the", "acronyms": [[48, 51], [0, 2], [5, 7]], "long-forms": [[25, 46]]}, {"text": " The system determines the position of the main part of  the situation relative to the point of speech (PS). The ", "acronyms": [[104, 106]], "long-forms": [[87, 102]]}, {"text": " 2.3 Perceptron Sequential Tagger This system uses a Global Linear Model (GLM), a sequential tagger using the perceptron algorithm", "acronyms": [[74, 77]], "long-forms": [[53, 72]]}, {"text": "function (Section 4.1).  Initiatives such as PropBank (PB) (Kingsbury and Palmer, 2002) have made possible the design of", "acronyms": [[55, 57]], "long-forms": [[45, 53]]}, {"text": "(:all it as word accuracy(W.A.). We use one  more measure, called character accuracy(C.A.)  that measures the character edit distance be- ", "acronyms": [[85, 89], [26, 29]], "long-forms": [[66, 83], [12, 25]]}, {"text": "Computational Linguistics Volume 23, Number 2  1993c). FUF (Functional Unification Formalism) is a programming language based on  functional unification (Kay 1979).", "acronyms": [[55, 58]], "long-forms": [[60, 92]]}, {"text": "ID full papers domain (TCS) 10 BB web pages domain (BB) 2 BI abstracts domain (BS) 10 Table 1: Characteristics of BioNLP-ST 2011 main tasks.", "acronyms": [[79, 81], [0, 2], [23, 26], [31, 33], [52, 54], [114, 123]], "long-forms": [[58, 70]]}, {"text": "The RASP toolkit (Briscoe et al, 2006) is used for sentence boundary detection, tokenisation, PoS tagging and finding grammatical relations (GR) between words in the text.", "acronyms": [[141, 143], [4, 8], [94, 97]], "long-forms": [[118, 139]]}, {"text": "which has been developed within the projects K1T-NASEV and its  successor KIT-FAST 2 will be described (for details see \\[Hanen-  1 LP = Linear Precedence; FCR = Feature Co-oecmenee R striction  KIT-FAST (FAST = Functor-Argument Structure for Translation; KIT = ", "acronyms": [[132, 134], [45, 54], [74, 82], [156, 159], [195, 203], [256, 259], [205, 209]], "long-forms": [[137, 154], [162, 193], [212, 254]]}, {"text": "learning community: ? Rectified Linear Unit (ReLU) (Nair and Hinton, 2010): max(0, x);", "acronyms": [[45, 49]], "long-forms": [[22, 43]]}, {"text": "ically measuring the semantic similarity between two texts, which was the aim of the 2013 Semantic Textual Similarity (STS) task (Agirre et al 2013).", "acronyms": [[119, 122]], "long-forms": [[90, 117]]}, {"text": " 2. Character Error Rate (CER): Edit distance in terms of characters between the target sentence", "acronyms": [[26, 29]], "long-forms": [[4, 24]]}, {"text": "is a very laborious and costly process. Silver standard corpus (SSC) annotation is a very recent direction of corpus development which", "acronyms": [[64, 67]], "long-forms": [[40, 62]]}, {"text": "given threshold, this binary feature fires.  4.3 Variant Feature (VAR) In the variant cipher, the plaintext is written into", "acronyms": [[66, 69]], "long-forms": [[49, 64]]}, {"text": "provement against Naive Bayes was reported. Our proposed model, tag guided RNN (TG-RNN), is designed to use the syntactic tag of the parent", "acronyms": [[80, 86]], "long-forms": [[64, 78]]}, {"text": "Best-Scoring-Choice Realization Pablo Gerva?s, Raquel Herva?s, Carlos Leo?n Natural Interaction based on Language (NIL) Universidad Complutense de Madrid", "acronyms": [[115, 118]], "long-forms": [[76, 113]]}, {"text": "CFG. The proof is based on a lexicalization procedure related to the lexicalization  procedure used to create Greibach normal form (GNF) as presented in Harrison 1978. ", "acronyms": [[132, 135], [0, 3]], "long-forms": [[110, 130]]}, {"text": "understood as follows: ? if the POS-tag of current word  is VB (Verb) and  its word-form  is ? can?", "acronyms": [[60, 62], [32, 39]], "long-forms": [[64, 68]]}, {"text": "4.3 Classifiers All evaluation tests were performed using two classifiers, Maximum Entropy (MaxEnt) and Support Vector Machines (SVM).", "acronyms": [[92, 98], [129, 132]], "long-forms": [[75, 90], [104, 127]]}, {"text": "Third Order Parser 93.07 20 hrs Quadratic Kernel(QK) 93.41 6 hrs Biquadratic Kernel(BK) 93.45 6 hrs 8-th Degree Polynomial Kernel(8K) 93.27 6 hrs", "acronyms": [[84, 86], [49, 51], [130, 132]], "long-forms": [[65, 82], [32, 48], [100, 129]]}, {"text": "the  locat ions  shown in F ig .4 .  The s lo t  SH~P represent  whether  the  par t   cor respond ing  to  th i s  frame is  a reg ion(~EG)  or a branch(BR A) The  SU~P s lo t  records  i t s  subpar ts  and the i r  locat ions  of or re ia t ions  to ", "acronyms": [[154, 158], [49, 53], [136, 139], [165, 169]], "long-forms": [[147, 152]]}, {"text": "rently, a pure statistical MT system based on Pharaoh is developed by BPPT and National News  Agency (ANTARA) using 500K sentences pair,  expected to have better accuracy and robustness ", "acronyms": [[102, 108], [27, 29], [70, 74]], "long-forms": [[79, 100]]}, {"text": "Soft cardinality has been shown to be a very strong text-overlapping baseline for the task of measuring semantic textual similarity (STS), obtaining 3rd place in SemEval-2012.", "acronyms": [[133, 136], [162, 174]], "long-forms": [[104, 131]]}, {"text": "irrespective of word order.  Longest Common Substring (LCS): This measures the longest sequence of words shared between", "acronyms": [[55, 58]], "long-forms": [[29, 53]]}, {"text": "1982, 1984; Clark 1992; Cremers 1996; Arts 2004). The present article will examine its consequences for the generation of referring expressions (GRE). In doing this, we dis-", "acronyms": [[145, 148]], "long-forms": [[108, 143]]}, {"text": "description where i t  is useful.  The posit ion of Linear Precedence (LP) state-  ments in th i s  formalism must now be c la r i f ied .", "acronyms": [[71, 73]], "long-forms": [[52, 69]]}, {"text": " 1 Introduction Data-driven machine translation (MT) relies on models that can be efficiently estimated from par-", "acronyms": [[49, 51]], "long-forms": [[28, 47]]}, {"text": " 0.7  0  20  40  60  80  100  120  140 information density (ID)Fisher information (FIR)query-by-committee (SVE)random CoNLL-03", "acronyms": [[60, 62], [107, 110], [118, 126], [83, 86]], "long-forms": [[39, 58], [63, 69]]}, {"text": "I first  describe the language used to characterize the semantics of  lexical items, SEL (for Simple Episodic Logic), then the  syntax and interpretation f logical forms.", "acronyms": [[85, 88]], "long-forms": [[94, 115]]}, {"text": "the method described in Section 3.2). We also present the number of linear equations (L.Eq.) used", "acronyms": [[86, 91]], "long-forms": [[68, 84]]}, {"text": "Table 3: Statistics of training and test corpus for the Canadian Hansards task (PP=perplexity, SL=sentence length). ", "acronyms": [[95, 97]], "long-forms": [[98, 113]]}, {"text": "ferent corpora, Academia Sinica (AS), City  University of Hong Kong (HK), Peking University (PK), and Microsoft Research Asia (MSR),  each of which has its own definition of a word.", "acronyms": [[127, 130], [33, 35], [69, 71], [93, 95]], "long-forms": [[102, 120], [16, 31], [58, 67], [74, 91]]}, {"text": "paring average precision values obtained 1) against the original, manual chronologies (APC), and 2) against the expert assessment (APE). These values", "acronyms": [[131, 134], [87, 90]], "long-forms": [[100, 129]]}, {"text": "3.2 To resolve gapping under serial verb construction Serial verb construction (SVC) (Baker, 1989) is construction in which a sequence of verbs appears in", "acronyms": [[80, 83]], "long-forms": [[54, 78]]}, {"text": "accessing semantic information represented in  input specifications, written in the form of the  Sentence Plan Language (SPL) (Kasper, 1989;  Bateman, 1997a), and in the knowledge base of ", "acronyms": [[121, 124]], "long-forms": [[97, 119]]}, {"text": "(I) it performs a translation between  intermediate languages constructed  over source language (SL) and target  language (TL) respectively (called ", "acronyms": [[97, 99], [123, 125]], "long-forms": [[80, 95], [105, 121]]}, {"text": " 1 Introduction Question answering (QA) systems have received a great deal of attention because they provide both", "acronyms": [[36, 38]], "long-forms": [[16, 34]]}, {"text": "mance on the NER task.  Maximum entropy classification (MaxEnt): The MaxEnt approach, or logistic regression, is", "acronyms": [[56, 62], [13, 16], [69, 75]], "long-forms": [[24, 54]]}, {"text": "tives falls in the middle range and what causes the large and small divergence of the document collection pairs with different topics (DT) and the same topic (ST) or perspective (SP), respectively.", "acronyms": [[135, 137], [159, 161], [179, 181]], "long-forms": [[117, 133], [147, 157], [166, 177]]}, {"text": "semantic links between NEs extracted from the answer sentence and the question focus word, which encodes the expected lexical answer type (LAT). We", "acronyms": [[139, 142], [23, 26]], "long-forms": [[118, 137]]}, {"text": "equivalent m Dutch For a sample of 59 Ital,an noun  s)nsets there is at least an overlap of 30% (20) with  Dutch Examples are Arbeltszeitverkurzung (DE)  = arbeidstijdverkortmg (NL) = (reduction of work- ", "acronyms": [[149, 151], [178, 180]], "long-forms": [[107, 121]]}, {"text": "inforced by the proposed method. In this method, the decision list (DL) learning algorithm (Yarowsky, 1995) is used.", "acronyms": [[68, 70]], "long-forms": [[53, 66]]}, {"text": "of Data-to-Speech systems have been and are be-  ing developed on the basis of D2S. Examples are  the Dial Your Disc (DYD)-system, which presents  information in English about Mozart compositions ", "acronyms": [[118, 121], [79, 82]], "long-forms": [[102, 116]]}, {"text": " 2 Question Classification We define Question Classification(QC) here to be the task that, given a question, maps it to one of", "acronyms": [[61, 63]], "long-forms": [[37, 59]]}, {"text": "The typical way to address these situations is to jointly model these relations, e.g., using Markov logic networks (MLN) (Poon and Vanderwende, 2010).", "acronyms": [[116, 119]], "long-forms": [[93, 114]]}, {"text": "The results are reported for Same Sentence (SS) and Previous Sentence (PS) models, and the joined results for each of the arguments (ALL) as average", "acronyms": [[71, 73]], "long-forms": [[52, 69]]}, {"text": "collocations in each sentence.  Perplexity from Language Model (PLM) Perplexity measures are extracted from a trigram language", "acronyms": [[64, 67]], "long-forms": [[32, 62]]}, {"text": "Table 2: Three kinds of preprocessing of a sentence in Japanese; N = noun, TOP = topic marker, ADV = adverbial particle, ADJ = adjective, COP = copula, EXCL = exclamation mark.", "acronyms": [[95, 98], [121, 124], [75, 78], [138, 141], [152, 156]], "long-forms": [[101, 110], [127, 136], [69, 73], [81, 86], [144, 150], [159, 170]]}, {"text": "noisy and potentially unreliable observations.  While scenario template creation (STC) is a difficult problem, its evaluation is arguably more dif-", "acronyms": [[82, 85]], "long-forms": [[54, 80]]}, {"text": "Narrative Summarization. Journal Traitement automatique des langues (TAL): Special  issue  on Context:  Automatic Text  Summariza-", "acronyms": [[69, 72]], "long-forms": [[33, 67]]}, {"text": "6. A rule to convert the Hindi word into its  base form (BF). ", "acronyms": [[57, 59]], "long-forms": [[46, 55]]}, {"text": "Bielefeld University  2 Center of Excellence ? Cognitive Interaction Technology?(CITEC), Bielefeld University     ", "acronyms": [[81, 86]], "long-forms": [[47, 79]]}, {"text": "Part of FrameNet is also a corpus of 135,000 annotated example sentences from the British National Corpus (BNC). ", "acronyms": [[107, 110]], "long-forms": [[82, 105]]}, {"text": "other synthesis techniques.  The TD-PSOLA (Time Domain Pitch Synchronous Overlap-add) developed by CNET is a very simple  but ingenious method which assures high voice quality, the only disadvantage is that it is based on a time: ", "acronyms": [[33, 41], [99, 103]], "long-forms": [[43, 84]]}, {"text": "Figure 1 Examples of contextual phenomena,  ellipsis depends on the context and means 'credit card'; it  is both a focus and an object (OBJ). ", "acronyms": [[136, 139]], "long-forms": [[128, 134]]}, {"text": "run in parallel. This kind of parallelism is a good fit for the Same Instruction Multiple Thread (SIMT) hardware paradigm implemented by modern GPUs.", "acronyms": [[98, 102], [144, 148]], "long-forms": [[64, 96]]}, {"text": "precisely the issue we address in this article. We concentrate on the task of automatically classifying NSUs, which we approach using machine learning (ML) techniques. Our aim", "acronyms": [[152, 154], [104, 108]], "long-forms": [[134, 150]]}, {"text": "where C is the concept that subsumes both C1 and C2 and has the highest information content (i.e., it is the least common subsumer (LCS)). ", "acronyms": [[132, 135]], "long-forms": [[109, 130]]}, {"text": "Although there is a modest cost associated with annotating data, we show that a reduction of 40% relative in alignment error (AER) is possible over the GIZA++ aligner (Och and Ney, 2003).", "acronyms": [[126, 129], [152, 158]], "long-forms": [[109, 124]]}, {"text": "identification. In Proceedings of the 24th International Conference on Computational Linguistics (COLING), pages 2585?2602, Mumbai, India.", "acronyms": [[98, 104]], "long-forms": [[71, 96]]}, {"text": "92  NAACL-HLT 2012 Workshop on Speech and Language Processing for Assistive Technologies (SLPAT), pages 28?36, Montre?al, Canada, June 7?8, 2012.", "acronyms": [[90, 95]], "long-forms": [[31, 88]]}, {"text": "pose augmenting queries in the style of relevance  feedback (Salton and Buckley 1990), Kalashnikov  (2007) treat Web Person Search (WePS) as a disambiguation problem whose objective is to distin-", "acronyms": [[132, 136]], "long-forms": [[113, 130]]}, {"text": "Brighton, BN1 9QN, England  Abstract  Generalised phrase structure grammars (GPSG's)  appear to offer a means by which the syntactic ", "acronyms": [[77, 83], [14, 17], [10, 13]], "long-forms": [[38, 75]]}, {"text": "both in the form of documents and factual  databases. These knowledge sources (KSs) are  intrinsically heterogeneous and dynamic.", "acronyms": [[79, 82]], "long-forms": [[60, 77]]}, {"text": "editor, Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC?08), Marrakech, Morocco, may. European Language Resources Association (ELRA). http://www.lrec-", "acronyms": [[172, 176], [96, 103]], "long-forms": [[131, 170], [61, 94]]}, {"text": "   In the SUM (Summarization) setting, the  entailment pairs were generated using two proce-", "acronyms": [[10, 13]], "long-forms": [[15, 28]]}, {"text": " In order to acquire labeled instances for training, we decompose the gold standard (GS) events into multiple events with single arguments.", "acronyms": [[85, 87]], "long-forms": [[70, 83]]}, {"text": "Queue to for user intervention.  4.2,  Document Processor (DP)   The DP identifies and extracts all SGML tags de- ", "acronyms": [[59, 61], [100, 104]], "long-forms": [[39, 57]]}, {"text": "L J  = lea:-ncd j o u r n a l s   PJ - 1 journals  NR = newt;pc?pcr reportasc  F = fictlon ", "acronyms": [[51, 53], [34, 36]], "long-forms": [[56, 77], [83, 90], [7, 10]]}, {"text": " Because we don't have any other useful resources except ChineseGigaword(CGW),We first computed mutual information for all 3-character words in two", "acronyms": [[73, 76]], "long-forms": [[57, 72]]}, {"text": "IGT-XML. At the heart of the model is a representation of interlinearized glossed text (IGT). Building", "acronyms": [[88, 91], [0, 7]], "long-forms": [[58, 86]]}, {"text": "mt. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING) - Volume 1, pages 1145?1152.", "acronyms": [[86, 92]], "long-forms": [[59, 84]]}, {"text": "Synthesis) is a learning system \\[12,13,14\\] which  consists of a learning element (Meta-XMAS), a  knowledge base (KB), and two inference ngines  of a morphological nalyzer (MOA) and a mor- ", "acronyms": [[115, 117]], "long-forms": [[99, 113]]}, {"text": "Parsing. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL), pp.", "acronyms": [[101, 104]], "long-forms": [[58, 99]]}, {"text": "Feature Description lexical the words of the product attribute(PA) the POS for each word of the PA", "acronyms": [[63, 65], [71, 74], [96, 98]], "long-forms": [[45, 61]]}, {"text": "Senior Researcher and Lecturer Knowledge Management Group Applied Computer Science Institute (AIFB) University of Karlsruhe, Germany", "acronyms": [[94, 98]], "long-forms": [[58, 92]]}, {"text": "SEMANTICS. The main component of SeSyn is a rule system (the syntax) which transforms the Semantic Analysis  (SA) of any given sentence into a Surface Structure (SS) of that sentence. The SAs represent meanings ina higher order ", "acronyms": [[162, 164], [33, 38], [110, 113], [188, 191]], "long-forms": [[143, 160], [90, 107]]}, {"text": "  1 Introduction  Word Sense Disambiguation (WSD) is wellknown as one of the more difficult problems in ", "acronyms": [[45, 48]], "long-forms": [[18, 43]]}, {"text": "It is encouraging that the results (after correcting the misaligned identifiers) for the patched system are approaching the Inter Tagger Agreement (ITA) level reported for OntoNotes sense tags by the task or-", "acronyms": [[148, 151]], "long-forms": [[124, 146]]}, {"text": " 1 Introduction Base Phrase Chunking (BPC), also known as shallow syntactic parsing, is the process by which ad-", "acronyms": [[38, 41]], "long-forms": [[16, 36]]}, {"text": "2003). Another kind of verb-based multiword expression is light verb constructions (LVCs), such as the examples in (1).", "acronyms": [[84, 88]], "long-forms": [[58, 82]]}, {"text": "trees than the height-one rules of standard contextfree grammars. Tree substitution grammars (TSGs) have been shown to improve upon the standard En-", "acronyms": [[94, 98]], "long-forms": [[66, 92]]}, {"text": "This paper examines the processing predictions of the ERH on a systematic class of relative clause types, the Accessibility Hierarchy (AH) shown in figure 1.", "acronyms": [[135, 137], [54, 57]], "long-forms": [[110, 133]]}, {"text": "adapted to a new domain.  Word sense disambiguation (WSD), on the other hand, is the closely related task of assigning a sense", "acronyms": [[53, 56]], "long-forms": [[26, 51]]}, {"text": "tim+ fo ! lowiug  se lnant i t :  d i~ iens iens~ dependeucy re la t ion   (\\]IR), coordieatien ned apposition constructions (CA) and  i :op ic . .", "acronyms": [[126, 128], [78, 80]], "long-forms": [[83, 110]]}, {"text": " 1 Introduction Amazon?s MechanicalTurk (AMT) is frequently used to evaluate experiments and annotate data in", "acronyms": [[41, 44]], "long-forms": [[16, 39]]}, {"text": "MSEAS (MS,MSEA, VP,i, OUT)  (1) Start with VP = VAR ({X1, \" \" ,X.}), MSEA = f~,  i=1, and OUT = O. When the computation is completed, MS is bound to the set of active ", "acronyms": [[90, 93], [0, 5], [7, 9], [10, 14], [16, 18], [22, 25], [43, 45], [48, 51], [69, 73], [134, 136]], "long-forms": [[96, 119]]}, {"text": "target translation: the gunman was killed by police .  The Penn English Treebank (PTB) (Marcus et al, 1993) is our source of syntactic information, largely", "acronyms": [[82, 85]], "long-forms": [[59, 80]]}, {"text": "particular components - -  immediate dominance (ID) rules, meta-  rules, linear precedence (LP) statements, feature co-occurrence  restrictions (FCRs), and feature specification defaults (FSDs)  - -  and four universal components - - a theory of syntactic fea- ", "acronyms": [[188, 192], [48, 50], [92, 94], [145, 149]], "long-forms": [[156, 186], [27, 46], [73, 90], [108, 143]]}, {"text": "ory (Mann and Thompson, 1988), or RST, represents text by labeled hierarchical structures called Discourse Trees (DTs), which can incorporate several layers of other linguistic information, e.g.,", "acronyms": [[114, 117], [34, 37]], "long-forms": [[97, 112]]}, {"text": "100 Another measure of accuracy that is frequently used is the so called Out Of Vocabulary (OOV) measure, which represents the percentage of words that was not recog-", "acronyms": [[92, 95]], "long-forms": [[73, 90]]}, {"text": " 1 Introduction The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sen-", "acronyms": [[61, 64]], "long-forms": [[28, 59]]}, {"text": "the interpolated and adapted models are compared.  For the Estonian task, letter error rate (LER) is also reported, since it tends to be a more indicative", "acronyms": [[93, 96]], "long-forms": [[74, 91]]}, {"text": "From every argument to the predicate, we extract all child  noun phrases (NP) and adjectival phrases (ADJP)  as candidate gaps as well.", "acronyms": [[74, 76], [102, 106]], "long-forms": [[60, 72], [82, 100]]}, {"text": " 3.2 ,6  Addi t ion  of T rans la t ion  Rules  FinMly, translation rules (TRis) are added to the set  of GLTPC, s. TRis are descriptions in which concepts ", "acronyms": [[75, 79], [106, 111], [116, 120]], "long-forms": [[56, 73]]}, {"text": "The semantic role labeling (SRL) can be divided into two separate stages: semantic role classification (SRC) and post inference (PI). ", "acronyms": [[129, 131], [28, 31], [104, 107]], "long-forms": [[113, 127], [4, 26], [74, 102]]}, {"text": "CORROLA TION  NP1 = (COR) (APP) (ADJ) (NC) N  NP2 = (NC) N  NP3 = N ", "acronyms": [[53, 55], [21, 24], [27, 30], [33, 36], [39, 41], [14, 17]], "long-forms": [[46, 51], [0, 12]]}, {"text": "figure 5).  Base clauses (BC)  are subclauses of type sub-  junctive and subordinate.", "acronyms": [[26, 28]], "long-forms": [[12, 24]]}, {"text": "1 Introduction  In this paper we address the event extraction task  defined in Automatic Content Extraction (ACE)1  program.", "acronyms": [[109, 112]], "long-forms": [[79, 107]]}, {"text": " ? Unlabeled Elementary Dependencies (UED) identical to LED, except ignoring all labeling", "acronyms": [[38, 41], [56, 59]], "long-forms": [[3, 36]]}, {"text": "emes are represented, and not function words.  Conceptual representations (ConcSs) used by  PRESENTOR are inspired by the characteristics ", "acronyms": [[75, 81], [92, 101]], "long-forms": [[47, 73]]}, {"text": "standard measures such as AUC values. For each positive+unlabeled (PU) corpus used in our evaluation we randomly selected x% of the positive ex-", "acronyms": [[67, 69], [26, 29]], "long-forms": [[47, 65]]}, {"text": "4.1 Syntactic template selection PERSONAGE?s input generation dictionary is made of 27 Deep Syntactic Structures (DSyntS): 9 for the recommendation claim, 12 for the comparison", "acronyms": [[114, 120]], "long-forms": [[87, 112]]}, {"text": "  MTI. The original Medical Text Indexer (MTI)  system, shown in Figure 1, consists of an infra-", "acronyms": [[42, 45], [2, 5]], "long-forms": [[20, 40]]}, {"text": " 5.3   Learning Algorithm: Conditional Random Field  Conditional Random Fields (CRF) is a formalism well-suited for learning and prediction on sequential data.", "acronyms": [[80, 83]], "long-forms": [[53, 78]]}, {"text": "tleneck has been addressed through gathering annotations using many untrained workers on platforms such as Amazon Mechanical Turk (MTurk), a task commonly referred to as crowdsourcing.", "acronyms": [[131, 136]], "long-forms": [[114, 129]]}, {"text": "When using the classifiers to predict the class of a test example, there are four possible outcomes; true positive (TP), true negative (TN), false positive (FP), and false nega-", "acronyms": [[116, 118], [136, 138], [157, 159]], "long-forms": [[101, 114], [121, 134], [141, 155]]}, {"text": "pondence between proofs and dependency structures.  Dependency grammar (DG) takes as fundamental  ~This approach of 'normal form parsing' has been ", "acronyms": [[72, 74]], "long-forms": [[52, 70]]}, {"text": "is indicated by the dotted black line.  The receiver operating characteristic (ROC) curves in Figures 2 and 3 demonstrate perfor-", "acronyms": [[79, 82]], "long-forms": [[44, 77]]}, {"text": "We used a  3-pass decoding strategy, in which the first pass uses the  speaker independent (SI) vowelized system, the second  pass uses the speaker adaptive (SA) non-vowelized ", "acronyms": [[92, 94], [158, 160]], "long-forms": [[71, 90], [140, 156]]}, {"text": "3.2 Generation Performance We now compare the GYRO system with the Combinatory Categorial Grammar (CCG)-based system described in (Zhang et al.,", "acronyms": [[99, 102], [46, 50]], "long-forms": [[67, 97]]}, {"text": "(2) dobj? det:DT NN prep:IN 7DT/det=determiner, NN=noun, IN/prep=preposition, dobj=direct object", "acronyms": [[48, 50], [14, 16], [17, 19], [60, 64], [78, 82], [28, 35], [4, 8], [20, 24]], "long-forms": [[51, 55], [65, 76], [83, 96], [36, 46]]}, {"text": "al., 2007) use the document-level topics extracted with Latent Dirichlet Allocation (LDA) as indicators of meanings for word sense disambigua-", "acronyms": [[85, 88]], "long-forms": [[56, 83]]}, {"text": "overlapping relations. In Annual Meeting of the Association for Computational Linguistics (ACL). ", "acronyms": [[91, 94]], "long-forms": [[48, 88]]}, {"text": "media, where evidences for both actions and ties are available. We begin by necessary description of preliminaries and notations, we then present the mutual latent random graphs (MLRGs) model, upon which both sources of evidence could be exploited simultaneously to capture their mutual influence.", "acronyms": [[179, 184]], "long-forms": [[150, 177]]}, {"text": "non-standard token?s formation process.  Machine translation (MT) is another commonly chosen method for text normalization.", "acronyms": [[62, 64]], "long-forms": [[41, 60]]}, {"text": " Experiments are performed on two datasets, the English Penn Treebank (PTB) dataset using the standard train, dev and test splits, and the ARK", "acronyms": [[71, 74]], "long-forms": [[56, 69]]}, {"text": "clude examples such as Facebook AI Research?s challenge problems for AI-complete QA (Weston et al, 2015) and the Allen Institute for AI?s (AI2) Aristo project (Clark, 2015) along with its recently", "acronyms": [[139, 142], [81, 83]], "long-forms": [[113, 137]]}, {"text": "They are Na?ve  Bayes (NB), Support Vector Machine (SVM),  Maximum Entropy (MaxEnt) (Kamal Nigam et al  1999) and standard chain CRFs (Fei et al 2003).", "acronyms": [[76, 82], [23, 25], [52, 55], [129, 133]], "long-forms": [[59, 74], [9, 20], [28, 50]]}, {"text": "The UMLS includes the Metathesaurus (MT),  which contains over one million biomedical concepts and the Semantic Network (SN), which  represents a high-level abstraction from the UMLS ", "acronyms": [[121, 123], [37, 39], [4, 8], [178, 182]], "long-forms": [[103, 119], [22, 35]]}, {"text": "Table 1: Categorization of suitability-labels.  3.1.2 Beneficial (BENEF) While SUIT only states that the consumption of", "acronyms": [[66, 71]], "long-forms": [[54, 64]]}, {"text": " In an effort to apply such models to noisy optical character recognition (OCR) text output, we endeavor to understand the effect", "acronyms": [[75, 78]], "long-forms": [[44, 73]]}, {"text": " BBLT Input Screen      We originally developed BBLT for ourselves as machine translation (MT) developers and evaluators, to rapidly see the meanings of Arabic strings", "acronyms": [[91, 93], [1, 5], [48, 52]], "long-forms": [[70, 89]]}, {"text": " The focus of this paper is a discussion of various methods used to create a set of acoustic models for  characterizing the PLU's used in large vocabulary recognition (LVR). The set of context independent ", "acronyms": [[168, 171], [124, 129]], "long-forms": [[138, 166]]}, {"text": "They  ha 1 Personal Name (PN); Date or Time (DT); Location Name  (LN); Team Name (TN); Competition Title (CT); Personal ", "acronyms": [[26, 28], [45, 47], [66, 68], [82, 84], [106, 108]], "long-forms": [[11, 24], [31, 43], [50, 63], [71, 80], [87, 104]]}, {"text": "MOR = morphological features (set) ? LEM = lemma ?", "acronyms": [[37, 40], [0, 3]], "long-forms": [[43, 48], [6, 19]]}, {"text": "121 domain adaptation algorithm mentioned in (Daume, 2007) based on Maximum Entropy model (MaxEnt) (Ratnaparkhi, 1996).", "acronyms": [[91, 97]], "long-forms": [[68, 83]]}, {"text": "some structural constraints which are mostly prag-  matic in natnre:  2based on PVM (parallel virtual madfine)  semRnb~ ", "acronyms": [[80, 83]], "long-forms": [[85, 109]]}, {"text": "using a set of data-driven terms.  We investigated how likely term frequency (TF) based RF is to discover HEWs.", "acronyms": [[78, 80], [88, 90], [106, 110]], "long-forms": [[62, 76]]}, {"text": "Sematnic data models are systems for  constructing precise descriptions of protions of  the real world - semantic data description (SDD)-  using terms that come from the real world rather ", "acronyms": [[132, 135]], "long-forms": [[105, 130]]}, {"text": "eugene@mathcs.emory.edu Abstract Community question answering (CQA) websites contain millions of question and answer", "acronyms": [[63, 66]], "long-forms": [[33, 61]]}, {"text": "ARG1, ARG2, MOD-BENEFICIARY, and MOD-TIME. To identify which slot has the most similarity  among its elements, we calculate the number of distinct elements (NDE) in each slot across the  propositions.", "acronyms": [[157, 160], [0, 4], [6, 10], [12, 27], [33, 41]], "long-forms": [[128, 155]]}, {"text": " MRS constraints have three kinds of literals, two kinds of elementary predications (EPs) in the first two lines and handle constraints in the third line:", "acronyms": [[85, 88], [1, 4]], "long-forms": [[60, 83]]}, {"text": "functions(CPU: Celeron TM 366, RAM: 64M).  2) Prediction precision(PP) =  number of words with correct BPs(CortBP) ", "acronyms": [[67, 69], [10, 13], [23, 25], [103, 106], [107, 113], [31, 34]], "long-forms": [[46, 66]]}, {"text": "and the parameters ? can be estimated using maximum likelihood estimation(MLE) on a training corpus(Och and Ney, 2003).", "acronyms": [[74, 77]], "long-forms": [[44, 73]]}, {"text": "In Proceedings of the Third International Conference on Web Search and Web Data Mining (WSDM), pages 101?110, New York, NY, USA, 2010.", "acronyms": [[88, 92], [120, 122], [124, 127]], "long-forms": [[56, 86]]}, {"text": "There are two other threads of research literature relevant to our work. Named entity (NE) extraction attempts to identify entities of interest", "acronyms": [[87, 89]], "long-forms": [[73, 85]]}, {"text": "the percentage of questions with a correct answer at rank 1, Mean Reciprocal Rank (MRR), and Mean Average Precision (MAP). The reported", "acronyms": [[117, 120], [83, 86]], "long-forms": [[93, 115], [61, 81]]}, {"text": "follows. NLC(:A): the analysis of concepts that play  a role in natural anguage; (NL)CA: the lattice the-  Karaphuis and Sarbo 205 Natural Language Concept Analysis ", "acronyms": [[82, 84], [9, 12], [85, 87]], "long-forms": [[64, 79]]}, {"text": "manual mapping. In the rest of the paper, we shall first  describe the Switchboard Dialogue Act (SWBD-DA)  Corpus and its annotation scheme (i.e. SWBD-DAMSL).", "acronyms": [[97, 104], [146, 156]], "long-forms": [[71, 95]]}, {"text": "the Brill tagger.  NNP = proper noun, CD = cardinal number,  CC = coordinating conjunction, JJ = adjective, VBG = verb,  gerund/present participle ", "acronyms": [[61, 63], [19, 22], [38, 40], [92, 94], [108, 111]], "long-forms": [[66, 90], [25, 36], [43, 58], [97, 106], [114, 118]]}, {"text": "in part by ONR grant number N00014-95-1-1164,  and has been done in collaboration with the US  Navy's NCCOSC RDT&E Division (NRaD), Ascent  Technologies, Mitre Corp., MRJ Corp., and SRI In- ", "acronyms": [[125, 129], [11, 14], [91, 93], [167, 170], [182, 185]], "long-forms": [[102, 123]]}, {"text": "The processing of BADGER is not significantly different than that of the CIRCUS system used i n previous MUC evaluations [4, 5, 6] . Concept node (CN) definitions are still used to create case frame instantiation s and multiple CN definitions can apply to the same text fragment .", "acronyms": [[147, 149], [105, 108], [228, 230]], "long-forms": [[133, 145]]}, {"text": "Table 9 Number of times a core grammatical function was annotated more than once in the treebank (TRBK) by the model using gold morphology (GOLD-M), and by the model using predicted morphology (PRED-M).", "acronyms": [[140, 146], [98, 102], [194, 200]], "long-forms": [[123, 138], [88, 96], [172, 192]]}, {"text": "2 Classifiers 2.1 NB Naive Bayes(NB) probabilistic classifiers are commonly studied in machine learning(Mitchell, 1996).", "acronyms": [[33, 35]], "long-forms": [[21, 31]]}, {"text": "In my semantic role labeling research, I used the Tilburg Memory Learner (TiMBL) for this purpose.", "acronyms": [[74, 79]], "long-forms": [[50, 72]]}, {"text": "six basic emotion tags to the Bengali blog sentences. Conditional Random Field (CRF)  based word level emotion classifier classifies ", "acronyms": [[80, 83]], "long-forms": [[54, 78]]}, {"text": "Markov Model (HHMM) word), all the corresponding TYP candidates triggered by categorized word features(CWF) should be removed.", "acronyms": [[103, 106], [14, 18], [49, 52]], "long-forms": [[77, 101], [0, 12]]}, {"text": "1 Introduction  Syntax parsing is one of the most fundamental  tasks in natural language processing (NLP) and  has attracted extensive attention during the past ", "acronyms": [[101, 104]], "long-forms": [[72, 99]]}, {"text": "XC (compound),   NN (noun),   NNP (proper ", "acronyms": [[17, 19], [0, 2], [30, 33]], "long-forms": [[21, 25], [4, 12]]}, {"text": "ian.fletcher, peter.maguire@cs.man.ac.uk Abstract Dialogue Acts (DAs) which explicitly ensure mutual understanding are frequent", "acronyms": [[65, 68]], "long-forms": [[50, 63]]}, {"text": "Figure 4: Canonical example pub from Saltzman and Munhall (1989) representing overlapping goals for tongue blade constriction degree (TBCD), lip aperture (LA), and glottis (GLO).", "acronyms": [[134, 138], [155, 157], [173, 176]], "long-forms": [[100, 132], [141, 153], [164, 171]]}, {"text": "Our relation extraction system is hierarchical (Bunescu and Mooney, 2005b; Sun et al, 2011) and apply maximum entropy (MaxEnt) in the MALLET", "acronyms": [[119, 125], [134, 140]], "long-forms": [[102, 117]]}, {"text": "      Input source sentence (ISS)    ", "acronyms": [[29, 32]], "long-forms": [[6, 27]]}, {"text": " 1 Introduction  Relation Extraction (RE) aims to identify a set of  predefined relations between pairs of entities in ", "acronyms": [[38, 40]], "long-forms": [[17, 36]]}, {"text": "Experimental results on Europarl with different translation directions (BLEU% on WMT08).  RW=Random Walk. * indicates the results are significantly better than the baseline (p<0.05).", "acronyms": [[90, 92], [72, 77], [81, 86]], "long-forms": [[93, 104]]}, {"text": "EN 94,725 2.58 Table 2: Corpus statistics: SR=Serbian, SL=Slovene, EN=English, BG=Bulgarian Tagset The Multext-East corpus is manually an-", "acronyms": [[67, 69], [79, 81], [0, 2], [43, 45], [55, 57]], "long-forms": [[70, 77], [82, 91], [46, 53], [58, 65]]}, {"text": "pendency and constituency parsing.  2.4.1 On Dependency Parsing (DP) ?", "acronyms": [[65, 67]], "long-forms": [[45, 63]]}, {"text": "Although later systems such as Wu and Ng (2013); Rozovskaya and Roth (2013) use Integer Linear Programming (ILP) to decode a global optimized result, the input scores", "acronyms": [[108, 111]], "long-forms": [[80, 106]]}, {"text": "In MT Summit XIII: the Thirteenth Machine Translation Summit [organized by the] AsiaPacific Association for Machine Translation (AAMT), pages 513-520.", "acronyms": [[129, 133], [3, 5]], "long-forms": [[92, 127]]}, {"text": "paper is the following:  Def. A generative system (GS) is a sequence TI,... ,Tn of TS,  whe~'~-TR(Tl,... ,Tn) is a relation between strings and D-trees and ", "acronyms": [[51, 53], [83, 85], [95, 97]], "long-forms": [[32, 49]]}, {"text": "training (Blum and Mitchell, 1998) has been successfully applied to English named entity recognition (NER) (Collins & Singer [henceforth C&S] (1999)).", "acronyms": [[102, 105], [137, 140]], "long-forms": [[94, 100]]}, {"text": "In Proc. of the Human Language Technologies (HLT): The Annual Conf.", "acronyms": [[45, 48]], "long-forms": [[16, 43]]}, {"text": "ing default parameters. Error analysis was done by means of Mean Squared Error estimate (MSE). ", "acronyms": [[89, 92]], "long-forms": [[60, 78]]}, {"text": "7 Conclusions We introduce a Laplacian structured sparsity model for computational branding analytics (CBA). In the", "acronyms": [[103, 106]], "long-forms": [[69, 101]]}, {"text": "Revue des Sciences de l?Education (RSE) ? Traduction, Terminologie et R?daction (TTR) ?", "acronyms": [[81, 84], [35, 38]], "long-forms": [[42, 79], [0, 33]]}, {"text": "Valerio Basile and Johan Bos and Kilian Evang and Noortje Venhuizen {v.basile,johan.bos,k.evang,n.j.venhuizen}@rug.nl Center for Language and Cognition Groningen (CLCG) University of Groningen, The Netherlands", "acronyms": [[163, 167]], "long-forms": [[118, 161]]}, {"text": "The \u0002 grams in an utterance SSG can be extracted by converting it to a finite state transducer (FST), \f\u000e  .", "acronyms": [[96, 99], [28, 31]], "long-forms": [[71, 94]]}, {"text": "quen cies Figure 6: Distribution of Ratio of Frequencies(RF) values over the nouns in the corpus", "acronyms": [[57, 59]], "long-forms": [[36, 55]]}, {"text": "Sentences from TST2-MUC4-0048 Sl : SALVADORAN PRESIDENT-ELECT ALFREDO CRISTIAII CONDEMNED THE TERRORIST KILLING OF ATTORNE Y GENERAL ROBERTO GARCIA ALVARADO AND ACCUSED THE FARABUNDO MARTI NATIONAL LIBERATION FRONT (FMLN ) OF THE CRIME .", "acronyms": [[216, 220]], "long-forms": [[173, 214]]}, {"text": ").  Rand Index (RI) (Rand, 1971) measures the percentage of decisions that are correct, penalizing false pos-", "acronyms": [[16, 18]], "long-forms": [[4, 14]]}, {"text": "We propose a method to improve the accuracy of parsing bilingual texts (bitexts) with the help of statistical machine translation (SMT) systems.", "acronyms": [[131, 134]], "long-forms": [[98, 129]]}, {"text": "Metonymy Often a sentence relates entities in a way inconsistent with the target ontology. For example, with the Component Library (CLib) ontology,movement properties (e.g., speed, acceleration) are defined as properties of the movement events, rather", "acronyms": [[132, 136]], "long-forms": [[113, 130]]}, {"text": "tagger (Cutting et al 1992) and LT POS tagger  (Mikheev 1997). Maximum Entropy (MaxEnt)  based taggers also seem to perform very well        ", "acronyms": [[80, 86], [32, 34], [35, 38]], "long-forms": [[63, 78]]}, {"text": "2008) and hierarchical log-bilinear embeddings (HLBL) (Mnih and Hinton, 2007) using the implementation in (Turian et al, 2010), Hellinger PCA (H-PCA) (Lebret and Collobert, 2014) and our connective-based representation (Bllip).", "acronyms": [[143, 148]], "long-forms": [[128, 141]]}, {"text": "The most  important forms of discourse of interest o  Natural Language Processing (NLP) are text  and dialogue.", "acronyms": [[83, 86]], "long-forms": [[54, 81]]}, {"text": "pora. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING), pages 993?1000.", "acronyms": [[88, 94]], "long-forms": [[61, 86]]}, {"text": "173 Figure 3: Frequency of word classes in the three corpora (BN = Broadcast News, Est = Press, Euro = Europarl).", "acronyms": [[62, 64], [96, 100]], "long-forms": [[67, 81], [103, 111]]}, {"text": "Abstract We describe a machine learning approach, a Random Forest (RF) classifier, that is used to automatically compile bilingual", "acronyms": [[67, 69]], "long-forms": [[52, 65]]}, {"text": "Lexical features show a much more mixed result. Type?Token Ratio (TTR) is only important for document classification, whereas most of the", "acronyms": [[66, 69]], "long-forms": [[48, 64]]}, {"text": "ADJ (adjectives), ADV (adverbs), CJ (conjunctions), CL (clitics), CN (common nouns), DA (definite articles), DEM (demonstratives), INF (infinitives), ITJ (interjections), NP (noun", "acronyms": [[85, 87], [109, 112], [0, 3], [18, 21], [33, 35], [52, 54], [66, 68], [131, 134], [150, 153], [171, 173]], "long-forms": [[89, 106], [114, 128], [5, 15], [23, 30], [37, 49], [56, 63], [70, 83], [136, 147], [155, 168], [175, 179]]}, {"text": "This paper explores the use of the homotopy method for training a semi-supervised Hidden Markov Model (HMM) used for sequence labeling.", "acronyms": [[103, 106]], "long-forms": [[82, 101]]}, {"text": " 250 Support Vector Machines (SVMs) construct a hyperplane in a multi-dimensional space which yields a good separation between positive and negative training examples, represented as data points.", "acronyms": [[30, 34]], "long-forms": [[5, 28]]}, {"text": "some plan P such that, if H executes P. then in the re-  sulting state, there exists a \\['F identifiable term P' such  that H knows that Denotation(Pl = Dem;tation(DI),  and 5\" intends that H execute P. ", "acronyms": [[164, 166]], "long-forms": [[153, 163]]}, {"text": "The query (Figure 4a) will match adjectives (ADJA) adjacent to a following noun (NN) which must not have another dependent that is either a modifying noun or name (NE).", "acronyms": [[81, 83], [45, 49], [164, 166]], "long-forms": [[75, 79], [33, 43], [158, 162]]}, {"text": "compared to the baseline and stem, respectively.  As for the Kirghiz to Chinese translation (KI-CH) task, improvements seem relative small compared", "acronyms": [[93, 98]], "long-forms": [[61, 79]]}, {"text": "Controlled English at Douglas SMART Controlled English ASD Simplified Technical English (ASD-STE) AECMA Simplified English (AECMA-SE)", "acronyms": [[89, 96], [30, 35], [98, 103], [124, 132]], "long-forms": [[55, 87]]}, {"text": "We show how these strategies are captured in a grammar developed in the Grammatical Framework (GF).1 We evaluated our method by experimenting", "acronyms": [[95, 97]], "long-forms": [[72, 93]]}, {"text": "Pengfei Lu Department of Computer Science Graduate Center City University of New York (CUNY) 365 Fifth Ave, New York, NY 10016 pengfei.lu@qc.cuny.edu  Matt Huenerfauth Department of Computer Science Queens College and Graduate Center City University of New York (CUNY) 65-30 Kissena Blvd, Flushing, NY 11367 matt@cs.qc.cuny.edu  Abstract  American Sign Language (ASL) synthesis software can improve the accessibility of in-formation and services for deaf individuals with low English literacy. The synthesis com-ponent of current ASL animation generation and scripting systems have limited handling of the many ASL verb signs whose movement path is inflected to indicate 3D locations in the signing space associated with discourse refer-ents.", "acronyms": [[363, 366], [87, 91], [118, 120], [263, 267], [299, 301], [530, 533], [611, 614]], "long-forms": [[339, 361], [58, 85], [108, 116], [234, 261]]}, {"text": "ically used as the target. For example, the NIST Open Machine Translation Evaluation (OpenMT) 2009 (Garofolo, 2009) constrained Arabic-English", "acronyms": [[86, 92], [44, 48]], "long-forms": [[49, 84]]}, {"text": "It is based on bilingual phrases, where a bilingual phrase (BP ) is simply two monolingual phrases (MP ) in which each one is supposed to be the translation of each", "acronyms": [[100, 102], [60, 62]], "long-forms": [[79, 98], [42, 58]]}, {"text": "grading.  The Content Assessment Module (CAM) presented in Bailey (2008) and Bailey and Meurers", "acronyms": [[41, 44]], "long-forms": [[14, 39]]}, {"text": " ? WHNP_NN_IN  Syntactic Parse Trees (PT)  72", "acronyms": [[38, 40], [3, 13]], "long-forms": [[25, 36]]}, {"text": "cjlin/libsvm/ System P R F1 Schwartz & Hearst (SH) .978 .940 .959 SaRAD .891 .919 .905", "acronyms": [[47, 49]], "long-forms": [[28, 45]]}, {"text": "_ _eI$X=A\u0007I&HLH7K5HOG\u0007X5HOGPMLHLK ^ CWX=A$X=APH U\u0003I&K5X\u0010K5HOG\u0007X5H&GflMLHJa\u0007HLK5MOI5CEc\u0007CEG! ", "acronyms": [[44, 47]], "long-forms": [[48, 90]]}, {"text": " 1 Introduction Coreference resolution (CoRe) is the process of finding markables (noun phrases) referring to the same", "acronyms": [[40, 44]], "long-forms": [[16, 38]]}, {"text": "J~:u phom:,l:ical (graphemic) empressio~ in to  5 l \\ [ ,+vei~  tecLogt+ah~illa~ieg (levm+l o+ US+st abbrev,  TR) + ,+:mr+ar:e  synkam (SR) + (neP'pfie/r+ic5 (HR) '+ phnnemics ,~nd phnnetit:ts  (g raphmaics} , ,  Eact+ ef the  ieve l~ i s  in terpreted  a~ a set, ", "acronyms": [[136, 138], [110, 112], [159, 161]], "long-forms": [[128, 134]]}, {"text": "syntactic tree fragments (STFs) and partial tree fragments (PTFs) 2.2.1 Syntactic Tree Kernels (STK) An STF is a connected subset of the nodes and", "acronyms": [[96, 99], [26, 30], [60, 64], [104, 107]], "long-forms": [[72, 94], [0, 24], [36, 58]]}, {"text": "for si ? Bm do Use Breadth First Search (BFS) to check if ?", "acronyms": [[41, 44]], "long-forms": [[19, 39]]}, {"text": "capture all the types of entities. Typical structures  of Chinese person name (CN), location name (LN)  and organization name (ON) are as follows: ", "acronyms": [[79, 81], [99, 101]], "long-forms": [[58, 77], [84, 97]]}, {"text": "Stephanie Strassel and Zhiyi Song and Joe Ellis University of Pennsylvania Linguistic Data Consortium (LDC) Philadelphia, PA, USA", "acronyms": [[103, 106], [126, 129], [122, 124]], "long-forms": [[75, 101]]}, {"text": "To explore the impact of the quality of annotation resources, we also use a Chinese language analysis tool: Language Technology Platform (LTP) (Che et al, 2010).", "acronyms": [[138, 141]], "long-forms": [[108, 136]]}, {"text": "8 Conclusion We proposed a framework to generate characteristicrich questions for question answering (QA) evaluation.", "acronyms": [[102, 104]], "long-forms": [[82, 100]]}, {"text": "transcription is carried out by using dynamic  programming alignment on the recognizer?s  hypothesis (HYP) and the non-literal transcription  that is used as reference (REF).", "acronyms": [[102, 105], [169, 172]], "long-forms": [[90, 100], [158, 167]]}, {"text": "a major Department of Agriculture system, due to inadequate agency planning.  Complete sets of the Federal mfomtion processing staodards (FIPS) are now avail-  able from the National Bureau of Standards at $46.00 each.", "acronyms": [[138, 142]], "long-forms": [[99, 136]]}, {"text": "extraction (RE) in a bootstrapping framework are regarded as very effective methods for building information extraction (IE) systems and for adapting them to new domains (e. g., (Riloff,", "acronyms": [[121, 123], [12, 14]], "long-forms": [[97, 119]]}, {"text": " The second set of experiments was run on the Chinese Treebank (CTB) data sets from Bakeoff-3 (Levow, 2006), which contains a training and a test", "acronyms": [[64, 67]], "long-forms": [[46, 62]]}, {"text": "Harman D.K. 1983. Overview of the second Text Retrieval Conference (TREC-2). Information Processing", "acronyms": [[68, 74], [7, 10]], "long-forms": [[34, 66]]}, {"text": " rio deal with unknown words is a big problem in  natural language processing(NLP) too. To recognize ", "acronyms": [[78, 81]], "long-forms": [[50, 76]]}, {"text": "Features. In Proceedings of the 21st Conference on Computational Linguistics (COLING). ", "acronyms": [[78, 84]], "long-forms": [[51, 76]]}, {"text": "been annotated and fed into a specialized learning system that learns classification rules. The rules are learned through an iterative semantic specialization (ISS) method applied to noun phrase constituents.", "acronyms": [[160, 163]], "long-forms": [[125, 158]]}, {"text": "can be specified.  The 'source condition(SCND)' represents  conditions on variables in the 'source pattern.'", "acronyms": [[41, 45]], "long-forms": [[24, 39]]}, {"text": "5.1 Overall Results Table 4 shows the parsing results for the StateSplit (SP) PCFG, the Head-Driven (HD) PCFG and the Relational-Realizational (RR) PCFG", "acronyms": [[74, 76], [78, 82], [101, 103], [105, 109], [144, 146], [148, 152]], "long-forms": [[67, 72], [88, 99], [118, 142]]}, {"text": "Each corpus uses a different set of entity labels.  MUC marks locations (LOC), organisations (ORG) and personal names (PER), in addition to numeri-", "acronyms": [[73, 76], [94, 97], [52, 55], [119, 122]], "long-forms": [[62, 71], [79, 92], [103, 111]]}, {"text": "Table 1: The acoustic features which are extracted from the audio clips using Praat (Boersma and Weenink, 2010).  (MFCCs)1 and Teager Energy Operator (TEO)2 (Kaiser, 1990) based features have also been con-", "acronyms": [[151, 154], [115, 120]], "long-forms": [[127, 149]]}, {"text": "H A V E  CSEXCH F O R  MOVEF IN 11  C H A N G E ,  CALL EL3MOP P O R  E R A S E  0 I 2   ANTEST CALLED FOR 14'IGLOT \" (AACC) S D =  15. RES= '3.", "acronyms": [[103, 106], [119, 123], [125, 128], [9, 15], [16, 21], [23, 28], [136, 139]], "long-forms": [[89, 102], [107, 115]]}, {"text": "(such as Noun, Verb, Adjective etc). De-lexicalized text representations through POS tagging were first considered for native language identification (NLI), where they were used as a proxy for syntax in order to capture certain types of grammatical errors (Wong and Dras, 2009).", "acronyms": [[151, 154], [81, 84]], "long-forms": [[119, 149]]}, {"text": "exposed through the feature HOOK to facilitate further composition. These properties include pointers to the local top handle (LTOP), the constituent?s primary index (INDEX), and the external argument, if any (XARG).", "acronyms": [[127, 131], [167, 172], [210, 214], [28, 32]], "long-forms": [[109, 118], [160, 165], [183, 199]]}, {"text": "? SRI has developed the DECIPHER speaker-independent speech recognition system, a  hidden Markov model (HMM)-based system that achieves tate-of-the-art recognition  performance through accurate modeling of phonetic and phonological detail.", "acronyms": [[104, 107], [2, 5], [24, 32]], "long-forms": [[83, 102]]}, {"text": "David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing  As a more intuitive example of refinement, consider  an English-like language with categories term (TE) and  intransitive verb phrase (IV) that both include singular ", "acronyms": [[183, 185], [218, 220]], "long-forms": [[177, 181], [192, 209]]}, {"text": "categories of both test texts  PoS tags  DET (Determiner)  NM (Pronoun) ", "acronyms": [[41, 44], [59, 61]], "long-forms": [[46, 56]]}, {"text": "We however noticed the relative degradation of quality in coordinating conjunctions (CC), determiners (DT) and personal pronouns (PRP). ", "acronyms": [[130, 133], [85, 87], [103, 105]], "long-forms": [[111, 128], [58, 83], [90, 101]]}, {"text": "Natural Language Generation (NLG). For example, STOP is a Natural Language Generation (NLG) system that generates tailored smoking cessation let-", "acronyms": [[87, 90], [29, 32]], "long-forms": [[58, 85], [0, 27]]}, {"text": "1. the mention type: person (PER), organization (ORG), location (LOC), geopolitical entity (GPE), facility (FAC), vehicle (VEH), and", "acronyms": [[65, 68]], "long-forms": [[55, 63]]}, {"text": "Univers i ty  of Vienna  The first part of this paper is dedicated to an overv iew  of the parser of the system VIE-LANG (Viennese Language  Understanding System).", "acronyms": [[112, 120]], "long-forms": [[122, 139]]}, {"text": "levels of the discourse tree. Segmented Discourse  Structure Theory (SDRT) is introduced (Asher,  1993) and the predictions of this theory are dis- ", "acronyms": [[69, 73]], "long-forms": [[30, 67]]}, {"text": "We chose Gaussian distributions. If the parents of node X are Y, P (X|Y ) = N(m + W ?", "acronyms": [[68, 71]], "long-forms": [[56, 63]]}, {"text": "utes of training time on an average laptop computer.  This model, the deep averaging network (DAN), works in three simple steps:", "acronyms": [[94, 97]], "long-forms": [[70, 92]]}, {"text": "grammatically correct (readability). We engaged the services of Amazon Mechanical Turks (AMT) to judge the generated sentences based on a discrete", "acronyms": [[89, 92]], "long-forms": [[64, 87]]}, {"text": "a new father node. The following simple rule forms a  noun phrase (NP). ", "acronyms": [[67, 69]], "long-forms": [[54, 65]]}, {"text": "                                                                  Barcelona, July 2004                                               Association for Computations Linguistics                        ACL Special Interest Group on Computational Phonology (SIGPHON)                                                     Proceedings of the Workshop of the", "acronyms": [[252, 259], [197, 200]], "long-forms": [[201, 250]]}, {"text": "ferent sources. The first feature source comes  from our DSSMs (DSSM and DSSM_BOW) using the output layers as feature generators as de-", "acronyms": [[57, 62]], "long-forms": [[64, 81]]}, {"text": "In Proceedings of the Fifth Mediterranean Morphology Meeting (MMM5), pages 269?290, Fr?jus.", "acronyms": [[62, 66]], "long-forms": [[42, 60]]}, {"text": "FA8750-09-C-0181. The second author also thanks the Vietnam Education Foundation (VEF) for its sponsorship.", "acronyms": [[82, 85]], "long-forms": [[52, 80]]}, {"text": "5th Conference of the Association for Machine Translation in the Americas (AMTA). Boston, Massachusetts.", "acronyms": [[75, 79]], "long-forms": [[22, 73]]}, {"text": "directed approach according to (Ephraim and Malah, 1985) based on two different noise estimation schemes, i.e. the minimum statistics approach (MS) as described in (Martin, 2001) and the minimum", "acronyms": [[144, 146]], "long-forms": [[115, 133]]}, {"text": "based on such formalisms include Generalized Phrase  Structure Grammar (GPSG) \\[Gazdar et al 1985\\],  Lexical Functional Grammar (LFG) \\[Bresnan 1982\\],  Functional Unification Grammar (bUG) \\[Kay 1984\\], ", "acronyms": [[130, 133], [72, 76], [186, 189]], "long-forms": [[102, 128], [33, 70], [165, 184]]}, {"text": "The Meter Corpus chosen as the test data  is a collection of court reports from the British Press Association (PA) and some leading  British newspapers (Gaizauskas 2001; Clough ", "acronyms": [[111, 113]], "long-forms": [[92, 109]]}, {"text": "Source Material (SMaterial) e.g., As, InGaAs   ? Source Material Characteristic  (SMChar) e.g. ,(111)B  ", "acronyms": [[82, 88], [17, 26], [38, 44]], "long-forms": [[49, 79], [0, 15]]}, {"text": "= Task Defined RAW SCORI~  ((! OMM(~OST x number of messages)  - (INFCOST x nnmber  o f  in fe rences)  ", "acronyms": [[31, 34]], "long-forms": [[36, 60]]}, {"text": "and EN-DE) with token frequency, sense distribution and most frequent translations ordered by the corresponding senses (T = temporal, CO = concession, CT = contrast). ", "acronyms": [[134, 136], [151, 153], [4, 9]], "long-forms": [[139, 149], [156, 164], [124, 132]]}, {"text": "ysis. The Chinese comma is viewed as a delimiter of elementary discourse units (EDUs), in the sense of the Rhetorical Structure Theory (Carlson et al,", "acronyms": [[80, 84]], "long-forms": [[52, 78]]}, {"text": " 2.4 Stanford Parser The Stanford Parser (SP) is an unlexicalized parser that rivals state-of-the-art lexical-", "acronyms": [[42, 44]], "long-forms": [[25, 40]]}, {"text": "way as the above feature.  The Acoustic Features (AF) were extracted directly from the wave files using SoX: Minimum,", "acronyms": [[50, 52], [104, 107]], "long-forms": [[31, 48]]}, {"text": "logical structure of the text is a boundary between two logical segments (see Figure 1).  The method is called Logical TextTiling (LTT), due to some similarities with the TextTiling algorithm for topic shifts detection (Hearst, 1997).", "acronyms": [[131, 134]], "long-forms": [[111, 129]]}, {"text": "and phrases and their compositionality. In Advances in Neural Information Processing Systems (NIPS). ", "acronyms": [[94, 98]], "long-forms": [[55, 92]]}, {"text": "In Ellen M. Voorhees and Donna K. Harman, editors, The Seventh Text Retrieval Conference (TREC-7), volume 7.", "acronyms": [[90, 96]], "long-forms": [[55, 88]]}, {"text": "Figure 3: System I performance for each relation (CC=CAUSE-EFFECT, IA=INSTRUMENTAGENCY, PP=PRODUCT-PRODUCER, OE=ORIGIN-ENTITY, TT=THEME-TOOL,", "acronyms": [[50, 52], [67, 69], [88, 90], [109, 111], [127, 129]], "long-forms": [[53, 65], [70, 86], [91, 107], [112, 125], [130, 140]]}, {"text": "strat1 40.1 24.4 15.0 strat2 38.2 22.5 14.5 Table 4: Word Error Rate (WER), Concept Error Rate (CER) and Interpretation Error Rate (IER) ac-", "acronyms": [[70, 73], [96, 99], [132, 135]], "long-forms": [[53, 68], [76, 94], [105, 130]]}, {"text": "itly mark objects of prepositions (POBJ), possessors in idafa construction (IDAFA), conjuncts (CONJ) and conjunctions (CC), and the accusative specifier, tamyiz (TMZ).", "acronyms": [[119, 121], [35, 39], [76, 81], [95, 99], [162, 165]], "long-forms": [[105, 117], [10, 33], [56, 74], [84, 93], [154, 160]]}, {"text": "parsing. In Tenth International Conference on Parsing Technologies (IWPT), pages 121?132, Prague, Czech Republic.", "acronyms": [[68, 72]], "long-forms": [[18, 66]]}, {"text": "columbia, edu  Abstract  Concept To Speech (CTS) systems are  closely related to two other types of ", "acronyms": [[44, 47]], "long-forms": [[25, 42]]}, {"text": " One of the most competitive summarization methods is based on Integer Linear Programming (ILP). ", "acronyms": [[91, 94]], "long-forms": [[63, 89]]}, {"text": "Table 1: Number of routes, directions, and tokens for the different settings. GM = Google Maps, CI = Campus Indoor, CO = Campus Outdoor.", "acronyms": [[78, 80], [96, 98], [116, 118]], "long-forms": [[83, 94], [101, 114], [121, 135]]}, {"text": "are verbs.  Translation Filter (TF) handles both Predicate Mismatch and Verb?Non-Verb translation shift er-", "acronyms": [[32, 34]], "long-forms": [[12, 30]]}, {"text": "In Proceedings of the International Conference on World Wide Web (WWW), pages 641?650. ", "acronyms": [[66, 69]], "long-forms": [[50, 64]]}, {"text": "prior polarity of verb, verb score (V_score).  Verb-PP (prepositional phrase) rules:  1.", "acronyms": [[52, 54]], "long-forms": [[56, 76]]}, {"text": "{kmpark, rim}@nlp.korea.ac.kr 1 Introduction The semantic role labeling (SRL) refers to finding the semantic relation (e.g. Agent, Patient, etc.)", "acronyms": [[73, 76]], "long-forms": [[49, 71]]}, {"text": "protein interaction as an example. In Proceedings  of the Pacific Symposium on Biocomputing (PSB),  Hawaii, USA.", "acronyms": [[93, 96], [108, 111]], "long-forms": [[58, 91]]}, {"text": "are assigned the correct head and dependency type ? and unlabeled attachment score (UAS) ? the per-", "acronyms": [[84, 87]], "long-forms": [[56, 82]]}, {"text": "Abstract We present a system that automatically induces Selectional Preferences (SPs) for Latin verbs from two treebanks by using", "acronyms": [[81, 84]], "long-forms": [[56, 79]]}, {"text": "be intuitively characterized as a way of trigger-  ing semantically related concepts which define for  each role the projective conclusion space (PCS). ", "acronyms": [[146, 149]], "long-forms": [[117, 144]]}, {"text": " 7.1 Support vector machines  Support vector machines (SVMs) were introduced by (Vapnik, 1995) as an instantiation ", "acronyms": [[55, 59]], "long-forms": [[30, 53]]}, {"text": "lingual extensions of approaches based on latent (LSI), generative (LDA, PLSI) as well as explicit (ESA) topic modelling can induce an interlingual topic space allowing documents", "acronyms": [[100, 103], [50, 53], [68, 71], [73, 77]], "long-forms": [[90, 98]]}, {"text": "Among  three state-of-the-art systems we have, the best Fscores of single character location (SCL) and single character person (SCP) are 43.63% and 43.48% ", "acronyms": [[94, 97], [128, 131]], "long-forms": [[67, 92]]}, {"text": " Other valuable categories are, for example,  pronominal adverbs (PAV) and infinitives of auxil-  iary verbs (VAINF), where the difference between ", "acronyms": [[66, 69], [110, 115]], "long-forms": [[46, 64]]}, {"text": "capture various relationships related to the predicate, we assign function label ? ADT (adjunct)? for", "acronyms": [[83, 86]], "long-forms": [[88, 95]]}, {"text": "corpus (DUC2002) and the second is automatically extracted from related web news stories (WNS) automatically extracted.", "acronyms": [[90, 93], [8, 15]], "long-forms": [[72, 88]]}, {"text": " 1 Introduction Coreference resolution (CR) ? the task of determin-", "acronyms": [[40, 42]], "long-forms": [[16, 38]]}, {"text": " The attribute of a node is one of part of speech (POS), lexical value (LEX), or dependency label (DEP), as for instance LEX(QUEUE0)", "acronyms": [[72, 75], [51, 54], [99, 102], [121, 124], [125, 131]], "long-forms": [[57, 64], [35, 49], [81, 91]]}, {"text": "wqK ,   and the word sequence of the web page,                    A=WA=wA1, wA2, ?, wAL,  ", "acronyms": [[68, 70]], "long-forms": [[71, 74]]}, {"text": "To tackle this  problem, we propose to employ the  Support Vector Machines(SVM) in  determining the grammatical functions.", "acronyms": [[75, 78]], "long-forms": [[51, 73]]}, {"text": "With respect to the EUROTRA MT system this has  important implications for the translation between the syntactic  dependency level - the EUROTRA Relational Structure (ERS)  and the semant ic  level  - the in ter face  St ructure  (IS).", "acronyms": [[167, 170], [20, 27], [28, 30], [231, 233]], "long-forms": [[137, 165], [205, 228]]}, {"text": "Entity linking (EL) recognizes mentions in a text and associates them to their corresponding entries in a knowledge base (KB), for example, Wikipedia", "acronyms": [[122, 124], [16, 18]], "long-forms": [[106, 120], [0, 14]]}, {"text": "Our work is most similar to the content selection method of the multimedia conversation system RIA (Responsive Information Architect) (Zhou and Aggarwal, 2004).", "acronyms": [[95, 98]], "long-forms": [[100, 132]]}, {"text": " 4 . i .1  Bagging (BAG)  From a training set of n examples, severaI sam- ", "acronyms": [[20, 23]], "long-forms": [[11, 18]]}, {"text": "3 Model We introduce a topic-model based approach to declarative knowledge (DK) acquisition and describe how this knowledge can be applied to two unsuper-", "acronyms": [[76, 78]], "long-forms": [[53, 74]]}, {"text": " We excluded only punctuation; we did no filtering for part of speech (POS). Each word was actually", "acronyms": [[71, 74]], "long-forms": [[55, 69]]}, {"text": "baseline adapted language model.  The Table 2 shows the word error rates (WERs) of experiments on the code switching lecture", "acronyms": [[74, 78]], "long-forms": [[56, 72]]}, {"text": "nority preference algorithm that models bridging recognition as a subtask of learning finegrained information status (IS). We substan-", "acronyms": [[118, 120]], "long-forms": [[98, 116]]}, {"text": "For exam-  ple, an analysis of the texts using Mann and Thomp-  son's (1987) Rhetorical Structure Theory (RST) would  result primarily in the relations sequence  and jo in t  ", "acronyms": [[106, 109]], "long-forms": [[77, 104]]}, {"text": "2 values (ARG2-4, ARGM-DIS (discourse), ARGM-LOC (locative), ARGM-MNR (manner), and ARGM-TMP (temporal)), but given the large number of degrees of free-", "acronyms": [[84, 92], [40, 48], [61, 69]], "long-forms": [[94, 102], [50, 58], [71, 77]]}, {"text": "the best among all other symmetrization heuristics. The other was a Tree Edit Distance (TED) model, popularly used in a series of NLP appli-", "acronyms": [[88, 91], [130, 133]], "long-forms": [[68, 86]]}, {"text": " From the set of erroneous instances: True Positive (TP) ML class 6= student class False Negative (FN) ML class = student class", "acronyms": [[53, 55], [99, 101], [57, 59], [103, 105]], "long-forms": [[38, 51], [83, 97]]}, {"text": "study on NER is mainly focused either on the proper name identification of person(PER), location(LOC), organization(ORG), time(TIM) and numeral(NUM) expressions almost in news do-", "acronyms": [[116, 119], [9, 12], [82, 85], [97, 100], [127, 130], [144, 147]], "long-forms": [[103, 114], [75, 81], [88, 96], [122, 126], [136, 143]]}, {"text": "V is the vocabulary size.  The question difficulty estimation (QDE) task aims to automatically learn the question difficul-", "acronyms": [[63, 66]], "long-forms": [[31, 61]]}, {"text": "In  Proc. of Intelligent Tutoring Systems (ITS). ", "acronyms": [[43, 46]], "long-forms": [[13, 41]]}, {"text": "cal machine translation. The 41th Annual meeting of the Association for Computational Linguistics (ACL), 311-318.", "acronyms": [[99, 102]], "long-forms": [[56, 97]]}, {"text": "Learning Summary Content Units with Topic Modeling Leonhard Hennig Ernesto William De Luca Distributed Artificial Intelligence Laboratory (DAI-Lab) Technische Universita?t Berlin", "acronyms": [[139, 146]], "long-forms": [[91, 137]]}, {"text": "proposed two novel features, Intra-sentence positional term weighting (IPTW) and the Patched language model (PLM), and showed their effectiveness by conducting automatic", "acronyms": [[109, 112], [71, 75]], "long-forms": [[85, 107], [29, 69]]}, {"text": "pre-rendered animations.  The Natural Language Understanding (NLU) module needs to cope with both chat and military", "acronyms": [[62, 65]], "long-forms": [[30, 60]]}, {"text": "most related words pop-up. Then the documents are re-ranked about their term frequency (TF) values (G. Salton and C. Buckley, 1988) and contextual infor-", "acronyms": [[88, 90]], "long-forms": [[72, 86]]}, {"text": "(section 24). Legend of models: ST=Split Tags; EC=enhanced connectivity. ", "acronyms": [[47, 49]], "long-forms": [[50, 71]]}, {"text": "The first system, as its name suggests, is very  simple: using the WSD model, it chooses the  most frequent sense (MFS) of the lemma l with  POS p according to WN (that is, the lowest num-", "acronyms": [[115, 118], [67, 70], [141, 144], [160, 162]], "long-forms": [[94, 113]]}, {"text": "The application of the program is demonstrated using the Aberdeen Report Judgment Scales (ARJS; Sporer, 2004) with a set of 72 deceptive and true accounts of a driving examination. Data on different types of inter-coder reliabilities are presented and implications for future research with computer-assisted qualitative coding procedures as well as training of coders are outlined. Credits This research has been supported by a grant from the German Science Foundation (Deutsche Forschungsgemeinschaft (DFG): Sp262/3-2) to the present author. The author would like to thank Edda Niederstadt and Nina F. Petermann for the coding of the data, and to Jaume Masip, Valerie Hauch, and Sarah Treiber for comments on an earlier version of this manuscript.", "acronyms": [[503, 506], [90, 94]], "long-forms": [[470, 501], [57, 88]]}, {"text": "In International Conference on Autonomous Agents and Multiagent Systems (AAMAS). ", "acronyms": [[73, 78]], "long-forms": [[31, 71]]}, {"text": "SS 0.47 5.1 100 times faster than that of Tree Kernel, and the retrieval speed of Subpath Set (SS) is about 1,000 times faster than that of Tree Kernel.", "acronyms": [[95, 97]], "long-forms": [[82, 93]]}, {"text": "9http://disi.unitn.it/moschitti/Tree-Kernel.htm 10for STS-2012 we also report the results for a concatenation of all five test sets (ALL) provement with the Mean = 0.7416 and Pearson", "acronyms": [[133, 136]], "long-forms": [[113, 116]]}, {"text": "derivations obtained from all stop states in the chart.  3.6 Minimum Risk Parse (MRP) MPD and MPP aim at obtaining the structure of a", "acronyms": [[81, 84]], "long-forms": [[61, 79]]}, {"text": "It is well known that for English, the automatic conversion of a constituency parser?s output to dependency format can achieve competitive unlabeled attachment scores (ULA) to a dependency parser?s output trained on automatically converted trees", "acronyms": [[168, 171]], "long-forms": [[139, 159]]}, {"text": "Semantic Specialization (ISS) (Girju, Badulescu,  and Moldovan, 2006), Na?ve Bayes (NB) 3  and  Maximum Entropy (ME)4.  ", "acronyms": [[113, 115], [25, 28], [84, 86]], "long-forms": [[96, 111], [0, 23], [71, 82]]}, {"text": " - 19  -  Both L I and L 2 are CSL's (Context sensitive languages). They ", "acronyms": [[31, 36]], "long-forms": [[38, 65]]}, {"text": "Figure 3: The system architecture.   CA = communicative act. ", "acronyms": [[37, 39]], "long-forms": [[42, 59]]}, {"text": "analysis as discussed in the next section.  Analysis of Variance (ANOVA) tests were performed on the full 5 years for each sector, to com-", "acronyms": [[66, 71]], "long-forms": [[44, 64]]}, {"text": "Table 3 presents the total number of training examples extracted from SemCor (SC) and from the background documents (BG). As expected, by", "acronyms": [[117, 119], [78, 80]], "long-forms": [[95, 105], [70, 76]]}, {"text": "are at least four candidates: less studied (LS) languages, resource scarce (RS) languages, less computerized (LC) languages, and less privileged (LP) languages.", "acronyms": [[146, 148], [44, 46], [76, 78], [110, 112]], "long-forms": [[129, 144], [30, 42], [59, 74], [91, 108]]}, {"text": "The results can be seen at:  http:/ /c lwww.essex.ac.uk/w3c/.  The project was  funded by JISC (the Joint Information Systems Com-  mittee of the UK Higher Education Funding Coun- ", "acronyms": [[90, 94], [146, 148]], "long-forms": [[100, 138]]}, {"text": "are contained in a XML file and each query  consists of following elements: Topic  Number(NUM),Topic Title(TITLE),Topic  question(DESC),Topic Narrative(NARR) and ", "acronyms": [[90, 93], [19, 22], [107, 112], [130, 134], [152, 156]], "long-forms": [[83, 88], [101, 106], [142, 151]]}, {"text": "All experiments carried out in this study are for the English (EN) - French (FR) language pair. ", "acronyms": [[77, 79], [63, 65]], "long-forms": [[69, 75], [54, 61]]}, {"text": "2008; Metzler and Cai, 2011).  Work in Content Based Image Retrieval (CBIR) (Datta et al., 2008) has progressed from systems that", "acronyms": [[70, 74]], "long-forms": [[39, 68]]}, {"text": "integer linear programming (ILP) conditional random field (CRF) support vector machine (SVM) latent semantic analysis (LSA)", "acronyms": [[88, 91], [28, 31], [59, 62], [119, 122]], "long-forms": [[64, 86], [0, 26], [33, 57], [93, 117]]}, {"text": "4 GTS with the Idea of Coordination Problem Game GTS (Game Theoretic Semantics) has been developed as an alternative semantics where major se-", "acronyms": [[49, 52], [2, 5]], "long-forms": [[54, 78]]}, {"text": "In Proceedings of the 24th International Conference on Computational Linguistics (COLING),Mumbai, India.", "acronyms": [[82, 88]], "long-forms": [[55, 80]]}, {"text": "initions of state cannot be sensitive to (sometimes critical) aspects of the dialogue context, such as the user?s last dialogue move (DM) (e.g. requesthelp) unless that move directly affects the status of", "acronyms": [[134, 136]], "long-forms": [[119, 132]]}, {"text": "which predicts the aligned source positions for every target word, and (c) the Positional Unknown (PosUnk) ?", "acronyms": [[99, 105]], "long-forms": [[79, 97]]}, {"text": "The idea is simply to count the mmlber of new  words introduced ow'x a moving interval and 1)roduce  what he calls a vocabulary managemenl profile (VMI'),  or lneasurements at intervals.", "acronyms": [[148, 152]], "long-forms": [[117, 146]]}, {"text": " Because LCS is a simple procedure, a second baseline based on Greedy String Tiling (GST) (Wise, 1996) was added after the evaluation pe-", "acronyms": [[85, 88], [9, 12]], "long-forms": [[63, 83]]}, {"text": "CC = coordinating conjunction; CD = cardinal number; JJ = adjective; MD = modal; NN = singular noun; NNP = proper noun; NNPS = plural proper noun; NNS = plural noun; RB = adverb; TO = to; VB = base form verb; VBD = past tense verb; VBZ = third-person singular present verb.", "acronyms": [[179, 181], [0, 2], [31, 33], [53, 55], [69, 71], [81, 83], [101, 104], [120, 124], [147, 150], [166, 168], [188, 190], [209, 212], [232, 235]], "long-forms": [[184, 186], [5, 29], [36, 44], [58, 67], [74, 79], [95, 99], [107, 118], [127, 145], [153, 164], [171, 177], [203, 207], [215, 230], [238, 273]]}, {"text": "details of this collection.  AECMA Simplified English (AECMA-SE) (AECMA 1986) was the predecessor of ASD Simplified Technical English.", "acronyms": [[55, 63], [66, 71], [101, 104]], "long-forms": [[29, 53]]}, {"text": "al., 2005) to quickly find possible answers, given the relational conjunction (RC) of the question. ", "acronyms": [[79, 81]], "long-forms": [[55, 77]]}, {"text": "2http://www.nist.gov/speech/tests/mt/ Table 1: Training, development and test data from Basic Travel Expression Corpus(BTEC) Japanese English", "acronyms": [[119, 123]], "long-forms": [[88, 117]]}, {"text": "2,5 y1,5 Figure 1: The Partial Lattice MRF (PL-MRF) Model for a 5-word sentence and a 4-layer lattice.", "acronyms": [[44, 50]], "long-forms": [[23, 42]]}, {"text": "  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 787?798, October 25-29, 2014, Doha, Qatar.", "acronyms": [[90, 95]], "long-forms": [[40, 88]]}, {"text": "In Proceedings of the 19th International Conference on Computational Linguistics (COLING?02), pages 218? ", "acronyms": [[82, 91]], "long-forms": [[55, 80]]}, {"text": " The sentence-level extraction is done with the subsequence kernel (SSK) approach from (Bunescu and Mooney, 2005), which was shown to give good re-", "acronyms": [[68, 71]], "long-forms": [[51, 66]]}, {"text": "fered to punched cards. Abbreviated alphabetical symbols  are used for the syntactic analysis (AP=adJective phrase)  because of the program's 24unlt search limitation.", "acronyms": [[95, 97]], "long-forms": [[98, 114]]}, {"text": " ? Unstressed (US) average: Each feature is normalized by its mean value in the un-", "acronyms": [[15, 17]], "long-forms": [[3, 13]]}, {"text": "Note also that there is some overlap of infer-  marion between the Lexical Systems analysis and  the Brandeis analysis, such as SUISCAT(TRAN)  and DO.", "acronyms": [[136, 140], [147, 149], [128, 135]], "long-forms": []}, {"text": "stream. In Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence (UAI), 20?29. ", "acronyms": [[89, 92]], "long-forms": [[49, 87]]}, {"text": "We apply the combination patterns to the training corpus, and count pairs of True Positives (TP) and False Positives (FP). The scores are calculated", "acronyms": [[118, 120], [93, 95]], "long-forms": [[101, 116], [77, 91]]}, {"text": "I_tt is raining.,  OBJ = Object: He read a book., ", "acronyms": [[19, 22]], "long-forms": [[25, 31]]}, {"text": "NE = Named Entity CE = Correlated Entity EP = Entity Profile SVO = Subject-Verb-Object", "acronyms": [[41, 43], [0, 2], [18, 20], [61, 64]], "long-forms": [[46, 60], [5, 17], [23, 40], [67, 86]]}, {"text": " 1  0  20  40  60  80  100  120  140 information density (ID)Fisher information (FIR)query-by-committee (SVE)random FlySlip", "acronyms": [[58, 60], [81, 84], [105, 108], [116, 123]], "long-forms": [[37, 56], [61, 67]]}, {"text": " A statistical classification technique based  on the use of Hidden Markov Models (HMM) was  used as a language discriminator.", "acronyms": [[83, 86]], "long-forms": [[61, 81]]}, {"text": "The second column represents three SMT systems, namely: the baseline system adapted to the domain (DA), the same system with a CSLM (DA+CSLM) and the project adapted sys-", "acronyms": [[99, 101], [35, 38], [127, 131]], "long-forms": [[91, 97], [133, 140]]}, {"text": "See Table 3 for the complete list of non-predicate filters describing restrictions on the role text (RT), role span (RS), and predicate frame (PF) in terms of the semantic type", "acronyms": [[101, 103], [117, 119], [143, 145]], "long-forms": [[90, 99], [106, 115], [126, 141]]}, {"text": "  Abbreviation: ACK=Acknowledgment; COMP=Completion;  SNU=Signal Non Understanding; Sources abbreviated as: F  = Friendship; V = Visibility; Rte = Route ", "acronyms": [[54, 57], [16, 19], [36, 40], [141, 144]], "long-forms": [[58, 82], [20, 33], [41, 51], [113, 123], [129, 139], [147, 152]]}, {"text": "Litkowski, K. C.: Syntactic Clues and Lexical Resources in Question-Answering. In E. M. Voorhees & D. K. Harman (eds.), The Ninth Text Retrieval Conference (TREC-9). ( 2001) 157-166 10.", "acronyms": [[157, 163]], "long-forms": [[120, 155]]}, {"text": "in the preceding verb phrase (PV), the head noun in the preceding noun phrase (PN) and the head noun in the following noun phrase (FN) when available (Chodorow et al, 2007).", "acronyms": [[131, 133], [30, 32], [79, 81]], "long-forms": [[108, 122], [17, 28], [56, 77]]}, {"text": " These features of Latin influenced the choice  of Dependency Grammars (DG)2 as the most  suitable grammar framework for building Latin ", "acronyms": [[72, 74]], "long-forms": [[51, 70]]}, {"text": "(domain specific) region. The upper region of the on-  tology is called the Ontology Base (OB) and contains  approximately 400 items that represent generalizations ", "acronyms": [[91, 93]], "long-forms": [[76, 89]]}, {"text": "known formalisms uch as Head Driven Phrase  Structure Grammar (HPSG), Lexical Functional  Grammar (LFG) or Slot Grammars (SG), because  SUG allows a modular and computational ", "acronyms": [[122, 124], [63, 67], [99, 102], [136, 139]], "long-forms": [[107, 120], [24, 61], [70, 97]]}, {"text": " Introduction  The DARPA ATIS Spoken Language System (SLS) task  represents ignificant new challenges for speech and natural ", "acronyms": [[54, 57], [19, 24], [25, 29]], "long-forms": [[30, 52]]}, {"text": "dimensional space, in which both texts and terms are represented by means of Domain Vectors (DVs), i.e. vectors representing the domain relevances among the linguistic object and", "acronyms": [[93, 96]], "long-forms": [[77, 91]]}, {"text": "Conceptual structures (ConcSs);  ? Parsed syntactic structures (PSyntSs). ", "acronyms": [[64, 71], [23, 29]], "long-forms": [[35, 62], [0, 21]]}, {"text": "We first experiment with the separately trained supertagger and parser, which are then combined using belief propagation (BP) and dual decomposition (DD).", "acronyms": [[122, 124], [150, 152]], "long-forms": [[102, 120], [130, 148]]}, {"text": "ilarity between given texts. The first approach is based on vector space models (VSMs) (Meadow, 1992).", "acronyms": [[81, 85]], "long-forms": [[60, 79]]}, {"text": "Our objective is to study the effect of using bigram features against co?occurrences in first (PB) and second (SC) order context vectors while using relatively small amounts of training data per word.", "acronyms": [[111, 113], [95, 97]], "long-forms": [[103, 109]]}, {"text": "This data may be presented in various forms, e.g. as  dictionaries, transition networks for lexical analysis,  augmented transition networks (ATN) for syntactic analysis,  semantic networks,  re la t ions ,  end so on.", "acronyms": [[142, 145]], "long-forms": [[111, 140]]}, {"text": " Results (in percentages) are for per-logical-predication (PR) and per-whole-graph (GRPH) tagging accurcies. ", "acronyms": [[84, 88], [59, 61]], "long-forms": [[77, 82], [46, 57]]}, {"text": "have been opened.  Named entity recognition (NER) is one of the  many fields of NLP that rely on machine learn?", "acronyms": [[45, 48], [80, 83]], "long-forms": [[19, 43]]}, {"text": "Linear Program relaxation based on single-commodity flow. LP(M): Linear Program relaxation based on multi-commodity flow.", "acronyms": [[58, 60]], "long-forms": [[65, 79]]}, {"text": "use(USE) social(SOC) body(BOD)  phy_creation(PCR) mental_creation(MCR)  verbal_creagion (VCR)  These are mostly taken from the classifications ", "acronyms": [[89, 92], [4, 7], [16, 19], [26, 29], [45, 48], [66, 69]], "long-forms": [[72, 87], [0, 3], [9, 15], [21, 25], [32, 44], [50, 65]]}, {"text": "smoothing as the evaluation metric.  Best v.s. Rest (BR) To score the best hypothesis in the n-best set", "acronyms": [[53, 55]], "long-forms": [[37, 51]]}, {"text": "duction to the two matrices. In particular, we adopt the Singular Value Decomposition (SVD), one of the most effective methods to approximate the original", "acronyms": [[87, 90]], "long-forms": [[57, 85]]}, {"text": "and there are many local minima on the error surface.  Therefore, we use an alternative loss function, minimum squared error (MSE) in equation (5), where Score(.)", "acronyms": [[126, 129]], "long-forms": [[103, 124]]}, {"text": "of a multi-class document categorization. We introduce PRBEP (precision recall break even point) as a measure which is popular in the area of infor-", "acronyms": [[55, 60]], "long-forms": [[62, 95]]}, {"text": "tion (IE). Considerable volume of location data was imported in a knowledge base (KB) with entities of general importance used for seman-", "acronyms": [[82, 84], [6, 8]], "long-forms": [[66, 80]]}, {"text": "tween anaphor and antecedent, the feature ddist captures the distance in sentences, the feature mdist the number of markables (NPs) between anaphor and antecedent.", "acronyms": [[127, 130]], "long-forms": [[106, 125]]}, {"text": "An alternative to QE is to perform the expansion in the document. Document Expansion (DE) was first proposed in the speech retrieval commu-", "acronyms": [[86, 88], [18, 20]], "long-forms": [[66, 84]]}, {"text": "and why they should be adhered to? involving a coordinated phrase in the object position consisting of an NP (najprostsze zasady ? the most basic principles?)", "acronyms": [[106, 108]], "long-forms": [[110, 121]]}, {"text": "The  motivation for this work is presented in section 4. Unsupervised Morphology Learner (UML)  framework is presented in section 5.", "acronyms": [[90, 93]], "long-forms": [[57, 88]]}, {"text": " A manually  prepared seed list that is used to frame the  lexical patterns for conjunct verbs (ConjVs)  contains frequently used Light Verbs (LVs).", "acronyms": [[96, 102], [143, 146]], "long-forms": [[80, 94], [130, 141]]}, {"text": " 1 Introduction Medical relation (MR) classification, an information extraction task in the clinical domain that was recently defined in the 2010 i2b2/VA Challenge (Uzuner et al.,", "acronyms": [[34, 36]], "long-forms": [[16, 32]]}, {"text": "3http://www.cjk.org 4https://translit.i2r.a-star.edu.sg/news2009/evaluation/ 5The six metrics are Word Accuracy in Top-1 (ACC), Fuzziness in Top-1 (Mean F-score), Mean Reciprocal Rank", "acronyms": [[122, 125]], "long-forms": [[103, 111]]}, {"text": "well. The formal framework for analysis will be the Discourse Representation Theory (DRT). ", "acronyms": [[85, 88]], "long-forms": [[52, 83]]}, {"text": "End the tutoring problem? Cause another round of dialogue/essay revision ITSpoke (Intelligent Tutoring SPOKEn dialogue system) 17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  156/206", "acronyms": [[73, 80]], "long-forms": [[82, 109]]}, {"text": "Coarse-to-fine n-best parsing and MaxEnt discriminative reranking Eugene Charniak and Mark Johnson Brown Laboratory for Linguistic Information Processing (BLLIP) Brown University", "acronyms": [[155, 160], [34, 40]], "long-forms": [[99, 153]]}, {"text": " Given the good results of the pilot we decided to deploy the task in Amazon Mechanical Turk (AMT) in order to crowd source the annotation task.", "acronyms": [[94, 97]], "long-forms": [[70, 92]]}, {"text": " ? BLEU (bilingual evalutation understudy) score: This score measures the precision of unigrams, bigrams, trigrams, and 4-grams with respect to a", "acronyms": [[3, 7]], "long-forms": [[9, 41]]}, {"text": " 2.2 Character-level text embeddings Simple Recurrent Networks (SRNs) were introduced by Elman (1990) as models of temporal, or", "acronyms": [[64, 68]], "long-forms": [[37, 62]]}, {"text": " In this paper, we propose to disambiguate NEs using a Personalized PageRank (PPR)-based random walk algorithm.", "acronyms": [[78, 81], [43, 45]], "long-forms": [[55, 76]]}, {"text": "1. Introduction Word segmentation is an important task in natural language processing (NLP) for languages without word delimiters (e.g., Chinese).", "acronyms": [[87, 90]], "long-forms": [[58, 85]]}, {"text": "an NP node with the grammatical function (GF) of the pronoun. The GF of the pronoun, in turn, is replaced by HD (head). Such unary branching NPs are added on top of nouns", "acronyms": [[109, 111], [3, 5], [42, 44], [66, 68], [141, 144]], "long-forms": [[113, 117], [20, 40]]}, {"text": " 1 Introduction Stanford Dependencies (SD) provide a functional characterization of the grammatical relations in", "acronyms": [[39, 41]], "long-forms": [[16, 37]]}, {"text": " 3.3 Bootstrapped Voting Experts The Bootstrapped Voting Experts (BVE) algorithm (Hewlett and Cohen, 2009) is an extension to VE.", "acronyms": [[66, 69], [126, 128]], "long-forms": [[37, 64]]}, {"text": "1978. Longman Dictionary of  Contemporary lCnglish (LI)OCE). Long\\]nan, liar- ", "acronyms": [[51, 59]], "long-forms": [[6, 50]]}, {"text": "in a Swedish Clinical Corpus Hercules Dalianis, Maria Skeppstedt Department of Computer and Systems Sciences (DSV) Stockholm University", "acronyms": [[110, 113]], "long-forms": [[65, 108]]}, {"text": " The transformation phase is done by applying singular value decomposition (SVD) to the initial term-by-sentence matrix defined as A = U?V T .", "acronyms": [[76, 79]], "long-forms": [[46, 74], [135, 138]]}, {"text": "English?German 45.59 43.72 Automatically aligned corpora average 47.99?4.20 45.75?3.64 Table 1: The grammatical coverage (GC) of NF-ITG for different corpora dependent on the interpretation of word alignments: contiguous Translation Equivalence or discontiguous Translation Equivalence", "acronyms": [[122, 124], [129, 135]], "long-forms": [[100, 120]]}, {"text": "grammars is denoted CFGS.  In a linear indexed grammar (LIG),2 strings are derived from nonterminals with an associated", "acronyms": [[56, 59], [20, 24]], "long-forms": [[32, 54]]}, {"text": "  Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 49?54, Boulder, Colorado, June 2009.", "acronyms": [[87, 92]], "long-forms": [[46, 85]]}, {"text": "each cross level text pair, i.e., Paragraph to Sentence (P-S), Sentence to Phrase (SPh), Phrase to Word (Ph-W) and Word to Sense (W-Se).", "acronyms": [[105, 109], [57, 60], [83, 86], [130, 134]], "long-forms": [[89, 103], [34, 55], [63, 81], [115, 128]]}, {"text": "parts of speech, and for different confidence levels. We compare our method to the Semantic Orientation from PMI (SO-PMI) method described in Turney (2002), the Spin model described in Takamura, Inui, and Okumura (2005), the shortest path method", "acronyms": [[114, 120]], "long-forms": [[83, 112]]}, {"text": "standing that shares tasks with OIE. AMR parsing (Banarescu et al, ), semantic role labeling (SRL) (Toutanova et al, 2008; Punyakanok et al, 2008)", "acronyms": [[94, 97], [37, 40], [32, 35]], "long-forms": [[70, 92]]}, {"text": "ALO ( in to )   RO (OST LOC)  PO (PRE)  ON (VO)) ", "acronyms": [[34, 37], [0, 3], [16, 18], [20, 23], [24, 27], [44, 46]], "long-forms": [[30, 32]]}, {"text": "gories Auxiliary-final VP For auxiliary verbs parsed as verb phrases (VP), this feature checks if the final element in the VP", "acronyms": [[70, 72], [23, 25], [123, 125]], "long-forms": [[56, 68]]}, {"text": "ticular, this includes a model of the grounding process (Clark, 1996) that involves recognition and construction of common ground units (CGUs) (see (Traum, 2003)). ", "acronyms": [[137, 141]], "long-forms": [[116, 135]]}, {"text": "work for sentence level feature extraction. In the Window Processing component, each token is further represented as Word Features (WF) and Position Features (PF) (see section 3.4.1 and 3.4.2). Then, the", "acronyms": [[132, 134], [159, 161]], "long-forms": [[117, 130], [140, 157]]}, {"text": "a baseline.  Language Model (LM): We model the semantic fit of a candidate substitute within the given context", "acronyms": [[29, 31]], "long-forms": [[13, 27]]}, {"text": "The rules  in an AG have a considerably different formal character as compared  to the 'rewrite rule' in a general phrase structure grmmmar (PSG). ", "acronyms": [[141, 144], [17, 19]], "long-forms": [[115, 139]]}, {"text": "The knowledge about actions and plans is stored in  a plan library structured on the basis of two main hier-  archies: the Decomposition Hierarchy (DH) and the  Generalization Hierarchy (GH) \\[Kautz and Allen, 86\\].", "acronyms": [[148, 150], [187, 189]], "long-forms": [[123, 146], [161, 185]]}, {"text": "oleary@cs.umd.edu Abstract The Text Analysis Conference (TAC) ranks summarization systems by their average score", "acronyms": [[57, 60]], "long-forms": [[31, 55]]}, {"text": "We applied 3 MCMC algorithms: Gibbs sampling (GS), MCSAT and Simulated Tempering (ST) for inference and the comparative NER results are shown in Table 1.", "acronyms": [[82, 84]], "long-forms": [[61, 80]]}, {"text": "pute probability scores of word sequences. The general conversational language model (LM) is based on data from the SWITCHBOARD corpus and a small", "acronyms": [[86, 88]], "long-forms": [[70, 84]]}, {"text": " Figure 1. Reference answer representation revisions  Typical facets, as in (1a), are derived directly from a dependency parse, in this case retaining its dependency type label, NMod (noun modifier).  Other facets, such as (1b-e), are the result of com-bining multiple dependencies, VMod(stick, to) and PMod(to, nail) in the case of (1c).", "acronyms": [[178, 182], [283, 287], [303, 307]], "long-forms": [[184, 197]]}, {"text": "Training uses balanced data (50:50). Testing uses two class distributions (C.D.): 50:50 (balanced) and Natural Distribution (N.D.). Improvements of our method are statistically significant with p<0.005 based on paired t-test.", "acronyms": [[125, 129], [75, 78]], "long-forms": [[103, 123], [54, 72]]}, {"text": "tion probabilities in both directions, seven features for the lexicalized distortion model, a word and a phrase penalty and a target language model (LM). ", "acronyms": [[149, 151]], "long-forms": [[133, 147]]}, {"text": "duction Factor, and the \"expected utility\" of a PA-  SSF is estimated as the Global Reduction Factor:  Reduct ion  Factor  The Reduction Factor (RF)  of  a given SSFssf is RF(ss f )  = n(ssf)  - 1, where ", "acronyms": [[145, 147], [48, 56], [172, 174], [162, 168]], "long-forms": [[127, 143]]}, {"text": "velopment and 23 for testing. Chinese data were extracted from the Penn Chinese Treebank (CTB) (Xue et al, 2005); articles 001-270 and 440-", "acronyms": [[90, 93]], "long-forms": [[72, 88]]}, {"text": "ing the following measures:   1. PrecisionCorrectTransliterations(PTrans)  2.", "acronyms": [[66, 72]], "long-forms": [[33, 64]]}, {"text": " In addition, the tense,                                                             1 S=Subject; IO=Indirect Object; DO=Direct Object;  V=Verb; ERG=Ergative; DAT=Dative ", "acronyms": [[98, 100], [118, 120], [145, 148], [159, 162]], "long-forms": [[101, 116], [121, 134], [89, 96], [139, 143], [149, 157], [163, 169]]}, {"text": "  1. RecallCorrectTransliteration  (RTrans)  The recall was computed using the sample as ", "acronyms": [[36, 42]], "long-forms": [[5, 33]]}, {"text": "@math.canterbury.ac.nz Abstract We introduce Peripheral Diversity (PD) as a knowledge-based approach to achieve multi-", "acronyms": [[67, 69]], "long-forms": [[45, 65]]}, {"text": " and  As for perceptron criterion, we employ the  average perceptron (AvgP) (Freund and  Sc", "acronyms": [[70, 74]], "long-forms": [[50, 68]]}, {"text": " Figure 4: Algorithm for calculating the F-measure confusion matrix of True Positives (T.P.), False Positives (F.P.), True Negatives (T.N.), and False Negatives (F.N.). The ranking technique described in this paper creates a list of", "acronyms": [[134, 138], [162, 166], [87, 92], [111, 115]], "long-forms": [[118, 132], [145, 160], [71, 85], [94, 109]]}, {"text": "Final step in treebuilding.  The English Destressin8 Rule (EDR) is used to  determ/ne which vowels should be reduced.", "acronyms": [[59, 62]], "long-forms": [[33, 57]]}, {"text": "and (W-1,W0,W1) ? Gazetteers (GAZ): We use two sets of gazetteers.", "acronyms": [[30, 33], [5, 8], [9, 11], [12, 14]], "long-forms": [[18, 28]]}, {"text": "with the overall metric of error per response fill  (ERR), overgeneration (OVG) does not correlate  with it, and substitution (SUB) correlates with it  only to a limited extent.", "acronyms": [[127, 130], [53, 56], [75, 78]], "long-forms": [[113, 125], [59, 73]]}, {"text": "*****- TRANSFOREATIONS * l f**   SCAN CALLED AT 1 I  ANTEST CALLED FOR 12?F ALAT 3 (AACC) ,SO= 13. RES= 0, TOP= 1:s ", "acronyms": [[67, 70], [84, 88], [91, 93], [99, 102], [107, 110], [76, 80]], "long-forms": [[53, 66]]}, {"text": "<AbstractText Label=?RESULTS? NlmCategory=?RESULTS?>Premature delivery rate was higher (p = 0.048) in the CKC group (14/36, 38.88%) than in control group (14/68, 20.5%) with a odds ratio (OR) of 2.455 (1.007 - 5.985); and premature delivery was related to cone depth, OR was significantly increased when the cone depth was more than", "acronyms": [[188, 190], [106, 109], [268, 270]], "long-forms": [[176, 186]]}, {"text": "2 Complexity of GPSG Components  A generalized phrase structure grammar contains five language-  particular components - -  immediate dominance (ID) rules, meta-  rules, linear precedence (LP) statements, feature co-occurrence ", "acronyms": [[145, 147], [16, 20], [189, 191]], "long-forms": [[124, 143], [170, 187]]}, {"text": "~ ~ . ~  5  Object S t r i n g  (OBJL1,ST) Refercn'ce Guide. .............. 9 ", "acronyms": [[33, 41]], "long-forms": [[12, 30]]}, {"text": "this assumption.  In a synchronous TAG (STAG) the elementary structures are ordered pairs of TAG trees, with a", "acronyms": [[40, 44], [93, 96]], "long-forms": [[23, 38]]}, {"text": "  3.3 Optimality Theory  Optimality Theory (OT) is a theory of language  and grammar, developed by Alan Prince and Paul ", "acronyms": [[44, 46]], "long-forms": [[25, 42]]}, {"text": "  Here the parameters are set using an algorithm  whose uniform resource name (URN),  xyz.edu/algo-1, is declared as an attribute of the ", "acronyms": [[79, 82]], "long-forms": [[56, 77]]}, {"text": " 1  0  20  40  60  80  100  120  140 information density (ID)Fisher information (FIR)query-by-committee (SVE)random Sig+Reply", "acronyms": [[58, 60], [81, 84], [105, 108]], "long-forms": [[37, 56], [61, 67]]}, {"text": "Interpreting news requires identifying its constituent events. Information extraction (IE) makes this feasible by considering only events of a specified type,", "acronyms": [[87, 89]], "long-forms": [[63, 85]]}, {"text": " The implementation of our approach is a system called LetSum (Legal text Summarizer), which has been developed in Java and Perl.", "acronyms": [[55, 61]], "long-forms": [[63, 84]]}, {"text": "In Proceedings of the 23rd International Conference on Computational Linguistics (COLING?10), pages 617? ", "acronyms": [[82, 91]], "long-forms": [[55, 80]]}, {"text": "The score measures the maximum overlap between a hypothesized cluster (HYP) and a corresponding gold standard cluster (GOLD), and computes a weighted average across all the HYP clus-", "acronyms": [[119, 123], [71, 74], [173, 176]], "long-forms": [[96, 109], [49, 61]]}, {"text": "*Event, *Mtrans-Action), and plans (i.e. *Pick-Up-  Gun). A hierarchy of Concept Class (CC) entities  stores knowledge both declaratively and procedurely ", "acronyms": [[88, 90]], "long-forms": [[73, 86]]}, {"text": "patterns. The Ngram features were generated using the Ngram Statistics Package (NSP) (Banerjee and Pedersen, 2003).1 The extraction pat-", "acronyms": [[80, 83]], "long-forms": [[54, 78]]}, {"text": "gorithm (PAS-PTK), which is highly more efficient and more accurate than the SSTK and (ii) a new kernel called Part of Speech sequence kernel (POSSK), which proves very accurate to represent shallow syn-", "acronyms": [[143, 148], [9, 16], [77, 81]], "long-forms": [[111, 141]]}, {"text": " 2 HMM transitions can be modeled using Weighted Finite State Automata (WFSAs), corresponding to regular expressions.", "acronyms": [[72, 77], [3, 6]], "long-forms": [[40, 70]]}, {"text": "on a Wikipedia corpus instead of the ukWaC corpus. The University of Sussex (UoS) team submitted two WSI systems that use dependency-parsed", "acronyms": [[77, 80], [37, 42], [101, 104]], "long-forms": [[55, 75]]}, {"text": "compared is a familiar problem from the fields of information retrieval (IR), text mining (TM), textual data analysis (TDA) and natural language processing (NLP) (Lebart and Rajman, 2000).", "acronyms": [[119, 122], [73, 75], [91, 93], [157, 160]], "long-forms": [[96, 117], [50, 71], [78, 89], [128, 155]]}, {"text": "LMs by perplexity (PPL). We use the Wall Street Journal (WSJ) portion of Penn Treebank (PTB). ", "acronyms": [[88, 91], [0, 3], [19, 22], [57, 60]], "long-forms": [[73, 86], [7, 17], [36, 55]]}, {"text": " 1 The following abbreviations are used POSS = possessive prefix/suffix; LOC = locative suffix; OBV = obviative suffix;", "acronyms": [[40, 44], [73, 76], [96, 99]], "long-forms": [[47, 57], [79, 87], [102, 111]]}, {"text": " The task addressed in this paper is also related to the Semantic Textual Similarity (STS) task (Agirre et al, 2012).", "acronyms": [[86, 89]], "long-forms": [[57, 84]]}, {"text": "Abbreviations POS = Part of Speech NE = Named Entity CE = Correlated Entity", "acronyms": [[35, 37]], "long-forms": [[40, 52]]}, {"text": "831 . . . demonstrated that HOIL-1L interacting protein (HOIP), a ubiquitin ligase that can catalyze the assembly of linear polyubiquitin chains, is recruited to DC40 in a TRAF2-dependent manner following engagement of CD40 . . .", "acronyms": [[57, 61], [162, 166], [172, 177], [219, 223]], "long-forms": [[28, 55]]}, {"text": " Since we planned to eventually test our algorithms in  word recognition on the Resource Management (RM)  database, our phone classification experiments were also ", "acronyms": [[101, 103]], "long-forms": [[80, 99]]}, {"text": "we maximize the log likelihood J(?) using a simple optimization technique called stochastic gradient descent (SGD). N,W", "acronyms": [[110, 113]], "long-forms": [[81, 108]]}, {"text": "meaning of the other. Examples are:  * Senior research assistant at the Belgian National Fund for Scientific Research (F.N.R.S.). ", "acronyms": [[119, 127]], "long-forms": [[89, 117]]}, {"text": "and Ripper, on the other hand, appear to take more advantage of some feature types than others. For the third task, lexical (LX) and discourse (DS) features apparently have more predictive power for both C4.5 and SVM than the other types.", "acronyms": [[125, 127], [144, 146], [213, 216]], "long-forms": [[116, 123], [133, 142]]}, {"text": " 5Note that this is a recursive lexical rule, which  Adjunct Extraposition Lexical Rule (AELR)  \"r,oc \\[\\] ICATIHEAD nou,~ Vverb\\] ", "acronyms": [[89, 93]], "long-forms": [[53, 87]]}, {"text": "4 Experimental Setup 4.1 Corpus and Experimental Expressions We use the British National Corpus (BNC),4 automatically parsed using the Collins parser (Collins,", "acronyms": [[97, 100]], "long-forms": [[72, 95]]}, {"text": "In sum, the text-to-text similarity measure combined with our sentence-level sen-timent analysis algorithm helps us identify the representative rationales of diverse opinions in an online deliberation. An overview of our meth-od is shown in Figure 1.  We applied our method in analyzing Wikipe-dia Article for Deletion (AfD) deliberation con-tent. Next we discuss how this method is used to analyze the content.", "acronyms": [[320, 323]], "long-forms": [[298, 318]]}, {"text": " ? Reduce(RE): Pop the stack. ", "acronyms": [[10, 12]], "long-forms": [[3, 9]]}, {"text": " 4 Classifier We used a linear support vector machine (SVM) classifier, which is standard for text data.", "acronyms": [[55, 58]], "long-forms": [[31, 53]]}, {"text": " A natural solution would be to take advantage  of machine readable dictionaries (MILD's), such  as Longman's Dictionary of Contemporary En- ", "acronyms": [[82, 88]], "long-forms": [[51, 80]]}, {"text": "(ARTG, PR.OC)I ^  (SUBS, SUSU, VT)2  , ARTG = article g~n&al  SUBS = substantif  compl~ment  VT  = verbe conjugu6 ", "acronyms": [[62, 66], [1, 5], [7, 12], [19, 23], [25, 29], [31, 33], [39, 43], [93, 95]], "long-forms": [[69, 79], [46, 60], [99, 104]]}, {"text": "A Linear Support Vector Machine text classifier (Joachims, 1999) was trained on Web pages from the Open Directory Project (ODP)6. These pages ef-", "acronyms": [[123, 126]], "long-forms": [[99, 121]]}, {"text": "second indicator of effective query is the recall at R document retrieved (Recall at R).  The last indicator measures the human effort (HE) in finding the answer. HE is ", "acronyms": [[136, 138], [163, 165]], "long-forms": [[122, 134]]}, {"text": "Upsala College  INTRODUCTION  A computerized conference (CC) is a form of co~znunica-  tion in which participants type into and read frc~ a ", "acronyms": [[57, 59]], "long-forms": [[32, 55]]}, {"text": "We ran our experiments with three corpora in different languages and representing different textual typologies: the British National Corpus (BNC), a ? bal-", "acronyms": [[141, 144]], "long-forms": [[116, 139]]}, {"text": "and Buckley, 1988), ResidualIDF(RIDF), Variance, Burstiness and Gain, are based on derivations from term frequency (TF) and document frequency (DF). ", "acronyms": [[116, 118], [144, 146], [32, 36]], "long-forms": [[100, 114], [124, 142], [20, 31]]}, {"text": "16 Production rule that expands n?s parent * * 17 Parse tree path from n to the nearest support verb * 18 Last part of speech (POS) subsumed by n * 19 Production rule that expands n?s left sibling *", "acronyms": [[127, 130]], "long-forms": [[111, 125]]}, {"text": "there are two ways of feeding the context vector into the main recurrent language model (RLM); (1) early fusion (EF) and (2) late fusion (LF), from Sec.", "acronyms": [[113, 115], [138, 140], [89, 92]], "long-forms": [[99, 111], [125, 136], [63, 87]]}, {"text": "Thus, it is necessary to define a proper ECS for each  language: Japanese ECS (J-ECS) \\[6\\] for Japanese language and  English ECS (E-ECS) \\[7\\] for English language. In the translation ", "acronyms": [[132, 137], [41, 44], [79, 84]], "long-forms": [[119, 130], [65, 77]]}, {"text": "certainty factor equals to 0.6 (3/5). The general formula for the certainty factor (CF) is shown as follow: CFi = Total number of the answer elements at leaf node i", "acronyms": [[84, 86], [108, 110]], "long-forms": [[66, 82]]}, {"text": "In order to  make the notion of focusing more precise I will use the  notion of Reference Time (RT), adopted from Reichen-  bach 1947 but reinterpreted pragmatically: RT is to be ", "acronyms": [[96, 98], [167, 169]], "long-forms": [[80, 94]]}, {"text": " A baseline system was also implemented using  the principle of most frequent sense (MFS),  where each word sense distribution was retrieved ", "acronyms": [[85, 88]], "long-forms": [[64, 83]]}, {"text": "conditional models are computed directly from data.  In this study, we use a Maximum Entropy (MaxEnt) classifier to combine the decision characteristic fea-", "acronyms": [[94, 100]], "long-forms": [[77, 92]]}, {"text": "corresponding to the point P.  Once a n  object has been added to the geometric model by specifying values  for its GSTART, GSIZE, and ROTN (rotation), the geometric coordinates for any  location on the object may be obtained by calling the funtion EXECLOCA with the ", "acronyms": [[135, 139], [249, 257], [116, 122], [124, 129]], "long-forms": [[141, 149]]}, {"text": "The thesis will examine two main areas: modelling cohesive devices within sentences and modelling discourse relations (DRs) across sentences.", "acronyms": [[119, 122]], "long-forms": [[98, 117]]}, {"text": "ing different training methods. The effects of discriminative training (CRF) and extended feature sets (lower section) are more than additive.", "acronyms": [[72, 75]], "long-forms": [[50, 70]]}, {"text": "left AV and right AV. For a string s with length l, we define the left accessor variety (LAV) as the types of distinct characters preceding s in", "acronyms": [[89, 92], [5, 7], [18, 20]], "long-forms": [[66, 87]]}, {"text": "MTCL = Machine Translation and Computational  Linguistics (1965-1968)  AJCL = AmericanJournal of Computational  Linguistics (1974-present) ", "acronyms": [[71, 75], [0, 4]], "long-forms": [[78, 110], [7, 57]]}, {"text": "In Proceedings of the Conference on Intelligent Text Processing and Computational Linguistics (CICLing), pages 376?387.", "acronyms": [[95, 102]], "long-forms": [[22, 93]]}, {"text": "Then, a supervised machine learning algorithm (e.g., Support Vector Machines  (SVM), na?ve Bayesian classifier (NB)) is applied  to the training examples to build a classifier that is ", "acronyms": [[79, 82], [112, 114]], "long-forms": [[85, 99], [53, 76]]}, {"text": "are also kernel methods that directly take into account the multiclass nature of the problem such as the kernel partial least squares regression (KPLS). ", "acronyms": [[146, 150]], "long-forms": [[105, 144]]}, {"text": "internal structure. This type of expression is an example  of what will be called a \"comp\\]ex basic expression\" (CBE). ", "acronyms": [[113, 116]], "long-forms": [[85, 110]]}, {"text": "few labels. In Advances in Social Networks Analysis and Mining (ASONAM), 2010 International Conference on, pages 192?199.", "acronyms": [[64, 70]], "long-forms": [[15, 62]]}, {"text": "exploited in (Goldberg and Zhu, 2006), which seeks document sentiments as an output of an optimisation problem (OPTIM) and the algorithm adopted by (Wu et al2009), that uses ranking", "acronyms": [[112, 117]], "long-forms": [[90, 110]]}, {"text": "a different word, such as job, in a given context) by defining a one-class learning algorithm based on support vector machines (SVM). They train a one-", "acronyms": [[128, 131]], "long-forms": [[103, 126]]}, {"text": "the preferred word attachments.  EventCorefBank (ECB) corpus: This corpus (Bejan and Harabagiu, 2010) of 482 documents", "acronyms": [[49, 52]], "long-forms": [[33, 47]]}, {"text": "Thus, we  name our system for generating compressions the  Adjustable Rate Compressor (ARC).   ", "acronyms": [[87, 90]], "long-forms": [[59, 85]]}, {"text": " 1 Introduction Open-domain Question Answering (QA) systems are concerned with the problem of trying", "acronyms": [[48, 50]], "long-forms": [[28, 46]]}, {"text": "12 Interac Figure 2: Upper chart: Turn-wise Interaction Quality (IQ) annotation from 3 raters. The final label is the median of", "acronyms": [[65, 67]], "long-forms": [[44, 63]]}, {"text": "[5] Corbett, J. C., M. B. Dwyer, J. Hatcliff, S. Laubach, C. S. Pasareanu, Robby and H. Zheng, Bandera: Extracting finite-state models from java source code, in: Proceedings of the International Conference on Software Engineering (ICSE), 2000. ", "acronyms": [[231, 235]], "long-forms": [[181, 229]]}, {"text": "and tests 2 and 3 are open tests performed on different test data. DM (i.e., Default Model) assigns all  incoming cases with the most likely class and it is ", "acronyms": [[67, 69]], "long-forms": [[77, 90]]}, {"text": "1 (TICCL) we gradually developed in prior projects is now TICCLops (TICCL online processing system). TICCLops is a fully", "acronyms": [[58, 66], [3, 8], [101, 109]], "long-forms": [[68, 98]]}, {"text": "Table 1: A classification of grammar rules for the HPB model. PR = phrasal rule, HR = hierarchical rule, GR = glue rule.", "acronyms": [[62, 64], [81, 83], [51, 54], [105, 107]], "long-forms": [[67, 79], [86, 103], [110, 119]]}, {"text": " 4.1 Lexical Sample Tasks We have evaluated our system on SensEval-2 (SE2) and SensEval-3 (SE3) lexical sample tasks and also", "acronyms": [[70, 73], [91, 94]], "long-forms": [[58, 68], [79, 89]]}, {"text": "a PP (Mirroshandel and Ghassem-Sani, 2011), the prepositional lexeme of the PP if e2 is governed by a PP, the POS of the head of the verb phrase (VP) if e1 is governed by a VP, the POS of the head of the", "acronyms": [[146, 148], [2, 4], [76, 78], [102, 104], [110, 113], [173, 175], [181, 184]], "long-forms": [[133, 144]]}, {"text": " 1 LR  Parser  Generat ion   Tree Adjoining Grammars (TAGs) are tree rewrit-  ing systems which combine trees with the sin- ", "acronyms": [[54, 58], [3, 5]], "long-forms": [[29, 52]]}, {"text": "Bigram Perplex. ( PP) MDI Missed Samples (MS) Bigram Missed Samples (MS)", "acronyms": [[42, 44], [18, 20], [22, 25], [69, 71]], "long-forms": [[26, 40], [7, 14], [53, 67]]}, {"text": "   Simple Segmentation Algorithm(SSA):  1.", "acronyms": [[33, 36]], "long-forms": [[3, 31]]}, {"text": " 2 Background: MaxEnt Models Maximum Entropy (MaxEnt) models are widely used in Natural Language Processing (Berger et", "acronyms": [[46, 52], [15, 21]], "long-forms": [[29, 44]]}, {"text": "conjuncts depend on it. Nilsson et al (2007)  advocate the Mel?cuk style (MS) for parsing  Czech, taking the first conjunct as the head, ", "acronyms": [[74, 76]], "long-forms": [[59, 72]]}, {"text": "Table 4. Comparative results in AIMed. The number of positive instances (POS) and negative instances (NEG) and macro-averaged precision (ma-P), recall (ma-R) and F1-score (ma-F) are shown.", "acronyms": [[73, 76], [32, 37], [102, 105], [137, 141], [152, 156], [172, 176]], "long-forms": [[53, 71], [82, 100], [111, 135], [144, 150], [162, 170]]}, {"text": "by each of these strategies.  The four Word Sense (WS) disambiguation  strategies resolve sense ambiguity errors.", "acronyms": [[51, 53]], "long-forms": [[39, 49]]}, {"text": "Abstract  This paper attempts to use an off-the-shelf  anaphora resolution (AR) system for Bengali. ", "acronyms": [[76, 78]], "long-forms": [[55, 74]]}, {"text": " Thus the determination of lexical scopes of  Complex Predicates (CPs) from a long consecutive sequence is indeed a crucial task.", "acronyms": [[66, 69]], "long-forms": [[46, 64]]}, {"text": "? iyi = 0 This is a quadratic programming (QP) problem and we can always find the global maximum of", "acronyms": [[43, 45]], "long-forms": [[20, 41]]}, {"text": "1425  Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 75?81, Gothenburg, Sweden, April 27, 2014.", "acronyms": [[75, 80], [84, 88]], "long-forms": [[41, 73]]}, {"text": "1. Introduction  Named entity(NE) recognition is important for recent  sophisticated information service such as question answering ", "acronyms": [[30, 32]], "long-forms": [[17, 28]]}, {"text": "Term Frequency-Inverse Document Frequency (TF-IDF) is a widely used similarity measure in Information Retrieval(IR). It has also been shown", "acronyms": [[112, 114], [43, 49]], "long-forms": [[90, 110], [0, 41]]}, {"text": " The two subgraphs are a parse structure subgraph (PSS) and a linear order subgraph (LOS). ", "acronyms": [[85, 88], [51, 54]], "long-forms": [[62, 83], [25, 49]]}, {"text": "Then the lexicon Chinese Semantic  Dictionary (CSD) containing sense descriptions  and the corpus Chinese Senses Pool (CSP) annotated with senses are built interactively, simulta-", "acronyms": [[119, 122], [47, 50]], "long-forms": [[98, 117], [17, 45]]}, {"text": "by a rhetorical relation R, Triple=verb pair associated with a relation R in V 2 R, BG = Background, cont.=continuation, elab.=elaboration.", "acronyms": [[84, 86], [121, 125], [101, 105]], "long-forms": [[89, 99], [16, 24], [63, 71], [107, 119], [127, 138]]}, {"text": "the procedures that manipulate an  intermediate representat ion of the query,  cal led the Meta Query Language (MQL). ", "acronyms": [[112, 115]], "long-forms": [[91, 110]]}, {"text": "BlogSum-generated summary content using ROUGE and compared the results with the original candidate list (OList). The t-test re-", "acronyms": [[105, 110], [40, 45]], "long-forms": [[80, 103]]}, {"text": "related to the segments bi and bj .  We obtain Dbest = argmaxD P (D|B) taking into all the combination of these probabilities.", "acronyms": [[66, 69]], "long-forms": [[47, 52]]}, {"text": "As first step we try to map the linguistic triple  into an ontology triple, by using an adaptation of  Aqualog?s Relation Similarity Service (RSS).  ", "acronyms": [[142, 145]], "long-forms": [[113, 140]]}, {"text": "multilingual MT system developed at the Laboratoire d'Analyse et de Technologie du Langage (LATL), University of Geneva. ", "acronyms": [[92, 96], [13, 15]], "long-forms": [[40, 90]]}, {"text": "regression model. For our regression task we use a Generalised Linear Model (GLM) via penalized maximum likelihood (Friedman et al, 2010).", "acronyms": [[77, 80]], "long-forms": [[51, 75]]}, {"text": "1 Introduction Since the introduction of BLEU (Papineni et al, 2002), automatic machine translation (MT) evaluation has received a lot of research interest.", "acronyms": [[101, 103], [41, 45]], "long-forms": [[80, 99]]}, {"text": "All the words were categorized  into three types: Lexicon words (LWs), Factoid  words (FTs), Named Entity (NEs). Accordingly, ", "acronyms": [[107, 110], [65, 68], [87, 90]], "long-forms": [[93, 105], [50, 63], [71, 85]]}, {"text": "We developed three ensemble learning approaches for recognizing disorder entities and a Vector Space Model based method for encoding. Our approaches achieved top rank in both subtasks, with the best F measure of 0.813 for entity recognition and the best accuracy of 74.1% for encoding, indicating the proposed approaches are promising.  1 Introduction  In recent years, clinical natural language processing (NLP) has received great attention for its critical role in unlocking information embedded in clinical documents. Leveraging such information can facilitate the secondary1 use of electronic health record (EHR) data to                                                      This work is licensed under a Creative Commons Attribution 4.0 International Licence.", "acronyms": [[408, 411], [612, 615]], "long-forms": [[379, 406], [586, 610]]}, {"text": " The actual performance of a system is measured in terms of detection error tradeoff (DET) curves and the minimal normalized cost.", "acronyms": [[86, 89]], "long-forms": [[60, 84]]}, {"text": "8. Strong forms of pronouns not preceded by preposition (unless they carry IC) t Table 1: Annotation guidelines; IC = Intonation Center 4.2 Evaluation framework", "acronyms": [[113, 115], [75, 77]], "long-forms": [[118, 135]]}, {"text": "Estimating Proficiency  Item Response Theory (IRT)  Item Response Theory (IRT) is the basis of modern  language tests such as TOEIC, and enables Com-", "acronyms": [[74, 77], [46, 49], [126, 131]], "long-forms": [[52, 72], [24, 44]]}, {"text": "Snow follows that of (Escudero et al, 2000c).  2.4 LazyBoost ing  (LB)  The main idea of boosting algorithms is to ", "acronyms": [[67, 69]], "long-forms": [[51, 60]]}, {"text": " 1 Introduction  Natural Language Generation (NLG) systems must of  course be evaluated, like all NLP systems.", "acronyms": [[46, 49], [98, 101]], "long-forms": [[17, 44]]}, {"text": "mender systems using a multidimensional approach.  ACM Transactions on Information Systems (TOIS), 23(1):103?145.", "acronyms": [[92, 96], [51, 54]], "long-forms": [[55, 90]]}, {"text": "ODQA system, SPIQA. The system derives disambiguating queries (DQs) that draw out additional information.", "acronyms": [[63, 66], [0, 4], [13, 18]], "long-forms": [[39, 61]]}, {"text": "=   where,   ij  is the term frequency(TF) of the j-th word  in the vocabulary in the document , i.e. the ", "acronyms": [[39, 41]], "long-forms": [[24, 37]]}, {"text": "Specifically, we achieve a roughly 10% improvement in precision on text from the information technology (IT) business press via post hoc rule-based error reduction.", "acronyms": [[105, 107]], "long-forms": [[81, 103]]}, {"text": " 2.6 Adverb  Group (AdvG)   Adverb group (AdvG) is used in the realization  of several circumstantial functions given in Sec- ", "acronyms": [[42, 46], [20, 24]], "long-forms": [[28, 40]]}, {"text": "end 1 <= V I ;   SPAN (SPANS, 'CONSTITUENTS ' ) = <TUP , CONSTITUENTS>;  TODO = TUP -t TODO;  r e t u r n ;  ", "acronyms": [[80, 83], [51, 54]], "long-forms": [[84, 86]]}, {"text": "therefore propose the joint optimisation of content selection and surface realisation using Hierarchical Reinforcement Learning (HRL). ", "acronyms": [[129, 132]], "long-forms": [[92, 127]]}, {"text": "637  Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 27?32, Sofia, Bulgaria, August 9, 2013.", "acronyms": [[70, 77]], "long-forms": [[36, 68]]}, {"text": "pound verb (CompV) is framed with these two  verbs. But, the second Light Verb (LV) may be  a part of another Complex Predicate (CP).", "acronyms": [[80, 82]], "long-forms": [[68, 78]]}, {"text": "error criteria: ? WER (word error rate): The WER is computed as the minimum", "acronyms": [[18, 21], [45, 48]], "long-forms": [[23, 38]]}, {"text": "SN = Sa-inflection oun (nominal verb)  CM = case marker (-nom/-acc argument)  PT = particle (other arguments)  VB = verb ", "acronyms": [[78, 80], [0, 2], [39, 41], [111, 113]], "long-forms": [[83, 91], [5, 22], [44, 55], [116, 120]]}, {"text": "ments. We experimented with several classifiers including: SVM, Logistic Regression (LR), and Naive Bayes.", "acronyms": [[85, 87], [59, 62]], "long-forms": [[64, 83]]}, {"text": "from standard formats to OpenNLP specific ones. We represented standard formats with EMF (an Ecore model for each one) and we created specific transformations using Java Emitter Templates (JET) 16", "acronyms": [[189, 192], [29, 32], [85, 88]], "long-forms": [[165, 187]]}, {"text": "2011.  Overview of the Infectious Diseases (ID) task of BioNLP Shared Task 2011.", "acronyms": [[44, 46], [56, 62]], "long-forms": [[23, 42]]}, {"text": "142 ? National University of Mongolia (NUM),  Mongolia ", "acronyms": [[39, 42]], "long-forms": [[6, 37]]}, {"text": "y) 7. Mutual dependency (MD) log P (xy)2P (x?)P (? y)", "acronyms": [[25, 27]], "long-forms": [[6, 23]]}, {"text": "Clear And Simple English (CASE) Caterpillar Fundamental English (CFE) Caterpillar Technical English (CTE) Diebold Controlled English (DCE)", "acronyms": [[101, 104], [26, 30], [65, 68], [134, 137]], "long-forms": [[70, 99], [0, 24], [32, 63], [106, 132]]}, {"text": "1 Introduction In this paper, we describe our submission to the Genia Event (GE) information extraction subtask of the BioNLP Shared Task.", "acronyms": [[77, 79], [119, 125]], "long-forms": [[64, 75]]}, {"text": "to ? constraints? in interactive topic models (ITM) (Hu et al, 2014).", "acronyms": [[47, 50]], "long-forms": [[21, 45]]}, {"text": "lead to over-fitting. Therefore, we propose another method, Probabilistic Soft Logic (PSL) (Broecheler et al, 2010).", "acronyms": [[86, 89]], "long-forms": [[60, 84]]}, {"text": "SaRAD .891 .919 .905 ALICE .961 .920 .940 Chang & Sch?utze (CS) .942 .900 .921 Nadeau & Turney (NT) .954 .871 .910", "acronyms": [[60, 62], [0, 5], [96, 98]], "long-forms": [[42, 58], [79, 94]]}, {"text": "did. We used files 1-270, 400-554, and 600-931 as source domain training data (STrain), files 271300 as source domain testing data (STest) and files", "acronyms": [[79, 85], [132, 137]], "long-forms": [[50, 72], [104, 130]]}, {"text": "Participants in this study included 39 children with typical development (TD) and 21 children with autism spectrum disorder (ASD). ASD was di-", "acronyms": [[125, 128], [74, 76], [131, 134]], "long-forms": [[99, 123], [53, 72]]}, {"text": "gel Balaban,  ? hsan Yal??nkaya Middle East Technical University, Ankara, Turkey and   ? mit Deniz Turan Anadolu University, Eski?ehir, Turkey  Corresponding author: dezeyrek@metu.edu.tr  Abstract  In this paper, we report on the annotation procedures we developed for annotating the Turkish Discourse Bank (TDB), an effort that extends the Penn Discourse Tree Bank (PDTB) annotation style by using it for annotating Turkish discourse. After a brief introduction to the TDB, we describe the annotation cycle and the annotation scheme we developed, defining which parts of the scheme are an extension of the PDTB and which parts are different.", "acronyms": [[308, 311], [367, 371], [470, 473], [607, 611]], "long-forms": [[284, 306], [341, 365]]}, {"text": "ambiguous word are included as features.  Medical Subject Headings (MeSH): The final feature is also specific to the biomedical do-", "acronyms": [[68, 72]], "long-forms": [[42, 66]]}, {"text": "These are the second-order prepositional complement (PC) and directional complement (LD) relations, and the first-order direct object (OBJ1) and subject (SU) relations. Finally, the setting SU+OBJ1 joins words obtained from subject", "acronyms": [[154, 156], [53, 55], [85, 87], [135, 138]], "long-forms": [[145, 152], [27, 51], [127, 133]]}, {"text": "consists of following elements: Topic  Number(NUM),Topic Title(TITLE),Topic  question(DESC),Topic Narrative(NARR) and  Topic Concepts(CONC).", "acronyms": [[108, 112], [63, 68], [46, 49], [86, 90], [134, 138]], "long-forms": [[98, 106], [57, 62], [39, 45], [125, 133]]}, {"text": "sources Tony Mullen and Nigel Collier National Institute of Informatics (NII) Hitotsubashi 2-1-2, Chiyoda-ku", "acronyms": [[73, 76]], "long-forms": [[38, 71]]}, {"text": "Syntactic features from SLA research (SLASYN) ? Mean length of clause (MLC) ?", "acronyms": [[71, 74], [24, 27], [38, 44]], "long-forms": [[48, 69]]}, {"text": "translation evaluation metrics such as BLEU score (Papineni et al, 2001), NIST score (Doddington, 2002) and Position Independent Word Error Rate (PER) (Och, 2002).", "acronyms": [[146, 149], [39, 43], [74, 78]], "long-forms": [[108, 144]]}, {"text": "5.2 Results We evaluate SO of words on three different sized corpora: Gigaword (GW) 6.2GB, GigaWord + 50% of web data (GW+WB1) 21.2GB and Gi-", "acronyms": [[80, 82], [24, 26], [119, 121], [122, 125]], "long-forms": [[70, 78]]}, {"text": " 1 Introduction Question answering (QA) has emerged as a practical research problem for pushing the boundaries", "acronyms": [[36, 38]], "long-forms": [[16, 34]]}, {"text": " In the RST framework, a text is first divided into several elementary discourse units (EDUs). Each", "acronyms": [[88, 92], [8, 11]], "long-forms": [[60, 86]]}, {"text": "SR+LM+SB 0.57 0.75 0.65 0.75 0.68 0.71 0.69 0.92 0.87 0.88 0.87 0.85 0.75 0.87 0.81 0.95 A0 - - - 0.85 - - - 0.93 - - - N/A - - - 0.97 Table 5: Alignment results for all datasets and configurations: Using semantic relations (SR), monosemous links (LM) or both (SR+LM).", "acronyms": [[225, 227], [120, 123], [248, 250], [261, 266]], "long-forms": [[205, 223], [230, 246]]}, {"text": "In l~,ooth's approach, the FSV is detined by re-  (:ursion on the truth conditional structure which  is itself derived from LF (i.e. Logical Form, the  Government and Binding level of semantic rep- ", "acronyms": [[124, 126], [27, 30]], "long-forms": [[133, 145]]}, {"text": "problem so that it includes finding the most probable corrections tags.  WDCLOREI arg max Pr( WDCLOREIIA ) WDCLOREI ", "acronyms": [[94, 104], [107, 115]], "long-forms": [[73, 89]]}, {"text": "5 Learning Algorithms We used two non-parametric learning approaches, Support Vector Machines (SVMs) (Shawe-Taylor and Cristianini, 2004) and Gaussian Processes (GPs)", "acronyms": [[95, 99], [162, 165]], "long-forms": [[70, 93], [142, 160]]}, {"text": "extrinsic and language independent features.  The student response analysis (SRA) task (Dzikovska et al 2013) addresses the fol-", "acronyms": [[77, 80]], "long-forms": [[50, 75]]}, {"text": "simardm@iro.umontreal.ca Abstract The term translation spotting (TS) refers to the task of identifying the target-language (TL)", "acronyms": [[65, 67]], "long-forms": [[43, 63], [107, 122]]}, {"text": "One part of the work is directed towards developing computational methods to facilitate the manual construction of SweFN. We have so far focused on three tasks: (1) semantic role labeling (SRL) (Johansson et al.,", "acronyms": [[189, 192], [115, 120]], "long-forms": [[165, 187]]}, {"text": " Figure 2 shows the learning curve for pseudoprojective parsing (P-Proj), compared to using only projectivized training data (Proj), measured as error", "acronyms": [[65, 71], [126, 130]], "long-forms": [[45, 63]]}, {"text": " 3. Construct a character list (CH)3, in which the characters are top 20 frequency in training", "acronyms": [[32, 34]], "long-forms": [[16, 25]]}, {"text": "There are two other functional tags which, unlike those listed above, can also be associated with numbered arguments in the frames files. The first one, EXT (extent), indicates that a constituent is a numerical argument on its verb, as in climbed 15%", "acronyms": [[153, 156]], "long-forms": [[158, 164]]}, {"text": "Previous shared tasks for grammar error correction, such as the HOO shared task of 2012 (HOO-2012) and the CoNLL-2013 shared task(CoNLL-2013),", "acronyms": [[89, 97], [130, 140], [107, 117]], "long-forms": [[64, 87]]}, {"text": "In Proceedings of the First International Conference on Language Resources and Evaluation (LREC), pages 581?588, Granada.", "acronyms": [[91, 95]], "long-forms": [[56, 74]]}, {"text": "of-the-art dependency parser, the 2014 online version. 4) PPAD Naive Bayes(NB) is the same as PPAD but uses a generative model, as opposed to", "acronyms": [[75, 77], [58, 62], [94, 98]], "long-forms": [[63, 73]]}, {"text": "mance figures are the standard measures used for this task: F-measure (harmonic mean of recall and precision) and slot error rate (SER), where separate type, extent and content error measures are averaged to get the reported result.", "acronyms": [[131, 134]], "long-forms": [[114, 129]]}, {"text": "services (person or company information bureau), ht this  situation, the event aml the attitude of file inforumtion  possessor (IP) is transported to a speaker (SP);journalist. ", "acronyms": [[161, 163], [128, 130]], "long-forms": [[152, 159], [104, 126]]}, {"text": "(DE), Greek (EL), English (EN), Spanish (ES), French (FR), Italian (IT), Korean (KO), Dutch (NL), Portugese (PT), Russian (RU), Swedish (SV) and Chinese (ZH) ?", "acronyms": [[123, 125], [1, 3], [13, 15], [27, 29], [41, 43], [54, 56], [68, 70], [81, 83], [93, 95], [109, 111], [137, 139], [154, 156]], "long-forms": [[114, 121], [18, 25], [32, 39], [46, 52], [59, 66], [73, 79], [86, 91], [98, 107], [128, 135], [145, 152]]}, {"text": "discourse analysis phase, the situation  frame is interpreted, resulting in one or  more instantiated knowledge base (KB)  objects, which are state or event ", "acronyms": [[118, 120]], "long-forms": [[102, 116]]}, {"text": "transmission envelope; the German and Portuguese services  are sent in the transmission enveloped esigned by the  International Press Telecommunications Council (IPTC). ", "acronyms": [[162, 166]], "long-forms": [[114, 160]]}, {"text": "1 25   2. Loca l  Word  Grouper  (LWG)  The funct ion  of th i s  b lock  is to fo rm ", "acronyms": [[34, 37]], "long-forms": [[10, 31]]}, {"text": "egie Group, Inc. (CGI) of Pittsburgh, PA is to promote  and further develop automatic Text Summarization  using a Maximal Marginal Relevance (MMR) metric to  generate summaries of documents hat are directly rele- ", "acronyms": [[142, 145], [18, 21], [38, 40]], "long-forms": [[114, 140]]}, {"text": "3.4 The  NATO Research  Study  Group  on  Speech  Process ing   The North Atlantic Treaty Organization (NATO) Re-  search Study Group on Speech Processing (RSG10) \\[87\\], ", "acronyms": [[104, 108], [9, 13], [156, 161]], "long-forms": [[68, 102], [110, 154]]}, {"text": "The word nchi is dis-  ambiguated with a rule relying on the Ncl of the  following genitive connector (GEN-CON). ", "acronyms": [[103, 110], [61, 64]], "long-forms": [[83, 101]]}, {"text": "Here we perform a set of experiments where we investigate the potential of multi-source transfer for NER, in German (DE), English (EN), Spanish (ES) and Dutch (NL), using cross-lingual", "acronyms": [[131, 133], [101, 104], [117, 119], [145, 147], [160, 162]], "long-forms": [[122, 129], [109, 115], [136, 143], [153, 158]]}, {"text": "wsj_1286)) In addition to the semantic roles described in the rolesets, verbs can take any of a set of general, adjunct-like arguments (ArgMs), distinguished by one of the function tags shown in Table 1.", "acronyms": [[136, 141]], "long-forms": [[125, 134]]}, {"text": "data with which to test research hypotheses. We de-  scribe the Air Travel Information System (ATIS) pilot  corpus, a corpus designed to measure progress in Spo- ", "acronyms": [[95, 99]], "long-forms": [[64, 93]]}, {"text": "Test Data Method Accuracy leave-one-out Minnen et al 83.58% Language Model (LM) 86.74% tenfold on development LM 84.72%", "acronyms": [[76, 78], [110, 112]], "long-forms": [[60, 74]]}, {"text": "Many different algorithms  have been used for this task, including some  machine learning (ML) algorithms, such as  Na?ve Bayesian model, decision trees, and ", "acronyms": [[91, 93]], "long-forms": [[73, 89]]}, {"text": "of the Spanish language. Our experimental project is a collaboration  of the Royal Spanish Academy (R.A.E.) and the Computer Center of  the University of Madrid (CCVM).", "acronyms": [[100, 106], [162, 166]], "long-forms": [[77, 98], [116, 160]]}, {"text": " P rev ious  Accomplishments  We have previously constructed a UNIX Consultant (UC), an intelligent NL-capable \"help\"  facility that allows naive users to learn about the UNIX operating system.", "acronyms": [[80, 82], [100, 102], [171, 175]], "long-forms": [[63, 78]]}, {"text": "the left hand side (LHS) of the rule, and ? the right hand side (RHS) of the rule.", "acronyms": [[65, 68], [20, 23]], "long-forms": [[48, 63], [4, 18]]}, {"text": "Hajdinjak and Mihelic? The PARADISE Evaluation Framework Number of help messages (NHM) and help-message ratio (HMR), i.e., the number and the ratio of system?s help messages;", "acronyms": [[82, 85], [111, 114]], "long-forms": [[57, 80], [91, 109]]}, {"text": "(Suchanek et al 2007) have been playing a pivotal role in many AI applications, such as relation extraction(RE), question answering(Q&A), etc. ", "acronyms": [[132, 135], [108, 110], [63, 65]], "long-forms": [[113, 130], [88, 107]]}, {"text": "for a comprehensive comparison: ? Mean absolute error (MAE) measures how closely predictions resemble their observed", "acronyms": [[55, 58]], "long-forms": [[34, 53]]}, {"text": "word sense disambiguation. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 27(7):1063?1074.", "acronyms": [[91, 95], [27, 31]], "long-forms": [[48, 89]]}, {"text": " 1 Introduction Assigning each word its most frequent sense (MFS) is commonly used as a baseline in Word Sense Dis-", "acronyms": [[61, 64]], "long-forms": [[40, 59]]}, {"text": "It has emerged in the context of information extraction (IE) and text mining (TM). The automatic recog-", "acronyms": [[78, 80], [57, 59]], "long-forms": [[65, 76], [33, 55]]}, {"text": "the use of lexical cohesion devices in each version of MT and HT in terms of the following two ratios, LC = lexical cohesion devices / content words, RC = repetition / content words.", "acronyms": [[103, 105], [55, 57], [62, 64], [150, 152]], "long-forms": [[108, 124], [155, 175]]}, {"text": " 1 Introduction Statistical machine translation (SMT) relies on tokenization to split sentences into meaningful units", "acronyms": [[49, 52]], "long-forms": [[16, 47]]}, {"text": "DS = Discharge Summary,  Echo = Echocardiogram, ED = Emergency Department,  GI = Operative Gastrointestinal, RAD = Radiology and  SP = Surgical Pathology. (%)", "acronyms": [[109, 112], [0, 2], [25, 29], [48, 50], [76, 78], [130, 132]], "long-forms": [[115, 128], [5, 22], [32, 46], [53, 73], [91, 107], [135, 153]]}, {"text": "inference procedures?Markov Chain Monte Carlo (MCMC) (Johnson et al 2012), Expectation Maximization (EM), and Variational Bayes (VB)10?as well as the discourse-level model described above.", "acronyms": [[129, 131], [47, 51], [101, 103]], "long-forms": [[110, 127], [21, 45], [75, 99]]}, {"text": "and opportunities. In Proceedings of the 1st International Temporal Web Analytics Workshop (TWAW), pages 1?8.", "acronyms": [[92, 96]], "long-forms": [[59, 90]]}, {"text": " In this paper, we will study how to adapt a general Hidden Markov Model (HMM)-based NE recognizer (Zhou and Su 2002) to biomedical domain.", "acronyms": [[74, 77], [85, 87]], "long-forms": [[53, 72]]}, {"text": "P,,nnsylvania (UPenn) Treebank. We plan to include  the parsed ICE-GB (Great Britain component of ICE)  and the BNC (British National Corpus) in the project ", "acronyms": [[67, 69], [98, 101], [112, 115], [15, 20]], "long-forms": [[71, 84], [117, 140], [0, 13]]}, {"text": "(SO) weighting in the spirit of (Zhang et al, 2007; Li et al, 2007), and finally (f) the same system but with the target order (TO) weighting. ", "acronyms": [[128, 130], [1, 3]], "long-forms": [[114, 126], [73, 80]]}, {"text": "we use the DUC2002 and DUC2004 data sets, both of which are open benchmark data sets from Document Understanding Conference (DUC) for generic automatic summarization evaluation.", "acronyms": [[125, 128], [11, 14], [23, 26]], "long-forms": [[90, 123]]}, {"text": "gold label (Section 3). Our algorithm is called The Structured Weighted Violations Perceptron (SWVP) as its update rule is based on a weighted sum of up-", "acronyms": [[95, 99]], "long-forms": [[52, 93]]}, {"text": "Three transliteration models have been used that  can generate the Hindi transliteration from an  English named entity (NE). An English NE is ", "acronyms": [[120, 122], [136, 138]], "long-forms": [[106, 118]]}, {"text": "? Rule One. For the first noun phrase (NP) encountered by the system, if 1) this NP has a name entity", "acronyms": [[39, 41]], "long-forms": [[26, 37]]}, {"text": "fast method to train SVM. SMO breaks the large  quadratic programming (QP) optimization problem needed to be resolved in SVM into a series ", "acronyms": [[71, 73], [21, 24], [26, 29], [121, 124]], "long-forms": [[48, 69]]}, {"text": "implementation of SVM.  Lexical Classifier (LC): This method calculates the number of positive words and negative words", "acronyms": [[44, 46]], "long-forms": [[24, 42]]}, {"text": "To train models using this information we use 870 generalized expectation (GE) criteria. GE criteria", "acronyms": [[75, 77], [89, 91]], "long-forms": [[50, 73]]}, {"text": "Phrase Extrac\"on GIZA++ Figure 3: Building a twin phrase table (PT). First, sep-", "acronyms": [[64, 66], [17, 23]], "long-forms": [[50, 62]]}, {"text": "Schu?tze reduces the dimensionality of this feature space using Singular Value Decomposition (SVD), which is also employed by related techniques such as Latent Semantic Indexing (Deerwester et", "acronyms": [[94, 97]], "long-forms": [[64, 92]]}, {"text": "  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1804?1809, October 25-29, 2014, Doha, Qatar.", "acronyms": [[90, 95]], "long-forms": [[40, 88]]}, {"text": " This named-entity tagger program is based on a first order Maximum Entropy Markov Model (MEMM) and is described in Yoshida and Tsujii (2007).", "acronyms": [[90, 94]], "long-forms": [[60, 88]]}, {"text": "In frame semantics, the meaning of words or word expressions, also called target words (TW), comprises aspects of conceptual structures, or frames, that de-", "acronyms": [[88, 90]], "long-forms": [[74, 86]]}, {"text": " 1 Introduction The RST Discourse Treebank (RST-DT) (Carlson et al, 2001), based on the Rhetorical Struc-", "acronyms": [[44, 50]], "long-forms": [[20, 42]]}, {"text": " ? Generat ionCoverage(GC).Thepercentageofcoml) lete  and correct iuterlingna expressions R}r which the gener- ", "acronyms": [[23, 25]], "long-forms": [[3, 21]]}, {"text": " This is reflected in the query focused tasks run in the Document Understanding Conference (DUC) and Text Analysis Conference (TAC) over the past", "acronyms": [[92, 95], [127, 130]], "long-forms": [[57, 90], [101, 125]]}, {"text": "340   Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 37?45, Gothenburg, Sweden, April 26-30 2014.", "acronyms": [[91, 96], [25, 29]], "long-forms": [[47, 89]]}, {"text": "social media. In Proceedings of the ACM International Conference on Web Search and Data Mining (WSDM), pages 291?300.", "acronyms": [[96, 100]], "long-forms": [[68, 94]]}, {"text": " BIBLIOGRAPHY  ALPAC (Automatic Language Processing Advisory Committee)  1966 Lanquage and Machines - Computers i n  Translation and Linguistics ", "acronyms": [[15, 20]], "long-forms": [[22, 70]]}, {"text": " They use Only Word-Seg (OWS), Whole Layer Weight (WLW), SC (SC) and FeedBack mechanism (FB) separately.", "acronyms": [[51, 54], [25, 28], [57, 59], [61, 63], [89, 91]], "long-forms": [[43, 49], [10, 23], [69, 77]]}, {"text": " 2.2 W3C Semantic Web The World Wide Web (WWW) was once designed to be as simple, as decentralized and as interop-", "acronyms": [[42, 45], [5, 8]], "long-forms": [[26, 40]]}, {"text": "The proposals directly affect the organization o f   groups w i t h i n  EOP including the Office of Telecommmicatians Policy  (UP) ; the 0fiice of Science and Technology Policy (OSTP) ; the Intergovernmental  Science, Engineering, and Technology Advisory Panel (ISETAP) ; the President s ", "acronyms": [[179, 183], [73, 76], [128, 130], [263, 269]], "long-forms": [[138, 177], [191, 260]]}, {"text": " 1 Introduction Biomedical Text Mining (TM) has become increasingly popular due to the pressing need to provide", "acronyms": [[40, 42]], "long-forms": [[27, 38]]}, {"text": "tation for the joint learning process. Specifically, we make use of the latent structural SVM (LS-SVM) (Yu and Joachims, 2009) formulation.", "acronyms": [[95, 101]], "long-forms": [[72, 93]]}, {"text": "the train and development sets in MC160 and MC500 and split them randomly into a 250-story training set (TRAIN) and a 200-story development set (DEV).", "acronyms": [[105, 110], [34, 39], [44, 49], [145, 148]], "long-forms": [[91, 99], [128, 139]]}, {"text": "Pos i t i ve  Recal l  (PR)  :  ? Pos i t ive  Prec is ion  (PP)  :  d ?", "acronyms": [[61, 63], [24, 26]], "long-forms": [[34, 58], [0, 21]]}, {"text": " 1 Introduction In statistical machine translation (SMT) reordering (also called distortion) refers to the order in", "acronyms": [[52, 55]], "long-forms": [[19, 50]]}, {"text": "3 Bayes ian  networks   A Bayes ian  network  (Pearl, 1988), or  Bayesian 1)el|el nel;work (BBN),  eonsisi;s of a sol;  of var iab les  and a sel; of d i rec ted  edges  (:on- ", "acronyms": [[92, 95]], "long-forms": [[65, 90]]}, {"text": "Query key words and concepts Token and concept Indexing Knowledge Source Adapters (KSAs)   integrate and deliver content from ", "acronyms": [[83, 87]], "long-forms": [[56, 81]]}, {"text": "for the discrimination of similar languages: The DSL corpus collection. In Proceedings of The Workshop on Building and Using Comparable Corpora (BUCC), Reykjavik, Iceland. ", "acronyms": [[145, 149], [49, 52]], "long-forms": [[106, 143]]}, {"text": "Figure 3: Dialogue system architecture    The Dialogue Manager (DM) uses sceneobject attributes, such as type, angle or interval ", "acronyms": [[64, 66]], "long-forms": [[46, 62]]}, {"text": "\u0000 OBST(obstacle): The boy stumbled over a stumb.  \u0000 INTT (intent): He came there to look for Jane. ", "acronyms": [[52, 56], [2, 6]], "long-forms": [[58, 64], [7, 15]]}, {"text": "We would expect this to be the case in general, but as always, cases exist where a conflict between a contrast (CoCo) and a change to a method (PModi) occur:", "acronyms": [[112, 116], [144, 149]], "long-forms": [[83, 110]]}, {"text": "is placed sixth out of seventeen systems according to Mean Absolute Error (MAE) and third according to Root Mean Squared Error (RMSE). The", "acronyms": [[128, 132], [75, 78]], "long-forms": [[103, 126], [54, 73]]}, {"text": "generation of textual descriptions from visual data, robot navigation tasks, giving directional instructions, and geographical information systems (GIS). ", "acronyms": [[148, 151]], "long-forms": [[114, 146]]}, {"text": "These derivations were induced using a collapsed Gibbs sampler, which sampled from the posterior of a Dirichlet process (DP) defined over the subtree rewrites of each nonterminal.", "acronyms": [[121, 123]], "long-forms": [[102, 119]]}, {"text": " 3 Results and Discussions Chain frequency (CF) and chain length (CL) reflect the dyad?s tweeting behaviors.", "acronyms": [[44, 46], [66, 68]], "long-forms": [[27, 42], [52, 64]]}, {"text": "baseline (BAS) system which is close to the system described in (Hu et al 2009), and three variants of our novel divide and conquer (DAC) system. Fea-", "acronyms": [[133, 136], [10, 13]], "long-forms": [[113, 131], [0, 8]]}, {"text": "Kanayama et al99 Probabilistic model (ME + HPSG) EDR (192,778) 88.55 Haruno et al98 Probabilistic model (DT + Boosting) EDR (50,000) 85.03 Fujio et al98 Probabilistic model (ML) EDR (190,000) 86.67 Table 4: Comparison with the related work", "acronyms": [[174, 176], [38, 40], [43, 47], [49, 52], [105, 107], [120, 123], [178, 181]], "long-forms": [[167, 172]]}, {"text": " As with most modern simulators, DISs are controlled via  graphical user interfaces (GUIs). However, the simulation ", "acronyms": [[85, 89], [33, 37]], "long-forms": [[58, 83]]}, {"text": "Recently, a larger set of word relatedness judgments was obtained by (Finkelstein et al, 2002) in the WordSimilarity-353 (WS-353) collection. Despite the", "acronyms": [[122, 128]], "long-forms": [[102, 120]]}, {"text": "hauer, haver, haber) and the corpus does not contain any other linguistic information, such as lemma and part of speech (PoS). ", "acronyms": [[121, 124]], "long-forms": [[105, 119]]}, {"text": " cs.uni-kassel.de/bibsonomy/dumps Content Relevance (CRM) model (Iwata et al, 2009) and Tag Allocation Model (TAM) (Si et al,", "acronyms": [[53, 56], [110, 113]], "long-forms": [[34, 51], [88, 108]]}, {"text": "ratings of IP strategies. In the following we use a Reinforcement Learning (RL) as a statistical planning framework (Sutton and Barto,", "acronyms": [[76, 78], [11, 13]], "long-forms": [[52, 74]]}, {"text": "Adding valency filtering to the setting in the preceding row. SUC = Subset of Stockholm-Umea? corpus of", "acronyms": [[62, 65]], "long-forms": [[68, 87]]}, {"text": "tracting sentence plan construction rules from the only publicly available corpus of discourse trees, the RST Discourse Treebank (RST-DT) (Carlson et al, 2002).", "acronyms": [[130, 136]], "long-forms": [[106, 128]]}, {"text": "PROD = Predicate $SUBJ -- SUBJECT value of feature ~OL  DET = Determiner NO = Noun Phrase (B~R I)  ADJ = Adjective GD = Gender  NU '~= Number PS = Person ", "acronyms": [[115, 117], [0, 4], [17, 22], [52, 54], [56, 59], [73, 75], [99, 102], [128, 130], [142, 144]], "long-forms": [[120, 126], [7, 16], [26, 33], [62, 72], [78, 82], [105, 114], [135, 141], [147, 153]]}, {"text": "given topic.  The Maximal Marginal Relevance (MMR) summarization method, which is based on a", "acronyms": [[46, 49]], "long-forms": [[18, 44]]}, {"text": " We focus on the following languages: German (DE), French (FR), Italian (IT), and Dutch (NL).", "acronyms": [[59, 61], [73, 75], [46, 48], [89, 91]], "long-forms": [[51, 57], [64, 71], [38, 44], [82, 87]]}, {"text": "\\[ Extra~:~nouns I IE~rac~'~ n?unsl i Calculating f requ~ vectors (FreqVa) I ICalculating frequency vectors (FreqVe)l  ._1 Calculating similarity I ", "acronyms": [[109, 115], [67, 73]], "long-forms": [[90, 107], [50, 65]]}, {"text": " 50 missed OG events were labeled as Past (PA) while FU events were commonly mislabeled as both PA", "acronyms": [[43, 45], [11, 13], [53, 55], [96, 98]], "long-forms": [[37, 41]]}, {"text": "2003). Recently, Huang et al (2015) showed that building a conditional random field (CRF) layer on top of bidirectional LSTM-RNNs performs com-", "acronyms": [[85, 88], [120, 129]], "long-forms": [[59, 83]]}, {"text": "from the remaining pool of data.  The intrinsic stopping criterion (ISC) we propose here focuses on the latter aspect of the ideal stop-", "acronyms": [[68, 71]], "long-forms": [[38, 66]]}, {"text": "On the standard view in transformational theory (Chomsky, 1981) both subject raising and object raising, or Exceptional Case Marking (ECM), cases are explained by the same principles.", "acronyms": [[134, 137]], "long-forms": [[108, 132]]}, {"text": "of the adjacency pair involving speaker B, we use four categories of features: structural, durational, lexical, and dialog act (DA) information. For the", "acronyms": [[128, 130]], "long-forms": [[116, 126]]}, {"text": "come. 2008. Deciding strictly local (SL) languages.", "acronyms": [[37, 39]], "long-forms": [[21, 35]]}, {"text": "namely person name, location name, organization name and miscellaneous name to apply  Support Vector Machine (SVM) based machine  learning technique.", "acronyms": [[110, 113]], "long-forms": [[86, 108]]}, {"text": "on a questionnaire provided to them. And a Mean Opinion Score(MoS) of 62.27% was achieved.", "acronyms": [[62, 65]], "long-forms": [[43, 61]]}, {"text": " verb. The third is end position (EP), after a predi-  cate.", "acronyms": [[34, 36]], "long-forms": [[20, 32]]}, {"text": "quency and its character string frequency is  less than or equal to 1%, it is a SWBS;  BMM-ASM (BMM ambiguity string mapping  table: the BMM-ASM table lists all the ", "acronyms": [[87, 94], [137, 144], [80, 84]], "long-forms": [[96, 124]]}, {"text": "Adverb Variation (AdvV) ? Modifier Variation (ModV) ?", "acronyms": [[46, 50]], "long-forms": [[26, 44]]}, {"text": "translation architecture, was developed under sponsorship from  Swedish Telecom by a collaboration between SRI International,  the Swedish Institute of Computer Science (SICS), and Telia  Research.", "acronyms": [[170, 174], [107, 110]], "long-forms": [[131, 168]]}, {"text": "Output (0 < x < 1)  Figure 3  Neural network architecture (DA = descriptor array of 20 items). ", "acronyms": [[59, 61]], "long-forms": [[64, 80]]}, {"text": "known as NP The corpus of English Wikipedia pages, known as EnWiki NP ( * NP) Hidden Markov Model (HMM) is used to solve ...", "acronyms": [[99, 102], [74, 76], [67, 69], [9, 11]], "long-forms": [[78, 97]]}, {"text": "Minimum Sub-Structure (MSS) 87.95 87.88 Context-Sensitive MSS (CMSS) 89.11 89.01 Chunking Tree (CT) 86.17 86.21 Linear Features (Kl) 90.79 90.46", "acronyms": [[96, 98], [23, 26], [58, 61], [63, 67], [129, 131]], "long-forms": [[81, 94], [0, 21]]}, {"text": "triplet model since it is based on word triplets, is not trained discriminatively but uses the classical maximum likelihood approach (MLE) instead. ", "acronyms": [[134, 137]], "long-forms": [[105, 123]]}, {"text": "gramming for probabilistic programming. In International Workshop on Statistical Relational AI (StarAI). ", "acronyms": [[96, 102]], "long-forms": [[69, 94]]}, {"text": "representation and transformation are necessary.  (2)  Latent Semantic Indexing (LSI) without  transformation (LSI-Com): we first merge the ", "acronyms": [[81, 84], [111, 118]], "long-forms": [[55, 79]]}, {"text": "quency weighted recall evaluation. We used a  Japanese frequency dictionary (FD) generated  from the Japanese EDR corpus (Isahara, 2007) to ", "acronyms": [[77, 79]], "long-forms": [[55, 75]]}, {"text": "learning is straightforward.  Very Reduced Regular Expression (VRRE):  Given a finite alphabet E,  the set of very ", "acronyms": [[63, 67]], "long-forms": [[30, 61]]}, {"text": "(BN) dev04f, rt03 and rt04 task using the stateof-the-art acoustic models trained on the English Broadcast News (BN) corpus (430 hours of audio) provided to us by IBM (Chen et al, 2009).", "acronyms": [[113, 115], [1, 3], [163, 166]], "long-forms": [[97, 111]]}, {"text": "on the labels from DSlabels+MinCut: (4) MaxEnt with named entities (NE); (5) MaxEnt with NE and semantic (SEM) features; (6) CRF with NE; (7) MaxEnt with NE and sequential (SQ) features;", "acronyms": [[106, 109], [68, 70], [89, 91], [125, 128], [134, 136], [142, 148], [154, 156], [173, 175], [40, 46]], "long-forms": [[96, 104], [52, 66]]}, {"text": "Broadcast News (BN), Newswire (NW), Broadcast Conversation (BC), Telephone Conversation (TC), Web Blog (WB) and Magazine (MZ). ", "acronyms": [[104, 106], [122, 124]], "long-forms": [[94, 102], [112, 120]]}, {"text": " 2.1 Named Entity Recognition We regard named entity recognition (NER) as a standalone task, independent of language identification.", "acronyms": [[66, 69]], "long-forms": [[40, 64]]}, {"text": "Abstract   In recent years, statistical approaches on  ATR (Automatic Term Recognition) have  achieved good results.", "acronyms": [[55, 58]], "long-forms": [[60, 86]]}, {"text": "unable to touch the robot?s screen or to verbalize a speech command (e.g. after a stroke) is the brain computer interface (BCI) of the robot (Hintermu?ller et al, 2011).", "acronyms": [[123, 126]], "long-forms": [[97, 121]]}, {"text": " 1 Introduction Question answering(QA) system aims at finding exact answers to a natural language question.", "acronyms": [[35, 37]], "long-forms": [[16, 33]]}, {"text": "c?2008 Association for Computational Linguistics Dialect Classification for online podcasts fusing Acoustic and Language based Structural and Semantic Information   Rahul Chitturi, John. H.L. Hansen1 Center for Robust Speech Systems(CRSS) Erik Jonsson School of Engineering and Computer Science University of Texas at Dallas Richardson, Texas 75080, U.S.A {rahul.ch@student, john.hansen@}utdallas.edu Abstract  The variation in speech due to dialect is a factor which significantly impacts speech system per-formance.", "acronyms": [[233, 237], [350, 355]], "long-forms": [[200, 231]]}, {"text": " 6 Over Segmentation  For wrongly spelled or OOV (out of vocabulary)  Urdu words, the system may forcibly break the ", "acronyms": [[45, 48]], "long-forms": [[50, 67]]}, {"text": "For aviation incidents, the advantage of the proposed prior is reflected in the location (LO) and country (CO) slots, which may confuse the various models as they both belong to the entity type loca-", "acronyms": [[107, 109], [90, 92]], "long-forms": [[98, 105], [80, 88]]}, {"text": "scoring n-grams in the sentence.  Mean logprob (ML) This score is the logprob of the entire sentence divided by the length of the", "acronyms": [[48, 50]], "long-forms": [[34, 46]]}, {"text": "  Abstract  Named entity recognition (NER) is nowadays an important task, which is responsi-", "acronyms": [[38, 41]], "long-forms": [[12, 36]]}, {"text": "below.  4.3.1 English Noun Compounds (ENC) Our first dataset is made up of 90 binary English", "acronyms": [[38, 41]], "long-forms": [[14, 36]]}, {"text": " 2.2 LNRE Nature  o f  the  Data   The LNRE (Large Number of Rare Events)  zone (Chitashvili & Baayen, 1993) is defined as ", "acronyms": [[39, 43], [5, 9]], "long-forms": [[45, 72]]}, {"text": "sity is developing the English Resource Grammar, an HPSG grammar for English, as a part of the Linguistic Grammars Online (LinGO) project (Flickinger, 2000).", "acronyms": [[123, 128], [52, 56]], "long-forms": [[95, 121]]}, {"text": "the Association for Computational Linguistics (ACL) and 17th International Conference on Computational Linguistics (COLING) 1998, pages 41?47, Montre?al.", "acronyms": [[116, 122], [47, 50]], "long-forms": [[89, 114], [4, 45]]}, {"text": "representation, a Partial-Lattice Markov Random Field (PL-MRF), which is a tractable variation of a Factorial Hidden Markov Model (HMM) for language modeling.", "acronyms": [[131, 134], [55, 61]], "long-forms": [[110, 129], [18, 53]]}, {"text": "mid method in DUC 2005. Proceedings of the 5th Document Understanding Conference (DUC). Van-", "acronyms": [[82, 85], [14, 17]], "long-forms": [[47, 80]]}, {"text": "Visweswariah et al (2011) regarded the preordering problem as a Traveling Salesman Problem (TSP) and applied TSP solvers for obtaining reordered words.", "acronyms": [[92, 95], [109, 112]], "long-forms": [[64, 90]]}, {"text": "User-generated content (UGC), and specially the microblog genre, has become an interesting resource for Natural Language Processing (NLP) tools and applications.", "acronyms": [[133, 136], [24, 27]], "long-forms": [[104, 131], [0, 22]]}, {"text": "In Proc. 6th Canadian Conf on AI (CSCSI-86), pp. 78?83.", "acronyms": [[34, 42], [45, 47]], "long-forms": [[13, 32]]}, {"text": "We conduct an extrinsic evaluation to compare  the different versions of ArSenL on the task of  subjectivity and sentiment analysis (SSA). We ", "acronyms": [[133, 136], [73, 79]], "long-forms": [[96, 131]]}, {"text": " 3 BUDS dialogue manager The Bayesian Update of Dialogue State (BUDS) dialogue manager is a POMDP-based dialogue", "acronyms": [[64, 68], [3, 7], [92, 97]], "long-forms": [[29, 62]]}, {"text": "appear in the labeled training data. In this paper, we call their method the latent variable method (LVM). ", "acronyms": [[101, 104]], "long-forms": [[77, 99]]}, {"text": "to the Markov Logic system. At each step, we compute both the maximum a posteriori (MAP) assignment of coreference relationships as well", "acronyms": [[84, 87]], "long-forms": [[62, 82]]}, {"text": "a topic model are compared. Latent Dirichlet Allocation (LDA) (Blei et al 2003) is a widely used type of topic model in which documents can be", "acronyms": [[57, 60]], "long-forms": [[28, 55]]}, {"text": "We use two different windows to define a triggering environment: one for morpheme and another for its part of speech (POS) tag. Figure 2 shows ", "acronyms": [[118, 121]], "long-forms": [[102, 116]]}, {"text": "we describe SCANMail, a system that employs automatic speech recognition (ASR), information retrieval (IR), information extraction (IE), and human computer interaction (HCI) technology to permit users to browse and search their voicemail messages by content", "acronyms": [[169, 172], [12, 20], [74, 77], [103, 105], [132, 134]], "long-forms": [[141, 167], [44, 72], [80, 101], [108, 130]]}, {"text": "Net?s ontological concepts and the correct sense of each word assigned by a Word Sense Disambiguation(WSD) module to extract three sets of pat-", "acronyms": [[102, 105]], "long-forms": [[76, 100]]}, {"text": "tion results in a better AER. Running ALP with deletion (TD) templates followed by multi-word (TMW ) templates results in a lower AER than running ALP", "acronyms": [[57, 59], [25, 28], [38, 41], [130, 133], [147, 150], [95, 98]], "long-forms": [[47, 55], [61, 93]]}, {"text": "Next subsections show the results obtained by TIPSem system in each one of the TempEval-2 tasks for English (EN) and Spanish (ES). More-", "acronyms": [[109, 111], [46, 52], [79, 89], [126, 128]], "long-forms": [[100, 107], [117, 124]]}, {"text": "\\[Harman, 1996\\] D. Harman. Overview of the Forth  Text RetrievalConference (TREC-4). In Proceedings ", "acronyms": [[77, 83]], "long-forms": [[44, 75]]}, {"text": "2.2 Conditional Random Fields Conditional random field (CRF) was an extension of both Maximum Entropy Model (MEMs) and Hidden Markov Models (HMMs) that was firstly", "acronyms": [[109, 113], [56, 59], [141, 145]], "long-forms": [[86, 107], [30, 54], [119, 139]]}, {"text": "to learn coherent topics. To solve this problem, we build a Markov Random Field (MRF) regularized Latent Dirichlet Allocation (LDA)", "acronyms": [[81, 84], [127, 130]], "long-forms": [[60, 79], [98, 125]]}, {"text": "VNMT 32.25 34.50++ 33.78++ 36.72?++ 30.92?++ 24.41?++ 32.07 Table 1: BLEU scores on the NIST Chinese-English translation task. AVG = average BLEU scores on test sets. We", "acronyms": [[141, 145], [0, 4], [69, 73], [88, 92], [127, 130]], "long-forms": [[133, 140]]}, {"text": "PP) MDI Missed Samples (MS) Bigram Missed Samples (MS) Figure 4: Values of PP and MS for automata for ad-hoc automata", "acronyms": [[51, 53], [0, 2], [4, 7], [24, 26], [82, 84], [75, 77]], "long-forms": [[35, 49], [8, 22]]}, {"text": "tempered EM (TEM) [8] algorithm, instead of a naive one, to avoid this problem. TEM algorithm is closely related to the deterministic annealing EM (DAEM) algorithm [17], and helps avoid local extrema by introducing inverse temperature ?.", "acronyms": [[148, 152], [13, 16], [80, 83]], "long-forms": [[120, 146], [0, 11]]}, {"text": "The language is defined by about 50 simple grammar rules. ? P5E2N3S4, F W A Standard Language (SLANG). See Section 4.1. ?", "acronyms": [[95, 100]], "long-forms": [[76, 93]]}, {"text": "139  Computational Linguistics Volume 18, Number 2  (18a) sense of JUMP = jumping. ", "acronyms": [[67, 71]], "long-forms": [[74, 81]]}, {"text": "frequency pairs, Erk et al(2010) drew (R, t)  pairs from each of five frequency bands in the  entire British National Corpus (BNC):  50-100  occurrences; 101-200; 201-500; 500-1000; and ", "acronyms": [[126, 129]], "long-forms": [[101, 124]]}, {"text": "? Toral (2013) explores the selection of data to train domain-specific language models (LM) from non-domain specific corpora by means", "acronyms": [[88, 90]], "long-forms": [[71, 86]]}, {"text": "to be relevant: 1. Subject (SS) 2.", "acronyms": [[28, 30]], "long-forms": [[19, 26]]}, {"text": "interchange of LRs. It also demonstrate how MLI  can be applied to Asian Language Resource (ALR)  through making the results of collaborative en-", "acronyms": [[92, 95], [15, 18], [44, 47]], "long-forms": [[67, 90]]}, {"text": " We perform our analyses on data from the 20082011 Text Analysis Conference (TAC)1 organized by the National Institute of Standards and Technol-", "acronyms": [[77, 80]], "long-forms": [[51, 75]]}, {"text": "{alexispalmer,ponvert,jbaldrid,carlotasmith}@mail.utexas.edu Abstract Situation entities (SEs) are the events, states, generic statements, and embedded facts and", "acronyms": [[90, 93]], "long-forms": [[70, 88]]}, {"text": "The MRF provides the base frame to  combine various statistical information  with maximum entropy (ME) method. ", "acronyms": [[99, 101], [4, 7]], "long-forms": [[82, 97]]}, {"text": "AVERAGE 3.31 316 72.58% 78.02% 84.65% Table 2: Word sense disambiguation results, including two baselines (MFS = most frequent sense; LeskC = Lesk-corpus) and the word sense disam-", "acronyms": [[107, 110], [134, 139]], "long-forms": [[113, 132], [142, 153]]}, {"text": "SC is mainly used in  mainland China while TC is mainly used in Taiwan  and Hong Kong (HK). In this experiment, we further ", "acronyms": [[87, 89], [0, 2], [43, 45]], "long-forms": [[76, 85]]}, {"text": "1 Introduction We extend a popular model, latent Dirichlet al location (LDA), to unbounded streams of documents.", "acronyms": [[72, 75]], "long-forms": [[42, 70]]}, {"text": "of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP), pages 342?350, Singapore.", "acronyms": [[99, 109], [7, 10], [92, 97]], "long-forms": [[23, 84]]}, {"text": "selection (FS). For word-level prediction, generalised linear models (GLM) (Collins, 2002) and GLM with dynamic learning", "acronyms": [[70, 73], [11, 13], [95, 98]], "long-forms": [[43, 68]]}, {"text": "is re-written as NN, and NNPS as NNP.  Parent (PP) The category of the parent node of the NP. ", "acronyms": [[47, 49], [17, 19], [25, 29], [33, 36], [90, 92]], "long-forms": [[39, 45]]}, {"text": "{yvchen, yww, anatoleg, air}@cs.cmu.edu Abstract Spoken dialogue systems (SDS) typically require a predefined semantic ontology", "acronyms": [[74, 77]], "long-forms": [[49, 72]]}, {"text": "The research systems were:  ? CANDIDE (IBM Research: French - English(FE)),  produced both FA and human-assisted (HA) outputs.", "acronyms": [[70, 72], [39, 42], [91, 93], [114, 116], [30, 37]], "long-forms": [[53, 68], [98, 112]]}, {"text": "phrase-based decoder that has been augmented to translate ambiguous input given in the form of a confusion network (CN), a weighted finite state representation of a", "acronyms": [[116, 118]], "long-forms": [[97, 114]]}, {"text": "tools freely available for many languages. That is the case for morphosyntactic analyzers (MSA), but not yet for full or even shallow parsers.", "acronyms": [[91, 94]], "long-forms": [[64, 89]]}, {"text": "1540  Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 7?14, Gothenburg, Sweden, April 27, 2014.", "acronyms": [[75, 80], [84, 88]], "long-forms": [[41, 73]]}, {"text": "4.4 Word Sense Induction In this section, we present an evaluation of our model on the word sense induction (WSI) tasks. The", "acronyms": [[109, 112]], "long-forms": [[87, 107]]}, {"text": "Intensional Allan Ramsay University of Manchester (UK) email: allan.ramsay@manchester.ac.uk", "acronyms": [[51, 53]], "long-forms": [[25, 49]]}, {"text": "In order to take the transitivity of outscoping relations into account, we use the transitive closure (TC) of DAGs. Let G+ =", "acronyms": [[103, 105], [110, 114]], "long-forms": [[83, 101]]}, {"text": "We require that the language I has an available Wordnet linked to the Princeton Wordnet (PWN) (Fellbaum, 1998). ", "acronyms": [[89, 92]], "long-forms": [[70, 87]]}, {"text": "UMichigan non-Tipster UNK X USouthern California non-Tipster SNAP X USussex (UK) non-Tipster SUSSEX X Table 1 .", "acronyms": [[77, 79], [22, 25], [61, 65], [93, 99]], "long-forms": [[68, 75]]}, {"text": "the titles of the entity articles titles(e) to represent the entities in the query and two ranking functions, Recursive TFISF (R-TFISF) and LC, 3", "acronyms": [[127, 134], [140, 142]], "long-forms": [[110, 125]]}, {"text": "produced by a transliteration system 1. Word Accuracy in Top-1 (ACC) Also known as Word Error Rate, it measures correct-", "acronyms": [[64, 67]], "long-forms": [[45, 53]]}, {"text": "(Eisner, 1996). We define role value labeled precision (RLP) and role value labeled recall (RLR) on dependency links as follows:", "acronyms": [[92, 95], [56, 59]], "long-forms": [[65, 90], [26, 54]]}, {"text": "matic and paradigmatic associations on the results of the clustering step. We conduct two experiments on SemEval-2012 task 2 and Scholastic Assessment Test (SAT) analogy quizzes to measure relational similarity to evaluate our model.", "acronyms": [[157, 160]], "long-forms": [[129, 155]]}, {"text": "This paper describes the Universal Decompositional Semantics (Decomp) project, which aims to augments Universal Dependencies (UD) data sets with robust, scalable semantic annotations based in lin-", "acronyms": [[126, 128], [62, 68]], "long-forms": [[102, 124], [35, 50]]}, {"text": "attempted to cut down on certain items in the process.  Figure 2: Translation examples (SRC = source, BASE = baseline system, BACKOFF = backoff", "acronyms": [[88, 91]], "long-forms": [[94, 100]]}, {"text": "Nu' (a) ~ Nu (a) AP (a)  OH  Nu' (a) = Nu (a) A(P (a)~ P' (a))  (3) la propri~t~ P contredit le noyau ; on a ~ la lois ", "acronyms": [[25, 27], [17, 19]], "long-forms": []}, {"text": "was supported in part by JSPS Research Fellowships for Young Scientists and in part by CREST, JST (Japan Science and Technology Agency). ", "acronyms": [[94, 97], [25, 29], [87, 92]], "long-forms": [[99, 127]]}, {"text": "3.1 The Information Extraction Pipeline  The extraction task we are addressing is that of the  Automatic Content Extraction (ACE)1 evaluations. ", "acronyms": [[125, 128]], "long-forms": [[95, 123]]}, {"text": "Table 1: Summary of distance values between the 380 observed A-N pairs and the predictions from each model (ADD=additive, MUL=multiplicative, PLSR=Partial Least Squares Regression).", "acronyms": [[108, 111], [122, 125], [61, 64], [142, 146]], "long-forms": [[112, 120], [126, 140], [147, 179]]}, {"text": "metric TF*S~, since we base the importance of a  ? SF = Segment frequency (How many segments does  the term occur in) ", "acronyms": [[51, 53], [7, 11]], "long-forms": [[56, 73]]}, {"text": "Mophological processing, syntactic parsing and  other useflfl tools have been proposed in the field  of natural language processing(NLP). Many ", "acronyms": [[132, 135]], "long-forms": [[104, 130]]}, {"text": " The headline  generation system we present uses  Singular Value Decomposition (SVD) to  guide the generation of a headline ", "acronyms": [[80, 83]], "long-forms": [[50, 78]]}, {"text": "Table 2: Overall scores of whole task as well as separately for each annotation format in terms of labeled precision (LP), recall (LR) and F 1", "acronyms": [[118, 120], [131, 133]], "long-forms": [[99, 116], [123, 129]]}, {"text": "NIST-06. The bilingual training corpus comes from Linguistic Data Consortium (LDC)6, which consists of 3.4M sentence pairs with 64M/70M Chi-", "acronyms": [[78, 81], [0, 7]], "long-forms": [[50, 76]]}, {"text": "KODIAK (Keystone to Overall Design for Inte-  gration and Application of Knowledge) is an implemen-  tation of CRT (Cognitive Representation Theory), an  approach to knowledge representation that bears simi- ", "acronyms": [[111, 114], [0, 6]], "long-forms": [[116, 147], [8, 82]]}, {"text": "explanations of these metrics are described below.  Symptom name recognition rate (RRdet),  recognition error rate (RERdet) and recognition ", "acronyms": [[83, 88], [116, 122]], "long-forms": [[65, 81], [92, 114]]}, {"text": ".  Longest TM Candidate Indicator (LTC):  Which indicates whether the given  is the ", "acronyms": [[35, 38]], "long-forms": [[3, 33]]}, {"text": "mathematical models from experimental data. The  algorithm is similar to Genetic Programming (GP),  but uses fixed-length character strings (called chro-", "acronyms": [[94, 96]], "long-forms": [[73, 92]]}, {"text": "rules, along with a few lexical rules involving a list of stop phrases, discourse cue phrases and wordlevel parts of speech (POS) tags. First, paragraph", "acronyms": [[125, 128]], "long-forms": [[108, 123]]}, {"text": "Prevalence and count of conditions by temporal  category and report genre. DS = Discharge Summary,  Echo = Echocardiogram, ED = Emergency Department, ", "acronyms": [[75, 77]], "long-forms": [[80, 97]]}, {"text": "predictive ones among all our features. We used the Correlation based Feature Subset (CFS) selection method in WEKA for this purpose.", "acronyms": [[86, 89], [111, 115]], "long-forms": [[52, 84]]}, {"text": "Fortunately, learning the reward function using IRL methods have already been proposed for the general (PO)MDP framework (Ng and Russell, 2000; Kim et al.,", "acronyms": [[104, 106], [48, 51], [107, 110]], "long-forms": [[78, 90]]}, {"text": "We evaluate the following two search algorithms: ? beam search algorithm (BS): (Tillmann, 2001; Tillmann and Ney, 2000)", "acronyms": [[74, 76]], "long-forms": [[51, 62]]}, {"text": "We developed and tested our system on 30 full  length UK archaeological reports archived by the  Arts and Humanities Data Service (AHDS)4. ", "acronyms": [[131, 135], [54, 56]], "long-forms": [[97, 129]]}, {"text": "nication after speech and email.4 Millions of users of instant messaging (IM) services and short message service (SMS) generate electronic content in a dialect that does not adhere to conventional gram-", "acronyms": [[114, 117], [74, 76]], "long-forms": [[91, 112], [55, 72]]}, {"text": " Issues, Tasks and Program Structures to Roadmap Research in Question & Answering (Q&A) http://www-nlpir.nist.gov/projrcts/", "acronyms": [[83, 86]], "long-forms": [[61, 81]]}, {"text": "the natural (CC natural) and strong (CC strong)  levels; and (b) advanced level texts from a popular  science magazine called Ci?ncia Hoje (CH). Table ", "acronyms": [[140, 142], [13, 15], [37, 39]], "long-forms": [[126, 138]]}, {"text": "vv@iiit.ac.in Abstract Recognition of Named Entities (NEs) is a difficult process in Indian languages like Hindi,", "acronyms": [[54, 57]], "long-forms": [[38, 52]]}, {"text": "Following are the two broad types of social events that were annotated: Interaction event (INR): When both entities participating in an event are aware of each other and of", "acronyms": [[91, 94]], "long-forms": [[72, 83]]}, {"text": "matical device for handling coordination in computa-  tional linguistics has been the SYSCONJ facility for  augmented transition networks (ATNs) (Woods 1973;  Bates 1978).", "acronyms": [[139, 143], [86, 93]], "long-forms": [[108, 137]]}, {"text": "Preliminary experimental data indicates that the approach is likely to be successful. The major benefit of the approach is that it makes extending pronunciation lexi-cons accessible to average users. 1 Introduction Speech recognition (SR) systems use pronuncia-tion lexicons to map words into the phoneme-like units used for acoustic modeling. Text-to-speech (TTS) systems also make use of pronunciation lexicons, both internally and as ?", "acronyms": [[235, 237], [360, 363]], "long-forms": [[215, 233], [344, 358]]}, {"text": "lowing rules are used in the detailed example.  if tense of el and of e2 is simple past (SP)  with perfective AP tben there is justification for ", "acronyms": [[89, 91], [110, 112]], "long-forms": [[76, 87]]}, {"text": "for alignments.  Recurrent neural network (RNN)-based models have recently demonstrated state-of-the-art per-", "acronyms": [[43, 46]], "long-forms": [[17, 41]]}, {"text": "We show that languageindependent features can be used for regression with Support Vector Machines (SVMs) and the Margin-Infused Relaxed Algorithm (MIRA), and", "acronyms": [[99, 103], [147, 151]], "long-forms": [[74, 97], [113, 145]]}, {"text": "The described research is undertaken in the course of the development of human computer interfaces for natural interaction in Virtual Reality (VR). Conducting empirical inves-", "acronyms": [[143, 145]], "long-forms": [[126, 141]]}, {"text": "The similarity of decisions can be evaluated by calculating the proportion of identical decisions (PID)when comparing the test results with those of the gold stan-", "acronyms": [[99, 102]], "long-forms": [[64, 97]]}, {"text": "characteristic, we regard the sentiment  classification as a sequence labeling problem and  use conditional random field (CRFs) model to  capture the relation between two adjacent ", "acronyms": [[122, 126]], "long-forms": [[96, 120]]}, {"text": "cessing information from a structured database ? a natural language interface to a database (NLIDB) (Kapetanios et al, 2010).", "acronyms": [[93, 98]], "long-forms": [[51, 91]]}, {"text": "CHBWGE, H l V E  CSERCH FOR HERGEF IN 10  merge features  i n t o  node 10 (making it a schwa)  ANTEST CALLED FOB 211SCFIHDA (AACC) , SD= 3. RES= 7.", "acronyms": [[126, 130], [134, 136], [0, 6], [8, 15], [17, 23], [28, 34], [24, 27], [141, 144]], "long-forms": [[96, 124]]}, {"text": "The relative clause itself has the category S; the incoming edge is labeled RC (relative clause). ", "acronyms": [[76, 78]], "long-forms": [[80, 95]]}, {"text": "  Abstract  Over the last few years, machine translation (MT) has transformed from an academic research  platform into a productivity or gisting tool adopted by several end users.", "acronyms": [[58, 60]], "long-forms": [[37, 56]]}, {"text": "Frame abbreviations:  INAN=inanimate NP, ANIM=animate NP, VBZ--inflected  main verb, IS=is, VBG=gerund, PP=prepositional phrase,  TO=to (prep.),", "acronyms": [[85, 87], [104, 106], [22, 26], [37, 39], [41, 45], [54, 56], [58, 61], [79, 83], [92, 95], [130, 132]], "long-forms": [[88, 90], [107, 127], [27, 36], [46, 53], [96, 102], [133, 135]]}, {"text": "lexicalized Baselines. In Proceedings of the ACL Workshop on Parsing German (PaGe), pages 40?46, Columbus, OH, USA.", "acronyms": [[77, 81]], "long-forms": [[61, 75]]}, {"text": "C H A N G E .  H A V E  CSEXCH FOB BEPGFF IN 1 4   ANTEST CALLEC FOR 23\"NASREL: \" (AACC) S D =  24, RES= 3. TOP= 1:s ", "acronyms": [[65, 68], [83, 87], [89, 92], [100, 103], [108, 111], [24, 30], [31, 34], [35, 41]], "long-forms": [[51, 64]]}, {"text": " 1 In t roduct ion   Language Understanding (LU) has been the focus of much research work in the last twenty ears. ", "acronyms": [[45, 47]], "long-forms": [[21, 43]]}, {"text": "low navigational directions. In Proceedings of the Association for Computational Linguistics (ACL), 2010.", "acronyms": [[94, 97]], "long-forms": [[51, 92]]}, {"text": "evaluate the quality of the paraphrase collection.  In parcitular, Amazon?s Mechanical Turk1 (MTurk) provides a way to pay people small amounts of", "acronyms": [[94, 99]], "long-forms": [[76, 92]]}, {"text": "is different from the annotation scheme (Abbas, 2012; Abbas, 2014) of phrase structure (PS) and the hyper dependency structure (HDS) of the URDU.KON-TB treebank along with the different", "acronyms": [[128, 131], [88, 90], [140, 151]], "long-forms": [[100, 126], [70, 86]]}, {"text": " 2.2 Recognizing subwords An automatic speech recognition (ASR) system (Jelinek, 1998) serves to recognize both queries", "acronyms": [[59, 62]], "long-forms": [[29, 57]]}, {"text": "classes in both original text and main text corpora.  chose Support Vector Machines (SVM) because it has been shown by other researchers in AGI", "acronyms": [[85, 88], [140, 143]], "long-forms": [[60, 83]]}, {"text": "various respects. While CKY requires a grammar in Chomsky Normal Form (CNF), LSCP takes an ordinary PG grammar, since no equivalent of the", "acronyms": [[71, 74], [24, 27], [77, 81], [100, 102]], "long-forms": [[50, 69]]}, {"text": "tl,...,tM i=2 i=N+I   (7)  which is a Nth-order Markovian chain for the language model (MLM). ", "acronyms": [[88, 91]], "long-forms": [[48, 86]]}, {"text": "word if it exceeds a certain threshold.  4.2 LDA Graph Method (LDA-GM) The LDA-GM algorithm creates a similarity graph", "acronyms": [[63, 69], [75, 81]], "long-forms": [[45, 61]]}, {"text": "(located at lower levels) in a taxonomy.  In the Information Retrieval (IR) community, browsing taxonomies.", "acronyms": [[72, 74]], "long-forms": [[49, 70]]}, {"text": "structures. 4 Such an algorithm has to define for every LFG a relation  F?(~,s)  (s is generable from (I)) between directed acyclic graphs (DAGs)  and terminal strings.", "acronyms": [[140, 144], [56, 59], [72, 74]], "long-forms": [[115, 138]]}, {"text": " The obtained Japanese scores as compared to the  scores from the initial English experiment (E-E-E)  are shown in Figure 6.", "acronyms": [[94, 99]], "long-forms": [[74, 92]]}, {"text": "rule in a CFG. It can  therefore fill the ACity (ArrivalCity) or the  DCity (DepartureCity) slot, and instantiate a ", "acronyms": [[42, 47], [10, 13], [70, 75]], "long-forms": [[49, 60], [77, 90]]}, {"text": "AO = all objects  MO = matched objects  TF = text filtering  FM = F-measures ", "acronyms": [[40, 42], [0, 2], [18, 20], [61, 63]], "long-forms": [[45, 59], [5, 16], [23, 38], [66, 76]]}, {"text": "The IBM Model 4 search space cannot be efficiently enumerated; therefore it cannot be trained directly using Expectation Maximization (EM). In practice, a sequence", "acronyms": [[135, 137], [4, 7]], "long-forms": [[109, 133]]}, {"text": "eal papers. Ill PTvcccdings of thc Pac'lific Sym-  posium on Biocomp'uting'98 (PSB'98), .Jan-  1uAYy.", "acronyms": [[79, 85], [16, 27]], "long-forms": [[51, 77]]}, {"text": "Abstract  This paper presents a new approach  based on Equivalent Pseudowords (EPs)  to tackle Word Sense Disambiguation ", "acronyms": [[79, 82]], "long-forms": [[55, 77]]}, {"text": "In (Frasconi et al., 2004) we introduced declarative kernels (DK) as a set of kernels working on mereotopological", "acronyms": [[62, 64]], "long-forms": [[41, 60]]}, {"text": "67  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 189?195, October 25-29, 2014, Doha, Qatar.", "acronyms": [[92, 97]], "long-forms": [[42, 90]]}, {"text": " Take for example the word cliff which could be a  proper (NP) 1 or a common noun (NN) (ignoring ca-  pitalization of proper nouns for the moment).", "acronyms": [[83, 85], [59, 61]], "long-forms": [[77, 81]]}, {"text": "day(x, fri) ? during(x, night) Here the logical form (LF) is a lambda-calculus expression defining a set of entities that are flights", "acronyms": [[54, 56]], "long-forms": [[40, 52]]}, {"text": "crafted features, lexicons, and grammars.  Meanwhile, recurrent neural networks (RNNs) what are the major cities in utah ?", "acronyms": [[81, 85]], "long-forms": [[54, 79]]}, {"text": "tion device, a Nippon Electric Corporation DP-200, was  added to an existing natural anguage processing system,  the Natural Language Computer (NLC) (Ballard 1979,  Biermann and Ballard 1980).", "acronyms": [[144, 147], [43, 45]], "long-forms": [[117, 142]]}, {"text": "3.2 Data Normalization The ACL shared task is very close in form and content to the Final Text Editions (FTE) task of the TCSTAR (TC-STAR, 2004) evaluation.", "acronyms": [[105, 108], [27, 30], [130, 137]], "long-forms": [[84, 103], [122, 128]]}, {"text": "driver was measured in two ways. The driver performed a Tactile Detection Task (TDT) (van Winsum et al, 1999).", "acronyms": [[80, 83]], "long-forms": [[56, 78]]}, {"text": "lated work. We then introduce Markov logic and our Markov Logic Network (MLN) for joint bio-event extraction.", "acronyms": [[73, 76]], "long-forms": [[51, 71]]}, {"text": " 1 Introduct ion  Many of the Natural Language Generation (NLG)  systems that produce flexible output, i.e. sentences ", "acronyms": [[59, 62]], "long-forms": [[30, 57]]}, {"text": "PAST (- +)  Finite verbs are specified as (PAST +) if they are in  the past tense, and as (PAST -) otherwise. ", "acronyms": [[91, 97], [0, 4], [43, 47]], "long-forms": [[71, 81]]}, {"text": "extremely limited in this domain. Thus, language 1KEY: COM=completive aspect, DEM=demonstrative, DIR=directional", "acronyms": [[55, 58], [78, 81], [97, 100]], "long-forms": [[59, 69], [82, 95], [101, 112]]}, {"text": "there is a link to the next node).  Prompts (PT) occur when the tutor attempts to elicit a meaningful contribution from the student.", "acronyms": [[45, 47]], "long-forms": [[36, 43]]}, {"text": "It makes sense now that you explained it, but I never used an else if in any of my other programs .04 POSITIVE FEEDBACK (P) Second part complete. .11 QUESTION (Q) Why couldn?t I have said if (i<5) .11 STATEMENT (S) i is my only index .07  REQUEST FOR FEEDBACK (RF) So I need to create a new method that sees how many elements are in my array? .16 RESPONSE (RSP) You mean not the length but the contents .14 UNCERTAIN FEEDBACK WITH ELABORATION (UE) I?m trying to remember how to copy arrays .008 UNCERTAIN FEEDBACK (U) Not quite yet .008  3.2 Task action annotation The tutoring sessions were task-oriented, focusing on a computer programming exercise.", "acronyms": [[261, 263], [357, 360], [444, 446]], "long-forms": [[239, 259], [102, 110], [150, 158], [201, 210], [347, 355], [407, 442], [495, 513]]}, {"text": "\"bridge\" between this bilingual word pair. This  leads us to use the term frequency(TF) mea-  sure.", "acronyms": [[84, 86]], "long-forms": [[69, 83]]}, {"text": "m a t i c a l l y  related s t r u c t u r e  is termed a prpposll t ion. -  Four r e l a t i o n s  of p a r t i c i p a t i o n  are dis t ingu ished :  agent  (AGT),  ins t rumenta l  (INS), objective (ORJ), and experiencer  (EXP) .", "acronyms": [[163, 166], [188, 192], [205, 208], [229, 232]], "long-forms": [[155, 160], [170, 185], [194, 203], [215, 226]]}, {"text": "notator. For brevity, we only considered PubMed as the source DB, and named entity recognition (NER)type annotations, which may be simply represented", "acronyms": [[96, 99]], "long-forms": [[70, 94]]}, {"text": "October-2001 w/out 2000 SPA 30.88 \u0000 95.68 \u0000 0.08 \u0000 Table 2: Results for Identifying Speech-Act DATE tags in the October-2001 Communicator Corpus, (Dim = Dimension of Date used for output classification (SPA = Speech Act, Maj. Cl.", "acronyms": [[203, 206], [24, 27], [95, 99], [147, 150], [226, 228]], "long-forms": [[209, 219], [153, 162]]}, {"text": "JOPER (enclitic personal) DEMON (demonstrative) 1 SING (singular) INTG (interogative) 2 PLUR (plural) CREFX (common reflexive) 3", "acronyms": [[66, 70], [88, 92], [0, 5], [26, 31], [50, 54], [102, 107]], "long-forms": [[72, 84], [94, 100], [33, 46], [7, 24], [56, 64], [109, 125]]}, {"text": "MOVE is a label for complex events that con-  sists o f  maximal ly  three sub-events,  namely  START, CHPOS (CHANGE OF POSITION), and STOP,  where the first and the last sub-event are optional ", "acronyms": [[103, 108]], "long-forms": [[110, 128]]}, {"text": "Besides, other tools such as ELAN2 or Anvil3 are available as well, as are tool kits such as the Annotation Graph Toolkit (AGTK)4 or the NITE XML Toolkit.5 While multimodal annotation", "acronyms": [[123, 127], [29, 34], [38, 44], [137, 145]], "long-forms": [[97, 121]]}, {"text": "Economics neighborhood f bank  bank  Subject Code EC = Economics  have it person out ", "acronyms": [[50, 52]], "long-forms": [[55, 64]]}, {"text": "]} (7) This optimization can be performed using the expectation maximization (EM) algorithm (Dempster, Laird, and Rubin 1977).", "acronyms": [[78, 80]], "long-forms": [[52, 76]]}, {"text": "Similarity  task  at  SEM  2013.  The  Semantic  Textual Similarity Core task  (STS)  computes the  degree  of  semantic  equivalence  between  two ", "acronyms": [[80, 83], [22, 25]], "long-forms": [[57, 77]]}, {"text": "cation which manipulates data using two well-known machine learning techniques, Naive Bayes(NB) and Support Vector Machines(SVMs).", "acronyms": [[92, 94], [124, 128]], "long-forms": [[80, 90], [100, 123]]}, {"text": "correction. ? P3E3N4S2, F W I Controlled Automotive Service Language (CASL) (Means and Godden 1996; Means, Chapman, and Liu 2000) is a controlled language for writing service manuals and bul-", "acronyms": [[70, 74], [14, 22]], "long-forms": [[30, 68]]}, {"text": "in the original English WordNet (Fellbaum, 1998) into lexicographer files. Arabic WordNet (AWN) (Elkateb et al 2006) allows us to recover super-", "acronyms": [[91, 94]], "long-forms": [[75, 89]]}, {"text": "Hence, any numerical optimization strategy may be used and practical solutions include limited memory BFGS (L-BFGS) (Liu and Nocedal, 1989), which is used in the popu-", "acronyms": [[108, 114]], "long-forms": [[87, 106]]}, {"text": " 11 4 Lexical Analysis and Named Entity Recognition (NE ) The lexicon we used contains only syntactic information such as parts of speech and subcategorization frames .", "acronyms": [[53, 55]], "long-forms": [[28, 39]]}, {"text": "annotating unlabeled data, for adapting  existing CRF-based named entity recognition (NER) systems to new texts or  domains.", "acronyms": [[86, 89], [50, 53]], "long-forms": [[60, 84]]}, {"text": "So, the  first matrix (with the data from IBL trained with Encoding 1) shows in its upper row  the classification of the words that have final stress (FIN). It appears that the classifier ", "acronyms": [[151, 154], [42, 45]], "long-forms": [[137, 142]]}, {"text": "Vector Machines (SVM) with radial basis kernel, Na??ve Bayes (NB), J48 Decision Trees (DT), and Neural Networks (NN) with back propagation. In", "acronyms": [[113, 115], [17, 20], [62, 64], [87, 89]], "long-forms": [[96, 111], [0, 15], [48, 60], [71, 85]]}, {"text": "DEP = dependency type ? MOR = morphological features (set) ?", "acronyms": [[24, 27], [0, 3]], "long-forms": [[30, 43], [6, 16]]}, {"text": " 3 Background Slot filling (SF) is a query-oriented relation extraction (RE) task in the Knowledge Base Popu-", "acronyms": [[28, 30], [73, 75]], "long-forms": [[14, 26], [52, 71]]}, {"text": "Eat_On_Time? Theme 3.3 Planning for Linguistic Variation Sentences generated by Picture Books vary in length and word complexity according to the user?s age. The variation in length is handled by specificity character goals (SCG) that are ap-pended as supporting details to their respective character goals. SCGs are designed so that their existence will give more detail to the preceding character goal while ensuring consistency, and that their non-existence will still make the story complete.", "acronyms": [[225, 228], [308, 312]], "long-forms": [[196, 223]]}, {"text": "Perhaps not surprisingly, therefore, few natural language understanding (NLU) systems use graphical presentational features to aid interpretation, and few natural language generation (NLG) systems attempt to render the output texts in a principled way.", "acronyms": [[184, 187], [73, 76]], "long-forms": [[155, 182], [41, 71]]}, {"text": "reordering (Hovy 1988; Marcu 1997; Reiter and Dale 2000).  Entity coherence, which is based on the way the referents of noun phrases (NPs) relate subsequent clauses in the text, is an important aspect of textual organization.", "acronyms": [[134, 137]], "long-forms": [[120, 132]]}, {"text": " Added to the usual space of local permutations defined by a low distortion limit (DL), this results in a linguistically informed definition of the search space", "acronyms": [[83, 85]], "long-forms": [[65, 81]]}, {"text": "In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI), Baltimore, MD, October. ", "acronyms": [[117, 120], [134, 136]], "long-forms": [[104, 115]]}, {"text": "2.1 Conditional Random Fields  Conditional random field (CRF) was an extension  of both Maximum Entropy Model (MEMs) and  Hidden Markov Models (HMMs) that was firstly ", "acronyms": [[111, 115]], "long-forms": [[88, 109]]}, {"text": "toolkit that contains a suit of modules for generic tasks in Natural Language Processing (NLP), Information Retrieval (IR), and Network Analysis (NA). ", "acronyms": [[146, 148]], "long-forms": [[128, 144]]}, {"text": " Ckakraborty, Tanmoy, 2010, Identification of NounNoun (N-N) Collocations as Multi-Word Expressions  in Bengali Corpus.", "acronyms": [[56, 59]], "long-forms": [[46, 54]]}, {"text": "GaChalign (Crosslingual): Gale-Church Sentence-level Aligner with variable parameters ? Indotag (Indonesian): Conditional Random Field (CRF) POS tagger. ", "acronyms": [[136, 139], [141, 144]], "long-forms": [[110, 134]]}, {"text": "? Negat ive Precis ion ( I~P)  :  * F -measure  (FM) ? ( ~2+I)?PP?PR /32 ?", "acronyms": [[49, 51], [25, 28]], "long-forms": [[36, 46]]}, {"text": "els, which seamlessly incorporates graphbased and more general supervision by extending the posterior regularization (PR) framework.", "acronyms": [[118, 120]], "long-forms": [[92, 116]]}, {"text": "University of Massachusetts-Boston  Abstract  Word sense disambiguation (WSD) is one of  the main challenges in Computational ", "acronyms": [[73, 76]], "long-forms": [[46, 71]]}, {"text": "Abstract We experiment with using different sources of distant supervision to guide unsupervised and semi-supervised adaptation of part-of-speech (POS) and named entity taggers (NER) to Twitter. ", "acronyms": [[178, 181], [147, 150]], "long-forms": [[156, 176], [131, 145]]}, {"text": "12  Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 137?142, October 25, 2014, Doha, Qatar.", "acronyms": [[82, 86]], "long-forms": [[46, 80]]}, {"text": " 3.2 Duluth Systems Evaluation The FScore (F-10), F-Measure (F-SC), and Jaccard Coefficient result in a comparable and consistent", "acronyms": [[61, 65]], "long-forms": [[35, 41]]}, {"text": "Nincc NIA ~ \\]laS started moving from toy  problems to ,'eal applications one of the biggest  difficully has been Knowledge Acquisition (KA)  of different lypes (lexical, grammatical, domain ", "acronyms": [[137, 139]], "long-forms": [[114, 135]]}, {"text": "model.  Case Frame Editor (CFE): Maintains the lexical  Case Frame Factbase, a data file of how to infer ", "acronyms": [[27, 30]], "long-forms": [[8, 25]]}, {"text": "evt EVENT lfr LIVING THING sub SUBSTANCE fod FOOD lme LINEAR MEASURE tme TIME Table 1: The 39 CoreLex basic types (BTs) and their WordNet anchor nodes Basic type WordNet anchor Examples", "acronyms": [[115, 118]], "long-forms": [[102, 113]]}, {"text": "predicate-only f-score, M = METEOR, WN = WordNet,  H_FL = human fluency score, H_AC = human accuracy  score, H_AVE = human average score.9   ", "acronyms": [[109, 114], [36, 38], [51, 55], [79, 83]], "long-forms": [[117, 130], [28, 34], [41, 48], [58, 71], [86, 100]]}, {"text": "sions to identify stylistic shifts in paraphrase, allowing us to differentiate stylistic properties in the Paraphrase Database (PPDB) with high accuracy. Sec-", "acronyms": [[128, 132]], "long-forms": [[89, 126]]}, {"text": "symbols as well as full names. Groups such as the  Human Genome Organisation (HUGO), Mouse Genome  Institute (MGI), UniProt, and the National Center for ", "acronyms": [[78, 82], [110, 113]], "long-forms": [[51, 76], [85, 108]]}, {"text": "In order to quantify the level of noise in the collected SMS data, we built a character-level language model(LM)13 using the questions in the FAQ data-set (vocabulary", "acronyms": [[109, 111], [57, 60], [142, 145]], "long-forms": [[94, 107]]}, {"text": "post-process of the internal diacritization task  using the same machine learning approach that  was trained on Base phrase (BP)-Chunk as well  as POS features of individual tokens with correct ", "acronyms": [[125, 127], [147, 150]], "long-forms": [[112, 123]]}, {"text": "study (usually as an elective) or not at all. At the  City University of New York (CUNY)?s Graduate  Center (the primary Ph.", "acronyms": [[83, 87]], "long-forms": [[54, 81]]}, {"text": "processing. In Proceedings of the Conference on  Knowledge Capture (K-CAP), pages 70-77, 2003. ", "acronyms": [[68, 73]], "long-forms": [[49, 66]]}, {"text": "3.3 Participants and Task Eighty participants were recruited from Amazon?s Mechanical Turk2 (MTurk) for this between2http://www.mturk.com", "acronyms": [[93, 98]], "long-forms": [[75, 91]]}, {"text": "experiments. For Hindi, we worked with the Hindi Dependency Treebank (HDT) released as part of Coling 2012 Shared Task (Bharati et", "acronyms": [[70, 73]], "long-forms": [[43, 68]]}, {"text": "The Cell or Tissue Type category was split into two fine grained classes, CELL and CLNE (cell line). ", "acronyms": [[83, 87], [74, 78]], "long-forms": [[89, 98]]}, {"text": "S = Spanish  JV = Joint Venture ?????????? ME = Microelectronics  Brief History of the Message Understanding Conferences", "acronyms": [[43, 45], [13, 15]], "long-forms": [[48, 64], [4, 11], [18, 31]]}, {"text": "X at Y (verb phr:~se, noun phrase)  X a.m. (corot?rand word)  After step (I) is finished, steps (II)-(IV) are repeated  recursively.", "acronyms": [[97, 99]], "long-forms": [[77, 88]]}, {"text": "mantic content Ks, sends a message m to R and R  interprets m as meaning CR. CS = cn is a neces-  sary condition for this turn of communication to ", "acronyms": [[77, 79], [15, 17], [73, 75]], "long-forms": [[82, 87]]}, {"text": " ? Activity Tree (AT): a tree-structure representing the current, past, and planned activities that", "acronyms": [[18, 20]], "long-forms": [[3, 16]]}, {"text": "In this paper we present our entry to the WMT?13 shared task: Quality Estimation (QE) for machine translation (MT). ", "acronyms": [[111, 113], [42, 48], [82, 84]], "long-forms": [[90, 109], [62, 80]]}, {"text": "In the leftmost column SSE-TRA and SSE-HDC refer to the trained and hand-coded SSE versions; the column NS indicates the number of sessions; the columns PSucc (perceived success), PAtt (perceived attention recognition), PUnd (perceived understanding), PNat (perceived naturalness), and POv (perceived overall performance) give average", "acronyms": [[153, 158], [180, 184], [23, 30], [35, 42], [79, 82], [104, 106], [220, 224], [252, 256]], "long-forms": [[160, 177], [186, 205], [226, 249], [258, 279], [291, 320], [286, 289]]}, {"text": "senses. Semantic role labeling is achieved using maximum entropy (MaxEnt) model based semantic role classification and integer linear", "acronyms": [[66, 72]], "long-forms": [[49, 64]]}, {"text": "back. We define a currency for annotation cost as Annotation cost Units (AUs). For an annotation bud-", "acronyms": [[73, 76]], "long-forms": [[50, 71]]}, {"text": "provided as input. The crawler generates the  Universal Resource Locator (URL) address for the  index (first) page of any particular date.", "acronyms": [[74, 77]], "long-forms": [[46, 72]]}, {"text": "2 Algorithms and Data  2.1 Task Definition and Data  The named entity (NE) task used for this  evaluation requires the system to identify all ", "acronyms": [[71, 73]], "long-forms": [[57, 69]]}, {"text": "INIT MED FIN TOTAL 201 (87.8%) 13 (5.7%) 15 (6.5%) 229 Table 1: Distribution of the Position (POS) of Discourse Adverbials", "acronyms": [[94, 97]], "long-forms": [[84, 92]]}, {"text": "For 1)reprocessing the dictionary definitions, we  have experimented with two ditDrent Caggers: the Xe-  rox PAR(J part-of-speech tagger \\[8\\], and the Chop-  per \\[9\\], an optimizing finit, e state luachine-hased tag- ", "acronyms": [[109, 112], [78, 86]], "long-forms": [[115, 119]]}, {"text": "ging. We ran this set of experiments on the part of Chinese Treebank 4 (CTB-4)6. Ninety percent of the", "acronyms": [[72, 77]], "long-forms": [[52, 70]]}, {"text": "We report both the aggregate curves precision/recall curves and Precision@N (P@N) in our experiments.", "acronyms": [[77, 80]], "long-forms": [[64, 75]]}, {"text": "knowledge in building the target domain classifier, we propose a novel optimization method based on the Na??ve Bayesian (NB) framework and stochastic gradient descent.", "acronyms": [[121, 123]], "long-forms": [[104, 119]]}, {"text": " ? Lexical Overlap and Length (LO): This set of features represents the lexical overlap between", "acronyms": [[31, 33]], "long-forms": [[3, 18]]}, {"text": "Hidden topic markov models. Artificial Intelligence and Statistics (AISTATS). ", "acronyms": [[68, 75]], "long-forms": [[28, 66]]}, {"text": "stituent category labels expressing adverbials (RB), coordinations (CC), various types of interjections (UH, INTJ) and adverbial phrases (ADVP). We may", "acronyms": [[138, 142], [48, 50], [68, 70], [105, 107], [109, 113]], "long-forms": [[119, 136], [53, 66], [25, 46], [90, 103]]}, {"text": "semble learning. Ren et al (2011) explored the use of label propagation (LP) (Zhu and Ghahramani, 2002) in building a semi-supervised senti-", "acronyms": [[73, 75]], "long-forms": [[54, 71]]}, {"text": "? All adjectives appearing after an article and a particle (PART) have the degree positive (Pos) (39 of 39 cases).", "acronyms": [[60, 64], [92, 95]], "long-forms": [[50, 58], [82, 90]]}, {"text": "Initiative (ECI) plans to distribute similar material in a variety of languages. Even  greater esources are expected from the Linguistic Data Consortium (LDC). And the ", "acronyms": [[154, 157], [12, 15]], "long-forms": [[126, 152]]}, {"text": "grammatical frameworks (HLG). Combinatory  Categorial Grammars (CCG) (Steedman, 1987;  Steedman, 1996; Steedman, 1998; Steedman and ", "acronyms": [[64, 67], [24, 27]], "long-forms": [[30, 62]]}, {"text": "expunged to meet United States HIPAA standards, (U.S. Health, 2002) and approved for release by the local Institutional Review Board (IRB); the sample must represent problems that medical records coders", "acronyms": [[134, 137], [49, 52], [31, 36]], "long-forms": [[106, 132]]}, {"text": " 3 Latent Semantic Analysis Latent Semantic Analysis (LSA) (Deerwester et al 1990) is a widely used continuous vector space", "acronyms": [[54, 57]], "long-forms": [[28, 52]]}, {"text": "Model (LEM) We propose an unsupervised latent variable model, called the Latent Event Model (LEM), to extract events from tweets.", "acronyms": [[93, 96], [7, 10]], "long-forms": [[73, 91]]}, {"text": "the two probability distributions is calculated using a standard information-theoretic measure, the Kullback Leibler (KL-)divergence: K\u0002L^M_NQP\u0012R`NQS S54%6\u001a7", "acronyms": [[118, 121], [146, 149], [134, 143]], "long-forms": [[100, 116]]}, {"text": "This paper presents a web application and a web service for the diagnostic evaluation of Machine Translation (MT). These web-based", "acronyms": [[110, 112]], "long-forms": [[89, 108]]}, {"text": "tourist resources was made by the Direcc?a?o Geral de Turismo (DGT) and afterwards the Inventory of Tourist Resources (IRT) emerged. ", "acronyms": [[119, 122], [63, 66]], "long-forms": [[87, 117], [45, 61]]}, {"text": "edge of syntax and semantics.   In connection to conjunct verbs (ConjVs),  (Mohanty, 2010) defines two types of conjunct ", "acronyms": [[65, 71]], "long-forms": [[49, 63]]}, {"text": "CRF) A wide range of contextual information, such as surrounding words (GREF), dependency or case structure (GTREF), and dependency path (GREF ), has been utilized for similarity calculation, and achieved considerable success.", "acronyms": [[138, 142], [0, 3], [72, 76]], "long-forms": [[109, 114]]}, {"text": " 1 In t roduct ion   Word Sense Disambiguation (WSD) is an open prob-  lem in Natural Language Processing.", "acronyms": [[48, 51]], "long-forms": [[21, 46]]}, {"text": "ining both BLEU and NIST scores? relationship to their Unlabeled Accuracy Score(UAS). ", "acronyms": [[80, 83], [11, 15], [20, 24]], "long-forms": [[55, 79]]}, {"text": " 1 Introduction Interactive question answering (QA) has been identified as one of the important directions in QA", "acronyms": [[48, 50], [110, 112]], "long-forms": [[28, 46]]}, {"text": "ous word in a given context. As a fundamental task in natural language processing (NLP), WSD can benefit applications such as machine transla-", "acronyms": [[83, 86], [89, 92]], "long-forms": [[54, 81]]}, {"text": "follows:  1. If the topic is an individual constant (IC), establish  restrictions (using the Restricts link), if any, on the ", "acronyms": [[53, 55]], "long-forms": [[32, 51]]}, {"text": "line models: ? Character Segmenter (CS): this model simply divides Chinese sentences into sequences", "acronyms": [[36, 38]], "long-forms": [[15, 34]]}, {"text": "~eather(WEA) ingestion(ING)  use(USE) social(SOC) body(BOD)  phy_creation(PCR) mental_creation(MCR)  verbal_creagion (VCR) ", "acronyms": [[74, 77], [95, 98], [8, 11], [23, 26], [33, 36], [45, 48], [55, 58], [118, 121]], "long-forms": [[61, 72], [79, 93], [1, 7], [13, 22], [29, 32], [38, 44], [50, 54], [101, 116]]}, {"text": "c, include latent variable models that simultaneously capture the semantics of words and sentences, such as latent semantic analysis (LSA) or latent Dirichlet alocation (LDA).", "acronyms": [[134, 137], [170, 173]], "long-forms": [[108, 132], [142, 168]]}, {"text": "Marton, Habash, and Rambow Arabic Parsing with Lexical and Inflectional Features Table 8 Models with functional features: GENDER, NUMBER, rationality (RAT). FN* = functional", "acronyms": [[151, 154], [157, 159]], "long-forms": [[138, 149]]}, {"text": "****I TRANSFORPlATICNS **SIW:  S C A N  C-ALLED AT 1 I  ANTFST CALLED FOR SrqSYLLA B (AACC) ,SD= 6 .  RES= 1 1 .", "acronyms": [[70, 73], [93, 95], [86, 90]], "long-forms": [[56, 69]]}, {"text": " In Proceedings of the International Conference on Language Resources and Evaluation (LREC). ", "acronyms": [[86, 90]], "long-forms": [[51, 69]]}, {"text": "Figure 2: Translation examples (SRC = source, BASE = baseline system, BACKOFF = backoff system, REF = reference). OOVs and their trans-", "acronyms": [[96, 99], [32, 35], [46, 50], [70, 77], [114, 118]], "long-forms": [[102, 111], [38, 44], [53, 61], [80, 87]]}, {"text": "= primary source; C06?C09 = CoNLL 2006?2009; I10 = ICON 2010; SM = shared modifier; CJ = conjunct; Nested CS = portion of CSs participating in nested CSs (both as the inner and outer CS); RT UAS = unlabeled attachment score of the roundtrip experiment described in Section 5.", "acronyms": [[191, 194], [28, 33], [62, 64], [84, 86], [106, 108], [122, 125], [150, 153], [183, 185]], "long-forms": [[197, 223], [67, 82], [89, 97]]}, {"text": "  Abstract  The Colorado Literacy Tutor (CLT) is a  technology-based literacy program, designed ", "acronyms": [[41, 44]], "long-forms": [[16, 39]]}, {"text": "Subset of significant adjacency pairs CORRECTTASKACTION?CORRECTTASKACTION;??EXTRADOMAINS?EXTRADOMAINT;?GROUNDINGS?GROUNDINGT;?ASSESSINGQUESTIONT?POSITIVEFEEDBACKS;??ASSESSINGQUESTIONS?POSITIVEFEEDBACKT;?QUESTIONT?STATEMENTS;?ASSESSINGQUESTIONT?STATEMENTS;?EXTRADOMAINT?EXTRADOMAINS;?QUESTIONS?STATEMENTT;?NEGATIVEFEEDBACKS?GROUNDINGT;?INCOMPLETETASKACTION?INCOMPLETETASKACTION;?POSITIVEFEEDBACKS?GROUNDINGT;??BUGGYTASKACTION?BUGGYTASKACTION 4 Models We learned three types of models using cross-validation with systematic sampling of training and testing sets.  4.1 First-Order Markov Model The simplest model we discuss is the first-order Markov model (MM), or bigram model (Figure 2). A MM that generates observation (state) sequence o1o2?ot is defined in the following way.", "acronyms": [[654, 656], [689, 691]], "long-forms": [[640, 652]]}, {"text": "telling. In Computers in Entertainment (CIE), Association for Computing Machinery (ACM), volume 5.", "acronyms": [[83, 86], [40, 43]], "long-forms": [[46, 81], [12, 38]]}, {"text": "In interaction with the user, the system should play the role of an Information Search Assistant (ISA). ", "acronyms": [[98, 101]], "long-forms": [[68, 96]]}, {"text": "301 3. False Attributes (FA) - these are situations where a value for an attribute has been spec-", "acronyms": [[25, 27]], "long-forms": [[7, 23]]}, {"text": "specification whose precise informational content and form is in turn defined by an appropriate Document Type Definition (DTD). ", "acronyms": [[122, 125]], "long-forms": [[96, 120]]}, {"text": "of derivations. Each such derivation is realized in  PROVERB by a proof communicative act (PEA),  following the viewpoint hat language utterances are ", "acronyms": [[91, 94]], "long-forms": [[66, 89]]}, {"text": "Since finding the optimal set of edges respecting transitivity is NP-hard, they employed Integer Linear Programming (ILP) to find the exact solution.", "acronyms": [[117, 120]], "long-forms": [[89, 115]]}, {"text": "respectively. Hacioglu et al (2004) showed that  tagging phrase by phrase (P-by-P) is better than  word by word (W-by-W).", "acronyms": [[75, 81], [113, 119]], "long-forms": [[57, 73], [99, 111]]}, {"text": "attempts to use synchronous parsing to produce the  tree structure of both source language (SL) and  target language (TL) simultaneously, most SSMT  approaches make use of monolingual parser to ", "acronyms": [[118, 120], [92, 94], [143, 147]], "long-forms": [[101, 116], [75, 90]]}, {"text": " Another important similarity measure is cosine similarity of Personalized PageRank (PPR) vectors.", "acronyms": [[85, 88]], "long-forms": [[62, 83]]}, {"text": " In Expertise column, C=Computer Scientist, BI=Bioinformatician, B=Biologist, L=Linguist ?", "acronyms": [[44, 46]], "long-forms": [[47, 63], [24, 42], [67, 76], [80, 88]]}, {"text": " Our approach differs in important ways from the  use of hidden Markov models (HMMs) for class-  based language modeling (Jelinek et al, 1992).", "acronyms": [[79, 83]], "long-forms": [[57, 77]]}, {"text": "transcripts produced with Automatic Speech Recognition  (ASR) systems tend to contain many recognition errors,  leading to low Information Retrieval (IR) performance  (Oard et al, 2007).", "acronyms": [[150, 152], [57, 60]], "long-forms": [[127, 148], [26, 54]]}, {"text": "It  is at this critical point, when care is being trans-  ferred from the Operating Room (OR) to the ICU  and monitoring is at a minimum, that the pa- ", "acronyms": [[90, 92], [101, 104]], "long-forms": [[74, 88]]}, {"text": " The pattern we used consists of a mix between the  part of speech (POS) tags and the mention tags for  the words in the training instance.", "acronyms": [[68, 71]], "long-forms": [[52, 66]]}, {"text": "cal work is extensive. We draw on this work to design an Abstract Meaning Representation (AMR) appropriate for sembanking.", "acronyms": [[90, 93]], "long-forms": [[57, 88]]}, {"text": "gramming. In Association for the Advancement of Artificial Intelligence (AAAI), pages 1050?1055. ", "acronyms": [[73, 77]], "long-forms": [[13, 71]]}, {"text": "is used to generate ground truth answers).  The Children?s Book Test (CBT) dataset, created by Hill et al (2016), contains 113,719 cloze-style", "acronyms": [[70, 73]], "long-forms": [[48, 68]]}, {"text": "{tvu, aaiti, mzhang}@i2r.a-star.edu.sg  Abstract  Term Extraction (TE) is an important component of many NLP applications.", "acronyms": [[67, 69], [105, 108]], "long-forms": [[50, 65]]}, {"text": "tools for the Indian Languages. For Telugu, though a Part Of Speech(POS) Tagger for Telugu, is available, the accuracy is less when compared to English", "acronyms": [[68, 71]], "long-forms": [[53, 66]]}, {"text": "blogs which accumulated a large number of posts during this period: Carpetbagger (CB),1 Daily Kos (DK),2 Matthew Yglesias (MY),3 Red State (RS),4 and Right Wing News (RWN).5 CB and MY ceased", "acronyms": [[123, 125], [140, 142], [82, 84], [167, 170], [181, 183], [174, 176]], "long-forms": [[105, 121], [129, 138], [68, 80], [150, 164]]}, {"text": "based method is slightly better. The two systems share the same topic relevance score (REL) and sentiment score, but the sentence-ranking method", "acronyms": [[87, 90]], "long-forms": [[70, 79]]}, {"text": "respect to phonology, morphology, syntax and the lexicon. Linguistic resources (lexica, corpora) and natural language processing (NLP) tools for such dialects (parsers) are very rare. ", "acronyms": [[130, 133]], "long-forms": [[101, 128]]}, {"text": ">puncS Hertz equipment is a major supplier of rental equipment N/N N S\\N (S\\S)/N N/N N (N\\N)/N N/N N > >", "acronyms": [[69, 72], [63, 66]], "long-forms": [[74, 82]]}, {"text": "process (PR)  quantity (QU)  relation (RE)  shape (SH) ", "acronyms": [[39, 41], [9, 11], [24, 26], [51, 53]], "long-forms": [[29, 37], [0, 7], [14, 22], [44, 49]]}, {"text": "based classifier is used to select the most informative examples for training an another type of  classifier based on multinomial na?ve Bayes (NB)  model (McCallum and Nigam, 1998b).", "acronyms": [[143, 145]], "long-forms": [[130, 141]]}, {"text": "icantly better performance than GIZA++. We also evaluated Support Vector Machines (SVM) classifiers on the same first order feature space and", "acronyms": [[83, 86], [32, 38]], "long-forms": [[58, 81]]}, {"text": "Finance and economics (FAE) 100  Education (EDU) 100  Entertainment (ENT) 100  Computer (COM) 100 ", "acronyms": [[69, 72], [23, 26], [44, 47], [89, 92]], "long-forms": [[54, 67], [0, 20], [33, 42], [79, 87]]}, {"text": " Definition 1 A character string ABC is called an overlap ambiguity string (OAS) if it can be segmented into two words either as AB/C or A/BC (not both), depending on context.", "acronyms": [[76, 79], [33, 36], [129, 133], [137, 141]], "long-forms": [[50, 74]]}, {"text": "He washed it. With Kamp's  discourse representation theory (DRT) (Kamp 1981; Kamp and Reyle 1993) a discourse  representation structure (DRS) in which the reference to the pronoun he is constrained ", "acronyms": [[60, 63], [137, 140]], "long-forms": [[27, 58], [100, 135]]}, {"text": "The scores returned by the similarity measures are used as features in a Maximum Entropy (ME) classifier (Jaynes, 1957; Good, 1963), which learns to sepa-", "acronyms": [[90, 92]], "long-forms": [[73, 88]]}, {"text": "Xue and Palmer, 2005). The present version  PCTB5 (PCTB Version 5), contains 18,782 sentences, 507,222 words, 824,983 Hanzi and 890 ", "acronyms": [[44, 49]], "long-forms": [[51, 65]]}, {"text": "validate the performance of our method:  1. Precision@N (P@N). P@N measures how ", "acronyms": [[57, 60], [63, 66]], "long-forms": [[44, 55]]}, {"text": "expert users in spoken dialogue systems. The key component of a spoken language understanding (SLU) system is the semantic parser, which translates the users?", "acronyms": [[95, 98]], "long-forms": [[64, 93]]}, {"text": "16: end while 17: return builtPPs 3.3 Extended GNPPA (E-GNPPA) The GNPPA described in section 3.1 assumes that", "acronyms": [[54, 61], [67, 72]], "long-forms": [[38, 52]]}, {"text": "description model, the Dublin Core Metadata Set, together with an interchange method provided by the Open Archives Initiative (OAI), make it possible to construct a union catalog over", "acronyms": [[127, 130]], "long-forms": [[101, 125]]}, {"text": "2 We use a new related measure, which we call the overall percentage error reduction (OPER), that uses the entire area under the curves given by", "acronyms": [[86, 90]], "long-forms": [[50, 84]]}, {"text": "grammars. In Proceedings of the Fourteenth International Conference on Computational Linguistics (COLING-92), pages 426?432, Nantes, 1992.", "acronyms": [[98, 107]], "long-forms": [[57, 96]]}, {"text": "The lexical features used are word bigrams. The Part of Speech (PoS) of the target word and its neighbors make up the the syntactic", "acronyms": [[64, 67]], "long-forms": [[48, 62]]}, {"text": "is Tws, for \"Translator's Workstation.\" We also used the  C-based X11 toolkit called MOTIF (Motif, 1991) and its Com-  monLisp interface called CLM (Babatz et.", "acronyms": [[85, 90]], "long-forms": [[92, 97]]}, {"text": "Linggle: a Web-scale Linguistic Search Engine for Words in Context    Joanne Boisson+, Ting-Hui Kao*, Jian-Cheng Wu*, Tzu-His Yen*, Jason S. Chang* +Institute of Information Systems and Applications *Department of Computer Science National Tsing Hua University HsinChu, Taiwan, R.O.C. 30013 {joanne.boisson, maxis1718, wujc86, joseph.yen, jason.jschang} @gmail.com     Abstract  In this paper, we introduce a Web-scale lin-guistics search engine, Linggle, that retrieves lexical bundles in response to a given query. The query might contain keywords, wildcards, wild parts of speech (PoS), synonyms, and ad-ditional regular expression (RE) operators. In our approach, we incorporate inverted file in-dexing, PoS information from BNC, and se-mantic indexing based on Latent Dirichlet Al-location with Google Web 1T. The method in-volves parsing the query to transforming it in-to several keyword retrieval commands.", "acronyms": [[584, 587], [636, 638], [278, 283], [708, 711], [729, 732]], "long-forms": [[567, 582], [616, 634]]}, {"text": "For the time being,  the object of the testing is the generative component (GC) of this  description enumerating semantic representations (SR's) of sentences. ", "acronyms": [[139, 143], [76, 78]], "long-forms": [[113, 137], [54, 74]]}, {"text": "The representative vectors for each phoneme category consist of the mean vectors of the Gaussian Mixture Model (GMM). ", "acronyms": [[112, 115]], "long-forms": [[88, 110]]}, {"text": " ? Implicit Attitude (IA) - n ? t dimensions are ex-", "acronyms": [[22, 24]], "long-forms": [[3, 20]]}, {"text": "Following the ideas of (Collobert et al, 2011), Zeng et al (2014) first solve relation classification using convolutional neural network (CNN). The", "acronyms": [[138, 141]], "long-forms": [[108, 136]]}, {"text": "-4, -12, and -109 are all disjoint speaker sets.)  (Codes: SD=speaker dependent (2400 training sentences for RM2), MS=multi-speaker, SI=speaker independent, -4=all 4  RM2 speakers combined, -12=all 12 RM1 SD speakers combined, -109=109 RM1 SI training speakers, SDG=SD Gaussians, ", "acronyms": [[59, 61], [133, 135], [109, 111], [115, 117], [167, 169], [201, 203], [205, 207], [236, 238], [240, 242], [262, 265], [266, 268]], "long-forms": [[62, 79], [136, 155], [118, 131]]}, {"text": "pendencies. Hochreiter and Schmidhuber (1997), thus proposed long short term memory (LSTMs), a variant of recurrent neural networks.", "acronyms": [[85, 90]], "long-forms": [[61, 83]]}, {"text": "IDF Approach. Proceedings of International Conference on Language Resources and Evaluation (LREC) 2012, European Language Resources Association", "acronyms": [[92, 96], [0, 3]], "long-forms": [[57, 75]]}, {"text": "1 In t roduct ion   This paper deals with the discovery, representation,  and use of lexical rules (LRs) in the process of large-  scale semi-automatic computational lexicon acqui- ", "acronyms": [[100, 103]], "long-forms": [[85, 98]]}, {"text": " From the results shown in Table 3, we could find the proposed semantic word embedding (SWE) model can consistently achieve 0.8% (or more) ab-", "acronyms": [[88, 91]], "long-forms": [[63, 86]]}, {"text": " 1 Introduction Question answering (QA) from a knowledge base (KB) has a long history within natural language", "acronyms": [[36, 38], [63, 65]], "long-forms": [[16, 34], [47, 61]]}, {"text": "wards Task 2.  4.1 Wikipedia system (WIKI) In the WIKI data a sentence is marked as uncertain", "acronyms": [[37, 41], [50, 54]], "long-forms": [[19, 28]]}, {"text": "BACKGROUN D The LOLITA (Large-scale, Object-based, Linguistic Interactor, Translator, and Analyser) system is de signed as a general purpose Natural Language Processing (NLP) system and has been under development a t the University of Durham since 1986 .", "acronyms": [[170, 173]], "long-forms": [[141, 168]]}, {"text": "proaches, we also report on supplying them with different reordering rule sets: a set that was learned on manually aligned data (MAN), and a set learned on the same data but with automatic", "acronyms": [[129, 132]], "long-forms": [[106, 114]]}, {"text": "on these intuitions, we define the following features: Document frequency of constituents (DF): We use the document frequency of a constituent as", "acronyms": [[91, 93]], "long-forms": [[55, 73]]}, {"text": "The types of links  traversed in the search (in the first case) or the checked slots (in the second case) are a  function of the semantic lass (SEM-C) of the first constituent. This function assigns to each ", "acronyms": [[144, 149]], "long-forms": [[129, 137]]}, {"text": "tences in the other part of the corpus. Therefore, we performed a language identification (LID)based filtering afterwards (performed only on the", "acronyms": [[91, 94]], "long-forms": [[66, 89]]}, {"text": "Table 2: Parsing accuracy for 2-planar parser in comparison to MaltParser with (PP) and without (P) pseudo-projective transformations. LAS = labeled attachment score; UAS = unlabeled attachment score; NPP = precision on non-projective arcs; NPR = recall on non-projective arcs.", "acronyms": [[167, 170], [80, 82], [241, 244], [201, 204], [135, 138]], "long-forms": [[173, 199], [141, 165], [257, 271]]}, {"text": "SK(d1,d1)?SK(d2,d2) 4 Experiments The use of WordNet (WN) in the term similarity function introduces a prior knowledge whose impact", "acronyms": [[54, 56], [0, 2], [10, 12]], "long-forms": [[45, 52]]}, {"text": "An example of a comma rule is the following: SX=S X ; ? SX=S X (18)", "acronyms": [[45, 47], [56, 58]], "long-forms": [[48, 51], [59, 62]]}, {"text": "facts or splits the  goal into new subgo~ls uch as to show the facts in the premises of n. The derivation of a fact is  conveyed by so-called mathematics ommunicating acts (MCAs) and accompanied by storing the  fact as a chunk in the declarative memory.", "acronyms": [[173, 177]], "long-forms": [[142, 171]]}, {"text": "targeted text. This type of question has been studied extensively in the Text Retrieval Conference Question Answering (QA) Track (Dang, Kelly, and Lin 2007). Using the", "acronyms": [[119, 121]], "long-forms": [[99, 117]]}, {"text": "1 Introduction A fairly novel area of retrieval called topic detection and tracking (TDT) attempts to design methods to automatically (1) spot new, previously unreported events, and (2)", "acronyms": [[85, 88]], "long-forms": [[55, 83]]}, {"text": "On the basis of these specifications, a mapping between VAML and Concrete AML (CAML) can be made. CAML", "acronyms": [[79, 83], [56, 60], [98, 102]], "long-forms": [[65, 77]]}, {"text": "TV programs they watch.  Collaborative filtering (CF) (Resnick et al, 1994; Breese et al, 1998) and content-based (or", "acronyms": [[50, 52], [0, 2]], "long-forms": [[25, 48]]}, {"text": "of CoNLL-2000 and LLL-2000, Lisbon, Portugal.  Tageszeitung (TAZ) Corpus. Contrapress Media GmbH.", "acronyms": [[61, 64], [3, 13], [18, 26], [92, 96]], "long-forms": [[47, 59]]}, {"text": "Xi, where Par(Xi) denotes the parents of Xi.  Conditional probability distributions (CPDs) can be defined in various ways, from look-up tables", "acronyms": [[85, 89], [10, 13]], "long-forms": [[46, 83], [30, 37]]}, {"text": "The rules, which may be different for each  dictionary, are written using a formalism in the spirit of  the \"definite clause grammars\" (DCG's) of Pereira and  Warren (1980) and \"modular logic grammars\" (MLG's) ", "acronyms": [[136, 141], [203, 208]], "long-forms": [[109, 133], [178, 200]]}, {"text": "P (di|h(d1,..., di?1)) Using a neural network architecture called Simple Synchrony Networks (SSNs), the history representation h(d1,..., di?1) is incrementally computed from", "acronyms": [[93, 97]], "long-forms": [[73, 91]]}, {"text": "We conduct a case study of dialectal language in online conversational text by investigating African-American English (AAE) on Twitter.", "acronyms": [[119, 122]], "long-forms": [[93, 117]]}, {"text": "guished from mentions in text or mentions in other sources. The Terence Annotation Format (TAF) provides a unified framework to annotate events, par-", "acronyms": [[91, 94]], "long-forms": [[64, 89]]}, {"text": " 1 Introduction Word Sense Disambiguation(WSD) is the process of assigning a meaning to a word based on the context", "acronyms": [[42, 45]], "long-forms": [[16, 41]]}, {"text": "ponent Analysis (PCA). We then compare our embeddings with the CW (Collobert and Weston, 2008), Turian (Turian et al.,", "acronyms": [[63, 65]], "long-forms": [[67, 87]]}, {"text": ". However, a method based on singular value decomposition (SVD) provides an efficient and exact solution to this prob-", "acronyms": [[59, 62]], "long-forms": [[29, 57]]}, {"text": "Construct word representation model for  corpus in the base time, D(TB), and in the  target time, D(TT). ( Section 2.1) ", "acronyms": [[100, 102]], "long-forms": [[85, 96]]}, {"text": "extract phrasal translations or transliterations of  phrase based on machine learning, or more  specifically the conditional random fields (CRF)  model.", "acronyms": [[140, 143]], "long-forms": [[113, 138]]}, {"text": "This paper proposes a method of sentence extraction based on Support Vector Machines (SVMs). To", "acronyms": [[86, 90]], "long-forms": [[61, 84]]}, {"text": "in their absence. If both people are aware of the event, we call it Interaction (INR): for example, one person is telling the other a story.", "acronyms": [[81, 84]], "long-forms": [[68, 79]]}, {"text": "cific characteristics in form, meaning, function, and distribution. Each entry includes a free text definition, schematic structural description, definitions of construction elements (CEs) and annotated example sentences.", "acronyms": [[184, 187]], "long-forms": [[161, 182]]}, {"text": "ment. In Proceedings of the 34th Annual Meeting of the Cognitive Science Society (CogSci), Sapporo. ", "acronyms": [[82, 88]], "long-forms": [[55, 80]]}, {"text": "Adjoining Grammars as the compilation of a  more abstract and modular layer of linguistic  description : the  metagrammar (MG). MG ", "acronyms": [[123, 125], [128, 130]], "long-forms": [[110, 121]]}, {"text": "mented in song sentiment classification, i.e. audiobased (AB) approach, knowledge-based (KB) approach and machine learning (ML) approach, in  which the latter two approaches are also referred to ", "acronyms": [[124, 126], [58, 60], [89, 91]], "long-forms": [[106, 122], [46, 56], [72, 87]]}, {"text": "Understanding (NLU) framework (see below), while ASR includes features such as speech/nonspeech (SNS) detection and automatic gain control (AGC).", "acronyms": [[97, 100], [15, 18], [49, 52], [140, 143]], "long-forms": [[79, 95], [116, 138]]}, {"text": "Table 2: Key details of semantic orientation (SO) lexicons. ASL = affix seeds lexicon, GI = General Inquirer, MSOL = Macquarie semantic orientation lexicon, PSL = Pitt subjectivity lexicon, SWN = SentiWordNet, TLL = Turney?Littman lexicon.", "acronyms": [[110, 114], [157, 160], [46, 48], [60, 63], [87, 89], [190, 193], [210, 213]], "long-forms": [[117, 155], [163, 188], [24, 44], [66, 85], [92, 108], [196, 208], [216, 238]]}, {"text": "A phonetic system represents sound segments as 3Phonemic and phonetic representations are given in the International Phonetic Alphabet (IPA). ", "acronyms": [[136, 139]], "long-forms": [[103, 134]]}, {"text": "target question, or zero if the target question was not found. The Mean Reciprocal Rank (MRR) is the mean of the reciprocal ranks over all the input ques-", "acronyms": [[89, 92]], "long-forms": [[67, 87]]}, {"text": "168 Figure 1: Plots of concreteness vs. imageability scores for literal vs. nonliteral words in the VUAMC (Conc=concreteness, Imag=imageability, NL=nonliteral, L=literal) concrete than the dependent/s; H", "acronyms": [[145, 147], [100, 105], [107, 111], [126, 130]], "long-forms": [[148, 158], [112, 124], [131, 143], [162, 169]]}, {"text": " 2) Prediction precision(PP) =  number of words with correct BPs(CortBP)  total word number (TWN) ", "acronyms": [[65, 71]], "long-forms": [[53, 63]]}, {"text": "In this example, only Midas can be chosen for the role of twit, but any member of the class PN (proper names) having the attributes male, brave and handsome can be", "acronyms": [[92, 94]], "long-forms": [[96, 108]]}, {"text": "5) is blocked by (7), because of the  passinginto the subject'a story about es'; i.e., the specifier of  INFL (in the transformational ccount) or of VP (in theories  like GPSG, etc.).", "acronyms": [[105, 109], [149, 151], [171, 175]], "long-forms": [[111, 134]]}, {"text": "for each word in the DAL. ( e.g., the verb definition for LOL (laugh out loud) in Wiktionary is ? To laugh", "acronyms": [[58, 61], [21, 24]], "long-forms": [[63, 77]]}, {"text": "ers. In Proceedings of the 19th International Conference on Compuatational Linguistics (COLING),  pages 556?562.", "acronyms": [[88, 94]], "long-forms": [[60, 86]]}, {"text": "maries C are overall better for answering questions than summaries B. Comparison between B and C (B-C) precision recall", "acronyms": [[98, 101]], "long-forms": [[89, 96]]}, {"text": "lar expressions. So the detection of factoid words  can be achieved by Finite State Automaton(FSA). ", "acronyms": [[94, 97]], "long-forms": [[71, 92]]}, {"text": "  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 177?182, October 25-29, 2014, Doha, Qatar.", "acronyms": [[90, 95]], "long-forms": [[40, 88]]}, {"text": "Our systems use both corpus-based and knowledge-based approaches: Maximum Entropy(ME) (Lau et al, 1993; Berger et al, 1996; Ratnaparkhi, 1998) is", "acronyms": [[82, 84]], "long-forms": [[66, 81]]}, {"text": "........................................ LTH  ........... Link between STH and LTHs  TLink (Translation Link) between language LTHs  Figure 2: Example of an STH linked to a Fragment ", "acronyms": [[85, 90], [71, 74], [79, 83], [127, 131], [157, 160], [41, 44]], "long-forms": [[92, 108]]}, {"text": " 3 The V IT  Format   The VIT (short for Verbmobil Interface Term) was  designed as a common output format for the two ", "acronyms": [[26, 29], [7, 11]], "long-forms": [[41, 65]]}, {"text": " Shirai, K., T. Tokunaga, and H. Tanaka: Automatic Extraction of Japanese Grammar f om  a Bracketed Corpus, in Natural Language Processing Pacific Rim Symposium(NLPRS'gs),  pp.", "acronyms": [[161, 169], [173, 175]], "long-forms": [[111, 160]]}, {"text": "Table 1: Purity (Pu), collocation (Co), and F1 scores of our model and the syntactic baseline in percent. Performance on arguments (Argn), adjuncts (ArgM), and overall results (Arg*) are shown separately. ", "acronyms": [[149, 153], [35, 37], [177, 180], [132, 136], [17, 19]], "long-forms": [[121, 130], [22, 33], [9, 15]]}, {"text": "They used a statistical finite-state transducer (SFST) as a generative model and a support vector machine (SVM) and conditional random fields (CRF) as discrim-", "acronyms": [[107, 110], [49, 53], [143, 146]], "long-forms": [[83, 105], [12, 47], [116, 141]]}, {"text": " 1 Introduction Natural Language Processing (NLP) and Machine Learning (ML) are making a significant impact in", "acronyms": [[45, 48], [72, 74]], "long-forms": [[16, 43], [54, 70]]}, {"text": "an all time high.  \u0000 HER (heritage): He named the new villa after his wife.", "acronyms": [[21, 24]], "long-forms": [[26, 34]]}, {"text": "search has encore'aged the FI{UM1 ) api)roach. The  SUMMONS (SUMMarizing Online News artMes)  system (McKeown and Radev, 1999) takes tem- ", "acronyms": [[52, 59]], "long-forms": [[61, 84]]}, {"text": "carded in LSI-based approaches. We dub our model ONETA (OrthoNormal Explicit Topic Analysis) and empirically show that on a cross-lingual retrieval", "acronyms": [[49, 54], [10, 13]], "long-forms": [[56, 91]]}, {"text": "native (see \\[2\\]).  Task  Manager  (TM)   In our previous experience, speech recognition systems ", "acronyms": [[37, 39]], "long-forms": [[21, 34]]}, {"text": "Way (1991) emphasizes the importance of this taxonomy by positing a central role for a dynamic type hierarchy (DTH) in metaphor, one that can create new and com-", "acronyms": [[111, 114]], "long-forms": [[87, 109]]}, {"text": "Not Available?.  OmegaWiki (OW) is a freely editable online dictionary like WKT.", "acronyms": [[28, 30], [76, 79]], "long-forms": [[17, 26]]}, {"text": "Abstract This paper explores the use of set expansion (SE) to improve question answering (QA) when the expected answer is a list of entities", "acronyms": [[90, 92], [55, 57]], "long-forms": [[70, 88], [40, 53]]}, {"text": " 1 Introduction Semantic Role Labeling (SRL), independently of the approach adopted, comprehends two steps be-", "acronyms": [[40, 43]], "long-forms": [[16, 38]]}, {"text": "pus Linguistics 2001 Conference, pages 274?280. Lancaster University (UK). ", "acronyms": [[70, 72]], "long-forms": [[58, 68]]}, {"text": "2004. A maxi-mum-entropy Chinese parser augmented by transformation-based learning. ACM Transactions on Asian Language Information Processing (TALIP) 3(2): 159-168. Pascale Fung, Zhaojun Wu, Yongsheng Yang and Dekai Wu.", "acronyms": [[143, 148]], "long-forms": [[88, 141]]}, {"text": "ditto Shi-fen three-hours ten-minute, i.e. 'three-  ten'), post-position phrases (GPs), preposition  phrases (PPs), br adverbs (ADVs). They all share ", "acronyms": [[128, 132], [82, 85], [110, 113]], "long-forms": [[119, 126], [88, 108], [59, 80]]}, {"text": "900  Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 48?57, Gothenburg, Sweden, April 27, 2014.", "acronyms": [[74, 79], [83, 87]], "long-forms": [[40, 72]]}, {"text": "coverage of the language's grammar rules.  This paper introduces a hidden Markov model (HMM) which  has been developed for Japanese word segmentation.", "acronyms": [[88, 91]], "long-forms": [[67, 86]]}, {"text": "the impact of various kinds of physical degradation that pages may endure before they are scanned and processed using optical character recognition (OCR) software. ", "acronyms": [[149, 152]], "long-forms": [[118, 147]]}, {"text": " For both these models, we use cost sensitive LibSVM with radial basis kernel function (RBF) as the learning algorithm (Hsu et al.,", "acronyms": [[88, 91], [46, 52]], "long-forms": [[58, 86]]}, {"text": "Berwick and Weinberg (1982). Gazdar noted that if  transformational grammars (TG's) were stripped of  all their transformations, they became CFL- ", "acronyms": [[78, 82], [141, 144]], "long-forms": [[51, 76]]}, {"text": "pus (Mitchell et al, 2003)1. Both the Newswire (NWIRE) and Broadcast News (BNEWS) sections where split into 60-20-20% document-based par-", "acronyms": [[75, 80], [48, 53]], "long-forms": [[59, 73], [38, 46]]}, {"text": " 3.3 Linear-chain CRF for Extraction The alignment CRF (AlignCRF) model described in Section 3.1 is able to predict labels for a text", "acronyms": [[56, 64], [18, 21]], "long-forms": [[41, 54]]}, {"text": "ple sentences. Such knowledge is also important for Textual Entailment (TE), a generic framework for modeling semantic inference.", "acronyms": [[72, 74]], "long-forms": [[52, 70]]}, {"text": "We annotate  the semantic roles for the 50 most frequent verbs in  the Quranic Arabic Dependency Treebank (QATB)  (Dukes and Buckwalter 2010).", "acronyms": [[107, 111]], "long-forms": [[71, 105]]}, {"text": "3 The  S imulat ion  Mode l   The computational simulation supports the evolu-  tion of a population of Language Agents (LAgts),  similar to Holland's (1993) Echo agents.", "acronyms": [[121, 126]], "long-forms": [[104, 119]]}, {"text": "Evaluation Metrics: We evaluate the performance of question retrieval using the following metrics: Mean Average Precision (MAP) and Precision@N (P@N).", "acronyms": [[123, 126], [145, 148]], "long-forms": [[99, 121], [132, 143]]}, {"text": "discourses presented to the human subjects.  6.1 Semantically Slanted Discourse (SSD) Methodology: The Motivation for the  First Part ", "acronyms": [[81, 84]], "long-forms": [[49, 79]]}, {"text": "(? baseline?) and MT (Madnani et al, 2012). RAE", "acronyms": [[18, 20], [44, 47]], "long-forms": [[22, 32]]}, {"text": "Each of these sets is further divided by three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews). ", "acronyms": [[114, 119], [66, 71], [85, 91]], "long-forms": [[98, 112], [56, 64], [74, 83]]}, {"text": "each frame from each camera view.  3.3 Dyadic Features (DF)  All of the features discussed above are low-level ", "acronyms": [[56, 58]], "long-forms": [[39, 54]]}, {"text": "\u0006? ( PM), tree matching without the auxiliary patterns (TM), and tree matching with the auxiliary patterns", "acronyms": [[56, 58]], "long-forms": [[49, 54]]}, {"text": " 2003. Voice extensible markup language (VoiceXML) version 2.0.", "acronyms": [[41, 49]], "long-forms": [[7, 39]]}, {"text": "1 Introduction For the past three decades, there has been a great deal of work on the automatic identification (ID) of languages from the speech signal alone.", "acronyms": [[112, 114]], "long-forms": [[96, 110]]}, {"text": "man annotators identified in the texts. TP (true positives) is |A?G|, FP (false positives) is |A\\G|, FN (false negatives) is |G\\A|, and precision (P ),", "acronyms": [[70, 72], [40, 42], [101, 103]], "long-forms": [[74, 89], [44, 58], [105, 120], [136, 145]]}, {"text": "In Proceedings of the Conference of the Association for Machine Translation in the Americas (AMTA), Denver, Colorado. ", "acronyms": [[93, 97]], "long-forms": [[22, 91]]}, {"text": "The CoreSC scheme consists of three layers; the first layer corresponds to eleven concepts (Background (BAC), Hypothesis (HYP), Motivation (MOT), Goal (GOA), Object (OBJ), Method (MET), Model", "acronyms": [[122, 125], [140, 143], [4, 10], [104, 107], [152, 155], [166, 169], [180, 183]], "long-forms": [[110, 120], [128, 138], [92, 102], [146, 150], [158, 164], [172, 178]]}, {"text": "Roget (RG) ablaze aglow alight argent auroral beaming blazing brilliant WordNet (WN) burnished sunny shiny lustrous undimmed sunshiny brilliant TransGraph (TG) nimble ringing fine aglow keen glad light picturesque Lin (LN) red yellow orange pink blue brilliant green white dark", "acronyms": [[156, 158], [219, 221], [81, 83], [7, 9]], "long-forms": [[144, 154], [214, 217], [72, 79], [0, 5]]}, {"text": "Entailment [13] was organized by SemEval-2.  Recognizing Inference in Text (RITE)2 organized by NTCIR-9 in 2011 is the first to expand ", "acronyms": [[76, 80], [96, 101]], "long-forms": [[45, 74]]}, {"text": "An Organization for a Dictionary of Word Senses  3. A \"Sense Data Item\" (SDI) represents one distinct sense common to a set of wordq  and/or phrases.", "acronyms": [[73, 76]], "long-forms": [[55, 70]]}, {"text": "We show that the best  prediction of translation complexity is given by the  average number of syllables per word (ASW). The ", "acronyms": [[115, 118]], "long-forms": [[77, 113]]}, {"text": " Data set We evaluate segmentation performance on the Penn Arabic Treebank (ATB).5 It consists of about 4,500 sentences of modern Arabic obtained", "acronyms": [[76, 79]], "long-forms": [[59, 74]]}, {"text": " 4.1 Representing Transformations as FSTs Finite State Transducers (FSTs) provide a natural formalism for representing output transformations.", "acronyms": [[68, 72], [37, 41]], "long-forms": [[42, 66]]}, {"text": "Context-Free Grammars 2.1 Minimalist Grammars A Minimalist Grammar (MG) (Stabler and Keenan, 2003)1 is a five-tuple", "acronyms": [[68, 70]], "long-forms": [[48, 66]]}, {"text": "tiveness of rule-based (Zilka et al., 2013), maximum entropy (MaxEnt) (Lee and Eskenazi, 2013) and deep neural network (DNN) (Henderson et al.,", "acronyms": [[62, 68]], "long-forms": [[49, 60]]}, {"text": "that is as close as possible to the gold standard C. Most work on verb clustering has used the Fmeasure or the Rand Index (RI) (Rand, 1971) for evaluation, which rely on counting pairwise", "acronyms": [[123, 125]], "long-forms": [[111, 121]]}, {"text": "2008) and a corpus annotated for the entities Finding, Substance and Body was used for training a conditional random fields (CRF) system (Wang, 2009) as well as for training an en-", "acronyms": [[125, 128]], "long-forms": [[98, 123]]}, {"text": "and tfidf of unigrams, bigrams, and trigrams.  DAL (Dictionary of Affect in Language) is a psycholinguistic resource to measure the emo-", "acronyms": [[47, 50]], "long-forms": [[52, 84]]}, {"text": "extend Eigenwords, spectral monolingual word embeddings based on canonical correlation analysis (CCA), to crosslingual settings with sentence-alignment.", "acronyms": [[97, 100]], "long-forms": [[65, 95]]}, {"text": "applied this formula to a vocabulary of single terms.  Subiect Field Code (SFC). This system applies a ", "acronyms": [[75, 78]], "long-forms": [[55, 73]]}, {"text": " 04 (a) Same Topic (ST) 0.00 0.01 0.02 0.03 0.04 0.05 0.06", "acronyms": [[20, 22]], "long-forms": [[8, 18]]}, {"text": "number of bilingual term pairs)  We compare our model with IBM Model 2  (IBM-2), and IBM Model 4 (IBM-4) implemented by GIZA++ (Och et al, 2003).", "acronyms": [[98, 103], [73, 78]], "long-forms": [[85, 96], [59, 70]]}, {"text": "The next-to-last  column shows the precision (PRE)--the true positives divided by all verbs that Lerner  judged to be +S. The final column shows the recall (REC)--the true positives divided  by all verbs that were judged +S by hand.", "acronyms": [[157, 160], [46, 49]], "long-forms": [[149, 155], [35, 44]]}, {"text": "on specific characteristics of the signs, have appeared in the international community: HamNoSys  (Prillwitz et al 1989), SEA (Sistema de Escritura  Alfab?tica) (Herrero, A., 2004) and SignWriting ", "acronyms": [[122, 125], [88, 96]], "long-forms": [[127, 134]]}, {"text": "1. Introduction Semantic role labeling (SRL) is the task of identifying arguments for a predicate and assigning semantically meaningful labels to them.", "acronyms": [[40, 43]], "long-forms": [[16, 38]]}, {"text": "CN Bank(CNB): 200,000 samples  ? TFN Bank(TFNB): 38,769 samples  CPN Bank(CPNB): 17,637 samples ", "acronyms": [[42, 46], [8, 11], [74, 78]], "long-forms": [[33, 40], [0, 7], [65, 73]]}, {"text": "110  ehange(CHA) communication(COMM)  cognition(COG) competition(COMP)  contact(CeNT) motion(MOT) ", "acronyms": [[48, 51], [65, 69]], "long-forms": [[38, 46], [53, 63]]}, {"text": "Deep-syntactic structures (DSyntSs);  ? Surface syntactic structures (SSyntSs);  61 ", "acronyms": [[70, 77]], "long-forms": [[40, 68]]}, {"text": "domain-oriented semantics of the GENIA event corpus, and suggests a factor for utilizing NLP techniques for Text Mining (TM) in the bio-medical domain.", "acronyms": [[121, 123], [33, 38], [89, 92]], "long-forms": [[108, 119]]}, {"text": "tion (Briscoe, 1994), more recently using rule-based filters (White and Rajkumar, 2008) in a combinatory categorial grammar (CCG). Our focus is specifically", "acronyms": [[125, 128]], "long-forms": [[93, 123]]}, {"text": "We apply LDA on  the user-word matrix UW:  UW = UM * MW  , where UM is the user-hidden matrix, MW is the ", "acronyms": [[48, 50], [9, 12], [38, 40], [43, 45], [53, 55], [65, 67], [95, 97]], "long-forms": [[51, 52], [21, 37]]}, {"text": "In Proc. of the 4th Workshop  on Treebanks and Linguistic Theories (TLT), pages  149?160.", "acronyms": [[68, 71]], "long-forms": [[33, 66]]}, {"text": "mentary and United Nations parallel corpora. The semantic phrase table (SPT) was extracted from the same corpora annotated with FreeLing (Carreras et", "acronyms": [[72, 75]], "long-forms": [[49, 70]]}, {"text": "tribution from most features but C1 seems to benefit more from GENIA named entity tagging, Human Phenotype Ontology (HPO), Foundation Model of Anatomy (FMA) and", "acronyms": [[117, 120], [33, 35], [63, 68], [152, 155]], "long-forms": [[91, 115], [123, 150]]}, {"text": "A Machine Learning based Approach to Evaluating Retrieval Systems Huyen-Trang Vu and Patrick Gallinari Laboratory of Computer Science (LIP6) University of Pierre and Marie Curie", "acronyms": [[135, 139]], "long-forms": [[103, 133]]}, {"text": "TM has been shown to be effective in several Information Retrieval (IR) and Natural Language Processing (NLP) applications. For example, in cross language IR, TM was used to handle out-of-vocabulary query words by mining transliterations between words in queries and top n retrieved documents and then using transliterations to expand queries (Udupa et al, 2009a). In Machine Translation (MT), TM can improve alignment at training time and help enrich phrase tables with named entities that may not appear in parallel training data. More broadly, TM is a character mapping problem.", "acronyms": [[389, 391], [68, 70], [105, 108], [155, 157], [159, 161], [394, 396]], "long-forms": [[368, 387], [45, 66], [76, 103]]}, {"text": "which fixes its results after a given time ? and report the corresponding word error rate (WER). This", "acronyms": [[91, 94]], "long-forms": [[74, 89]]}, {"text": "call this set of features Feat-IV.  Table 3 demonstrates the word error rate(WER) improvement enabled by our binary subsampling", "acronyms": [[77, 80]], "long-forms": [[61, 75]]}, {"text": "are usually followed by a number n ? 0. DU = discourse unit, ce = conversational event, K = DRS, u = utterance, sem", "acronyms": [[40, 42], [92, 95]], "long-forms": [[45, 54], [101, 110]]}, {"text": "s+trsl Alhnd qmrA<STnAEyA <lY Almryx ? India will send a satellite to Mars [in 2013]?. In every tree node, the terms above the line arepart of the CATiB annotations: the word, POS (VRB = verb, PRT = particle, PROP = proper noun, NOM = nominal)and relation (MOD = modifier, SBJ = subject, OBJ = object). The terms under the line are the Buckwalter POS tag, thelemma and the gloss, respectively.", "acronyms": [[181, 184], [193, 196], [209, 213], [229, 232], [257, 260], [273, 276], [288, 291], [176, 179], [147, 152], [347, 350]], "long-forms": [[187, 191], [199, 207], [216, 222], [235, 246], [263, 271], [279, 286], [294, 300]]}, {"text": " 2. Tezt routing, tezt fdter/n9, and SDI (selective dissemination of information): These terms  refer to a loose collection of text classification tasks such as managing personal electronic mail, ", "acronyms": [[37, 40]], "long-forms": [[42, 65]]}, {"text": "  Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 67?68, Gothenburg, Sweden, April 27, 2014.", "acronyms": [[71, 76]], "long-forms": [[37, 69]]}, {"text": "only from the corresponding source language segment. We use the Moses statistical MT (SMT) toolkit (Koehn et al.,", "acronyms": [[86, 89]], "long-forms": [[70, 84]]}, {"text": "qn  e.g., ? MP (Member of Parliament)? ", "acronyms": [[12, 14]], "long-forms": [[16, 36]]}, {"text": "In this paper we restrict our attention to the  translation from the English-oriented level (EL)  to the domain model level (DML) since this is  where CEs are disambiguated bychoosing unam- ", "acronyms": [[125, 128], [93, 95], [151, 154]], "long-forms": [[105, 123], [69, 91]]}, {"text": "(iv) Embedded appositional phrases.  (2) Very long PE's (Phrasal Elements) appear occasionally. ( eg.", "acronyms": [[51, 55]], "long-forms": [[57, 73]]}, {"text": "Gabrilovich and Markovitch, 2007; Radinsky et al., 2011), the vector space models (VSMs) based on the idea of distributional similarity (Turney", "acronyms": [[83, 87]], "long-forms": [[62, 81]]}, {"text": "competition submissions). Notice that most were using Support Vector Machine (SVM) with bagof-word features in a very small window, local col-", "acronyms": [[78, 81]], "long-forms": [[54, 76]]}, {"text": " 3 Corpus description The British National Corpus (BNC) (Leech, 1992) is annotated with POS tags, using the CLAWS-4", "acronyms": [[51, 54], [88, 91], [108, 115]], "long-forms": [[26, 49]]}, {"text": "verbs. They adopted the Nearest Neighbor (NN) and Information Bottleneck (IB) methods for clustering.", "acronyms": [[74, 76], [42, 44]], "long-forms": [[50, 72], [24, 40]]}, {"text": "Since the bilingual corpus is only aligned at the document level, we performed sentence alignment using the Champollion Tool Kit (CTK).4 After removing sentences with no aligned sentence, a total", "acronyms": [[130, 133]], "long-forms": [[108, 128]]}, {"text": " ? Bigram Predictability (BP): Defined as the predictability of a word given a previous word, it", "acronyms": [[26, 28]], "long-forms": [[3, 24]]}, {"text": " 2 Platform Architecture  The Application Generation Platform (AGP), created during the European project GEMINI, is an ", "acronyms": [[63, 66], [105, 111]], "long-forms": [[30, 61]]}, {"text": "1 Introduction Linguistics studies have shown that action verbs often denote some change of state (CoS) as the result of an action, where the change of state of-", "acronyms": [[99, 102]], "long-forms": [[82, 97]]}, {"text": "vestigate four factors: text length (TL), sentence length (SL), average number of words per sentence (WS), and average number of characters per word (CW). Since", "acronyms": [[150, 152], [37, 39], [59, 61], [102, 104]], "long-forms": [[129, 148], [24, 35], [42, 57], [82, 100]]}, {"text": "grammar (LTAG) (Bangalore and Joshi, 1999) and then extended to other lexicalized grammars, such as combinatory categorial grammar (CCG) (Clark, 2002) and Head-driven phrase structure grammar", "acronyms": [[132, 135], [9, 13]], "long-forms": [[100, 130]]}, {"text": "185  Table h Size of the corpora of HTML pages (in Mb) collected on the four patterns (1.a-d)  through AltaVista (AV) and Northern Light (NL). ", "acronyms": [[114, 116], [138, 140], [36, 40], [51, 53]], "long-forms": [[103, 112], [122, 136]]}, {"text": "Extraction algorithms: ReV = REVERB; Comp = Compression; Data sets: NS = NewsSpike URLs; All = news 2008-2014.", "acronyms": [[83, 87], [23, 26], [37, 41]], "long-forms": [[73, 82], [29, 35], [44, 55]]}, {"text": "only limited discontinuities in each tree.  Generalized Multitext Grammar (GMTG) offers a way to synchronize Mildly Context-Sensitive", "acronyms": [[75, 79]], "long-forms": [[44, 73]]}, {"text": "perform rather well because the combined recency  bias representation worked well on its own and be-  cause the restricted memory (RM) bias essentially  discards features that are distant from the relative ", "acronyms": [[131, 133]], "long-forms": [[112, 129]]}, {"text": "is necessary to train sentence prediction models, a third approach that uses labeled comment data for training (CTr) but sentences for testing (STe) is included in the CTR/STE row.", "acronyms": [[144, 147], [112, 115], [168, 175]], "long-forms": [[121, 142], [85, 110]]}, {"text": "UAS = unlabeled attachment score; UEM = unlabeled exact match; LAS = labeled attachment score. ", "acronyms": [[63, 66], [0, 3], [34, 37]], "long-forms": [[69, 93], [6, 32], [40, 61]]}, {"text": "  Secondly, as for the word order of prepositional  phrases (PP), Arabic and English are similar in  that PPs generally appear at the end of the sen-", "acronyms": [[61, 63], [106, 109]], "long-forms": [[52, 59]]}, {"text": "fr, veronis@fraixll  .univ-aix. fr  Abstract, MULTEXT (Multilingual Text \"Fools and  Corpora) is the largest project funded in the Commission ", "acronyms": [[46, 53], [22, 30]], "long-forms": [[55, 72]]}, {"text": "tions. The CSR techniques are based on a continuous-  observation Hidden Markov Model (HMM) approach. ", "acronyms": [[87, 90], [11, 14]], "long-forms": [[66, 85]]}, {"text": "In this paper, we describe a mechanism which gen-  erates rebuttals to such rejoinders in the context of  arguments generated from Bayesian etworks (BNs)  (Pearl, 1988).", "acronyms": [[149, 152]], "long-forms": [[131, 147]]}, {"text": "den Markov Models (HMMs), Conditional Random Fields (CRFs), Maximum Entropy Markov  Models (MEMMs), etc. ", "acronyms": [[92, 97], [19, 23], [53, 57]], "long-forms": [[60, 90], [4, 17], [26, 51]]}, {"text": "age caption generator. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June.", "acronyms": [[90, 94], [30, 34]], "long-forms": [[49, 88]]}, {"text": " 1356 Batch Training (BFGS) Online Training (SD) Simulated parameter initialization chunked data selection Annealing", "acronyms": [[22, 26], [45, 47]], "long-forms": [[6, 20]]}, {"text": " The algorithm was first proposed by the Institute for Computer Science  and Technology (ICST) of the National Bureau of Standards (NBS') in 1973. ", "acronyms": [[132, 136], [89, 93]], "long-forms": [[102, 130], [41, 87]]}, {"text": " 1 Introduction Word Sense Disambiguation (WSD) is the process of resolving the meaning of a word unambiguously", "acronyms": [[43, 46]], "long-forms": [[16, 41]]}, {"text": " 2 Methodo logy   A User Centered (UC) approach was adopted for the  design of GEPPETTO.", "acronyms": [[35, 37], [79, 87]], "long-forms": [[20, 33]]}, {"text": " 5 Conclusion Our approach is akin to so-called semantic role labelling (SRL) approaches [CM05] and to several rewriting approaches developed to modify parsing output in RTE systems [Ass07].", "acronyms": [[73, 76], [90, 94], [170, 173], [183, 188]], "long-forms": [[48, 71]]}, {"text": "sentence, Multiple Linear Regression is used to  build a quantitative model relating the content  tags of the source language (SL) sentence to the  response, which is assumed to be the sum of the ", "acronyms": [[127, 129]], "long-forms": [[110, 125]]}, {"text": "Question reformulation ? Information Extraction (IE) ?", "acronyms": [[49, 51]], "long-forms": [[25, 47]]}, {"text": "The divergence of the two probability distributions is calculated using a standard information-theoretic measure, the Kullback Leibler (KL-) divergence (Cover and Thomas 1991): Fixednesssyn (v, n)", "acronyms": [[136, 139]], "long-forms": [[118, 134]]}, {"text": "3.4 Innovative Features of SPTK The most similar kernel to SPTK is the Syntactic Semantic Tree Kernel (SSTK) proposed in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Mos-", "acronyms": [[103, 107], [27, 31], [59, 63]], "long-forms": [[81, 101]]}, {"text": "entries in an existing knowledge base is called entity linking and has been proposed and studied in the Knowledge Base Population (KBP) track of the Text Analysis Conference (TAC) (McNamee and Dang,", "acronyms": [[131, 134], [175, 178]], "long-forms": [[104, 129], [149, 173]]}, {"text": "Arabic Penn TreeBank POS tagset. Base Phrase (BP) Chunking is the process of creating non-recursive base phrases such", "acronyms": [[46, 48], [21, 24]], "long-forms": [[33, 44]]}, {"text": "One means of achieving a fiat structure with extrinsic  ordering is by using the ID/LP formalism, a subformalism of  GPSG that allows immediate dominance (ID) information to be  specified separately from linear precedence (LP) notions. (", "acronyms": [[155, 157], [81, 86], [117, 121], [223, 225]], "long-forms": [[134, 153], [204, 221]]}, {"text": "abbreviations. ACM Transactions on Information Systems (TOIS), 24(3):380?404. ", "acronyms": [[56, 60], [15, 18]], "long-forms": [[19, 54]]}, {"text": "To overcome this problem, Shen et al (2008) proposed a dependency language model (DLM) to exploit longdistance word relations for SMT.", "acronyms": [[82, 85], [130, 133]], "long-forms": [[55, 80]]}, {"text": "tion task which involves acquiring patterns in the distribution of opinion-bearing words and targets using machine learning (ML) techniques. In partic-", "acronyms": [[125, 127]], "long-forms": [[107, 123]]}, {"text": "guished in Boxer: 1. Discourse Representation Structures (DRSs) 2.", "acronyms": [[58, 62]], "long-forms": [[21, 56]]}, {"text": "To model the relations between objects and verbs, we follow the data preparation in (Le et al 2013), using the British National Corpus (BNC) which has been preprocessed and parsed using TreeTagger and", "acronyms": [[136, 139]], "long-forms": [[111, 134]]}, {"text": " 4.4 Tokenizing Multiword Expressions      Multiword Expressions (MWEs) are two or  more words that behave like a single word syntac-", "acronyms": [[66, 70]], "long-forms": [[43, 64]]}, {"text": "noun modification? which generally is shown in the form of a Noun phrase (NP) [A DE B]. A in-", "acronyms": [[74, 76]], "long-forms": [[61, 72]]}, {"text": "tagging, lemmatization, etc.). For corpus query, we employ the Corpus Query Processor (CQP) (CWB; Evert, 2004) which works on the basis of", "acronyms": [[87, 90]], "long-forms": [[63, 85]]}, {"text": " 1 Introduction  Feature term formalisms (FTF) have proven extremely  useful for the declarative representation f linguistic ", "acronyms": [[42, 45]], "long-forms": [[17, 40]]}, {"text": "To our knowledge there exist two off the shelf English Arabic Machine Translation (MT) systems: Tarjim and Almisbar.3 We use both MT systems to translate", "acronyms": [[83, 85], [130, 132]], "long-forms": [[62, 81]]}, {"text": " 2.3 Parsing and DSyntS conversion We adopt Deep Syntactic Structures (DSyntSs) as a format for syntactic structures because they can", "acronyms": [[71, 78], [17, 23]], "long-forms": [[44, 69]]}, {"text": " A simple approach is presented in (Cardie and  Pierce, 1998) called Treebank Apl)roach (TA). This ", "acronyms": [[89, 91]], "long-forms": [[69, 87]]}, {"text": "When using only the former type of feature function, our classifier is equivalent to a maximum entropy (MaxEnt) model. ", "acronyms": [[104, 110]], "long-forms": [[87, 102]]}, {"text": "recognition. In Proceedings of the 26th Conference on Artificial Intelligence (AAAI). ", "acronyms": [[79, 83]], "long-forms": [[54, 77]]}, {"text": "class of mildly context sensitive grsmmars which we  230  call \"Ranked Node Rewriting Grammaxs\" (RNRG's). ", "acronyms": [[97, 103]], "long-forms": [[64, 94]]}, {"text": "are either too wordy or too ungrammatical. Table 1 shows the compression rates (CompR) for the two 8", "acronyms": [[80, 85]], "long-forms": [[61, 78]]}, {"text": "which allows POS tagged and chunked data to be represented (including recursion), and Shakti Standard Format (SSF)2. The editor allows", "acronyms": [[110, 113], [13, 16]], "long-forms": [[86, 108]]}, {"text": "F = F-Measure with Recall and Precision Weighted Equally  J = Japanese S = Spanish  ME = Microelectronics  Mul t i l ingua l  ", "acronyms": [[84, 86]], "long-forms": [[89, 105], [4, 13], [62, 70], [75, 82]]}, {"text": " of the International Joint Conference on Artificial Intelligence (IJCAI). ", "acronyms": [[67, 72]], "long-forms": [[8, 65]]}, {"text": "ing measure of the loss in modeling accuracy:     Probability Loss (PL):   )()()(),( vuvuvu +?", "acronyms": [[68, 70]], "long-forms": [[50, 66]]}, {"text": "We discuss related work in section 5, and conclude in section 6.  2 Index of Productive Syntax (IPSyn) The Index of Productive Syntax (Scarborough, 1990) evaluates a child?s linguistic development by ana-", "acronyms": [[96, 101]], "long-forms": [[68, 94]]}, {"text": "sentences (Sent.), the number of tokens (Tokens) and the unlabeled attachment score (UAS) of MST. ", "acronyms": [[85, 88], [11, 15], [41, 47], [93, 96]], "long-forms": [[57, 83], [0, 9], [33, 39]]}, {"text": "languages. Another, resource-light approach treats the context as a bag of words (BoW) and detects the similarity of contexts on the basis of colloca-", "acronyms": [[82, 85]], "long-forms": [[68, 80]]}, {"text": "location(LOC) psych_feature(PSY)  cognition(COG) feeling(FEEL)  motivation(MOT) abstraction(ABS)  time(TIME) space(SPA) attribute(ATT) ", "acronyms": [[75, 78], [92, 95], [9, 12], [28, 31], [44, 47], [57, 61], [103, 107], [115, 118], [130, 133]], "long-forms": [[64, 73], [80, 90], [0, 8], [14, 27], [34, 43], [49, 56], [98, 102], [109, 114], [120, 129]]}, {"text": " The weight selection is performed by using the  minimum error rate training (MERT) for log-linear  model parameter estimation (Och, 2003).", "acronyms": [[78, 82]], "long-forms": [[49, 76]]}, {"text": "machine learning tasks. We used character n-grams, word n-grams, Parts of Speech (POS) tag n-grams, and perplexity of character trigrams as features.", "acronyms": [[82, 85]], "long-forms": [[65, 80]]}, {"text": "We have proposed two independent evaluation measures: statistical analysis (SA) and classification accuracy (AC). ", "acronyms": [[109, 111], [76, 78]], "long-forms": [[99, 107], [54, 74]]}, {"text": "We performed the same experiments on three dif-  ferent corpora:  Corpus SN (Spanish Novel) train: 15Kw, test:  2Kw, tag set size: 70.", "acronyms": [[73, 75]], "long-forms": [[77, 90]]}, {"text": "model. We tuned the parameters of these features with Minimum Error Rate Training (MERT) (Och, 2003) on the NIST MT03 Evaluation data set (919", "acronyms": [[83, 87], [108, 112], [113, 117]], "long-forms": [[54, 81]]}, {"text": "A study of global inference algorithms in multi-document summarization. In Proceedings of the 29th European Conference on Information Retrieval (ECIR), pages 557?564. ", "acronyms": [[145, 149]], "long-forms": [[99, 143]]}, {"text": "Figure 1: An entity and relation example (Roth and Yih, 2004). Person (PER) and location (LOC) entities are connected by Live in and Located in", "acronyms": [[71, 74], [90, 93]], "long-forms": [[63, 69], [80, 88]]}, {"text": "ability and to give analytical insights into the  features. Classification Accuracy (CAcc), the  percentage of the correctly labeled instances over ", "acronyms": [[85, 89]], "long-forms": [[60, 83]]}, {"text": "46 2 Related Work and Overview Although Spreading Activation (SA) is foremost a cognitive theory modelling semantic mem-", "acronyms": [[62, 64]], "long-forms": [[40, 60]]}, {"text": "ipants represent cognitive scenarios as schematic representations of events, objects, situations, or states of affairs. The participants are called frame elements (FEs) and are described in terms of semantic roles such as AGENT, LOCATION, or MANNER.", "acronyms": [[164, 167]], "long-forms": [[148, 162]]}, {"text": "The meaning of the abbreviations is as follows (for definitions see Section 1): Incr = Incrementality; DP = Discriminatory Power; Train = Trainability; Type = Hardwired Type Selection; Hum = Human Preference Modelling; FB = Full Brevity .", "acronyms": [[219, 221], [103, 105], [130, 135], [185, 188], [169, 173]], "long-forms": [[224, 236], [108, 128], [138, 150], [191, 196], [152, 156]]}, {"text": "of Electrical and Computer Engineering Pohang University of Science and Technology (POSTECH) Advanced Information Technology Research Center (AITrc) San 31, Hyoja-Dong, Pohang, Republic of Korea, 790-784", "acronyms": [[142, 147], [84, 91]], "long-forms": [[93, 140], [39, 82]]}, {"text": "jective U-shaped is an example of gesture enriching an adjectival meaning through the interface default Adjective meaning extended (AdjMExt) AdjMExt: Adjective(u), sem(u) is ?", "acronyms": [[132, 139], [141, 148]], "long-forms": [[104, 130]]}, {"text": "We have adapted the list from Rambow et al(2006) for Arabic, and call it here CORE12. It contains the following tags: verb (V), noun (N), adjective (AJ), adverb (AV), proper noun (PN), pronoun (PRO), relative pronoun (REL), preposition (P), conjunction (C), particle", "acronyms": [[149, 151], [162, 164], [180, 182], [194, 197], [218, 221], [78, 84]], "long-forms": [[138, 147], [118, 122], [128, 132], [154, 160], [167, 178], [185, 192], [200, 216], [224, 235], [241, 252]]}, {"text": "Task (Pradhan et al 2011), one text from each of the five represented genres: Broadcast Conversations (BC), Broadcast News (BN), Magazine (MZ), News Wire (NW) and Web Blogs and News Groups", "acronyms": [[124, 126], [139, 141]], "long-forms": [[108, 122], [129, 137]]}, {"text": "i. The Eng!\\[sh t_qMal_a~franslationSsSSSSSSSS_2~trm  Baak~reusd  Computer Aided T~anslation (CAT) research at Universiti  Sa~m MalsysL~ (USM) began in 1976 as an individual research ", "acronyms": [[94, 97], [138, 141]], "long-forms": [[66, 82], [111, 136]]}, {"text": "(Para), POS, syntactic dependency tree (DT), syntactic constituent tree (CT), named entities (NE), WordNet Relations (WNR), WordNet supersenses (WNSS), semantic role labeling (SRL), causal relations (CR), query classes (QC), query-log co-ocurrences (QLCoOcc).Models: bag-of-words scoring (BOW), tree matching (TreeMatch), linear (LM), log-linear (LLM), statistical learning", "acronyms": [[220, 222], [8, 11], [40, 42], [73, 75], [94, 96], [118, 121], [145, 149], [176, 179], [200, 202], [250, 257], [289, 292], [310, 319], [330, 332], [347, 350]], "long-forms": [[205, 218], [23, 38], [55, 71], [78, 92], [99, 116], [124, 143], [152, 174], [182, 198], [225, 248], [267, 279], [295, 308], [322, 328], [335, 345]]}, {"text": "Using the XTAG Tree Adjoining Grammar [Gro01], we start by listing these variations. Indeed a Tree Adjoining Grammar (TAG) lists the set of all possible syntactic configurations for basic clauses and groups them into so-called (tree) families.", "acronyms": [[118, 121], [10, 14], [39, 44]], "long-forms": [[94, 116]]}, {"text": "either lexically encoded, or depends on the intrinsic properties of G, or coincides with a salient VPT (viewpoint). In striking contrast with", "acronyms": [[99, 102]], "long-forms": [[104, 113]]}, {"text": "rithms for learning neuropsychological and demographic data which are then used for the prediction of Clinical Dementia Rating (CDR) scores for different sub-types of Dementia and other cog-", "acronyms": [[128, 131]], "long-forms": [[102, 126]]}, {"text": "system utterances with respect o dialog context.  Utterances can be either appropriate (AP), inappro-  priate (IP), or ambiguous (AM).", "acronyms": [[88, 90]], "long-forms": [[75, 86]]}, {"text": "v2i = v3i ? a circular convolution model (CON) v1 ? v2 = v3", "acronyms": [[42, 45]], "long-forms": [[23, 34]]}, {"text": "and labeled by the people on Amazon Mechanical Turk, a web service. Amazon Mechanical Turk (MTurk) allows individuals to post jobs on MTurk with a set fee that are", "acronyms": [[92, 97]], "long-forms": [[75, 90]]}, {"text": "al. ( 2008), on the other hand, include features from the grammar in a maximum entropy (ME) classifier to predict new lexical entries for the", "acronyms": [[88, 90]], "long-forms": [[71, 86]]}, {"text": "? airplane?. We will call this the GN (general noun) lexicon.", "acronyms": [[35, 37]], "long-forms": [[39, 51]]}, {"text": "tially lexicalized) syntactic dependencies and patterns. The weight \u0000 is the Local Mutual Informa-tion (LMI) (Evert, 2005) computed on link type frequency (negative LMI values are raised to 0).3.1 Test set", "acronyms": [[104, 107], [165, 168]], "long-forms": [[77, 102]]}, {"text": " Based on the statistics shown in Table 3, the likelihood ratio tests (LRT) model captures the statistical association between a pattern p and a word", "acronyms": [[71, 74]], "long-forms": [[47, 69]]}, {"text": "the first optimum solution is obtained.  (c) EPN for the last optimum solution (EPN-L): The number of the expanded problems when", "acronyms": [[80, 85]], "long-forms": [[45, 78]]}, {"text": "Figure 1: Overall architecture of Sentiment Classifier when a word is used with highly positive (HP), positive (P), highly negative (HN), negative (N) or objective (O) meaning based on a sentiment sense inven-", "acronyms": [[133, 135], [97, 99]], "long-forms": [[116, 131], [80, 95], [102, 110], [138, 146], [154, 163]]}, {"text": "shown in Figure 2. It is observed that the numbers of instances of Conjunct Verb (ConjV),  Passives (Pass), Auxiliary Construction (AC) ", "acronyms": [[82, 87], [101, 105], [132, 134]], "long-forms": [[67, 80], [108, 130], [91, 99]]}, {"text": " In order to rate models M1, M2, M3 in comparison to the vector space model (VS) using MSTs, STs and CTs as alternative hierarchi-", "acronyms": [[77, 79], [87, 91], [93, 96], [101, 104]], "long-forms": [[57, 69]]}, {"text": "ly corrected. An n-gram (n= 2 and 3) language model was then built from the Sinica corpus released  by the Association for Computational Linguistics and Chinese Language Processing (ACLCLP) using  the SRILM toolkit (Stolcke, 2002).", "acronyms": [[182, 188], [201, 206]], "long-forms": [[107, 180]]}, {"text": "Figure 1: Vocabulary growth rates for English,  Spanish, German and Korean for the Spontaneous  Scheduling Task (SST). ", "acronyms": [[113, 116]], "long-forms": [[83, 111]]}, {"text": "2 Related Work The availability of emotion-rich text has helped to promote studies of sentiments from a boutique science into the mainstream of Text Data Mining (TDM). The ?", "acronyms": [[162, 165]], "long-forms": [[144, 160]]}, {"text": "Our initial experiment includes language model (LM), word posterior probability (WPP), confusion network (CN), and word lexicon (WL) features for a total of 11", "acronyms": [[106, 108], [48, 50], [81, 84], [129, 131]], "long-forms": [[87, 104], [32, 46], [53, 79], [115, 127]]}, {"text": "ing at combining the strengths of different grammars, we describes a synthetic synchronous grammar (SSG), which tentatively in this paper, integrates a syn-", "acronyms": [[100, 103]], "long-forms": [[69, 98]]}, {"text": "Chinese Semantic Dictionary (CSD) for  Chinese-English machine translation, the  Chinese Concept Dictionary (CCD) for  cross-language text processing, the multi-level ", "acronyms": [[109, 112], [29, 32]], "long-forms": [[81, 107], [0, 27]]}, {"text": " 1 Introduction Quality Estimation (QE) for Machine Translation (MT) involves judging the correctness of the output of an MT system given an input and no reference translation (Blatz et al.,", "acronyms": [[36, 38], [65, 67], [122, 124]], "long-forms": [[16, 34], [44, 63]]}, {"text": "the identified reading level. Text plans define  rules on Noun Phrase (NP) density and lexical  choice.", "acronyms": [[71, 73]], "long-forms": [[58, 69]]}, {"text": "One possibility is the use of semantic annotation, using sentence-level propositional Logical Forms (LF). It seems more cogni-", "acronyms": [[101, 103]], "long-forms": [[86, 99]]}, {"text": "tions and so on.  3.2 The Greedy Prepend Algorithm (GPA) To learn a decision list from a given set of training", "acronyms": [[52, 55]], "long-forms": [[26, 50]]}, {"text": "We report results for the ATAS versions (ATAS-TC, ATAS-CRF) and for the baselines (Z-CRF, C-value, FRTC) as well as for using supervised (S-SEL) and unsupervised feature selection (U-SEL) in system setting (S) and gold boundary setting (G).", "acronyms": [[181, 186], [26, 30], [41, 48], [50, 58], [83, 88], [90, 97], [99, 103], [138, 143]], "long-forms": [[149, 179]]}, {"text": "6 Event Ordering TimeML defines three different types of links: subordinate (SLINK), temporal (TLINK), and aspectual (ALINK).", "acronyms": [[77, 82], [17, 23], [95, 100], [118, 123]], "long-forms": [[64, 75], [85, 93], [107, 116]]}, {"text": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI?77), page 67=76. ", "acronyms": [[81, 89]], "long-forms": [[22, 79]]}, {"text": "/(cs + |N |?)  P (GR = gri|SCF = s) = (csgri +?) /(cs + |G|?)", "acronyms": [[18, 20]], "long-forms": [[23, 30]]}, {"text": "experiments can be listed as follows.  Head Word (HW.) The predicate?s head word as", "acronyms": [[50, 53]], "long-forms": [[39, 48]]}, {"text": " i=1:n P (GR = gri|SCF = s) The three terms, given the hyper-parameters and", "acronyms": [[10, 12]], "long-forms": [[15, 22]]}, {"text": " 1 Introduction Information Extraction (IE) refers to the problem of extracting structured information from unstructured", "acronyms": [[40, 42]], "long-forms": [[16, 38]]}, {"text": " At least for case schemata we have as first al-   ternative the choice between the realization types :CLAUSE  and :NG (noun group). For semantic structures from titles we ", "acronyms": [[116, 118]], "long-forms": [[120, 130]]}, {"text": "This paper presents the UNITOR system that participated in the *SEM 2013 shared task on Semantic Textual Similarity (STS). The task is", "acronyms": [[117, 120], [24, 30], [64, 67]], "long-forms": [[88, 115]]}, {"text": "Table 3: AMT evaluation results. Numbers are percentages or counts. BL = baseline, SY = system, N-D = no decision, B=S = same sentence selected by baseline and system", "acronyms": [[68, 70], [83, 85], [9, 12], [96, 99]], "long-forms": [[73, 81], [88, 94], [102, 113]]}, {"text": "Since this is a binary classification task, we have 5 different tags: B-L (Beginning of a literal chunk), I-L (Inside of a literal chunk), B-I (Beginning an Idiomatic chunk), I-I (Inside an Idiomatic chunk),", "acronyms": [[106, 109], [139, 142], [70, 73], [175, 178]], "long-forms": [[111, 130], [144, 166], [75, 97], [180, 199]]}, {"text": "on three official testsets.  NIST 2008 Open Machine Translation (OpenMT) Evaluation9 has distributed test data from 2 domains: Newswire and Web.", "acronyms": [[65, 71]], "long-forms": [[39, 63]]}, {"text": " 2.3 Evaluation We use the Dutch part of EuroWordNet (DWN) (Vossen, 1998) for evaluation of our hypernym ex-", "acronyms": [[54, 57]], "long-forms": [[27, 52]]}, {"text": "for topic models. In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI), pages 27?34.", "acronyms": [[99, 102]], "long-forms": [[59, 97]]}, {"text": "An integrated, conditional model of information extraction and coreference with application to citation graph construction. In 20th Conference on Uncertainty in Artificial Intelligence (UAI). ", "acronyms": [[186, 189]], "long-forms": [[146, 184]]}, {"text": "increasingly more important.  In ordinary phrase structure grammars (PSG's),  the only mechanism for capturing the kinds of merg- ", "acronyms": [[69, 74]], "long-forms": [[42, 67]]}, {"text": "natural language utterances. It accesses a database typi-  cal for the information retrieval task (CORDIS). ", "acronyms": [[99, 105]], "long-forms": [[59, 97]]}, {"text": "that to go from the head of the chunk to the target in the dependency graph (Figure 3), you traverse a SUB (subject) link upwards. ", "acronyms": [[103, 106]], "long-forms": [[108, 115]]}, {"text": "resulting grammar. We cast the minimization as an integer linear program (ILP). Let V be the set of", "acronyms": [[74, 77]], "long-forms": [[50, 72]]}, {"text": "The most successful stochastic language models  have been based on finite-state descriptions such  as n-grams or hidden Markov models (HMMs)  (Jelinek et al, 1992).", "acronyms": [[135, 139]], "long-forms": [[113, 133]]}, {"text": "mapping all non-core argument labels in the guessed and correct labelings to NONE.  Coarse Modifier Argument Measures (COARSEARGM). Sometimes it is sufficient to", "acronyms": [[119, 129], [77, 81]], "long-forms": [[84, 117]]}, {"text": "Setting P0.1 P0.25 P0.33 P0.5 Best-F1 ContextSim (CS) 42.9 69.6 60.7 58.7 49.6 SpellingSim (SS) 90.5 74.2 69.9 64.6 50.9 (a) from baseline models", "acronyms": [[92, 94], [50, 52]], "long-forms": [[79, 90], [38, 48]]}, {"text": "predicted this outcome correctly in 70.37% of the cases (upper left cell). However,  IBL also predicted the outcome penultimate stress (PEN) in 25.26% of the words and  440 ", "acronyms": [[136, 139], [85, 88]], "long-forms": [[116, 127]]}, {"text": "NEARING A PROJECT PROPOSAL TO OTTA BOARD  As the  Urns,,. C6ngress Office of Techdblogy Assessment (OTA) planning  sttidy on te lecomunica t ions ,  computers and information p o l i c i e s  approaches ", "acronyms": [[100, 103], [30, 34]], "long-forms": [[67, 98]]}, {"text": "bor.hodoscek@gmail.com Abstract Regarding the construction of an ontology of Japanese lexical properties (JLP-O) as fundamental in terms of establishing a conceptual framework to guide and facilitate the construction of a large-scale", "acronyms": [[106, 111]], "long-forms": [[77, 104]]}, {"text": "or more previous turns in the dialogue. The third column shows the mean error and standard error (SE) predicted for the model specified by the first two columns. When", "acronyms": [[98, 100]], "long-forms": [[82, 96]]}, {"text": "are shown in Table 4. Not surprisingly, using all gazetteer features (AllG) boosts the F1 score from 85.14 % to 88.30%, confirming the power", "acronyms": [[70, 74]], "long-forms": [[46, 59]]}, {"text": "edge mining.  Biomedical NER (Bio-NER) tasks are, in general, more difficult than ones in the news domain.", "acronyms": [[30, 37]], "long-forms": [[14, 28]]}, {"text": "The parameters ? are estimated through the optimization of a Maximum Likelihood (ML) criterion using the Expectation-Maximization (EM) al-", "acronyms": [[81, 83], [131, 133]], "long-forms": [[61, 79], [105, 129]]}, {"text": "c?2009 Association for Computational Linguistics Report on the First NLG Challenge on Generating Instructions in Virtual Environments (GIVE) Donna Byron", "acronyms": [[135, 139], [69, 72]], "long-forms": [[86, 133]]}, {"text": "features extracted from the LFG parse.  Lexical Functional Grammar (LFG) (Bresnan, 2000) is a constraint-based theory of grammar.", "acronyms": [[68, 71], [28, 31]], "long-forms": [[40, 66]]}, {"text": "by using RBM to implement the middle layers,  since RBM can be learned very quickly by the  Contrastive Divergence (CD) approach. ", "acronyms": [[116, 118], [9, 12], [52, 55]], "long-forms": [[92, 114]]}, {"text": "Extended Markup Language (XML) is a pro-  posed standard (XML, 1997) specified by the World  Wide Web Consortium (W3C). In XML, tags and ", "acronyms": [[114, 117]], "long-forms": [[93, 112]]}, {"text": " bo und Figure 1: Accuracy for Na??veBayes classifier (NBC) and Majority Rule (MR) 4 Experimental results", "acronyms": [[79, 81], [55, 58]], "long-forms": [[64, 77], [31, 53]]}, {"text": "ious learning algorithms. Our best model, based on support vector machines (SVM), significantly outperforms previous FFL formulas.", "acronyms": [[76, 79], [117, 120]], "long-forms": [[51, 74]]}, {"text": "a mistake when we generate the final output that results in a lower score of 56.31% in term of Labeled Attachment Score (LAS), reported by organizers.", "acronyms": [[121, 124]], "long-forms": [[95, 119]]}, {"text": "We use two ways to measure contribution in terms of graphemes: contseq(w, b) is the length of the longest prefix/suffix of word w which blend b begins/ends with, and contlcs(w, b) is the longest common subsequence (LCS) of w and b. This yields four features:", "acronyms": [[215, 218]], "long-forms": [[187, 213]]}, {"text": "where P is the Macro Precision and R is the Macro Recall. We also use tree induced error (TIE) in the experiments.", "acronyms": [[90, 93]], "long-forms": [[70, 88], [21, 30], [50, 56]]}, {"text": "Abstract Data sparsity is one of the main factors that make word sense disambiguation (WSD) difficult.", "acronyms": [[87, 90]], "long-forms": [[60, 85]]}, {"text": "cf. Webber 1987b), representing the narrative's unfold-  ing contents, and the l inear text structure (LTS), whose  components are linked by rhetorical relations such as ", "acronyms": [[103, 106]], "long-forms": [[79, 101]]}, {"text": "query, some form of translation is required. One might conjecture that a combination of two existing fields, IR and machine translation (MT), would be satisfactory for accomplishing the combined translation and retrieval task.", "acronyms": [[137, 139]], "long-forms": [[116, 135]]}, {"text": "outer: the perceived external frame or point of reference for  the action, event, or state as a whole  Means (MNS):  inner: the perceived immediate affeetor or effeetor of the ", "acronyms": [[110, 113]], "long-forms": [[103, 108]]}, {"text": "2 Methods In this IRB-approved study, we obtained the Shared Annotated Resource (ShARe) corpus originally generated from the Beth Israel Dea-", "acronyms": [[81, 86]], "long-forms": [[54, 79]]}, {"text": "2003) on the term-sentence matrix of human model summaries used in the Document Understanding Conference (DUC) 2007 Pyramid evaluation1.", "acronyms": [[106, 109]], "long-forms": [[71, 104]]}, {"text": " ? Unaligned word penalty feature (UWP): hUWP (Q,S,A), which is defined as the ratio", "acronyms": [[35, 38], [41, 45]], "long-forms": [[3, 25]]}, {"text": "(equivalent to relation). Their relation instances are named entity(NE)-mention pairs conforming to a set of pre-specified rules.", "acronyms": [[68, 70]], "long-forms": [[55, 67]]}, {"text": "Table 4. WSD precision recall and F-measure for  the algorithm based on aligned wordnets (AWN),  for AWN with clustering (AWN+C) and for ", "acronyms": [[90, 93], [9, 12], [122, 127], [101, 104]], "long-forms": [[72, 88]]}, {"text": "dleware architecture (Scha?fer, 2006). It starts with sentence boundary detection (SBR) and regular expression-based tokenization using its built-in", "acronyms": [[83, 86]], "long-forms": [[54, 71]]}, {"text": "from Si.  Feature Causality Diagram (FCD): CNB allows each feature Y, which occurs in a  given document, to have a Feature Causality Diagram (FCD).", "acronyms": [[37, 40], [43, 46], [142, 145]], "long-forms": [[10, 35], [115, 140]]}, {"text": "ment, we compared the following three methods for word  similarity measure:  * the Bunruigoihyo thesaurus (BGH): the similarity  between case fillers is measured by a function be- ", "acronyms": [[107, 110]], "long-forms": [[83, 105]]}, {"text": "In STS, we encoded only similarity feature between the two sentences. Thus, we used two classes of kernels: (1) the syntactic/semantic class (SS) with the final kernel defined as K(p 1", "acronyms": [[142, 144], [3, 6]], "long-forms": [[126, 140]]}, {"text": "The generator operates from a declarative know-  ledge base of linguistic knowledge, common to that used  by PHRAN (PHRasal ANalyzer; Wilensky and Arens,  1980).", "acronyms": [[109, 114]], "long-forms": [[116, 132]]}, {"text": " Proceedings of 24th International Conference on Computational Linguistics (COLING): Posters. ", "acronyms": [[76, 82]], "long-forms": [[49, 74]]}, {"text": "model in their study is the relative height by range model, where (in our notation): (13) relative height by range (RH-R): ? ", "acronyms": [[116, 120]], "long-forms": [[90, 114]]}, {"text": "pseudo-terms?. We also discuss the use of Hidden Markov Models (HMMs) to capture contextual information.", "acronyms": [[64, 68]], "long-forms": [[42, 62]]}, {"text": "among other ways). We refer to cases in which the subject and object of the relation are contained within a phrase headed by a Noun as Relational NP?s (RNP). ", "acronyms": [[152, 155]], "long-forms": [[135, 150]]}, {"text": "While much of the focus in developing a statistical machine translation (SMT) system revolves around the translation model (TM), most systems do not emphasize the role of the language model (LM).", "acronyms": [[124, 126], [73, 76], [191, 193]], "long-forms": [[105, 122], [40, 71], [175, 189]]}, {"text": "Mauser et al 2009). One promising approach is the Discriminative Word Lexicon (DWL). In this", "acronyms": [[79, 82]], "long-forms": [[50, 77]]}, {"text": "score word pairs for relatedness (on a scale of 0 to 10), which is in contrast to the similarity judgments requested of the Miller and Charles (MC) and Rubenstein and Goodenough (RG) participants.", "acronyms": [[144, 146], [179, 181]], "long-forms": [[124, 142], [152, 177]]}, {"text": "Evaluating the quality of language output tasks such as Machine Translation (MT) and Automatic Summarisation (AS) is a challenging topic in Natural Language Processing", "acronyms": [[110, 112], [77, 79]], "long-forms": [[85, 108], [56, 75]]}, {"text": "SEPA parameters are S = 13, 000, N = 20. In both rows, SEPA results for the in-domain (left) and adaptation (middle) scenarios are compared to the confidence (CB) and minimum length (ML) baselines. The", "acronyms": [[183, 185], [0, 4], [55, 59], [159, 161]], "long-forms": [[167, 181]]}, {"text": "Fabio Aiolli, Giovanni Da San Martino, Alessandro Sperduti, and Alessandro Moschitti,  Efficient Kernel-based Learning for Trees, to appear in the IEEE Symposium on  Computational Intelligence and Data Mining (CIDM), Honolulu, Hawaii, 2007.  ", "acronyms": [[210, 214], [147, 151]], "long-forms": [[166, 208]]}, {"text": "3 Approach Following this intuition, we fit a directed Gaussian graphical model (GGM) that simultaneously considers (i) each word?s embedding (obtained from", "acronyms": [[81, 84]], "long-forms": [[64, 79]]}, {"text": "Since by default we return up to RT=100  search engine results to user, we will extract the  top RQ=RT/(#newQuery+1) entries from results of  each new query and original query.", "acronyms": [[97, 99], [33, 35]], "long-forms": [[100, 115]]}, {"text": " In earlier topic modeling work such as latent Dirichlet alocation (LDA) (Blei et al, 2003; Griffiths and Steyvers, 2004), documents are treated as bags of", "acronyms": [[68, 71]], "long-forms": [[53, 66]]}, {"text": "strated via an algorithm for joint unsupervised learning of the topology and parameters of a hidden Markov model (HMM); states and short state-sequences through this HMM cor-", "acronyms": [[114, 117], [166, 169]], "long-forms": [[93, 112]]}, {"text": " Preclinical data have supported the use of  fludarabine and cyclophosphamide (FC) in  combination for the treatment of indolent ", "acronyms": [[79, 81]], "long-forms": [[45, 77]]}, {"text": "to match portions of a PAS.  3.2 The Shallow Semantic Tree Kernel (SSTK) The SSTK is based on two ideas: first, we change", "acronyms": [[67, 71], [23, 26], [77, 81]], "long-forms": [[37, 65]]}, {"text": "::= RL RL ::= prep rel loc word(S, object word) RL=rel loc word |", "acronyms": [[48, 50], [4, 6], [7, 9]], "long-forms": [[51, 58]]}, {"text": "(PART+), (e.g., +\u000b s+ will [future]). Most shallow is the class of conjunctions (CONJ+), (e.g., +  w+", "acronyms": [[81, 86], [1, 6]], "long-forms": [[67, 79]]}, {"text": "This  was a motivating factor for the establishment of the  Common Pattern Specification Language (CPSL)  Working Group devoted to formulating a CPSL in ", "acronyms": [[99, 103], [145, 149]], "long-forms": [[60, 97]]}, {"text": "Studies such as Cinque (2006) and Rizzi  (1999) propose detailed functional phrases such  as TopP (Topic Phrase) in order to fully describe  the syntactic structures of a language.", "acronyms": [[93, 97]], "long-forms": [[99, 111]]}, {"text": "Second, in many applications, an effective means of incorporating distributional semantics is Random Indexing (RI). Thus", "acronyms": [[111, 113]], "long-forms": [[94, 109]]}, {"text": "Just as in Figure 2, the initial model is denoted with a bold symbol in the left part of the plot. Also for reference the relevant Lexicon 1 accuracy (LEX 1) is denoted with a ? at the far right.", "acronyms": [[151, 156]], "long-forms": [[131, 140]]}, {"text": "Route INJECTION ORAL SMOKING SNORTING Aspect CHEMISTRY (Pharmacology, TEK) CULTURE (Culture, Setting, Social, Spiritual) EFFECTS (Effects)", "acronyms": [[75, 82], [70, 73], [121, 128]], "long-forms": [[84, 91], [130, 137]]}, {"text": "   (2)  LSA-based (Latent Semantic Analysis based)  trigger word similarity: LSA (Deerwester et ", "acronyms": [[8, 17], [77, 80]], "long-forms": [[19, 43]]}, {"text": "8. Strong forms of pronouns not preceded by a preposition (unless they carry IC) t Table 1: Annotation guidelines; IC = Intonation Center. ", "acronyms": [[115, 117], [77, 79]], "long-forms": [[120, 137]]}, {"text": "To solve the ILP models we used lp solve, a highly efficient GNU-licence Mixed Integer Programming (MIP) solver11, that implements the Branch-and-Bound algorithm.", "acronyms": [[100, 103], [13, 16], [61, 72], [32, 34]], "long-forms": [[73, 98]]}, {"text": "between interdependent ? E steps (as might arise for an  assumption such as ((ANB)?C)). It is straightforward ", "acronyms": [[78, 84]], "long-forms": [[57, 72]]}, {"text": "The entries in the  subjectivity word list have been labeled with  part of speech (POS) tags as well as either  strong or weak subjective tag depending on the ", "acronyms": [[83, 86]], "long-forms": [[67, 81]]}, {"text": "to facilitate understanding. We used latent Dirichlet alocation (LDA) (Blei, Ng, and Jordan, 2003) as our exploratory tool.", "acronyms": [[65, 68]], "long-forms": [[37, 63]]}, {"text": "2009. Word sense disambiguation: A survey. ACM Computing Surveys (CSUR),41(2):10. ", "acronyms": [[66, 70], [43, 46]], "long-forms": [[47, 64]]}, {"text": "participate in the interpretation f the CLS (e.g., elements bearing the thematic roles assigned by  the predicate, etc.). DPSs (DP structures) semantically characterize noun phrases. They consist ", "acronyms": [[122, 126], [40, 43]], "long-forms": [[128, 141]]}, {"text": "HOO) pro-posed and initiated a shared task in 2011 (Dale and Kilgarriff, 2010), which attempts to tackle the problem by developing tools or techniques for the non-native speaker of English, which will automat-ically correct the English prose of the papers so that they can be accepted. This tools and tech-niques may also help native English speakers. This task is simply expressed as text-to-text generation or Natural language Generation (NLG). In the 2011 shared task, all possible errors were covered which made the task enormously huge.", "acronyms": [[441, 444], [0, 3]], "long-forms": [[412, 439]]}, {"text": " The growing need to  manage and search large video collections presents  a challenge to traditional information retrieval (IR)  technologies.", "acronyms": [[124, 126]], "long-forms": [[101, 122]]}, {"text": "To this  end, more and more information extraction (IE)  systems using natural language processing (NLP)  have been developed for use in the biomedical ", "acronyms": [[100, 103], [52, 54]], "long-forms": [[71, 98], [28, 50]]}, {"text": " We follow Curran (2004) and use two performance measures: direct matches (DIRECT) and inverse rank (INVR).", "acronyms": [[75, 81], [101, 105]], "long-forms": [[59, 73], [87, 99]]}, {"text": "CONN =  nil;  konj( KONJ )  FUNDF = fundf n( NOMINAL ); /* No nil */ ", "acronyms": [[20, 24], [0, 4], [28, 33]], "long-forms": [[14, 18]]}, {"text": "(adjectives), ADV (adverbs), PRON (pronouns), DET (determiners), ADP (prepositions or postpositions), NUM (numerals), CONJ (conjunctions), PRT (particles), PUNC (punctuation marks) and", "acronyms": [[102, 105], [118, 122], [14, 17], [29, 33], [46, 49], [65, 68], [139, 142], [156, 160]], "long-forms": [[107, 115], [124, 136], [19, 26], [35, 43], [51, 62], [70, 99], [144, 153], [162, 173]]}, {"text": "Similarity function We consider two similarity functions: The Lin (2001) similarity measure, and the Balanced Inclusion (BInc) similarity measure (Szpektor and Dagan, 2008).", "acronyms": [[121, 125]], "long-forms": [[101, 119]]}, {"text": "contribution: Functional GENDER and NUMBER features contribute more than their form-based counterparts, in both gold and predicted conditions; rationality (RAT) as a single feature on top of the POS tag set helps in gold (and with Easy-First Parser, also in predicted conditions)?but when used in combination with", "acronyms": [[156, 159], [195, 198]], "long-forms": [[143, 154]]}, {"text": " ? REL = relation + property; ARG = NP/VP/ADJ", "acronyms": [[3, 6], [30, 33]], "long-forms": [[9, 17], [36, 45]]}, {"text": "placed in a transcript. Here, we focus on the syndrome of primary progressive aphasia (PPA). PPA", "acronyms": [[87, 90], [93, 96]], "long-forms": [[58, 85]]}, {"text": "is that of the closest centroid.  The Naive Bayes (NB) classifier is based on a probabilistic model which assumes conditional in-", "acronyms": [[51, 53]], "long-forms": [[38, 49]]}, {"text": "method does not select any dimension.  Median Selection (MSel). As a further method", "acronyms": [[57, 61]], "long-forms": [[39, 55]]}, {"text": "For Arabic, morphological segmentation is performed by MADA 3.2 (Habash et al, 2009), using the Penn Arabic Treebank (PATB) segmentation scheme as recommended by El Kholy and Habash", "acronyms": [[118, 122], [55, 59]], "long-forms": [[96, 116]]}, {"text": "Table 1 FactBank annotation scheme. CT = certain; PR = probable; PS = possible; U = underspecified; + = positive; ?", "acronyms": [[36, 38], [50, 52], [65, 67]], "long-forms": [[41, 48], [55, 63], [70, 78], [84, 98], [104, 112]]}, {"text": "Measures for Semantic Relations Extraction Alexander Panchenko Center for Natural Language Processing (CENTAL) Universite?", "acronyms": [[103, 109]], "long-forms": [[63, 90]]}, {"text": "BG 80,757 1.34 EN 94,725 2.58 Table 2: Corpus statistics: SR=Serbian, SL=Slovene, EN=English, BG=Bulgarian", "acronyms": [[58, 60], [70, 72], [15, 17], [0, 2], [82, 84], [94, 96]], "long-forms": [[61, 68], [73, 80], [85, 92], [97, 106]]}, {"text": "occurrence restrictions (FCRs), feature specification  defaults (FSDs), linear precedence (LP) statements,  and universal feature instantiation principles (UIPs). ", "acronyms": [[156, 160], [25, 29], [65, 69], [91, 93]], "long-forms": [[112, 154], [32, 63], [72, 89]]}, {"text": "though this is never the case.) The second such  feature \"Theme as Chomeuf  (TAC) is the only  non-trinary-valued feature in our learner; it spec- ", "acronyms": [[77, 80]], "long-forms": [[58, 74]]}, {"text": "If the polarity of expressed statement is not  neutral and reinforcement is negative, then the  polarity of the statement (PP) is reversed and  score is intensified: ", "acronyms": [[123, 125]], "long-forms": [[96, 104]]}, {"text": " Since precision is measured as the proportion of true positives (TP) to the sum of true positives and false positives (FP): 1748", "acronyms": [[120, 122], [66, 68]], "long-forms": [[103, 118], [50, 64]]}, {"text": "Theoretically, the expressive power of converting the cospecs of a GLS into DCG parse rules i s equivalent to the power of a Lexicalized Tree Adjoining Grammar with collocations (Shieber[14]) , what we have termed Hyper Lexicalized Tree Adjoining Grammars (HTAGs) (Pustejovsky[13]) . ", "acronyms": [[257, 262], [67, 70], [76, 79]], "long-forms": [[214, 255]]}, {"text": "though domain sublanguages are characterized by specific vocabularies, a well-defined border between specific sublanguages (SLs) and general language (GL) vocabularies is difficult to establish", "acronyms": [[124, 127], [151, 153]], "long-forms": [[110, 122], [133, 149]]}, {"text": "In a third stage, they are put in a Multilingual Polyphraz Memory (MPM). A \"polyphrase\" is a structure", "acronyms": [[67, 70]], "long-forms": [[36, 65]]}, {"text": "would also be possible.  Personalized PageRank similarity (PPR) (Agirre and Soroa, 2009) measures the semantic relatedness between two word senses s", "acronyms": [[59, 62]], "long-forms": [[25, 57]]}, {"text": "/fi:/. 2.1 Foreign Words From an information retrieval (IR) perspective, foreign words in Arabic can be classified into two gen-", "acronyms": [[56, 58]], "long-forms": [[33, 54]]}, {"text": "many competing approaches to tagging problems including Hidden Markov Models (HMMs), Maximum Entropy Markov Models (MEMMs) and Conditional Random Fields (CRFs).", "acronyms": [[116, 121], [78, 82], [154, 158]], "long-forms": [[89, 114], [56, 76], [127, 152]]}, {"text": "means of |P (G)|. This guarantees that neither trees of maximum height (MHT) nor of maximum degree (MDT), i.e. trees which trivially", "acronyms": [[72, 75], [100, 103]], "long-forms": [[56, 70], [84, 98]]}, {"text": "2007). The practical NLP application based evaluations are automatic speech recognition (ASR), information retrieval (IR) and statistical machine", "acronyms": [[89, 92], [21, 24], [118, 120]], "long-forms": [[59, 87], [95, 116]]}, {"text": "qnp?0.6 NP(qdet, qn), qnp?0.4 NP(qnp, qpp), qpp?1.0 PP(qprep, qnp), qdet?1.0 DET(the),", "acronyms": [[52, 54], [77, 80], [30, 32], [8, 10]], "long-forms": [[56, 60]]}, {"text": "of FIS model used to resolve each expression.  4.1 Similarity Features (SIM) Similarity features represent the lexical overlap", "acronyms": [[72, 75], [3, 6]], "long-forms": [[51, 61]]}, {"text": "A mobile real-time speech-to-speech translation (S2ST) device is one of the grand challenges in natural language processing (NLP). It involves", "acronyms": [[125, 128], [49, 53]], "long-forms": [[96, 123], [19, 47]]}, {"text": "SVO = Subject-Verb-Object GE = General Event PE = Predefined Event Rule-based", "acronyms": [[45, 47], [0, 3], [26, 28]], "long-forms": [[50, 66], [6, 25], [31, 44]]}, {"text": "Second, we demonstrate correlation to a database of real-world international conflict events, the Militarized Interstate Dispute (MID) dataset (Jones et al, 1996).", "acronyms": [[130, 133]], "long-forms": [[98, 128]]}, {"text": "The majority of dependency-based features are constructed using the properties of edges and vertices along the shortest path (SP) of an entity pair. ", "acronyms": [[126, 128]], "long-forms": [[111, 124]]}, {"text": "ancient than transport 1.83E-102 old ancient 0.005 Table 8: Substitution Feature Table (SubFT) 3.3.2 Phrase Substitution", "acronyms": [[88, 93]], "long-forms": [[60, 86]]}, {"text": "Traditional readability measures for L1 Swedish at the text level include LIX (L?asbarthetsindex, ? Readability index?)", "acronyms": [[74, 77], [37, 39]], "long-forms": [[79, 96]]}, {"text": " ? Max Similarity (MaxSim): For tuple ? in an", "acronyms": [[19, 25]], "long-forms": [[3, 17]]}, {"text": "4.2 Dataset and preprocessing To evaluate the proposed approach, we use SemEval-2013 datasets: TW (tweets obtained by merging learn and development data) and SMS, in", "acronyms": [[95, 97], [158, 161], [72, 84]], "long-forms": [[99, 105]]}, {"text": " 2 American National Corpus The American National Corpus (ANC) project (Ide and Macleod, 2001; Ide and Suderman, 2004) has", "acronyms": [[58, 61]], "long-forms": [[32, 56]]}, {"text": "is shown in PLATE 1. The second part is the  Prompt Piano Server (PPS), which is an IVR  (interactive voice response) server with a Dialogic ", "acronyms": [[66, 69], [84, 87]], "long-forms": [[45, 64]]}, {"text": "various types of goodness measures, such as Description Length Gain (DLG) proposed by Kit and Wilks (1999), Accessor Variety (AV) proposed by Feng et al. (", "acronyms": [[126, 128], [69, 72]], "long-forms": [[108, 124], [44, 67]]}, {"text": "dhi/NEP road/NEL. The structure of the tagged  element using the Shakti Standard Format (SSF)5  will be as follows: ", "acronyms": [[89, 92], [0, 7], [8, 16]], "long-forms": [[65, 87]]}, {"text": " INTRODUCTION  Compound Nouns: Compound nouns (CNs) are a  commonly occurring construction in language ", "acronyms": [[47, 50]], "long-forms": [[31, 45]]}, {"text": "  This approach has been employed in Augmentative  and Alternative Communication (AAC), in the  form of multimodal vocabularies in assistive de-", "acronyms": [[82, 85]], "long-forms": [[37, 80]]}, {"text": " 1 Introduction Information retrieval (IR) has been studied since an earlier stage [e.g., (Menzel, 1966)] and sev-", "acronyms": [[39, 41]], "long-forms": [[16, 37]]}, {"text": "Probable PR+ (probable) PR? ( not probable) [NA] Possible PS+ (possible) PS? ( not certain) [NA]", "acronyms": [[58, 61]], "long-forms": [[63, 71]]}, {"text": "adaptation scenario. Duan et al (2009) proposed a Domain Adaptation Machine (DAM) method to learn a Least-Squares SVM classifier for target do-", "acronyms": [[77, 80], [114, 117]], "long-forms": [[50, 75]]}, {"text": "teams employed vector-based linear classifiers of different types: Hacioglu et al (2004) and Park et al (2004) used Support Vector Machines (SVM) with polynomial kernels, Carreras et al (2004) used Voted Percep-", "acronyms": [[141, 144]], "long-forms": [[116, 139]]}, {"text": " Opennlp maxent1, an implementation of Maximum Entropy (ME) modeling, is used as the classification tool.", "acronyms": [[56, 58]], "long-forms": [[39, 54]]}, {"text": "This representation, together with target language words, are fed to a deep neural network (DNN) to form a stronger NNJM.", "acronyms": [[92, 95], [116, 120]], "long-forms": [[71, 90]]}, {"text": "As a starting point, the classes for complements  and features developed by the New York Univer-  sity Linguistic String Project (LSP) (Fitzpatrick,  1981), were selected sin(x, the coverage is very ", "acronyms": [[130, 133]], "long-forms": [[103, 128]]}, {"text": "the Tomita parser, which handles Japanese and Spanish as well as English . The parser output is grammatical structures called Functionally Labelled Templates (FLTs) which are built using a linguistic formalism that modifies and extends the f-structure of Lexical-Functional Grammar (LFG) .", "acronyms": [[159, 163], [283, 286]], "long-forms": [[126, 157], [255, 281]]}, {"text": "associated with each. The next column indicates the percentage of the majority class (MAJ.) and count", "acronyms": [[86, 90]], "long-forms": [[70, 78]]}, {"text": "In Proceedings of the Conference of the Pacific Association for Computational Linguistics (PACLING), pages 120?128. ", "acronyms": [[91, 98]], "long-forms": [[40, 89]]}, {"text": "make assertions that personal pronouns like \\she\" cannot co-refer with \\company\".  In MUC-7, we developed a word sense disambiguation (WSD) module, which removes some of the implausible senses from the list of potential senses.", "acronyms": [[135, 138], [86, 91]], "long-forms": [[108, 133]]}, {"text": "labeled as negative; otherwise, the review is labeled as positive.  3.2 Lexicon-Based Method in Chinese Language: LEX(CN) This method first translates English sentiment lexica into Chinese lexica, and then", "acronyms": [[118, 120], [114, 117]], "long-forms": [[96, 112]]}, {"text": "adv Adverbial words(RB, RBR, RBS)  adj Adjunct word(JJ,JJR,JJS)  advP Adverb phrase(ADVP)  punct Punctuation(,) ", "acronyms": [[84, 88]], "long-forms": [[70, 82]]}, {"text": "production strategies. In Proceedings of the 16th International Conference on Computational Linguistics (COLING?96), pages 249?254.", "acronyms": [[105, 114]], "long-forms": [[64, 103]]}, {"text": "ate the surface form in the opposite direction.  Amazon?s Mechanical Turk (MTurk) is becoming an essential tool for creating annotated resources", "acronyms": [[75, 80]], "long-forms": [[58, 73]]}, {"text": "This I will  claim to be in contrast with the ability of temporal  subordinate clauses and noun phrases (NPs) to direct the  listener to any position in the evolving structure.)", "acronyms": [[105, 108]], "long-forms": [[91, 103]]}, {"text": "Reject? validations for reliably deliberate (Rel) and unreliable (URel) subsets of the metaphor production data, given that the", "acronyms": [[66, 70], [45, 48]], "long-forms": [[54, 64], [24, 32]]}, {"text": "Allocation (LDA), but using linguistic dependency information in place of simple features from bag of words (BOW) representations.", "acronyms": [[109, 112], [12, 15]], "long-forms": [[95, 107]]}, {"text": "In this work, we apply Dirichlet Process Mixture Models (DPMMs) to a learning task in natural language processing (NLP): lexical-semantic verb clustering.", "acronyms": [[115, 118], [57, 62]], "long-forms": [[86, 113], [23, 55]]}, {"text": "step, we apply the CFG IDENTIFICATION to the string  under (2) in order to \"transform\" the sequence of simple  syntactic units into so-called Segmentation Units (SU)  \\[we use the following conventions: \"( )\" for facultativi- ", "acronyms": [[162, 164], [19, 22]], "long-forms": [[142, 160]]}, {"text": "2007) from 4 domains, labeled positive or negative. We apply logistic regression (LR) and SVM using unigram and bigram features.", "acronyms": [[82, 84], [90, 93]], "long-forms": [[61, 80]]}, {"text": "ACC mPUR + ACC The random baseline(BL) is calculated as follows: BL = 1/number of classes", "acronyms": [[35, 37], [0, 3], [4, 8], [11, 14], [65, 67]], "long-forms": [[26, 33]]}, {"text": "we annotate ? Chen? as the Agent (ARG0)  of the full predicate ?[", "acronyms": [[34, 38]], "long-forms": [[20, 32]]}, {"text": "ellieioncy has been drastically improved for n)orpho-  logical analysis by representing large dictionaries with  Finite State Automata (FSA) and by representhig two-  level rnles and le?ical hlforination with finite-state ", "acronyms": [[136, 139]], "long-forms": [[113, 134]]}, {"text": "egorization. ACM Transactions on Information Systems (TOIS), 12(3):233?251. ", "acronyms": [[54, 58], [13, 16]], "long-forms": [[17, 52]]}, {"text": "of modals and auxilliaries is deterministic.  Syntactic Chunk (CHUNK): This feature explicitly models the syntactic phrases in which our", "acronyms": [[63, 68]], "long-forms": [[56, 61]]}, {"text": "Abstract In this paper we present results from the METER (MEasuring TExt Reuse) project whose aim is to explore issues", "acronyms": [[51, 56]], "long-forms": [[58, 78]]}, {"text": "with their scope and corresponding negated events is an important task that could benefit other natural language processing (NLP) tasks such as extraction of factual information", "acronyms": [[125, 128]], "long-forms": [[96, 123]]}, {"text": "1(c)) for each k. 3.3.2 PLEB PLEB (Point Location in Equal Balls) was first proposed by Indyk and Motwani (1998) and further", "acronyms": [[29, 33], [24, 28]], "long-forms": [[35, 64]]}, {"text": "LDEP(NEXT) + Table 1: History-based features (TOP = token on top of stack; NEXT = next token in input buffer; HEAD(w) = head of w; LDEP(w) = leftmost depen-", "acronyms": [[75, 79], [0, 4], [46, 49], [5, 9], [110, 117], [131, 138]], "long-forms": [[82, 92], [52, 64], [120, 129], [141, 155]]}, {"text": "4.1 The NIST evaluation scheme The National Institute of Science and Technology (NIST) proposed an evaluation scheme that looks at the following properties when", "acronyms": [[81, 85], [8, 12]], "long-forms": [[35, 79]]}, {"text": "adaptation led to a considerable improvement of +4.1 BLEU and large improvements in terms of METEOR and Translation Edit Rate (TER). We", "acronyms": [[127, 130], [53, 57], [93, 99]], "long-forms": [[104, 125]]}, {"text": "A Unified Model of Phrasal and Sentential Evidence for Information Extraction. In Proc. Conference on Empirical Methods in Natural Language Processing 2009, (EMNLP-09). David Yarowsky.", "acronyms": [[158, 166], [82, 86]], "long-forms": [[102, 155]]}, {"text": "HG-ALN 0.266 0.359 Table 1: The Pk and WindowDiff scores of uniform segmentation (UNI), TextTiling (TT), baseline alignment (B-ALN), and alignment with hier-", "acronyms": [[100, 102], [82, 85], [0, 6], [125, 130]], "long-forms": [[88, 98], [60, 67], [105, 123]]}, {"text": "It is not useful to exploit latent  semantic analysis directly on the user-topic matrix  UR = UQ * QR , where UR represents how many  times each user is diffused for existing topic R (R ", "acronyms": [[94, 96], [89, 91], [99, 101], [110, 112]], "long-forms": [[97, 98]]}, {"text": "New York, N.Y. 10027  Introduction  COMET (COordinated Multimedia Explanation  Testbed) is an experimental system that generates inter- ", "acronyms": [[36, 41], [10, 14]], "long-forms": [[43, 86], [0, 8]]}, {"text": "2. Definition of Stochastic Context-Free Grammars  We will now define stochastic ontext free grammars (SCFGs) and establish some  notation.", "acronyms": [[103, 108]], "long-forms": [[70, 101]]}, {"text": "NP re-annotation very helpful for the performance. We think it is because of the annotation style of the Upenn Chinese Treebank (CTB). According to Xue et al", "acronyms": [[129, 132], [0, 2]], "long-forms": [[111, 127]]}, {"text": "1 The following abbreviations are used POSS = possessive prefix/suffix; LOC = locative suffix; OBV = obviative suffix; DIM = diminutive suffix; NUM = number marking suffix; IN", "acronyms": [[72, 75], [95, 98], [39, 43], [119, 122], [144, 147], [173, 175]], "long-forms": [[78, 86], [101, 110], [46, 56], [125, 135], [150, 156]]}, {"text": "137 pare our system with a non-sequential classifier,  a support vector machine (SVM), with the same  settings as those described above.", "acronyms": [[81, 84]], "long-forms": [[57, 79]]}, {"text": " The objective of this study is to illustrate a  word support model (WSM) that is able to improve our WP-identifier by achieving better ", "acronyms": [[69, 72], [102, 104]], "long-forms": [[49, 67]]}, {"text": "number of phrase pairs that can be extracted. We observe that it (OEF) is able to find more than 14% more phrase pairs than heuristic methods and", "acronyms": [[66, 69]], "long-forms": []}, {"text": "We begin by describing how for our typical model, the Viterbi EM objective can be formulated as a mixed integer quadratic programming (MIQP) problem with nonlinear constraints (Figure 2).", "acronyms": [[135, 139]], "long-forms": [[98, 133]]}, {"text": "90 Table 1: Comparison of emotion corpora ordered by the amount of annotations (abbreviations: T=tokenization, POS=part-of-speech tagging, L=lemmatization, DP=dependency parsing, NER=Named Entity Recognition). ", "acronyms": [[156, 158], [179, 182], [111, 114]], "long-forms": [[159, 177], [183, 207], [97, 109], [115, 129], [141, 154]]}, {"text": "They show improvements of up to 5.3% on two real tasks: pitch accent prediction and optical character recognition (OCR). ", "acronyms": [[115, 118]], "long-forms": [[84, 113]]}, {"text": " Because of data sparseness, we cannot reliably use a  maximum likelihood estimator (MLE) for bigram prob-  abilities.", "acronyms": [[85, 88]], "long-forms": [[55, 83]]}, {"text": "Collaboratively constructed resources like Wiktionary (WKT) and OmegaWiki (OW) provide a viable option for such cases and seem especially suitable", "acronyms": [[75, 77]], "long-forms": [[64, 73]]}, {"text": " ? Self-training Segmenters (STS): two variant models were defined by the approach re-", "acronyms": [[29, 32]], "long-forms": [[17, 27]]}, {"text": "573   Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 51?59, Sofia, Bulgaria, August 9, 2013.", "acronyms": [[71, 78]], "long-forms": [[37, 69]]}, {"text": "BC = Broadcast Conversations; BN = Broadcast News; CTS = Conversational Telephone Speech; NW = Newswire; UN = Usenet Newsgroups; and WL = Weblogs. ", "acronyms": [[105, 107], [133, 135], [0, 2], [30, 32], [51, 54], [90, 92]], "long-forms": [[110, 127], [138, 145], [5, 28], [35, 49], [57, 88], [95, 103]]}, {"text": "ing Language Understanding Engine), and subsequently analyze its performance on the task?s shared texts. BLUE consists of a pipeline of a parser, logical form (LF) generator, an initial logic generator, and subsequent processing modules.", "acronyms": [[160, 162]], "long-forms": [[146, 158]]}, {"text": "tance Metric from Relative Comparisons. Advances in Neural Information Processing Systems (NIPS).. J. Weeds, D. Weir and D. McCarthy.", "acronyms": [[91, 95]], "long-forms": [[52, 89]]}, {"text": "(ARG0) and ? Greenspan? as the object (ARG1) of the noun predicate ?", "acronyms": [[39, 43]], "long-forms": [[24, 37]]}, {"text": "3. Generation of Crisp Descriptions Arguably the most fundamental task in the generation of referring expressions (GRE), content determination (CD) requires finding a set of properties that jointly identify the in-", "acronyms": [[115, 118], [144, 146]], "long-forms": [[78, 113], [121, 142]]}, {"text": " For French, the main problem was to retrieve MWEs (Multi Word Expression) in pred data mode.", "acronyms": [[46, 50]], "long-forms": [[52, 73]]}, {"text": "tional words and notional words. In  the field  of Natural Language Processing(NLP), many  studies on text computing or word meaning ", "acronyms": [[79, 82]], "long-forms": [[51, 77]]}, {"text": "ing the most similar. This year we set up two tasks: (i) a core task (CORE), and (ii) a typed-similarity task (TYPED).", "acronyms": [[70, 74], [111, 116]], "long-forms": [[59, 63], [88, 93]]}, {"text": "3.3 Sentiment Model The design of the sentiment model used in our system was based on the assumption that the opinions expressed would be highly subjective and contextualized.  Therefore, for generating data for model training and testing, we used a crowd-sourcing approach to do sentiment annotation on in-domain political data. To create a baseline sentiment model, we used Amazon Mechanical Turk (AMT) to get as varied a population of annotators as possible. We designed an interface that allowed annotators to perform the annotations outside of AMT so that they could participate anonymously.", "acronyms": [[400, 403]], "long-forms": [[376, 398]]}, {"text": "pick PRON up?, where PRON is the part of speech (POS) tag for pronouns.", "acronyms": [[49, 52], [21, 25], [5, 9]], "long-forms": [[33, 47]]}, {"text": "an ASR system. The main idea was to design a language model (LM) to combine the trigram language model probability with the translation", "acronyms": [[61, 63], [3, 6]], "long-forms": [[45, 59]]}, {"text": "correct class of an item from its context. The Maximum Entropy (MaxEnt) framework is especially suited for integrating evidence from var-", "acronyms": [[64, 70]], "long-forms": [[47, 62]]}, {"text": "= argmaxjP (zi = j|sk).  4.2 Lexical Chain Segmenter (LCSeg) Our second model is the lexical chain based seg-", "acronyms": [[54, 59]], "long-forms": [[29, 52]]}, {"text": "- coordination (COORD) : traite les c,'~s imples de  coordination,  - statistique (STAT) : utilis6 sur des s6quences qu'il  est impossible de d6sambigui'ser A l'aide ", "acronyms": [[83, 87], [16, 21]], "long-forms": [[70, 81], [0, 14]]}, {"text": " 1 Introduction Question Answering (QA) from structured data, such as DBPedia (Auer et al.,", "acronyms": [[36, 38], [70, 77]], "long-forms": [[16, 34]]}, {"text": "There-fore, the end for the tram was sealed in the 1970s.] As an application example, a small corpus consisting of 21 newspaper articles is analyzed. The corpus belongs to the interdisciplinary pro-ject Future Mobility (FuMob), which is funded by the Excellent Initiative of the German federal and state governments. The methodological ap-proach consists of three steps, which are per-formed iteratively: (1) manual discourse-linguistic argumentation analysis, (2) semi-automatic Text Mining (PoS-tagging and linguis-tic multi-level annotation), and (3) data merge.", "acronyms": [[220, 225]], "long-forms": [[203, 218]]}, {"text": " Table 2 shows part of a decision list for the target noun chicken that was learned from a subset of the BNC (British National Corpus) [17]. Note that the", "acronyms": [[105, 108]], "long-forms": [[110, 133]]}, {"text": " 1 Introduction Margin infused relaxed algorithm (MIRA) has been widely adopted for the parameter optimization in", "acronyms": [[50, 54]], "long-forms": [[16, 48]]}, {"text": "Note that the autoPS heuristic for ranking senses is a more precise estimator than the WordNet most?frequent?sense (MFS). ", "acronyms": [[116, 119], [14, 20]], "long-forms": [[95, 114]]}, {"text": "1. Introduction  A verb phrase ellipsis (VPE) exists when a  sentence has an auxiliary verb but no verb phrase ", "acronyms": [[41, 44]], "long-forms": [[19, 39]]}, {"text": "every node be covered by some lexeme.  Partial SemSpec (PSemSpec): The contribution that the lexeme can  make to a sentence SemSpec.", "acronyms": [[56, 64]], "long-forms": [[39, 54]]}, {"text": "using the distributional similarity metric described by Lin (1998). We use WordNet (WN) as our sense inventory.", "acronyms": [[84, 86]], "long-forms": [[75, 82]]}, {"text": "and embedded phrase levels: ? Object reordering (ObjR), in which the objects and their dependents are moved in front", "acronyms": [[49, 53]], "long-forms": [[30, 47]]}, {"text": "Ill the last two  experimeuts a memory with the analysis of tile  most frequent word-forms (MFW) in Basque  was used, so that only word-forms not found ", "acronyms": [[92, 95]], "long-forms": [[66, 84]]}, {"text": " Definition 2.5  Given a grammar, G, define MCL(G) (Maximum Change in Length) as:  MCL(G) = max { m \\] A (.. q/1. . .", "acronyms": [[44, 47], [83, 86], [92, 95]], "long-forms": [[52, 76], [25, 32]]}, {"text": "timing. This flexibility is in contrast to speech output in spoken dialogue systems (SDSs) which typically generate, synthesize and deliver speech", "acronyms": [[85, 89]], "long-forms": [[60, 83]]}, {"text": "(pre-nominal or post-nominal) and predicative functions; (ii) a unigram distribution (level uni), independently encoding the parts of speech (POS) of the words preceding and following the adjective, respec-", "acronyms": [[142, 145]], "long-forms": [[125, 140]]}, {"text": "evaluating the attribute subsets. Their evaluation is based on consistency (CBF) and correlation (CFS). ", "acronyms": [[76, 79], [98, 101]], "long-forms": [[63, 74], [85, 96]]}, {"text": "Syntactic Tree  Ambiguous Semantic  Expression (EFL)  Unambiguous Semantic ", "acronyms": [[48, 51]], "long-forms": [[36, 46]]}, {"text": "Head+Path 80.0 72.8 31.8 22.4 Path 80.0 72.7 31.6 22.0 Table 5: Parsing accuracy (AS = attachment score, EM = exact match; U = unlabeled, L = labeled) Unlabeled Labeled", "acronyms": [[82, 84], [105, 107]], "long-forms": [[87, 103], [110, 121], [127, 136], [142, 149]]}, {"text": "phrase structure grammar (PSG) as thc tagging  formalisms(Lecch & Garside 1991), and some  adopt dependency grammar(DG) 1993, Komatsu,  Jin, & Yasuhara, 1993).", "acronyms": [[116, 118], [26, 29]], "long-forms": [[97, 114], [0, 24]]}, {"text": "son mari.  Les confessions (CO) is much most faithful to the content, yet, the translator has significantly departed", "acronyms": [[28, 30]], "long-forms": [[15, 26]]}, {"text": "190  troductory phase (GREET-INTRODUCE-TOPIC), the  negotiation phase (NEGOTIATE) and the closing  phase (FINISH).", "acronyms": [[71, 80], [106, 112]], "long-forms": [[52, 69], [90, 104]]}, {"text": "bines the output of all the 13 base models introduced previously. We implemented the meta-classifier using Support Vector Machines (SVMs)15 with a quadratic polynomial kernel, and C = 0.01 (tuned in the development set).16 Lastly, Table 13 shows the results", "acronyms": [[132, 136]], "long-forms": [[107, 130]]}, {"text": "10 ESA on senses and Wikipedia Link Measure (WLM) compute similarity on a sense-level, however, sim-", "acronyms": [[45, 48], [3, 6]], "long-forms": [[21, 43]]}, {"text": "semantic F1 of 85.63 for English.  Time Expression Identification (TEI) and Normalization (TEN): We use the time module", "acronyms": [[67, 70]], "long-forms": [[35, 65]]}, {"text": "patterns allows a 4-way classification of slopes of lines: fast rising, rising, level, falling.  These are the 4 Fundamental Pattern Features (FPF). A combination of 2 or  3 (of the 4) ", "acronyms": [[143, 146]], "long-forms": [[113, 141]]}, {"text": "A S O W B E  - as + Object of be  A S S E R T I O N ~ S ~ ~ ~ ~ ~ ~  + Tense + V e r b  Object  ASTG = Adjective String  C l  SHOULD -- Subjunctive foYm of ASSERTllgZQ ", "acronyms": [[96, 100]], "long-forms": [[103, 119]]}, {"text": "uation test sets. Equal Error Rates (EER), where FA = FR, are given in Table 5. Results on EVAL", "acronyms": [[54, 56], [37, 40], [49, 51], [91, 95]], "long-forms": [[18, 35]]}, {"text": "Table 5: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, McCCJ=McClosky-Charniak-Johnson parser, Charniak=Charniak parser, SD=Stanford Dependency conversion, GE=GE task corpus.", "acronyms": [[94, 97], [73, 75], [138, 143], [178, 186], [204, 206], [239, 241]], "long-forms": [[98, 125], [76, 92], [144, 169], [187, 195], [242, 244], [207, 226]]}, {"text": "are the formal-language theoretic foundation for n-gram models (Garcia et al, 1990), which are widely used in natural language processing (NLP) in part because such distributions can be estimated", "acronyms": [[139, 142]], "long-forms": [[110, 137]]}, {"text": "lexicon tool, with a classification phase based on  Featured-Based kernel such as SL kernel and TreeBased kernel such as Dependency tree (DT) kernel  (Culotta and Sorensen, 2004) and Phrase Structure ", "acronyms": [[138, 140], [82, 84]], "long-forms": [[121, 136]]}, {"text": "We evaluate the lexicons proposed in Section 3 both intrinsically (by comparing their lexicon entries against General Inquirer (GI) lexicon) and extrinsically (by using them in a phrase polarity anno-", "acronyms": [[128, 130]], "long-forms": [[110, 126]]}, {"text": "S2LS. The best parameters were then used on the Senseval-3 English Lexical Sample task (S3LS), where a similar semi-supervised method was used", "acronyms": [[88, 92], [0, 4]], "long-forms": [[48, 86]]}, {"text": "tant of these is the controlled vocabulary terms assigned by human indexers. NLM?s controlled vocabulary thesaurus, Medical Subject Headings (MeSH),2 contains approximately 23,000 descriptors arranged in a hierarchical structure and more than 151,000", "acronyms": [[142, 146], [77, 82]], "long-forms": [[116, 140]]}, {"text": " This paper proposes an approach for implicit feature detection based on SVM and Topic Model(TM). ", "acronyms": [[93, 95], [73, 76]], "long-forms": [[81, 91]]}, {"text": "negative has an incorrect, but plausible, stress pattern, u. We adopt a Support Vector Machine (SVM) solution to these ranking constraints as described by", "acronyms": [[96, 99]], "long-forms": [[72, 94]]}, {"text": "The methods for scoring the Template Element, Template Relation, Scenario Template, and Named Entity tasks are  very similar. From the standpoint of calculating scores, The template element (TE) task is the basic task of these four. ", "acronyms": [[191, 193]], "long-forms": [[173, 189]]}, {"text": "Table 5 shows the results when experimenting with various tree structures (see columns 2-5): (i) the basic tree (BT), (ii) the basic tree augmented with part-of-speech information (BTP), (iii) shallow syntactic tree (ShT), and (iv) syntactic tree (ST). We", "acronyms": [[217, 220], [113, 115], [181, 184], [248, 250]], "long-forms": [[193, 215], [101, 111], [127, 179], [232, 246]]}, {"text": "proposed by (Jia and Zhao, 2013). We will mainly consider MIU accuracy (MIU-Acc) which is the ratio of the number of completely corrected gen-", "acronyms": [[72, 79]], "long-forms": [[58, 70]]}, {"text": " 4. Coreference (COR) As mentioned in our discussion of transitional phrases, a strong argument", "acronyms": [[17, 20]], "long-forms": [[4, 15]]}, {"text": "Figure 1 shows the example of the input format of ACABIT in XML makes use of which conforms to Document Type Definition (DTD) in Figure 2.", "acronyms": [[121, 124], [50, 56], [60, 63]], "long-forms": [[95, 119]]}, {"text": "WDS 0.931 [0.905, 0.958] 0.813 [0.738, 0.887] 0.872 R=Random; LR=LexRank; DR=DivRank; DR(p)=DivRank with Priors; CLR=C-LexRank; WDS=Word Distributional Similarity; C.I.=Confidence Interval", "acronyms": [[128, 131], [0, 3], [62, 64], [74, 76], [86, 91], [113, 116], [164, 167]], "long-forms": [[132, 162], [54, 60], [65, 72], [77, 84], [92, 111], [117, 126], [169, 188]]}, {"text": "It includes the four original partners  of the LATER project and the following new partners: University of Amsterdam (UvA) in the Netherlands, Free University of Bolzano-Bozen (FUB) ", "acronyms": [[118, 121], [47, 52], [177, 180]], "long-forms": [[93, 116], [143, 175]]}, {"text": "models. Among stochastic models, bi-gram and  tri-gram Hidden Markov Model (HMM) are  quite popular.", "acronyms": [[76, 79]], "long-forms": [[55, 74]]}, {"text": "Figure 1(a), the node @VP indicates that a binarization has been performed on the subtree VP (VBD PRT PP). All remaining rules that", "acronyms": [[90, 92], [23, 25]], "long-forms": [[94, 101]]}, {"text": "a directed acyclic graph, and a set of conditionnal probablities, each node being represented as a Random Variable (RV). Parametrizing the BN", "acronyms": [[116, 118], [139, 141]], "long-forms": [[99, 114]]}, {"text": "la AR  TD  par PREP (prEposition)  main SUBS (substamif)  REC8 (rEcursif simple) ", "acronyms": [[40, 44], [3, 5], [7, 9], [15, 18], [58, 62]], "long-forms": [[46, 55], [21, 32], [64, 72]]}, {"text": "et al, 2000b). A more complex application targets the Aircraft Maintenance Manual (AMM) of the Airbus A320 (Rinaldi et al, 2002b).", "acronyms": [[83, 86]], "long-forms": [[54, 81]]}, {"text": "This problem  is of practical interest for the design of various types  of natural anguage interfaces (NLI's) that make use of  different knowledge sources.", "acronyms": [[103, 108]], "long-forms": [[75, 101]]}, {"text": "The parameters are trained using the 764 Margin Infused Relaxed Algorithm (MIRA) (Crammer et al, 2006).", "acronyms": [[75, 79]], "long-forms": [[41, 73]]}, {"text": "mantic representation is not so clear cut. Generalising only verbs to semantic files (SFv) was the best option in most of the experiments, particularly", "acronyms": [[86, 89]], "long-forms": [[70, 84]]}, {"text": "In ear l ier  papers devoted to interpersonal  interaction iFrank,1981; Levinson,1981\\] much atten-  tion is paid to studying the role of speecb act (SA)  i n  d ia logue  s t ructure .", "acronyms": [[150, 152]], "long-forms": [[138, 148]]}, {"text": "Taggers have been developed for a variety of languages, including Modern Standard Arabic (MSA) (Khoja, 2001; Diab et al, 2004).", "acronyms": [[90, 93]], "long-forms": [[66, 88]]}, {"text": " The ACE 2005 data set alo contains a set of ariticles from the broadcast news (BN) source which is written entirely in lower case.", "acronyms": [[80, 82], [5, 8]], "long-forms": [[64, 78]]}, {"text": " 3.1 Classification Our evaluation was performed using the Maximum Entropy (MaxEnt) and Support Vector Machine (SVM) classifiers.", "acronyms": [[76, 82], [112, 115]], "long-forms": [[59, 74], [88, 110]]}, {"text": "respective polarities. This new value will be called  Positive Association (PosA). The PosA value is ", "acronyms": [[76, 80], [87, 91]], "long-forms": [[54, 74]]}, {"text": "To further investigate the effectiveness of our  method, the third set of experiments evaluate the  negative transfer detection (NTD) compared to  co-training (CO) without negative transfer ", "acronyms": [[129, 132], [160, 162]], "long-forms": [[100, 127], [147, 158]]}, {"text": "Table 3: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, SDE=Software Development Engineer, CoreNLP=Stanford CoreNLP, Porter=Porter stemmer, Snowball=Snowball stemmer, WN-lemma=WordNet lemmatization, McCCJ=McClosky-Charniak-Johnson", "acronyms": [[138, 141], [73, 75], [94, 97], [173, 180], [199, 205], [222, 230], [249, 257], [281, 286]], "long-forms": [[142, 171], [76, 92], [98, 125], [181, 197], [206, 220], [231, 247], [258, 279], [287, 312]]}, {"text": "question answering over RDF data. In World Wide Web (WWW), pages 639?648. ", "acronyms": [[53, 56], [24, 27]], "long-forms": [[37, 51]]}, {"text": "grammatical person and number (1PS, 1PP, 2P, 3PS, 3PP), the quantified pronouns (QUANT), and a group including all other expressions (OTHER). ", "acronyms": [[134, 139], [81, 86]], "long-forms": [[115, 132], [60, 79]]}, {"text": "LA     =   The average length (ALen) of chunks for each  type is the average number of tokens in each chunk ", "acronyms": [[31, 35], [0, 2]], "long-forms": [[15, 29]]}, {"text": "matic speech recognizers in Speech Normalized Orthographic Representation (SNOR) format, or from optical character recognition (OCR) output. For the", "acronyms": [[128, 131], [75, 79]], "long-forms": [[97, 126], [28, 73]]}, {"text": " For example, the surface subject (S-SBJ) of a passive verb is also the logical object (L-OBJ). These", "acronyms": [[88, 93], [35, 40]], "long-forms": [[72, 86], [18, 33]]}, {"text": " 1 Introduction Word sense disambiguation (WSD) is a key enabling technology.", "acronyms": [[43, 46]], "long-forms": [[16, 41]]}, {"text": " ? Abbreviation features (ABB): For every term in the noslang dictionary, we checked whether", "acronyms": [[26, 29]], "long-forms": [[3, 15]]}, {"text": "CIMA is an online information center maintained by the Spanish Agency for Medicines and Health Products (AEMPS). CIMA provides", "acronyms": [[105, 110], [0, 4], [113, 117]], "long-forms": [[84, 103]]}, {"text": "Conjoined noun phrases are required to all  be members of the same semantic  class, which may be one of the set PERSON, PHYSOB (physical object), LOCNAME  (location name), ATTRNAME (attribute name), or MEASU (measurement unit). ", "acronyms": [[172, 180], [202, 207], [112, 118], [120, 126], [146, 153]], "long-forms": [[182, 196], [209, 225], [128, 143], [156, 169]]}, {"text": "features are chosen due to their effectiveness and availability for on-line detection.  They are independent word probability (IWP), anti-word pair (AWP), word formation analogy Table 8", "acronyms": [[127, 130], [149, 152]], "long-forms": [[97, 125]]}, {"text": "The general idea of the main algorithm is to align phrase synsets from the Patty taxonomy with verb synsets in WordNet. To this end, we first construct a directed candidate alignment graph (CAG). Section", "acronyms": [[190, 193]], "long-forms": [[163, 188]]}, {"text": "1 Introduction Part-Of-Speech(POS) tagging is the essential basis of Natural language processing(NLP). It is the pro-", "acronyms": [[97, 100], [30, 33]], "long-forms": [[69, 95], [15, 29]]}, {"text": "non-terminals is extended by means of conditional and additive categories according to Combinatory Categorical Grammar (CCG) (Steedman, 1999). ", "acronyms": [[120, 123]], "long-forms": [[87, 118]]}, {"text": " 1 Introduction Information extraction (IE) systems recover structured information from text.", "acronyms": [[40, 42]], "long-forms": [[16, 38]]}, {"text": "ducted experiments on the same dataset for sentence identification using interaction patterns generated by another pattern generating algorithm (PGA) (Huang et al.,", "acronyms": [[145, 148]], "long-forms": [[115, 143]]}, {"text": "Abstract Crowd-sourcing approaches such as Amazon?s Mechanical Turk (MTurk) make it possible to annotate or collect large amounts of", "acronyms": [[69, 74]], "long-forms": [[52, 67]]}, {"text": " The application will eventually be deployed using a Software as a Service (SaaS) model. It will", "acronyms": [[76, 80]], "long-forms": [[53, 74]]}, {"text": "The primary purpose of the toolkit is to allow students to concentrate on building natural language processing (NLP) systems.", "acronyms": [[112, 115]], "long-forms": [[83, 110]]}, {"text": "results are reported together with the error propagation from argument position classification for Same Sentence (SS), Previous Sentence (PS) models and joined results (ALL) as precision (P), recall", "acronyms": [[114, 116], [138, 140], [169, 172], [188, 190]], "long-forms": [[99, 112], [119, 136], [177, 186]]}, {"text": "5.1 Experimental Settings To evaluate our algorithm?s performance, we designed a Mechanical Turk (MTurk) experiment in which human annotators assess the quality of the", "acronyms": [[98, 103]], "long-forms": [[81, 96]]}, {"text": "For words which failed to be guessed by  tile guessing rules we applied the standard method  of classifying them as common nouns (NN) if they  are not capitalised inside a sentence and proper ", "acronyms": [[130, 132]], "long-forms": [[123, 128]]}, {"text": "Adobe website:2.03 Adobe Systems:1.82 Data mining (DM), also known as Knowledge-Discovery in Databases (KDD) or Knowledge-Discovery and Data Mining (KDD), is the process of automatically searching large volumes of data for patterns.", "acronyms": [[51, 53], [104, 107], [149, 152]], "long-forms": [[38, 49], [70, 101], [112, 140]]}, {"text": "In addition, we also  experimented with different combinations of  translation models (TM), phrase-based and  factor-based, trained on various datasets to ", "acronyms": [[87, 89]], "long-forms": [[67, 85]]}, {"text": "a set of features in the Sentence Scoring phase.  The Maximal Marginal Relevance (MMR) algorithm is then used in the Sentence Re-ordering", "acronyms": [[82, 85]], "long-forms": [[54, 80]]}, {"text": "Table 7 shows the effects of merging the sub-  ject accessibility bias with both recency biases and  the restricted memory bias (RM). The results in ", "acronyms": [[129, 131]], "long-forms": [[105, 122]]}, {"text": " 1 Introduction In recognizing textual entailment (RTE), automated systems assess whether a human reader", "acronyms": [[51, 54]], "long-forms": [[19, 49]]}, {"text": "et al, 1993). The learning algorithm was inspired  by several Inductive Logic Programming (ILP) sys-  tems and primarily consists of a specific-to-general ", "acronyms": [[91, 94]], "long-forms": [[62, 89]]}, {"text": "ergistic working of several components: speech recognition (ASR), spoken language understanding (SLU), dialog management (DM), language generation (LG) and text-to-speech synthesis", "acronyms": [[122, 124], [60, 63], [97, 100], [148, 150]], "long-forms": [[103, 120], [40, 58], [66, 95], [127, 146]]}, {"text": "ABSTRACT  We present a progress report on our research  on nominal compounds (NC's). Recent approaches to ", "acronyms": [[78, 82]], "long-forms": [[59, 76]]}, {"text": " 1.1 Elman and RCC networks  Simple recurrent networks (SRN's) of the Elman type  are similar to three-layer perceptrons but with recurrent ", "acronyms": [[56, 61]], "long-forms": [[29, 54]]}, {"text": "by the organizers). The results are compared to the best system and the MFS (Most Frequent Sense) baseline.", "acronyms": [[72, 75]], "long-forms": [[77, 96]]}, {"text": " A dialogue act is defined as a pair consisting of a communicative function (CF) and a semantic content (SC): a =< CF,SC >.", "acronyms": [[77, 79], [105, 107], [115, 117], [118, 120]], "long-forms": [[53, 75], [87, 103]]}, {"text": " We used an online-large margin algorithm, MIRA (McDonald and Pereira, 2006; Crammer et al, 2005), for updating the weights.", "acronyms": [[43, 47]], "long-forms": [[49, 69]]}, {"text": " For an annotation project, text pieces from a source database (DB) are often copied in a local storage and annotations are attached to them.", "acronyms": [[64, 66]], "long-forms": [[54, 62]]}, {"text": "  2 Dimensionality Reduction   VSM (Vector Space Model) is a basic technique  to transform text documents to numeric vectors.", "acronyms": [[31, 34]], "long-forms": [[36, 54]]}, {"text": "Perhaps the most well-known is that of Merialdo (1994), who used MLE to train a trigram hidden Markov model (HMM). More recent", "acronyms": [[109, 112], [65, 68]], "long-forms": [[88, 107]]}, {"text": "2008.  Deciding strictly local (SL) languages. In Jon Breit-", "acronyms": [[32, 34]], "long-forms": [[16, 30]]}, {"text": "Under the former, they include  personal pronouns, sentential \" i t ,\"  and null-comple-  ment anaphora, and under the latter, verb phrase (VP)  ellipsis, sluicing, gapping, and stripping.", "acronyms": [[140, 142]], "long-forms": [[127, 138]]}, {"text": "2. TREE ADJO IN ING GRAMMARS- -TAG's   We now introduce tree adjoining grammars (TAG's). TAG's ", "acronyms": [[81, 86], [31, 36], [89, 94]], "long-forms": [[56, 79]]}, {"text": "lates in the treebank; it is erroneous because close to wholesale needs another layer of structure, namely adjective phrase (ADJP) (Bies et al, 1995, p. 179). ", "acronyms": [[125, 129]], "long-forms": [[107, 123]]}, {"text": "by (Punyakanok et al, 2004). The process is formulated as an integer linear programming (ILP) problem that takes as inputs the confidences over each", "acronyms": [[89, 92]], "long-forms": [[61, 87]]}, {"text": "923 DOs, Active: \"AGENT STRING AUX active-verb-element DETERMINER * POSTMOD\"DOs, Passive: \"DETERMINER * AUX active-verb-element element\"TVs, Active: \"AGENT STRING AUX * DETERMINER active-noun- element POSTMOD\"TVs, Passive:\"DET active-noun-element AUX * POSTMOD\" Figure 4: Query patterns for retrieving direct objects (DOs) and transitive verbs (TVs) in the Hypothesize step. ", "acronyms": [[318, 321], [345, 348], [31, 34], [104, 107], [163, 166], [4, 7], [76, 79], [247, 250], [136, 139], [209, 212]], "long-forms": [[302, 316], [327, 343]]}, {"text": "resolution pipeline consisted primarily of the C&C parser and Boxer (Curran et al, 2007), which produce Discourse Representation Structures (DRSs). ", "acronyms": [[141, 145], [47, 50]], "long-forms": [[104, 139]]}, {"text": " respectively display the results obtained without and with the use of subcat features (SF). The sec-", "acronyms": [[88, 90]], "long-forms": [[71, 86]]}, {"text": " 1 Introduction Using natural language processing (NLP) techniques to mine software corpora such as code com-", "acronyms": [[51, 54]], "long-forms": [[22, 49]]}, {"text": "This paper discusses the automatic labeling of semantic relations in nominalized noun phrases (NPs) using a support vector machines learning algorithm.", "acronyms": [[95, 98]], "long-forms": [[81, 93]]}, {"text": "354  Table 1: Precision and recMI tables for experiments starting with words-only queries (Words) through phrase (Del l )   and word (Del2) deletion to proper noun (Caps) and noun phrase (NP) grouping. The queries were evaluated on ", "acronyms": [[188, 190], [134, 138], [114, 119]], "long-forms": [[175, 186]]}, {"text": " We cover two main thrusts: (i) a black-box evaluation of several NE taggers (commercial and research systems); and (ii) an error analysis of system performance. 2.1 Evaluation data Our evaluation data set contains three distinct sec-tions.  The largest component consists of publicly-available financial reports filed with the Securities and Exchange Commission (SEC), in particular the 2003 forms 10-K filed by eight Fortune 500 com-panies.  These corporate annual reports share the same subject matter as much business news: sales, profits, acquisitions, business strategies and the like.", "acronyms": [[364, 367], [66, 68]], "long-forms": [[328, 362]]}, {"text": "17 classes set in Sun et al(2008).  We used the spectral clustering (SPEC) method and settings as in Sun and Korhonen (2009) but", "acronyms": [[69, 73]], "long-forms": [[48, 67]]}, {"text": " 1 Introduction Word sense disambiguation (WSD) is the task of assigning sense tags to ambiguous lexical items", "acronyms": [[43, 46]], "long-forms": [[16, 41]]}, {"text": "non-terminal symbols to characterize linguistic objects allow us to use much richer statistical means such as ME (maximum entropy model), etc.", "acronyms": [[110, 112]], "long-forms": [[114, 129]]}, {"text": "(i) identify the scope of coordinations regardless of phrase types, and (ii) detect noun phrase (NP) coordinations and identify their scopes.", "acronyms": [[97, 99]], "long-forms": [[84, 95]]}, {"text": "representative popular heterogeneous corpora, i.e. 232 Penn Chinese Treebank (CTB) and PKU?s People?s Daily (PPD).", "acronyms": [[78, 81], [109, 112]], "long-forms": [[60, 76], [87, 107]]}, {"text": "(ADV), cause (CAU), direction (DIR), extent (EXT), location (LOC), manner (MNR), and time (TMP), modal verbs (MOD), negative markers (NEG), and discourse connectives (DIS). ", "acronyms": [[134, 137], [1, 4], [14, 17], [31, 34], [45, 48], [61, 64], [75, 78], [91, 94], [110, 113], [167, 170]], "long-forms": [[116, 124], [7, 12], [20, 29], [37, 43], [51, 59], [67, 73], [85, 89], [97, 102], [144, 153]]}, {"text": "of General Linguistics  MAINE, JUNE '94  SEMANTIC SYNTAX (SeSyn) is a direct continuation of work done in the '60s and '70s under the name of GENERATIVE  SEMANTICS.", "acronyms": [[58, 63]], "long-forms": [[41, 56]]}, {"text": " 2.3 IR Similarity Measures (IR) The information retrieval?based features (IR) were based on a dump of English Wikipedia from Novem-", "acronyms": [[75, 77], [5, 7], [29, 31]], "long-forms": [[37, 58]]}, {"text": "some freedom in the ordering of major phrasal categories like  NPs  and adverbial phrases - for example, in the linear order of  subject (SUB J), direct object (DOBJ), and indirect object (lOB J)  with respect o one another.", "acronyms": [[138, 143], [63, 66], [161, 165], [189, 195]], "long-forms": [[129, 136], [146, 159], [172, 187]]}, {"text": "CCG, as well as others.  A combinatory categorial grammar (CCG) is a categorial grammar whose rule system consists of", "acronyms": [[59, 62], [0, 3]], "long-forms": [[27, 57]]}, {"text": "actual dependency annotations cheaply. We use the Graph Fragment Language (GFL), which was created with the goal of making annotations eas-", "acronyms": [[75, 78]], "long-forms": [[50, 73]]}, {"text": " ? Shallow Syntactic Similarity (SP) SP-Op-?.", "acronyms": [[33, 35], [37, 44]], "long-forms": [[3, 31]]}, {"text": "3.4 Algorithm The algorithm first splits the data into appropriate units (SL=source language, TL=target language): 1.", "acronyms": [[74, 76], [94, 96]], "long-forms": [[77, 92], [97, 112]]}, {"text": "tence pairs were selected from the WMT Giga corpus if the perplexity of their French part with respect to a language model (LM) trained on French news data was below a given threshold.", "acronyms": [[124, 126], [35, 38]], "long-forms": [[108, 122]]}, {"text": "All-before 8 0.0313 88.03 Table 1. Instance classification accuracy (CA) using  different feature sets.", "acronyms": [[69, 71]], "long-forms": [[44, 67]]}, {"text": "To allow for portability, the SABA parser translates its natural  language input into an ~mtermediate\" s mantic network formalism  called SF (for \"Sentence Formalism'), presented in details in (Binot,  1984, 1985).", "acronyms": [[138, 140], [30, 34]], "long-forms": [[147, 165]]}, {"text": "Afterward we name the TD composed of words from gold training set and tagged test set and as Na??ve TD (NTD) for its unbalanced coverage in training and test set.", "acronyms": [[104, 107], [22, 24]], "long-forms": [[93, 102]]}, {"text": "Num. of Friendships 265 Average Clustering Coefficient (ACC) 0.42 Diameter 12 Table 1: Statistical information of our Foursquare dataset.", "acronyms": [[56, 59]], "long-forms": [[24, 54]]}, {"text": "the toolkits. Sizes are given for the resulting transducers (VM = Verbmobil). ", "acronyms": [[61, 63]], "long-forms": [[66, 75]]}, {"text": "end returnmodels [] Algorithm 1: Positive Diversity Tuning (PDT) lectively produce very diverse translations.3", "acronyms": [[60, 63]], "long-forms": [[33, 58]]}, {"text": "1001   Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 844?853, October 25-29, 2014, Doha, Qatar.", "acronyms": [[95, 100]], "long-forms": [[45, 93]]}, {"text": "tion access tasks. Current approaches to AZ rely on supervised machine learning (ML). ", "acronyms": [[81, 83], [41, 43]], "long-forms": [[63, 79]]}, {"text": "ajaynagesh@cse.iitb.ac.in Abstract Information Extraction (IE) has become an indispensable tool in our quest to handle the data", "acronyms": [[59, 61]], "long-forms": [[35, 57]]}, {"text": " The experiments were performed using the  Wall Street Journal (WSJ) corpus of the Uni-  versity of Pennsylvania (Marcus et al, 1993) ", "acronyms": [[64, 67]], "long-forms": [[43, 62]]}, {"text": "a question written in natural language is called ? Question Answering?(QA), and has gotten a lot of attention recently.", "acronyms": [[71, 73]], "long-forms": [[51, 69]]}, {"text": "model for sequence classification. In Proceedings of International Conference on Data Mining (ICDM). ", "acronyms": [[94, 98]], "long-forms": [[53, 92]]}, {"text": "factoid ones - as well as new elements ? such as  expected polarity type (EPT). However, opi-", "acronyms": [[74, 77]], "long-forms": [[50, 72]]}, {"text": "Baselines We use the following baselines. The first is the Homogenous Poisson Process (HPP) trained on the training set of the rumour.", "acronyms": [[87, 90]], "long-forms": [[59, 85]]}, {"text": "method for unambiguous bilingual segmentation where tokens are defined as minimal phrases, called minimal translation units (MTUs). Figure 1", "acronyms": [[125, 129]], "long-forms": [[98, 123]]}, {"text": "such as Declarative Sentence(SDEC),  Noun Phrase(NP), Inf init ive  Phrase(INF), and Verb Phrase(VP),  are big structures with some.k~y ", "acronyms": [[97, 99], [29, 33], [49, 51], [75, 78]], "long-forms": [[85, 95], [8, 28], [37, 48], [54, 74]]}, {"text": "3.3  Parameter  es t imat ion   In supervised lcarning~ the simpliest parameter  estimation is the maximum likelihood(ML) cs-  t imation(Duda et al, 1973) which lnaximizes ", "acronyms": [[118, 120]], "long-forms": [[99, 116]]}, {"text": " 1 Introduction Language identification (LangID) is the problem of determining what natural language a document is written in.", "acronyms": [[41, 47]], "long-forms": [[16, 39]]}, {"text": "tasks. While having the same model structure as Hidden Markov Models (HMMs), CRFs are trained discriminatively and can use large numbers of corre-", "acronyms": [[70, 74], [77, 81]], "long-forms": [[48, 68]]}, {"text": " As an example consider the multiple alignments in Figure 4, with the gold standard alignment (GS) on the left and the generated alignment (GA) on", "acronyms": [[95, 97]], "long-forms": [[70, 83]]}, {"text": "get, with results deteriorating as we move to information retrieval (IR), multi-document summarization (SUM), and information extraction (IE). ", "acronyms": [[138, 140]], "long-forms": [[114, 136]]}, {"text": "BLEU-4 (Papineni et al, 2002) used in the two  experiments, we design another evaluation metrics Reordering Accuracy (RAcc) for forced decoding evaluation.", "acronyms": [[118, 122], [0, 6]], "long-forms": [[97, 116]]}, {"text": "precision, recall and f-measure. Precision measures the number of correct Named Entities(NEs) in the 107", "acronyms": [[89, 92]], "long-forms": [[74, 87]]}, {"text": "form (FFC); from this decision he/she formulates a natural language utterance with certain features including the sentence type (SeTp) the subject type (SuTp) and punctuation (Punct).", "acronyms": [[129, 133], [6, 9], [153, 157], [176, 181]], "long-forms": [[114, 127], [139, 151], [163, 174]]}, {"text": "Lexico-syntactic properties of English Non-Deverbal Event Nouns (NDV E N),  Process Nouns (PR-N) and Result Nouns (RESN) and Non Event Nouns (NEN).", "acronyms": [[91, 95], [65, 72], [115, 119], [142, 145]], "long-forms": [[76, 89], [39, 62], [101, 113], [125, 139]]}, {"text": "2. Corpus Resource  This study uses the Switchboard Dialog Act (SWBD-DA)  Corpus as the corpus resource, which is available online ", "acronyms": [[64, 71]], "long-forms": [[40, 62]]}, {"text": "ber of hours of domain-specific spontaneous speech used for AM adaptation, the number of titles used to construct the language model (LM), the type of LM, the type of grammar rules in the Phoenix book", "acronyms": [[134, 136], [151, 153], [60, 62]], "long-forms": [[118, 132]]}, {"text": "ability of reordering models to capture this tag sequence in system translations. Popovic et al (2006) use the relative difference between WER (word error rate) and PER (position independent word error rate) to indicate reordering errors.", "acronyms": [[139, 142], [165, 168]], "long-forms": [[144, 159], [170, 206]]}, {"text": "The most common and obvious way to  deal with disjunctive constraints i to expand the grammat-  ical description to disjunctive normal form (DNF) during a  pre-processing step, thereby eliminating disjunction from the ", "acronyms": [[141, 144]], "long-forms": [[116, 139]]}, {"text": "Recent work investigates ways of accommodating supervision with LDA, e.g. supervised topic models (Blei and McAuliffe, 2007), Labeled LDA (L-LDA) (Ramage et al, 2009) or DiscLDA (Lacoste-Julien", "acronyms": [[139, 144], [64, 67], [170, 177]], "long-forms": [[126, 137]]}, {"text": "3.2 Formalizing Paradigmatic Relations with Lexical Functions Lexical functions (LF) are a formal tool designed to describe all types of genuine lexical relations", "acronyms": [[81, 83]], "long-forms": [[62, 79]]}, {"text": "common view of the semantics of time. Since the target application domain is an historical database, we  present the essential features of the Historical Relational Database Model (HRDM), an extension to the  relational model motivated by the desire to incorporate more \"real world\" semantics into a database at ", "acronyms": [[181, 185]], "long-forms": [[143, 179]]}, {"text": "tion). All markables have named entity types such as FACILITY, GPE (geopolitical entity), PERSON, LOCATION, ORGANIZATION, PERSON, VEHI-", "acronyms": [[63, 66]], "long-forms": [[68, 87]]}, {"text": "plementation of SVR, with tuned parameters.  Ranking: An SVM model for ranking (SVMRank) is trained using as ranking pairs all pairs of stu-", "acronyms": [[80, 87], [16, 19]], "long-forms": [[57, 78]]}, {"text": "company was interested in knowledge discovery  approaches applicable to the data aggregated by its  Emergency Control System (ECS) in the form of  field service tickets.", "acronyms": [[126, 129]], "long-forms": [[100, 124]]}, {"text": "text categorization tasks. The newer method of Latent Semantic Indexing (LSI) 3 (Deerwester et al.,", "acronyms": [[73, 76]], "long-forms": [[47, 71]]}, {"text": "More recently, (Areces et al, 2008) analysed GRE as a problem in Description Logic (DL), a formalism which, like Conceptual Graphs, is specifically designed for", "acronyms": [[84, 86], [45, 48]], "long-forms": [[65, 82]]}, {"text": "Among the NEs we select six of them as the recognized objects, that is, personal name (PN), date or time (DT), location name (LN), team name (TN), competition title (CT) and per-", "acronyms": [[106, 108], [126, 128]], "long-forms": [[92, 104], [111, 124]]}, {"text": "AS for word  order,  ther{{ ar<~ basieal\\]}Z two  phrase  'types i n  German:  noun-dependent   phrases,  l i ke  no(:~n phrase  ( NP ) and  prepos i t iona l  phrase  ( !:'", "acronyms": [[131, 133]], "long-forms": [[114, 127]]}, {"text": "? P2E1N3S2, C S D G ASD Simplified Technical English (ASD-STE) (ASD 2013), often abbreviated to Simplified Technical English (STE) or just Simplified English, is a CNL for the aerospace", "acronyms": [[54, 61], [0, 10], [126, 129], [164, 167], [64, 67]], "long-forms": [[20, 52], [96, 124]]}, {"text": "(SBAR-TMP (IN after) (S (NP (DT the) (NN sale)) (VP (AUX is) (VP (VBN completed))) ))))))))", "acronyms": [[66, 69], [1, 9], [25, 27], [29, 31], [38, 40], [49, 51], [53, 56], [62, 64]], "long-forms": []}, {"text": "2.1 Collection Tasks To collect our data, we used two different types of human intelligence tasks (HITs). In type 1, the", "acronyms": [[99, 103]], "long-forms": [[73, 97]]}, {"text": "i );3 MFS = Maximal Freq Sequences(d1 i", "acronyms": [[6, 9]], "long-forms": [[12, 37]]}, {"text": " 2 Tutorial Dialogue Setting and Data My Science Tutor (MyST) (Ward et al, 2010) is a conversational virtual tutor designed to improve science learning and understanding for students in grades 3-5.", "acronyms": [[56, 60]], "long-forms": [[38, 54]]}, {"text": "match number, SM (Short Match) is the continuous match number which is no more than 4, and LM (Long Match) is the continuous match number which is more than 4.", "acronyms": [[91, 93]], "long-forms": [[95, 105]]}, {"text": "108   Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, page 1, Gothenburg, Sweden, April 27, 2014.", "acronyms": [[75, 80], [84, 88]], "long-forms": [[41, 73]]}, {"text": "denote Run1, Run2, and Run3, respectively, our submissions to the shared task; FL=Flagging, FS=Feature stacking, DS=Domain stacking. ", "acronyms": [[92, 94], [113, 115], [79, 81]], "long-forms": [[95, 111], [116, 131], [82, 90]]}, {"text": "languages by using approaches based on CCA (Canonical Correlation Analysis) and multilingual PLSA (Probabilistic Latent Semantic Analysis). ", "acronyms": [[93, 97], [39, 42]], "long-forms": [[99, 137], [44, 74]]}, {"text": ">60 ICE ICE ICE ICE 10C 1~ 10C I0C  >.Y0 ICE ICE ICE ICE ICE IOC I(E 1~  >40 IO(J ICE ICE lO0 ICE ICE 1~ ICE  >35 ICE lO(l ICE ICE lie lOC IOC lOC ", "acronyms": [[77, 79]], "long-forms": [[82, 93]]}, {"text": "5.3 Evaluation Metrics For YA, we used the standard implementations for P@1 and mean reciprocal rank (MRR) (Manning et al, 2008).", "acronyms": [[102, 105], [27, 29]], "long-forms": [[80, 100]]}, {"text": "tract syntactic features for FB-LTAG.  We use with Sejong Treebank (SJTree) which  contains 32 054 eojeols (the unity of segmenta-", "acronyms": [[68, 74]], "long-forms": [[51, 66]]}, {"text": " ? Research Question 1 (RQ1): How do we define suggestions in suggestion mining?", "acronyms": [[24, 27]], "long-forms": [[3, 22]]}, {"text": "4.2 Cognate based features Dictionaries mostly fail to return translation entries for named entities (NEs) or specialized terminology.", "acronyms": [[102, 105]], "long-forms": [[86, 100]]}, {"text": "If we put these two constraints together we obtain the constraint MINS = MAXS, which means that the area where quantifiers take scope (the MAXS-", "acronyms": [[73, 77], [66, 70], [139, 143]], "long-forms": []}, {"text": "{zhongzhi, nght}@comp.nus.edu.sg Abstract Word sense disambiguation (WSD) systems based on supervised learning", "acronyms": [[69, 72]], "long-forms": [[42, 67]]}, {"text": "called D2S. D2S has been used as the foundation of a number of language-generating systems, including GOALGETTER, a system that generates soccer reports in Dutch.1 D2S consists of two modules: (1) a language generation module (LGM) and (2) a speech generation module (SGM) which turns the generated text into a speech signal.", "acronyms": [[227, 230], [12, 15], [7, 10], [164, 167], [268, 271]], "long-forms": [[199, 225], [242, 266]]}, {"text": "These features capture the context of the adverb and help in deciding the presence of the manner (MNR) component. ", "acronyms": [[98, 101]], "long-forms": [[90, 96]]}, {"text": "fidence information about each system?s hypothesis. This feature class includes the confusion network (CN) word confidence, CN slot entropy, and the number of alter-", "acronyms": [[103, 105], [124, 126]], "long-forms": [[84, 101]]}, {"text": "an~ (AN)  art~fact (AR)  attribute (AT)  body (BO) ", "acronyms": [[36, 38], [5, 7], [20, 22], [47, 49]], "long-forms": [[25, 34], [10, 18], [41, 45], [0, 3]]}, {"text": "AVERAGE 70.8% 70.1% Table 2: Ten-fold cross-validation classification results, using a Na??ve Bayes (NB) or Support Vector Machines (SVM) classifier", "acronyms": [[101, 103], [133, 136]], "long-forms": [[87, 99], [108, 131]]}, {"text": "               XOAJC + LC*Ave(XOAJC)/Ave(XOAR)  The second strategy consists in building a prediction model for BLAST bit score (BBS) using the  XOA score and the log-cosine LC as predictors ", "acronyms": [[129, 132], [41, 45], [30, 35], [15, 20], [23, 25], [145, 148], [174, 176]], "long-forms": [[112, 127]]}, {"text": "stood statistical models?statistical dependency parsers, probabilistic context-free grammars (PCFGs), and word translation models (TMs)?can be effectively combined into a unified framework that jointly searches for the best", "acronyms": [[131, 134], [94, 99]], "long-forms": [[111, 129], [57, 92]]}, {"text": "The task of location normalization is to identify  the correct sense of a possibly ambiguous  location Named Entity (NE). Ambiguity is very ", "acronyms": [[117, 119]], "long-forms": [[103, 115]]}, {"text": " One suggestion is is to use as a natural anguage  grammar the Core Language Engine (CLE)  (Alshawi 1992).", "acronyms": [[85, 88]], "long-forms": [[63, 83]]}, {"text": "To estimate the weights ? i in formula (1), we  use Minimum Error Rate Training (MERT) algorithm, which is widely used for phrase-based ", "acronyms": [[81, 85]], "long-forms": [[52, 79]]}, {"text": "tags and word.  Rich Morphological Features (Rich-MF): In addition to the elementary features we use the am-", "acronyms": [[45, 52]], "long-forms": [[16, 43]]}, {"text": "tic models, which in this case are hidden Markov models (HMM), and described in terms of wellknown Mel frequency cepstral coefficients (MFCCs) (Benesty et al, 2008).", "acronyms": [[136, 141], [57, 60]], "long-forms": [[99, 134], [35, 54]]}, {"text": "~  I n  recent  years  the  prob lem o f  man 'mach ine  communicat ion  by  means   o f  natura l  language (NL) i s  becoming  a pract i ca l  one .  And the  ", "acronyms": [[110, 112]], "long-forms": [[90, 108]]}, {"text": " 2.1 Weighted regular tree grammars A weighted regular tree grammar (WRTG) is a 4tuple G = (S,L,R, s`), where S and L are two", "acronyms": [[69, 73]], "long-forms": [[38, 67]]}, {"text": "guishes tile outputs of these two phases by the  data types l:l.hetRep (rhetorical representation)  and DocRep (document representation). ", "acronyms": [[104, 110]], "long-forms": [[112, 135]]}, {"text": " What we describe is part of a theory of language (knowledge and processing)  called Word Grammar (WG) (Hudson 1984; 1990). Section 2 introduces the knowledge ", "acronyms": [[99, 101]], "long-forms": [[85, 97]]}, {"text": "Han, C-H., Han, N-R., Ko, E-S.and Palmer, M.: Development and Evaluation of a Korean  Treebank and Its Application to NLP.in Proceedings of the 3rd International Conference on  Language Resources and Evaluation (LREC).(2002)  5.", "acronyms": [[212, 216]], "long-forms": [[177, 195]]}, {"text": "are evaluated using nuggets drawn from citation texts (CT), or abstracts (AB), and DP surveys are evaluated using nuggets from citation texts (CT). ", "acronyms": [[143, 145], [55, 57], [74, 76], [83, 85]], "long-forms": [[127, 141], [39, 53], [63, 72]]}, {"text": "Our model incorporates simple priors inspired by the minimum description length (MDL) principle, as well as overlapping features such as morphemes and", "acronyms": [[81, 84]], "long-forms": [[53, 79]]}, {"text": "3 Architecture of SCQA As shown in Figure 2, SCQA consists of a pair of deep convolutional neural networks (CNN) with convolution, max pooling and rectified lin-", "acronyms": [[108, 111], [18, 22], [45, 49]], "long-forms": [[77, 106]]}, {"text": "2.3 Approach BUAP-RUN-3: Random Indexing and Bag of Concepts The vector space model (VSM) for document representation supporting search is probably the most", "acronyms": [[85, 88], [13, 23]], "long-forms": [[65, 83]]}, {"text": " 4.2 Data  We used the Wall Street Journal (WSJ) of the years  88-89.", "acronyms": [[44, 47]], "long-forms": [[23, 42]]}, {"text": "using only a single, probable alignment.\" The single most probable assignment Ama~  is the maximum a posteriori (MAP) assignment:  Amax = ar~maxPr(U,A, VIO ) (22) -- AE~4 ", "acronyms": [[113, 116], [166, 168], [152, 155]], "long-forms": [[91, 111]]}, {"text": " This representation treats clitics as separate tokens and abstracts the orthographic rewrites they undergo when cliticized. See the handling of the l/PREP+Al/DET in word #6 in Table 5.  This representation is used by the LDC in the Penn Arabic Treebank (PATB) (Maamouri  et al., 2004) and tools such as MADAMIRA (Pasha et al.,", "acronyms": [[255, 259], [222, 225], [149, 155], [156, 162], [304, 312]], "long-forms": [[233, 253]]}, {"text": "set of basically two algorithms. One algorithm is a  variant of Alignment Based Learning (ABL), as  described in Van Zaanen (2001).", "acronyms": [[90, 93]], "long-forms": [[64, 88]]}, {"text": "We evaluated our parsers using standard labeled accuracy scores (LAS) and unlabeled accuracy scores (UAS) excluding punctuation.", "acronyms": [[101, 104], [64, 68]], "long-forms": [[74, 99], [40, 63]]}, {"text": "1. Construct word representation model for  corpus in the base time, D(TB), and in the  target time, D(TT). (", "acronyms": [[71, 73], [103, 105]], "long-forms": [[54, 62], [88, 99]]}, {"text": "rates of sentences (46.1%) (53.9%) (40.4%) (59.6%) (70.7%) (29.3%) (54.3%) (45.7%) (64.3%) (35.7%) supervised CRF (baseline) 46.78 60.99 48.57 60.01 56.92 67.91 79.60 97.35 75.69 91.03 JESS-CM (CRF/HMM) 49.02 62.60 50.79 61.24 62.47 71.30 85.87 97.47 80.84 92.85 (gain from supervised CRF) (+2.24) (+1.61) (+2.22) (+1.23) (+5.55) (+3.40) (+6.27) (+0.12) (+5.15) (+1.82)", "acronyms": [[194, 201], [185, 192]], "long-forms": []}, {"text": " 1 Introduction Synchronous contex free grammars (SCFGs) generalize traditional context-free grammars to generate", "acronyms": [[50, 55]], "long-forms": [[16, 48]]}, {"text": "give an indication as to what the vibhakti/TAM are.  Words with PSP (postposition) and NST (noun with spatial and temporal properties) tags are generally", "acronyms": [[64, 67], [34, 46], [87, 90]], "long-forms": [[69, 81]]}, {"text": "face form via the application of a set of grammar rules based on particular linguistic theories, e.g. Lexical Functional Grammar (LFG), HeadDriven Phrase Structure Grammar (HPSG), Com-", "acronyms": [[130, 133], [173, 177]], "long-forms": [[102, 128], [136, 171]]}, {"text": "2010. The PASCAL Visual Object Classes Challenge 2010 (VOC2010) Results.", "acronyms": [[55, 62]], "long-forms": [[17, 53]]}, {"text": "entities presence feature (DIC), numerical entities presence feature (NUM), question specific feature (SPE), and dependency validity feature (DEP). ", "acronyms": [[142, 145], [27, 30], [70, 73], [103, 106]], "long-forms": [[113, 123], [85, 93]]}, {"text": "According to the fifth rule, the Arabic letter Z may match an empty string on the English side, if there is an English consonant (EC) in the right context of the English side.", "acronyms": [[130, 132]], "long-forms": [[111, 128]]}, {"text": "a first-order statistical language model can reduce perplex-  ity by at least a factor of 10 with little computation, while  applying complete natural language (NL) models of syn-  tax and semantics to all partial hypotheses typically requires ", "acronyms": [[161, 163]], "long-forms": [[143, 159]]}, {"text": "(i) string kernels applied to sentences, or PTK applied to structural representations with and without embedded relational information (REL). This", "acronyms": [[136, 139], [44, 47]], "long-forms": [[112, 122]]}, {"text": "Video in sentences out.  In Association for Uncertainty in Artificial Intelligence (UAI). ", "acronyms": [[84, 87]], "long-forms": [[44, 82]]}, {"text": "pirical study for text classification which manipulates data using two well-known machine learning techniques, Naive Bayes(NB) and Support Vector Machines(SVMs).", "acronyms": [[123, 125], [155, 159]], "long-forms": [[111, 121], [131, 154]]}, {"text": "against the human annotation.  2.3 Distributed Tree Kernel (DTK) Distributed Tree Kernel (DTK) (Zanzotto and", "acronyms": [[60, 63], [90, 93]], "long-forms": [[35, 58], [65, 88]]}, {"text": "  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 477?487, October 25-29, 2014, Doha, Qatar.", "acronyms": [[90, 95]], "long-forms": [[40, 88]]}, {"text": "76 4 Multi-media Information Networks A Multimedia Information Network (MINet) is a structured collection made up of a set of multimedia documents (e.g., texts and images) and links between these documents.", "acronyms": [[72, 77]], "long-forms": [[40, 70]]}, {"text": "through IBM, by the Disruptive Technology Office (DTO) Phase III Program for Advanced Question Answering for Intelligence (AQUAINT) through Broad Agency Announcement (BAA) N61339-06-", "acronyms": [[123, 130], [8, 11], [50, 53], [167, 170]], "long-forms": [[95, 121], [20, 48], [140, 165]]}, {"text": "ofwi. Just like the statistical pproaches in many automatic POS tagging programs, our job is to select a  constituent boundary sequence B'with the highest score, P(BIS), from all possible sequences. ", "acronyms": [[164, 167], [60, 63]], "long-forms": [[136, 160]]}, {"text": "2011). The default loss function is expected error (EE) (Och, 2003; Cherry and Foster, 2012).", "acronyms": [[52, 54]], "long-forms": [[36, 50]]}, {"text": "Based on these two conditions we have come up with a linear combination of two cost components, similar to Maximal Marginal Relevance (MMR) (Carbonell and Goldstein, 1998).", "acronyms": [[135, 138]], "long-forms": [[107, 133]]}, {"text": "Note that the proponents of the BootCaT method seem to acknowledge this evolution, see for example Marco Baroni?s talk at this year?s BootCaTters of the world unite (BOTWU) workshop: ?", "acronyms": [[166, 171], [32, 39]], "long-forms": [[134, 164]]}, {"text": "to any text, so we shall comment on them.  Frequent Candidates (FC) ? this is a boosting score", "acronyms": [[64, 66]], "long-forms": [[43, 62]]}, {"text": "(3) The measure introduced by Resnik (Resnik, 1995) (RES) returns the information content (IC) of the LCS of two concepts:", "acronyms": [[91, 93], [53, 56], [102, 105]], "long-forms": [[70, 89]]}, {"text": "Their study with three different learners ? na??ve Bayes, maximum entropy (MaxEnt) and the support vector machine (SVM) ?", "acronyms": [[75, 81], [115, 118]], "long-forms": [[58, 73], [91, 113]]}, {"text": "operation!  On the other hand, we did start working on machine translation (MT) in 1987. As", "acronyms": [[76, 78]], "long-forms": [[55, 74]]}, {"text": "SN  where CN = common oun  PN = proper name  SN = Sa-inflection oun (nominal verb) ", "acronyms": [[27, 29], [0, 2], [10, 12], [45, 47]], "long-forms": [[32, 43], [50, 67], [15, 25]]}, {"text": "written japanese. In Proceedings of the 6th  Workshop on Asian Language Resources (ALR),  pages 101?102.", "acronyms": [[83, 86]], "long-forms": [[57, 81]]}, {"text": "     - French/English (fra-eng)    Seven Recognizing Textual Entailment (RTE)  evaluation tracks have already been held: RTE-1 ", "acronyms": [[73, 76]], "long-forms": [[41, 71]]}, {"text": " 2004. The Automatic Content Extraction (ACE) Program?Tasks, Data, and Evaluation.", "acronyms": [[41, 44]], "long-forms": [[11, 39]]}, {"text": "PCEDT 0.7681 0.7072 0.7364 0.0712 Average 0.8402 0.8090 0.8241 0.1397 Table 3: Labeled precision (LP), recall (LR), F 1", "acronyms": [[98, 100], [0, 5], [111, 113]], "long-forms": [[79, 96]]}, {"text": "When these approaches are applied to normal Twitter users accuracy results significantly decrease.  Sentiment Analysis (SA) has been widely studied in the last decade in multiple domains. Most work", "acronyms": [[120, 122]], "long-forms": [[100, 118]]}, {"text": "otherwise be very limited annotated data. The resource, the Online Database of INterlinear text (ODIN), makes this data available and provides additional annotation", "acronyms": [[97, 101]], "long-forms": [[60, 90]]}, {"text": " 3.1 Evaluation methods We use the Relative Utility (RU) method (Radev et al, 2000) to compare our various summaries.", "acronyms": [[53, 55]], "long-forms": [[35, 51]]}, {"text": "audiences have little trouble mapping a collection  of noun phrases onto the same entity, this task of  noun phrase (NP) coreference r solution can present  a formidable challenge to an NLP system.", "acronyms": [[117, 119], [186, 189]], "long-forms": [[104, 115]]}, {"text": "4.1 Selection of PPs in the Lexicon Our parser makes use of the computational lexicon HaGenLex (Hagen German Lexicon, see (Hartrumpf et al, 2003)), which is a general do-", "acronyms": [[86, 94], [17, 20]], "long-forms": [[96, 116]]}, {"text": " Recently researchers have been investigating Amazon Mechanical Turk (MTurk) as a source of non-expert natural language annotation, which is a", "acronyms": [[70, 75]], "long-forms": [[53, 68]]}, {"text": "We gratefully acknowledge the support of Turkish  Scientific and  Technological Research Council of  Turkey  (TUBITAK)  and  METU  Scientific  Research  Fund  (no.", "acronyms": [[110, 117], [125, 129]], "long-forms": []}, {"text": "the Extraction of Potential Opinion Phrases. Notation: po=potential opinion, M=modifier, NP=noun phrase, S=subject, P=predicate, O=object.", "acronyms": [[89, 91], [55, 57]], "long-forms": [[92, 103], [58, 75], [79, 87], [107, 114], [118, 127], [131, 137]]}, {"text": " Before we discuss the significant sentence in answer mails, we classified answer mails into three types: (1) direct answer (DA) mail, (2) questioner?s reply (QR) mail, and (3) the others.", "acronyms": [[125, 127], [159, 161]], "long-forms": [[110, 123], [139, 157]]}, {"text": "For our simulations, we built two subcorpora by filtering out entity annotations: the PENNBIOIE gene corpus (PBgene), including the three gene entity subtypes generic, protein, and rna,", "acronyms": [[109, 115]], "long-forms": [[86, 100]]}, {"text": "represented in an n ? n matrix of objects by a  multidimensional scaling (MDS) of the distance  between each object.", "acronyms": [[74, 77]], "long-forms": [[48, 72]]}, {"text": "oracle? which determines the predominant sense, or most frequent sense (MFS), of each noun in our WSJ test data perfectly, and", "acronyms": [[72, 75], [98, 101]], "long-forms": [[51, 70]]}, {"text": "embeddings from the Neural Language Model of Collobert and Weston [2008] and word representations from random indexing (RI)1. These, however, were", "acronyms": [[120, 122]], "long-forms": [[103, 118]]}, {"text": " 1 Introduction Minimum error rate training (MERT)?also known as direct loss minimization in machine learning?is a", "acronyms": [[45, 49]], "long-forms": [[16, 43]]}, {"text": "these areas. Speci\fcally, our goals when entering MUC-7 were to: \u000f Increase the accuracy in the Template Element (TE) task and the Template Relation (TR) task su\u000eciently for operational use, i.e., F-Measures of 85% and 80% respectively,", "acronyms": [[114, 116], [150, 152], [50, 55]], "long-forms": [[96, 112], [131, 148]]}, {"text": "The open class  word (host) tends to be uninflected, and only  the light verb (LV) carries tense, agreement  and aspect markers.", "acronyms": [[79, 81]], "long-forms": [[67, 77]]}, {"text": "Table 4: Reranking results (%BLEU on TEST).  Discriminative Word/Tag LMs (DISC): For each language pair, we generated 10,000-best lists for", "acronyms": [[74, 78], [69, 72], [37, 41], [29, 33]], "long-forms": [[45, 59]]}, {"text": "Abstract  This article focuses on the development of  Natural Language Processing (NLP) tools for  Computer Assisted Language Learning ", "acronyms": [[83, 86]], "long-forms": [[54, 81]]}, {"text": "sequence of ATN arcs which is matched against the  input string. A pattern arc (PAT) has been added to  the ATN formalism with a form similar to that of oth- ", "acronyms": [[80, 83], [108, 111]], "long-forms": [[67, 74], [12, 15]]}, {"text": "For this task we train and test three different statistical models: an n-gram language model, a maximum entropy model (MaxEnt) and a (linear) support vector machine (SVM).", "acronyms": [[119, 125], [166, 169], [71, 77]], "long-forms": [[96, 111], [142, 164]]}, {"text": "117 d?eriv?es) (AP (ADJ thiazidiques) (COORD (PONCT ,) (NP (DET les) (ADV plus) (ADJ accessibles)) (PONCT ,) (AP (ADJ disponibles)))) (PP (P sous forme de) (NP (NC m?edicaments) (AP (ADJ g?en?eriques)))))))))", "acronyms": [[114, 117], [20, 23], [16, 18], [39, 44], [46, 51], [56, 58], [60, 63], [70, 73], [81, 84], [100, 105], [110, 112], [135, 137], [157, 159], [161, 163], [179, 181], [183, 186]], "long-forms": [[118, 129]]}, {"text": "research relies is that the failures of current automatic metrics are not algorithmic: BLEU, Meteor, TER (Translation Edit Rate), and other metrics efficiently and correctly compute informative distance", "acronyms": [[101, 104], [87, 91]], "long-forms": [[106, 127]]}, {"text": "In this section, we define pomsets as a model for describing concurrency. A labelled partial order (LPO) is a 4 tuple (V, ?,", "acronyms": [[100, 103]], "long-forms": [[76, 98]]}, {"text": "We extend the SPARSELDA (Yao et al, 2009) inference scheme for latent Dirichlet alocation (LDA) to tree-based topic models.", "acronyms": [[91, 94], [14, 23]], "long-forms": [[63, 89]]}, {"text": "The third is end position (EP), after a predi-  cate. Pre position (PreP) and post position (PostP)  are provided for adverbs as modifiers.", "acronyms": [[68, 72], [93, 98], [27, 29]], "long-forms": [[54, 66], [78, 91], [13, 25]]}, {"text": " 1 Introduction Natural Language Inference (NLI), i.e. the task of determining whether an NL hypothesis can be in-", "acronyms": [[44, 47], [90, 92]], "long-forms": [[16, 42]]}, {"text": "natural problems, and outperform several widelyused conventional models, e.g., support vector machines (SVMs), conditional random fields (CRFs) and hidden Markov models (HMMs).", "acronyms": [[138, 142], [104, 108], [170, 174]], "long-forms": [[111, 136], [79, 102], [148, 168]]}, {"text": "In this paper, we propose  methods to detect and correct WOEs in Chinese sentences. Conditional random fields (CRFs)  based WOEs detection models identify the sentence segments containing WOEs.", "acronyms": [[111, 115], [57, 61], [124, 128], [188, 192]], "long-forms": [[84, 109]]}, {"text": "been proposed in \\[Uszkoreit 87\\]: p.145 in his German  grammar. It makes the adverbial phrase (AdvP) a sister  node of the verb and its arguments: ", "acronyms": [[96, 100]], "long-forms": [[78, 94]]}, {"text": "during the last two years. In this first of four installerments, the  Association of Data Processing Service Organizations, Inc. (ADAPSO) is  considered with respect to its membership, charter, organization and ", "acronyms": [[130, 136]], "long-forms": [[70, 122]]}, {"text": "Abstract This work looks at a temporal aspect of multiword expressions (MWEs), namely that the behaviour of a given n-gram and", "acronyms": [[72, 76]], "long-forms": [[49, 70]]}, {"text": ". . . ( 7) To shorten notation, we use state abbreviations (e.g., CA = California :state). ", "acronyms": [[66, 68]], "long-forms": [[71, 81]]}, {"text": "115  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 566?576, October 25-29, 2014, Doha, Qatar.", "acronyms": [[93, 98]], "long-forms": [[43, 91]]}, {"text": "removed for expository reasons.  rewrites into an (optional) sentence adjunct (SA), a  subject, a verbphrase and subject's right adjunct ", "acronyms": [[79, 81]], "long-forms": [[61, 77]]}, {"text": "ments were annotated with word-level labels by professional translators using the core categories in MQM (Multidimensional Quality Metrics) 13", "acronyms": [[101, 104]], "long-forms": [[106, 138]]}, {"text": "They are not constrained  by features of any previous utterance in the  discourse segment (DS), and the elements of Cf(Un)  are partially ordered to reflect relative prominence ", "acronyms": [[91, 93], [119, 121], [116, 118]], "long-forms": [[72, 89]]}, {"text": "2013).  Currently the most active framenet research teams are working on Swedish FrameNet (SweFN) (Borin et al.,", "acronyms": [[91, 96]], "long-forms": [[73, 89]]}, {"text": "ran, and the historical ancestor of the other varieties. Modern Standard Arabic (MSA) is the modern  version of CA and is, broadly speaking, the univer-", "acronyms": [[81, 84]], "long-forms": [[57, 79]]}, {"text": "set we trained on both glosses and statistical MT data, for the OnWN and FNWN test sets we trained on glosses only (OnWN), and for the SMT test set we trained on statistical MT data only (MTnews and", "acronyms": [[116, 120], [47, 49], [64, 68], [73, 77], [135, 138], [174, 176], [188, 194]], "long-forms": [[99, 114]]}, {"text": "Table 3: Validation results for metaphor interpretation for English and Russian.  (ALL), or just two (TWO) validators. In most of", "acronyms": [[102, 105]], "long-forms": [[97, 100]]}, {"text": "mentary ASR systems, a technique first proposed in the context of NIST?s ROVER system (Fiscus, 1997) with a 12% relative error reduction (RER), and subsequently widely employed in many ASR", "acronyms": [[138, 141], [8, 11], [185, 188]], "long-forms": [[112, 136]]}, {"text": "the discrimination of similar languages: The DSL corpus collection. In Proceedings of the 7th Workshop on Building and Using Comparable Corpora (BUCC), Reykjavik, Iceland. ", "acronyms": [[145, 149]], "long-forms": [[106, 143]]}, {"text": "pact of syllabification on the L2P problem in English. Their Syllabification by Analogy (SbA) algorithm is a data-driven, lazy learning approach.", "acronyms": [[89, 92], [31, 34]], "long-forms": [[61, 87]]}, {"text": "In order to represent gram-  mar rules distributively, we adopt categorial unifi-  cAtion grammar (CUG) Where eaclh category owns  its functional type.", "acronyms": [[99, 102]], "long-forms": [[64, 97]]}, {"text": "would have higher perplexity.  Syntactic Score (SC) Some erroneous sentences often contain words and concepts that are locally cor-", "acronyms": [[48, 50]], "long-forms": [[41, 46]]}, {"text": " 1 Introduction In the semantic dependency parsing (SDP) task of SemEval 2014, the meaning of a sentence is repre-", "acronyms": [[52, 55]], "long-forms": [[23, 50]]}, {"text": "http://www.ukp.tu-darmstadt.de Abstract In this paper, we present a machine learning approach for word sense alignment (WSA) which combines distances between senses in the graph representations of lexical-semantic resources", "acronyms": [[120, 123]], "long-forms": [[98, 118]]}, {"text": " ? Minimum Bayes Risk (MBR). We rescore the", "acronyms": [[23, 26]], "long-forms": [[3, 21]]}, {"text": "When ready and mature,  technology and language processing techniques will be  incorporated into Foreign Broadcast Information Service (FBIS)  processing.", "acronyms": [[136, 140]], "long-forms": [[97, 134]]}, {"text": "this, in addition to the four actions of the NonInc algorithm, we introduce two new actions: Left Reveal (LRev) and Right Reveal (RRev). For this,", "acronyms": [[130, 134], [106, 110]], "long-forms": [[116, 128], [93, 104]]}, {"text": " 2 Normalized Compression Distance Normalized compression distance (NCD) is a similarity measure based on the idea that a string x is", "acronyms": [[68, 71]], "long-forms": [[35, 66]]}, {"text": "We used 1300 texts (DEV) as our training set, 200 texts (TST1+TST2) for tuning, and 200 texts (TST3+TST4) as a test set. All 1700 docu-", "acronyms": [[95, 104]], "long-forms": [[88, 93]]}, {"text": "ded systems. It is widely used by software certification authorities such as FAA (Federal Aviation Association), and it establishes some guidelines and", "acronyms": [[77, 80]], "long-forms": [[82, 110]]}, {"text": "to pour) means that the entity (wine) is localized to exterior locus (barrel) and crosses the intermediate locus IME(LOC) to be localized to the interior INT(LOC) (the_bottle).", "acronyms": [[117, 120]], "long-forms": [[107, 112]]}, {"text": "tions.  3.1 Simple Classification (SC) Given an expression x consisting of n words x1,", "acronyms": [[35, 37]], "long-forms": [[12, 33]]}, {"text": " 156 The Basque Dependency Treebank (BDT) is a dependency treebank in its original design, due to", "acronyms": [[37, 40]], "long-forms": [[9, 35]]}, {"text": "fcn@dsic.upv.es Abstract State-of-the-art Machine Translation (MT) systems are still far from being perfect.", "acronyms": [[63, 65]], "long-forms": [[42, 61]]}, {"text": "Apple Events  1 Introduction  The SlmSum (Slmulatmn of Summarizing)  system does what its name pronuses It simu- ", "acronyms": [[34, 40]], "long-forms": [[42, 66]]}, {"text": " The machine receives natural language input (text)  with referring expressions (RE), and possibly other  input (e.g. mouse clicks on a screen) with pseudo- ", "acronyms": [[81, 83], [46, 50]], "long-forms": [[58, 79], [39, 44]]}, {"text": "Learning\". In Proceedings of the 3 rd ACL  Workshop on Very Large Corpora (WVLC95). ", "acronyms": [[75, 81]], "long-forms": [[43, 73]]}, {"text": "to learn a lexicon. The theory of the TAD states is Universal Theory (UT); a UT metalanguage enables an abstract characteriza-", "acronyms": [[70, 72], [38, 41], [77, 79]], "long-forms": [[52, 68]]}, {"text": "unitary operator. Therefore, the primary problem  of building a quantum classifier (QC) is to find  the correct or optimal unitary operator.", "acronyms": [[84, 86]], "long-forms": [[64, 82]]}, {"text": "Ah receptor recognizes the B cell transcription factor, BSAP (b) Grf40 binds to linker for activation of T cells (LAT) (c)", "acronyms": [[114, 117], [56, 60]], "long-forms": [[80, 106]]}, {"text": "five tasks) representing fine-grained bio-IE.  2.1 Genia task (GE) The GE task (Kim et al, 2011) preserves the task", "acronyms": [[63, 65], [71, 73], [38, 45]], "long-forms": [[51, 56]]}, {"text": "\t\u000f\u000e \u0010\u0011\t\u0013\u0012\u0014\u0010\u0016\u0015\u0016\u0015\u0016\u0015\u0017\u0010\u0011\t\u0019\u0018\u001a\u0007 consists of a directed acyclic graph (DAG) that encodes a set of conditional independence assertions about vari-", "acronyms": [[64, 67]], "long-forms": [[40, 62]]}, {"text": "interpreters. In International Conference on Learning Representations (ICLR). ", "acronyms": [[71, 75]], "long-forms": [[17, 69]]}, {"text": "This usage is domain specific and the referent is fixed as a second person subject.  pora: 1) three transcripts of family conversation (FaCon) drawn from Australian English Corpus (Monash University 1996~1998) collecting family interviews about their past holidays (Nariyama 2004); 2) three 30-minute-TV Australian drama transcripts (TV) (Nariyama 2004); 3) Switchboard corpus consisting of telephone conversation on a variety of specified every day topics (Cote 1996).  Referent   FaCon TV dramas Switchboard I we you he/she it they ", "acronyms": [[136, 141], [482, 487], [334, 336], [301, 303]], "long-forms": [[115, 134]]}, {"text": "? A chunking rule:  PP = prep, NP#1, if (pythontest(#1)). ", "acronyms": [[20, 22]], "long-forms": [[25, 29]]}, {"text": "higher indicating better.  We used Amazon?s Mechanical Turk (MTurk)5 to collect the human judgements.", "acronyms": [[61, 66]], "long-forms": [[44, 59]]}, {"text": "pre-processed ATB (Table 10). Consequently, this particular Arabic MWE identification experiment is similar to joint parsing and named entity recognition (NER) (Finkel and Manning 2009).", "acronyms": [[155, 158], [67, 70], [14, 17]], "long-forms": [[129, 153]]}, {"text": "Section 3 for exact criteria), reporting  approximately 40% precision and 45% recall for  transitional probability (TP) and 50% precision and  53% recall for mutual information (MI) on the first ", "acronyms": [[116, 118], [178, 180]], "long-forms": [[90, 114], [158, 176]]}, {"text": "There have been several efforts to incorporate lexical hierarchies into statistical processing, primarily for the problem of prepositional phrase (PP) attachment.", "acronyms": [[147, 149]], "long-forms": [[125, 145]]}, {"text": "pattern, up to mi example questions.  Question Pattern (QPi):  When do Q_PRN Q_MVerb Q_BNP?", "acronyms": [[56, 59], [71, 76], [77, 84], [85, 90]], "long-forms": [[38, 54]]}, {"text": " enard Centre de Recherche Informatique de Montr?eal (CRIM) Montr?eal, QC, Canada", "acronyms": [[54, 58], [71, 73]], "long-forms": [[7, 52]]}, {"text": " The best method ASSVM outperforms other methods most clearly on METH (Method) category. Al-", "acronyms": [[65, 69], [17, 22]], "long-forms": [[71, 77]]}, {"text": "presidential nomination to seek the backing of the {{w|Libertarian Party (United States)|Libertarian Party}} (LP). ", "acronyms": [[110, 112]], "long-forms": [[89, 107]]}, {"text": " 3 The TMop framework TMop (Translation Memory open-source purifier) is an open-source TM cleaning software written", "acronyms": [[22, 26], [87, 89]], "long-forms": [[28, 46]]}, {"text": "to analyse the e\u000bects of applying pronominal anaphora resolution to Question Answering (QA) systems. ", "acronyms": [[88, 90]], "long-forms": [[68, 86]]}, {"text": " 2 Hidden Markov Models Hidden Markov models (HMMs) are commonly used to represent a wide range of linguistic phe-", "acronyms": [[46, 50]], "long-forms": [[24, 44]]}, {"text": "2 Background 2.1 Surface Realization with Combinatory Categorial Grammar (CCG) CCG (Steedman, 2000) is a unification-based cat-", "acronyms": [[74, 77], [79, 82]], "long-forms": [[42, 72]]}, {"text": "by the name of its author or the author?s place of  work.  In computational linguistic (CL) terms thi s  exercise relies on proper noun extra ction.", "acronyms": [[88, 90]], "long-forms": [[62, 86]]}, {"text": "State (STT) 42.85 76.93 Gender (GEN) 67.42 84.17 Determiner (DET) 59.71 85.41 Number (NUM) 70.61 87.31", "acronyms": [[61, 64]], "long-forms": [[49, 59]]}, {"text": "shown in (1).2  2~Vc use lhe fo l low ing  abbrev ia t ions :  NOM : nominat ive ;   ACC = accusat ive ;  AI)N = adnomina l ;  CI. = c lass i l ier ;  ARGSTR ", "acronyms": [[85, 88], [106, 110]], "long-forms": [[91, 98], [113, 121]]}, {"text": "web. We require parallel data to build a statistical machine translation (SMT) system that translates from German into Sim-", "acronyms": [[74, 77]], "long-forms": [[41, 72]]}, {"text": "didate substitutes, as described below.  Lexical Baseline (LB): In this approach we use the pre-existing lexical resources to provide a rank-", "acronyms": [[59, 61]], "long-forms": [[41, 57]]}, {"text": "Research in molecular-biology field is discovering enormous amount of new facts, and thus there is an increasing need for information extraction (IE) technology to support database building and to find", "acronyms": [[146, 148]], "long-forms": [[122, 144]]}, {"text": "studied for text categorization task (Forman, 2003).  Information gain (IG) is one of state of the art criteria for feature selection, which measures the de-", "acronyms": [[72, 74]], "long-forms": [[54, 70]]}, {"text": "mark of language attainment at different stages of learning. The English Profile (EP)2 research programme aims to enhance the learning, teaching", "acronyms": [[82, 84]], "long-forms": [[65, 80]]}, {"text": "concerned with video lecture viewing only) before 11 Figure 4: Variation of Average Information Processing Indices(IPI) for Video 4-6 Figure 5: Variation of Average Information Processing Indices(IPI) for the full course", "acronyms": [[115, 118]], "long-forms": [[84, 113]]}, {"text": "person names, organization names, location names, etc. The template element (TE) task extracts information centered around an entity, like the acronym,", "acronyms": [[77, 79]], "long-forms": [[59, 75]]}, {"text": "Table 1. Judgment count for the sample instances (HA=high attachment; LA=low attachment; and A=Ambiguous)   ", "acronyms": [[70, 72]], "long-forms": [[73, 87]]}, {"text": " ? Reduce Left - X (RL) : Pops the top two nodes from the stack, combines them into a new node", "acronyms": [[20, 22]], "long-forms": [[3, 14]]}, {"text": "We show each sentence to three unique workers on Amazon Mechanical Turk (MTurk) and ask each to judge how well the paraphrase retains the mean-", "acronyms": [[73, 78]], "long-forms": [[56, 71]]}, {"text": "First, we provide background on Open IE and how it relates to Semantic Role Labeling (SRL). Section 3 de-", "acronyms": [[86, 89], [37, 39]], "long-forms": [[62, 84]]}, {"text": "61 Table 2: Three kinds of preprocessing of a sentence in Japanese; N = noun, TOP = topic marker, ADV = adverbial particle, ADJ = adjective, COP", "acronyms": [[78, 81], [98, 101], [124, 127], [141, 144]], "long-forms": [[84, 89], [72, 76], [130, 139], [104, 113]]}, {"text": "There is no person boiling noodles A woman is boiling noodles in water Example 9051 (ENTAILMENT) A pair of kids are sticking out blue and green colored tongues", "acronyms": [[85, 95]], "long-forms": [[71, 83]]}, {"text": "{wangruibo,gaoyahui}@sxu.edu.cn Abstract In this paper, semantic role labeling(SRL) on Chinese FrameNet is divided into the", "acronyms": [[79, 82]], "long-forms": [[56, 78]]}, {"text": "adjectives, and specifies the participants and properties of the situation it describes, the so called frame elements (FEs). ", "acronyms": [[119, 122]], "long-forms": [[103, 117]]}, {"text": "The current   representat ion fo r  t h a t  sentence i n  pur system would be:  Z V l  =Ncorn(elephant,X1) PI =P.P(size,X1 ,small)  & =Ncom(animal,X1) P2 =P(size ,XI ,large) ", "acronyms": [[108, 110], [89, 94], [81, 86], [136, 140], [112, 115], [152, 154], [164, 166], [104, 106]], "long-forms": []}, {"text": "Yoram Bachrach is a researcher in the Online Services and Advertising group at Microsoft Research Cambridge UK. His research area is artificial intelligence (AI), focusing on multi-agent systems and computational game theory.", "acronyms": [[158, 160], [108, 110]], "long-forms": [[133, 156]]}, {"text": "In E.M. Voorhees and  D.K. Harman, editors, The 3d Text RE-  trieval Conference (TREC-3). ", "acronyms": [[81, 87], [3, 6], [22, 25]], "long-forms": [[48, 79]]}, {"text": "ALCOGRAM. ? P2E5N5S1, C T W D A I Common Logic Controlled English (CLCE) (Sowa 2004) is a language that can be translated into first-order logic with equality in the form of the Conceptual Graph", "acronyms": [[67, 71], [0, 8], [12, 20], [74, 78]], "long-forms": [[34, 65]]}, {"text": "ror rate (WWER), which gives a weight on errors from the viewpoint of IR, instead of word error rate (WER), which treats all words uniformly.", "acronyms": [[102, 105], [10, 14], [70, 72]], "long-forms": [[85, 100]]}, {"text": "but more often there is only one.  FN=false negative, etc.). I also consider micro- and", "acronyms": [[35, 37]], "long-forms": [[38, 52]]}, {"text": "formation of globally dispersed virtual communities, one of which is the very active and growing movement of Open Source Software (OSS) development.", "acronyms": [[131, 134]], "long-forms": [[109, 129]]}, {"text": "translation with overall understanding?.  Rhetorical structure theory (RST) (Mann and  Thompson, 1988) provides us with a good per-", "acronyms": [[71, 74]], "long-forms": [[42, 69]]}, {"text": "Instead of simple web page counts and complex  web page collection, we propose a novel model,  a Web Search with Double Checking (WSDC), to  analyze snippets.", "acronyms": [[130, 134]], "long-forms": [[97, 128]]}, {"text": "In Proc. of the 38th Annual Meeting of the Association for Computational Linguistics (ACL), pages 440?447, Hong Kong, October.", "acronyms": [[86, 89]], "long-forms": [[43, 84]]}, {"text": " tage of the OpenCCG realizer?s ability to generate from disjunctive logical forms (DLFs), i.e. packed semantic dependency graphs (White, 2004; White,", "acronyms": [[84, 88], [13, 20]], "long-forms": [[57, 82]]}, {"text": "This article describes the collaborative work on applying  the newly proposed ISO standard for dialogue act  annotation to the Switchboard Dialogue Act (SWBD-DA)  Corpus, as part of our on-going effort to promote ", "acronyms": [[153, 160], [78, 81]], "long-forms": [[127, 151]]}, {"text": " Classifier models. We used a first-order linear chain conditional random fields (CRF) model as a sequence labeler and a Maximum Entropy (Maxent) classifier model as a", "acronyms": [[82, 85], [138, 144]], "long-forms": [[55, 80], [121, 136]]}, {"text": " ? Reverse Gap (RG), if (i2 + 1) < i3 for OL and if (i6 + 1) < i1 for OR. (", "acronyms": [[16, 18]], "long-forms": [[3, 14]]}, {"text": "sible transliteration candidates. We measured performance using the Mean Reciprocal Rank (MRR) measure.", "acronyms": [[90, 93]], "long-forms": [[68, 88]]}, {"text": "the global normalization of random field models,  and avoid the label bias problem that exists in  maximum entropy Markov models (MEMMs). ", "acronyms": [[130, 135]], "long-forms": [[99, 128]]}, {"text": "the problem as a multi-label classification task,  we trained a binary classification model for each  code using support vector machine (SVM) with  ten-fold cross-validation.", "acronyms": [[137, 140]], "long-forms": [[113, 135]]}, {"text": "When the morphophonology returns multiple parse candidates, the system employs an N -gram language model (LM) 21", "acronyms": [[106, 108], [82, 89]], "long-forms": [[90, 104]]}, {"text": "entry description to a lexeme. A part-of-speech of the lexeme is set to a common noun (NN ) where the minimum word probability of NN is assigned", "acronyms": [[87, 89], [130, 132]], "long-forms": [[81, 85]]}, {"text": " 1 Introduction Noun phrase (NP) coreference resolution, the task of determining which NPs in a text or dialogue re-", "acronyms": [[29, 31], [87, 90]], "long-forms": [[16, 27]]}, {"text": "knowledge powered model to several baselines.  Random Guess Model (RG). Random guess is", "acronyms": [[67, 69]], "long-forms": [[47, 59]]}, {"text": "annotation ? the Penn Chinese Treebank (CTB)(Xia et al, 2000), and the People?s Daily News (PDN) corpus from Beijing University.", "acronyms": [[92, 95], [40, 43]], "long-forms": [[71, 90], [22, 38]]}, {"text": "The general architecture of D2S is represented in Figure 1. It consists of two modules, the Language Gen-  eration Module (LGM), and the Speech Generation Module (SGM). The LGM takes data as input .and ", "acronyms": [[163, 166], [28, 31], [123, 126], [173, 176]], "long-forms": [[137, 161], [92, 121]]}, {"text": "Winnow and voted-perceptrons (Zhang et al2002;  Collins, 2002), or by using the sequence labeling  models, such as Hidden Markov Models (HMMs)  (Molina and Pla, 2002) and Conditional Random ", "acronyms": [[137, 141]], "long-forms": [[115, 135]]}, {"text": "Other functions such as textual element (ET), sentence adjunct (AO), negation (NEG), vocative (VOC) and verb modifiers (MOD) were tagged, but did not receive", "acronyms": [[79, 82], [95, 98], [41, 43], [64, 66], [120, 123]], "long-forms": [[69, 77], [85, 93], [32, 39], [109, 117], [46, 62]]}, {"text": "HLT/EMNLP, 2005  http://www.nist.gov/speech/tests/ace/ace07/doc, The  ACE 2007 (ACE07) Evaluation Plan, Evaluation of  the Detection and Recognition of ACE Entities, Val-", "acronyms": [[80, 85], [0, 9], [152, 155]], "long-forms": [[70, 78]]}, {"text": "Budanitsky and Hirst Lexical Semantic Relatedness Figure 5 Precision (PD), recall (RD), and F-measure (FD) for malapropism detection by measure and scope. ", "acronyms": [[70, 72], [83, 85], [103, 105]], "long-forms": [[59, 68], [75, 81], [92, 101]]}, {"text": "5 5 of such properties is acyclicity, as in Hidden Markov Models (HMMs). For", "acronyms": [[66, 70]], "long-forms": [[44, 64]]}, {"text": "speech recognition (ASR), dialog management (DM), database access (DB Access), data storage (DB) and oral response generation (RG). In ad-", "acronyms": [[127, 129], [20, 23], [45, 47], [67, 76], [93, 95]], "long-forms": [[106, 125], [0, 18], [26, 43], [50, 65], [79, 91]]}, {"text": " 3.3.1 Determinantal Point Processes Determinantal point processes (DPPs) are distributions over subsets that jointly prefer quality of", "acronyms": [[68, 72]], "long-forms": [[37, 66]]}, {"text": "4 Crowd-sourcing Multiple-choice Questions from Tables We use Amazon?s Mechanical Turk (MTurk) service to generate MCQs by imposing constraints", "acronyms": [[88, 93], [115, 119]], "long-forms": [[71, 86]]}, {"text": "for Statistical Machine Translation Shixiang Lu, Zhenbiao Chen, Bo Xu Interactive Digital Media Technology Research Center (IDMTech) Institute of Automation, Chinese Academy of Sciences, Beijing, China", "acronyms": [[124, 131]], "long-forms": [[70, 115]]}, {"text": "Web Search 1 Figure 1: Architecture of the Multi-task Deep Neural Network (DNN) for Representation Learning: The lower layers are shared across all tasks, while top layers are task-specific.", "acronyms": [[75, 78]], "long-forms": [[54, 73]]}, {"text": "  1. RecallCorrectTransliteration  (RTrans)  The recall is going to be computed using the ", "acronyms": [[36, 42]], "long-forms": [[5, 33]]}, {"text": "1203 Figure 1: Bootstrapped Learning. ( HT = hashtag; HP = hashtag pattern) dov et al.,", "acronyms": [[54, 56], [40, 42]], "long-forms": [[59, 74], [45, 52]]}, {"text": "cognition(COG) competition(COMP)  contact(CeNT) motion(MOT)  emoeion(ENO) perception(PER)  possession(POSS) stat ive(STA) ", "acronyms": [[85, 88], [10, 13], [27, 31], [42, 46], [55, 58], [69, 72], [102, 106], [117, 120]], "long-forms": [[74, 84], [0, 9], [15, 26], [34, 41], [48, 54], [61, 68], [91, 101], [108, 116]]}, {"text": " The two-level analysis of the cited forms ap-  pears below ST = sm'face tape, PT -- pattern  tape, 115.\\[' -- root tape, VT : vocal{sin tat)e , and ", "acronyms": [[60, 62]], "long-forms": [[65, 77]]}, {"text": "0.467 (+126%)?  Total Document Reciprocal Rank (TDRR) PubMed 0.495 0.137 0.038 0.331", "acronyms": [[48, 52]], "long-forms": [[16, 46]]}, {"text": "SUBS = substantif  compl~ment  VT  = verbe conjugu6  PROC = pronom compl~ment  SUSU = substantif  sujet ", "acronyms": [[53, 57], [0, 4], [31, 33], [79, 83]], "long-forms": [[60, 72], [7, 17], [37, 42], [86, 103]]}, {"text": "3 Framework We model the information extraction task as a markov decision process (MDP), where the model learns to utilize external sources to improve upon", "acronyms": [[83, 86]], "long-forms": [[58, 81]]}, {"text": "The model is presented below. 4 The Model This study employs feed-forward artificial neu-ral networks with a backpropagation algorithm as computational models for the analysis of un-accusative/unergative distinction in Turkish. 4.1 Artificial Neural Networks and Learn-ing Paradigms  An artificial neural network (ANN) is a compu-tational model that can be used as a non-linear statistical data modeling tool. ANNs are gener-ally used for deriving a function from observa-tions, in applications where the data are com-plex and it is difficult to devise a relationship ", "acronyms": [[314, 317]], "long-forms": [[287, 312]]}, {"text": " 1 Introduction  Statistical Machine Translation(SMT) is currently the state of the art solution to the machine ", "acronyms": [[49, 52]], "long-forms": [[17, 47]]}, {"text": "5 System Description The PEZ system consists of three components, viz (i) a Web Translation Memory (WebTM) crawler, (ii) the XLING reranker and (iii) a longest", "acronyms": [[100, 105], [25, 28], [125, 130]], "long-forms": [[76, 98]]}, {"text": "domains: ? Artificial Intelligence (AI) domain: 4,119 papers extracted from the IJCAI proceedings", "acronyms": [[36, 38], [80, 85]], "long-forms": [[11, 34]]}, {"text": "ity. In Proceedings of Treebanks and Linguistic Theories (TLT) 2003, V\u007faxj\u007fo, Sweden. ", "acronyms": [[58, 61], [71, 74]], "long-forms": [[23, 56]]}, {"text": "mvzaanen@uvt.nl Gerhard van Huyssteen Centre for Text Technology (CTexT) North-West University", "acronyms": [[66, 71]], "long-forms": [[38, 64]]}, {"text": " Most commonly, recurrent neural networks are trained with stochastic gradient descent (SGD), where the gradient of the training criterion is com-", "acronyms": [[88, 91]], "long-forms": [[59, 86]]}, {"text": "of the Annual Meeting of the ACL and the International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP). ", "acronyms": [[117, 120], [29, 32], [110, 115]], "long-forms": [[120, 121]]}, {"text": "mance.  We investigated chopping criteria based on a fixed number of words (FIXED), at  speaker changes (TURN), at pauses (PAUSE), and, for reference, at actual sentence ", "acronyms": [[76, 81], [105, 109], [123, 128]], "long-forms": [[53, 74], [115, 121]]}, {"text": "ability integral transform to generate empirical cumulative density functions (ECDF): now instead of the probability density function (PDF) space, we are working in the ECDF space where the value of each", "acronyms": [[135, 138], [79, 83], [169, 173]], "long-forms": [[105, 133], [39, 77]]}, {"text": "to prevent this class of mistakes. To put it another way, we hoped to exploit the correlation between named-entities and noun phrase (NP) boundaries. A", "acronyms": [[134, 136]], "long-forms": [[121, 132]]}, {"text": "Because LSA is closely related to principle component analysis (PCA), extensions of PCA such as canonical correlation analysis (CCA) and oriented principle component analysis (OPCA) can leverage", "acronyms": [[128, 131], [8, 11], [64, 67], [84, 87], [176, 180]], "long-forms": [[96, 126], [34, 62], [137, 174]]}, {"text": "37  Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, page 97, Gothenburg, Sweden, April 27, 2014.", "acronyms": [[73, 78]], "long-forms": [[39, 71]]}, {"text": "tried two types of expansion, one mainly using synonyms (SYN), and one mainly using hypernyms or related links (LNK). ", "acronyms": [[112, 115], [57, 60]], "long-forms": [[105, 110], [47, 55]]}, {"text": " 658     We investigate the effect of thyroid transcription factor 1 (TTF-1) ...x: a", "acronyms": [[70, 75]], "long-forms": [[46, 68]]}, {"text": "Lioma C. and Ounis I., A Syntactically-Based Query  Reformulation Technique for Information Retrieval,  Information Processing and Management (IPM), Elsevier Science, 2007 ", "acronyms": [[143, 146]], "long-forms": [[104, 141]]}, {"text": "number of correct matched constituents in proposed parse  number of constituents in treebank parse  3) Crossing Brackets(CBs) ffinumber of constituents which violate constituent boundaries with a  constituent inthe treebank parse.", "acronyms": [[121, 124]], "long-forms": [[103, 120]]}, {"text": "son, 2012; Vlas and Robinson, 2011). Due to its expressiveness, natural language (NL) became a popular medium of communication between users and", "acronyms": [[82, 84]], "long-forms": [[64, 80]]}, {"text": " Using a statistical model called prediction by partial matching (PPM), Teahan et al (2000) reported a significantly better result.", "acronyms": [[66, 69]], "long-forms": [[34, 64]]}, {"text": "al., 2005) filters and summarizes the OmniPage output into Intermediate XML (IXML), as well as correcting certain characteristic errors from that stage.", "acronyms": [[77, 81]], "long-forms": [[59, 75]]}, {"text": "Since all covariance matrices are positive semi-definite, the quadratic program (QP) remains convex in w?, ", "acronyms": [[81, 83]], "long-forms": [[62, 79]]}, {"text": "Orlando, Florida 32810  AFIPS CONSTITUENT SOCIETIES  Instrument Society of America (ISA)  Purpose ", "acronyms": [[84, 87], [24, 29]], "long-forms": [[53, 82]]}, {"text": "These are selected from the LDC English Gigaword corpus. AFP = Agence France-Presse; AFW = Associated Press Worldstream; NYT = New York Times; XIN = Xinhua News Agency; and CNA = Central News Agency of Taiwan denote the sections of the LDC English Gigaword", "acronyms": [[121, 124], [143, 146], [28, 31], [57, 60], [85, 88], [173, 176], [236, 239]], "long-forms": [[127, 141], [149, 160], [63, 83], [91, 119], [179, 198]]}, {"text": "overall scores considering all metrics. To these systems we added minimum Bayes risk (MBR) decoding (Kumar and Byrne, 2004).", "acronyms": [[86, 89]], "long-forms": [[66, 84]]}, {"text": "Table 1: Probabilities computed for each type of linguistic information. Error codes correspond to the five error types in the CoNLL 2013 shared task: ArtOrDet (article or determiner), Nn (noun number), Prep (prepositions), SVA (subject-verb agreement) and Vform (verb form).", "acronyms": [[151, 159], [224, 227], [127, 132], [185, 187]], "long-forms": [[161, 182], [229, 251], [189, 200]]}, {"text": "served as the founding Editor-in-Chief of ACM  Transactions on Knowledge Discovery from Data (TKDD). He has received ACM SIGKDD In-", "acronyms": [[94, 98], [42, 45], [117, 120], [121, 127]], "long-forms": [[47, 92]]}, {"text": "ture subset selection [2][4][8]. Yang and Pederson  found information gain (IG) and chi-square test (CHI)  most effective in aggressive term removal without los-", "acronyms": [[76, 78], [101, 104]], "long-forms": [[58, 74], [84, 99]]}, {"text": "1 Introduction Annotated corpora are essential for most research in natural language processing (NLP). For exam-", "acronyms": [[97, 100]], "long-forms": [[68, 95]]}, {"text": "linguistic resources  ? Semantic Analysis Module (SAM) interpreting  LPM output using application knowledge ", "acronyms": [[50, 53], [69, 72]], "long-forms": [[24, 48]]}, {"text": "rank verb pairs with respect to the strength of their association with a particular discourse relation. We adapted versions of standard lexical association measures like PMI (pointwise mutual information) and their variants, as well as some measures specific to the association of a causal relation between items (Do", "acronyms": [[170, 173]], "long-forms": [[175, 203]]}, {"text": "while the NB+E extractor has the worst. Training the CRF with negative examples (CRF+E) gave better precision in extracted information then train-", "acronyms": [[81, 86], [10, 14]], "long-forms": [[53, 79]]}, {"text": " The test set (Table 13) consisted of the beginnings of three short stories by  Ernest  Hemingway,  15 three articles f rom the New York Times (NYT), 16 the first three chapters of  a novel  by  Uwe JohnsonS the first two chapters of a short story by Heiner Mfiller, TM ", "acronyms": [[144, 147], [267, 269]], "long-forms": [[128, 142]]}, {"text": "787 After labeling the reference BINet, we train a learning to rank (L2R) model2 using the following features for scoring nodes in the target BINet", "acronyms": [[69, 72]], "long-forms": [[51, 67]]}, {"text": "translation from one source language to multiple target languages, inspired by the recently proposed neural machine translation(NMT) framework proposed by Bahdanau et al (2014).", "acronyms": [[128, 131]], "long-forms": [[101, 126]]}, {"text": " The motivation for that work is twofold: on the one hand it builds on the strength of the first sense heuristic in Word Sense Disambiguation (WSD) (i.e. the heuristic of choosing themost commonly used sense of a word, irrespective of the context in which", "acronyms": [[143, 146]], "long-forms": [[116, 141]]}, {"text": "rameter set to decode WSMT 2006 Europal test set (TEST1) and used the second on WSMT news commentary test set 2007 (TEST2)6. Table 6 shows the", "acronyms": [[116, 121], [80, 84], [22, 26], [50, 55]], "long-forms": [[101, 114], [40, 48]]}, {"text": " 1997) has led us to employ, among other param-  eters, mutual information (MI) bits of individ-  ual characters derived from large hierarchically ", "acronyms": [[76, 78]], "long-forms": [[56, 74]]}, {"text": "the earliest in the passage is returned. We used the selective gain computation (SGC) algorithm (Zhou et al, 2003) to select features and estimate", "acronyms": [[81, 84]], "long-forms": [[53, 79]]}, {"text": "projected expectations from English. To this end, we adopt the Generalized Expectation (GE) Criteria framework introduced by Mann and McCallum", "acronyms": [[88, 90]], "long-forms": [[63, 86]]}, {"text": "de Marneffe, Manning, and Potts The Pragmatic Complexity of Veridicality Assessment under an attitude predicate (say), the events in Examples (6a) and (6b) are assessed as certain (CT+), whereas the words highly confident in Example (6c) trigger PR+, and may in Example (6d) leads to PS+.", "acronyms": [[181, 184], [246, 249], [284, 287]], "long-forms": [[172, 179]]}, {"text": "we have established direct contact with the south korean delegation through tribal elders .  Figure 2: Random sample of 5 items from study in Section 4: original Google translation (GT), results of targeted paraphrasing translation process (TP), and a human reference translation.", "acronyms": [[182, 184], [241, 243]], "long-forms": [[162, 180], [220, 239]]}, {"text": "The SemEval?2007 task for extracting frame semantic structures relies on the human annotated data available in the FrameNet (FN) database. The", "acronyms": [[125, 127], [4, 11]], "long-forms": [[115, 123]]}, {"text": "ptishes a rather inconsequential change with respect o a  previously non-existent link or with respect to a link  No impairment (NI) Q Confusion (C)  Q Mislearning (ML) Q Insufficient Learning (IL) ", "acronyms": [[129, 131], [165, 167], [194, 196]], "long-forms": [[114, 127], [152, 163], [171, 192], [135, 144]]}, {"text": "Figure 1: The system combination architecture.  system prior weights and a language model (LM). ", "acronyms": [[91, 93]], "long-forms": [[75, 89]]}, {"text": "Computational Linguistics Volume 40, Number 1 of the 22nd International Conference on Computational Linguistics (COLING?08), pages 71?84, Manchester.", "acronyms": [[113, 122]], "long-forms": [[86, 111]]}, {"text": "For WSD evaluation, three measures are used: (1) Jaccard Index (JI), which measures the degree of overlap between the induced senses and the gold", "acronyms": [[64, 66], [4, 7]], "long-forms": [[49, 62]]}, {"text": " 1 Introduction In this paper, we propose TroFi (Trope Finder), a nearly unsupervised clustering method for sep-", "acronyms": [[42, 47]], "long-forms": [[49, 61]]}, {"text": "topics vary over time, we aggregate the microblog posts published in a month as a document. Then, we use a Latent Dirichlet Allocation (LDA) to estimate their topics. Figure 1 illustrates an example, where", "acronyms": [[136, 139]], "long-forms": [[107, 134]]}, {"text": "  We extracted bag-of-word features and trained a  Support Vector Machine (SVM) classifier (Burges, 1998) using the above dataset.", "acronyms": [[75, 78]], "long-forms": [[51, 73]]}, {"text": "special case describing whether/t /  is glottalized. A context other than preceding phoneme and following  phoneme is incorporated; the first split (nodes 0 and 10) in this tree is on syllable boundary (SYLL-BDRY),  indicating that when / t /  is glottalized it is generally in syllable-final position.", "acronyms": [[203, 212]], "long-forms": [[184, 201]]}, {"text": "pense of introducing noise.  We propose Embedded base phrase(EBP) detection as algorithm.2.", "acronyms": [[61, 64]], "long-forms": [[40, 60]]}, {"text": "tion of precise probability scores for partial hypotheses contain-  ing islands, in the context of  a Stochastic-Context-Free-Grammar  (SCFG) for Language Modeling (LM). The second issue is the ", "acronyms": [[165, 167], [136, 140]], "long-forms": [[146, 163], [102, 133]]}, {"text": "From our point of view, it  is very interesting to compare the results of Czech  stochastic POS (SPOS) tagger and a modified RB-  POS tagger for Czech.", "acronyms": [[97, 101]], "long-forms": [[81, 95]]}, {"text": "tor machines: learning with many relevant features. In European Conference on Machine Learning (ECML). ", "acronyms": [[96, 100]], "long-forms": [[55, 94]]}, {"text": "4 Supervised Named Entity Recognition In the first part of this work, we adopt a supervised named entity recognition (NER) framework for the attribute extraction problem from eBay listing titles.", "acronyms": [[118, 121]], "long-forms": [[92, 116]]}, {"text": "ILP.  An integer linear program(ILP) is basically the same as a linear program.", "acronyms": [[32, 35], [0, 3]], "long-forms": [[9, 30]]}, {"text": "measured on separate grammatical and ungrammatical data: Gr = Grammatical, AG = Agreement, RW = Real-Word, EW = Extra Word, MW = Missing Word", "acronyms": [[107, 109], [57, 59], [75, 77], [91, 93], [124, 126]], "long-forms": [[112, 122], [62, 73], [80, 89], [96, 105], [129, 141]]}, {"text": "The label restricted means the model is restricted to recovering rules that have been seen in training data. LR = labeled recall. LP = labeled", "acronyms": [[109, 111], [130, 132]], "long-forms": [[114, 128], [135, 142]]}, {"text": "Baselines are a unigram query likelihood (QL) model (bag of words) and a highly effective sequential dependence (SD) variant of the Markov random field (MRF) model (Metzler and Croft,", "acronyms": [[113, 115], [42, 45], [153, 156]], "long-forms": [[90, 111], [132, 151]]}, {"text": "ing decisions in multi-party discussions.  Several types of dialogue act (DA) are distinguished on the basis of their roles in", "acronyms": [[74, 76]], "long-forms": [[60, 72]]}, {"text": "This paper is an at tempt  to provide part  of the basis for a general theory of robust  process ing in Machine Trans lat ion  (MT) wi th  relevance to other areas of Natural  Language ", "acronyms": [[128, 130]], "long-forms": [[104, 125]]}, {"text": "Abstract In this paper, we propose a new syntaxbased machine translation (MT) approach based on reducing the MT task to a tree-", "acronyms": [[74, 76], [109, 111]], "long-forms": [[53, 72]]}, {"text": "In this paper, we address the problem of parsing transcribed spoken Levantine Arabic (LA).We do not assume the existence of any anno-", "acronyms": [[86, 88]], "long-forms": [[68, 84]]}, {"text": "O N S  *****  SCAN CALLED AT 1 I  ANTEST CALL'EC FOR 'I \"REDVO U (AACC) ,SD= 2 .  RES= 6.", "acronyms": [[49, 52], [66, 70], [73, 75], [82, 85]], "long-forms": [[34, 48]]}, {"text": "3 Experimental Results and Discussion We conducted closed track experiments on the Hong Kong City University (CityU) corpus in The Second International Chinese Word Segmen-", "acronyms": [[110, 115]], "long-forms": [[93, 108]]}, {"text": "nications Advancement Foundation, Japan, in part by the Center for Intelligent Information Retrieval, and in part by the Defense Advanced Research Projects Agency (DARPA), USA under contract number HR0011-06-C-0023.", "acronyms": [[164, 169], [172, 175]], "long-forms": [[121, 162]]}, {"text": "2 Description of the France Telecom 3000 Voice Agency corpus The France Telecom 3000 (FT3000) Voice Agency service, the first deployed vocal service at France", "acronyms": [[86, 92]], "long-forms": [[65, 84]]}, {"text": "few open source programs. Since we are interested in a fully supervised WSD tool, IMS (It Makes Sense) (Zhong and Ng, 2010) is selected in our", "acronyms": [[82, 85], [72, 75]], "long-forms": [[87, 95]]}, {"text": " For comparison we re-implemented the probabilistic Visual Objects Algorithm (VOA) of Mitchell et al(2013).", "acronyms": [[78, 81]], "long-forms": [[52, 76]]}, {"text": "(LDA), Maximum Likelihood Linear Transform (MLLT), Boosted Maximum Mutual Information (BMMI), Minimum Phone Error (MPE). It pro-", "acronyms": [[115, 118], [44, 48], [87, 91]], "long-forms": [[94, 113], [7, 42], [51, 85]]}, {"text": "Japanese  (Jap). Germanic (Get), and Southern Romance (SRom). Only the ", "acronyms": [[55, 59], [11, 14], [27, 30]], "long-forms": [[37, 53], [0, 8], [17, 25]]}, {"text": " In table 1, we present the accuracy of the model trained on the output of the joint inference (JOINT) against that of the self-training baseline (SELF).", "acronyms": [[96, 101], [147, 151]], "long-forms": [[79, 84], [123, 136]]}, {"text": "(ST), i.e. any node of a tree along with all its descendants. A subset tree (SST) exploited by the SubSetTreeKernel is a more", "acronyms": [[77, 80], [1, 3]], "long-forms": [[64, 75], [99, 109]]}, {"text": "In: Ernst Buch-berger (ed.): Tagungsband der 7. Konferenz zur Verarbeitung nat?rlicher Sprache (KONVENS), Universit?t Wien, 161?168. Strube, Gerhard (1984).", "acronyms": [[96, 103]], "long-forms": [[48, 94]]}, {"text": "23-28, 1992   Proceedings of NAACL-HLT 2015 Student Research Workshop (SRW), pages 110?117, Denver, Colorado, June 1, 2015.", "acronyms": [[71, 74], [29, 38]], "long-forms": [[44, 69]]}, {"text": "? and possibly split up ? into True Positive (TP) and False Positive (FP) entities.", "acronyms": [[46, 48], [70, 72]], "long-forms": [[31, 44], [54, 68]]}, {"text": "each other.  Normalized common neighbors (NCN). Nor-", "acronyms": [[42, 45]], "long-forms": [[13, 40]]}, {"text": "AB to letter l ji ? A where A is a regular letter alphabet and AB=A?{B} includes B as an abstract morpheme start symbol", "acronyms": [[63, 65]], "long-forms": [[66, 70]]}, {"text": "Abstract  Since statistical machine translation (SMT)  and translation memory (TM) complement  each other in matched and unmatched regions, ", "acronyms": [[79, 81], [49, 52]], "long-forms": [[59, 77], [16, 47]]}, {"text": "Two criteria are used:  1. Overlapping Ambiguity Strings (OAS): the  reference segmentation and the segmenter ", "acronyms": [[58, 61]], "long-forms": [[27, 56]]}, {"text": " 1 Introduction The task of Semantic Role Labeling (SRL) is to identify predicate-argument relationships in natural", "acronyms": [[52, 55]], "long-forms": [[28, 50]]}, {"text": "HN=highly negative terms, N=negative, P=positive, HP=highly positive, INV=invertors, DIM=diminishers, INV=invertors. ", "acronyms": [[85, 88], [0, 2], [50, 52], [70, 73], [102, 105]], "long-forms": [[89, 100], [3, 18], [28, 36], [40, 48], [53, 68], [74, 83], [106, 115]]}, {"text": "User Group (WON).4 Research and development  is carried out in close collaboration with user  groups and intellectual property (IP) professionals to ensure solutions and software are delivered ", "acronyms": [[128, 130], [12, 15]], "long-forms": [[105, 126]]}, {"text": "email: allan.ramsay@manchester.ac.uk Debora Field University of Sheffield (UK) email: D.Field@sheffield.ac.uk", "acronyms": [[75, 77]], "long-forms": [[50, 73]]}, {"text": "However, one interesting result came from extending the feature space with topics derived from Latent Dirichlet Allocation (LDA) using similar methods to Ramage et al (2009).", "acronyms": [[124, 127]], "long-forms": [[95, 122]]}, {"text": "approaches. In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 419?424. ", "acronyms": [[82, 86]], "long-forms": [[57, 80]]}, {"text": "10?16). Results for per-predication (PR) and per-whole-graph (GRPH) tagging percentage accuracies are listed. (", "acronyms": [[62, 66], [37, 39]], "long-forms": [[55, 60], [24, 35]]}, {"text": " The third thread is the sponsorship of the international  Message Understanding Conferences (MUC's) and Text  Retrieval Conferences (TREC's).", "acronyms": [[94, 99], [134, 140]], "long-forms": [[59, 92], [105, 132]]}, {"text": "Knowing the precise identity of Fisher vector ??(?), we propose a natural measure which we call  Weighted Gradient Uncertainty (WGU) based on the facts explained in the previous paragraph:  ????(???)", "acronyms": [[128, 131]], "long-forms": [[97, 126]]}, {"text": "based chunking; 3. MEMM-based word segmenter with Support Vector Machines (SVM)-based chunking.", "acronyms": [[75, 78], [19, 23]], "long-forms": [[50, 73]]}, {"text": " Performance has been measured with both the question followed by an extension (Q+E), as well as the question followed by the target and then", "acronyms": [[80, 83]], "long-forms": [[45, 78]]}, {"text": "8. THE SAIL INTERFACING SYSTEM  The SAIL Interfacing System (S.I.S.) is the f ramework   where a user  can interact with SAIL in developing NL ", "acronyms": [[61, 67], [140, 142], [121, 125]], "long-forms": [[36, 59]]}, {"text": "given the precorrected sentence. Each Noun Phrase (NP) in  the test sentence will be pre-corrected as correc-", "acronyms": [[51, 53]], "long-forms": [[38, 49]]}, {"text": "For instance, a problem-tagged entity is represented as a first word tagged B-P (begin problem) and other 59", "acronyms": [[76, 79]], "long-forms": [[81, 94]]}, {"text": "Our model can now be represented like this:  241  Database (DB)  Facts about hotels ", "acronyms": [[60, 62]], "long-forms": [[50, 58]]}, {"text": "In Proceedings of the International Conference on Data Engineering (ICDE). ", "acronyms": [[68, 72]], "long-forms": [[22, 66]]}, {"text": "2.2 Keystroke Ratio (KSR) In addition to these metrics, suffix prediction can be evaluated by the widely used keystroke ratio (KSR) metric (Och et al, 2003).", "acronyms": [[127, 130], [21, 24]], "long-forms": [[110, 125], [4, 19]]}, {"text": "54  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 325?335, October 25-29, 2014, Doha, Qatar.", "acronyms": [[92, 97]], "long-forms": [[42, 90]]}, {"text": "heres to the dimensions presented in Table 2, and negation scopes are modeled using a first order linear-chain conditional random field (CRF)2, with a label set of size two indicating whether a", "acronyms": [[137, 140]], "long-forms": [[111, 135]]}, {"text": " 1 Introduction Relation extraction (RE) is the task of determining the existence and type of relation between two tex-", "acronyms": [[37, 39]], "long-forms": [[16, 35]]}, {"text": "The  suggestions made here for the organization of space are only a working  set for which l i t t le  justification can be offered: location (LOC)--a  neutral statement of position, contact--in physical contact, and -* near ", "acronyms": [[143, 146]], "long-forms": [[133, 141]]}, {"text": "structure by first computing the similarity of each proposition to the others using a Latent Dirichlet Allocation (LDA) model. LDA is a genera-", "acronyms": [[115, 118], [127, 130]], "long-forms": [[86, 113]]}, {"text": " 2 Extended typed  A-ca lcu lus   CU(\\] (Categorial U,,ificAtion (l:ra,nma,r) \\[8\\] is a,d-  vantageous, compared to other phrase structure ", "acronyms": [[34, 36]], "long-forms": [[41, 64]]}, {"text": "cos(d, c).  Candidate Rank (CR) The features described so far disambiguate every surface form s ?", "acronyms": [[28, 30]], "long-forms": [[12, 26]]}, {"text": "Non-MonoClausal Verbs (NMCV), Passives  (Pass) and Auxiliary Construction (AC) that  are identified as compound verbs (CompVs). ", "acronyms": [[119, 125], [23, 27], [41, 45], [75, 77]], "long-forms": [[103, 117], [0, 21], [30, 38], [51, 73]]}, {"text": "as a statistical model of natural anguage, t and weak-  eus Jelinek et al's contention that \"in an ambiguous  but appropriately chosen probabilistic CFG (PCFG),  correct parses are Ifigh probability parses\" (p. 2).", "acronyms": [[154, 158]], "long-forms": [[135, 152]]}, {"text": "Patrizia Paggio University of Copenhagen Centre for Language Technology (CST) Njalsgade 140, 2300-DK Copenhagen", "acronyms": [[73, 76], [93, 100]], "long-forms": [[41, 71]]}, {"text": "machine learning algorithms from the Python scikit-learn4 package: Na??ve Bayes (NB), Maximum Entropy (MaxEnt), and Support Vector Machines (SVM).", "acronyms": [[103, 109], [81, 83], [141, 144]], "long-forms": [[86, 101], [67, 79], [116, 139]]}, {"text": "figure 1. To avoid confusion, we refer to this basic  unit throughout as a Temporal Unit (TU). ", "acronyms": [[90, 92]], "long-forms": [[75, 88]]}, {"text": "course Connectives. Proceedings of the Fourth Workshop on Treebanks and Linguistic Theories (TLT). ", "acronyms": [[93, 96]], "long-forms": [[58, 91]]}, {"text": "and (?) denote Run1, Run2, and Run3, respectively, our submissions to the shared task; FL=Flagging, FS=Feature stacking, DS=Domain stacking.", "acronyms": [[87, 89], [100, 102], [121, 123]], "long-forms": [[90, 98], [103, 119], [124, 139]]}, {"text": "1 Introduction Creating the annotated corpus needed for training a NER (named entity recognition) model is costly. ", "acronyms": [[67, 70]], "long-forms": [[72, 96]]}, {"text": "where cLen is the length of a pattern; cMatch is  the number of matched tags; cPtn is the number of  protein name tag (PTN) skipped by the alignment  in the sentence;  cVb is the number of skipped ", "acronyms": [[119, 122], [168, 171], [78, 82], [6, 10], [39, 45]], "long-forms": [[101, 113], [18, 24], [64, 71]]}, {"text": "DC-10-30?s number 1 engine, a General Electric CF6-50C2, experienced a casing breach when the 2nd-stage low pressure turbine (LPT) anti-rotation nozzle locks failed.?", "acronyms": [[126, 129], [47, 55], [0, 8]], "long-forms": [[104, 124]]}, {"text": " 2.3 Graphical User Interface The graphical user interface (GUI) is an important feature that has been recently added to Clairlib", "acronyms": [[60, 63]], "long-forms": [[34, 58]]}, {"text": "Pierre PN Note that a preposition (PR) with lemma de and a determiner (DT) with lemma le and the same gender and number as the common noun have been", "acronyms": [[71, 73], [7, 9], [35, 37]], "long-forms": [[59, 69], [22, 33]]}, {"text": "    The difference between the two models was the design of the input layer. The first model (henceforth, the diagnostics model DIAG) took diagnostics as input nodes, whereas the second model (henceforth, the semantic parameters model SEMANP) took semantic parameters as input nodes, as presented in detail below.    The Diagnostics Model (DIAG): Binary ac-ceptability values of the phrases or sentences formed by the syntactic diagnostics constituted the input nodes for the network (see above for the SI diagnostics). Each syntactic diagnostic provided a binary value (either 0 or 1) to one of the input nodes.", "acronyms": [[340, 344], [128, 132], [235, 241]], "long-forms": [[321, 338], [110, 120], [209, 234]]}, {"text": "We first describe how to generate multiple FDTs for each sentence pair in training corpus C based on the forced decoding (FD) technique, which performs via the following four steps:", "acronyms": [[122, 124], [43, 47]], "long-forms": [[105, 120], [83, 89]]}, {"text": "The tag B-X (Begin) represents the first word of a named entity of type X, for example, PER (Person) or LOC (Location). The tag I-X (In-", "acronyms": [[88, 91], [104, 107]], "long-forms": [[93, 99], [109, 117]]}, {"text": "Jiang, Hua. Xu} @uth.tmc.edu tangbuzhou@gmail.com yukun.chen@Vanderbilt. Edu      Abstract This work describes the participation of the University of Texas Health Science Center at Houston (UTHealth) team on the SemEval 2014 ? Task 7 analysis of clinical text challenge.", "acronyms": [[190, 198]], "long-forms": [[136, 188]]}, {"text": "ear (lin) kernel, second degree polynomial kernel (d=2), and RBF kernel (rbf); SVM with transductive inference (TSVM) and linear (lin) kernel or second degree polynomial (d=2) ker-", "acronyms": [[112, 116]], "long-forms": [[88, 110]]}, {"text": "5, we discuss our approach to increase the coverage of the model by using synset ID?s from the English WordNet (EWN). Section 6 describes our", "acronyms": [[112, 115], [81, 85]], "long-forms": [[95, 110]]}, {"text": "without any adaptation.  Laplacian SVM (L-SVM) This is a semisupervised learning method based on label", "acronyms": [[40, 45]], "long-forms": [[25, 38]]}, {"text": " In Proceedings of the 24th International Conference on Computational Linguistics (COLING). ", "acronyms": [[83, 89]], "long-forms": [[56, 81]]}, {"text": "2http://www.statmt.org/wmt12/ by filling in lexical gaps in resource-poor languages with the aid of Machine Translation (MT). ", "acronyms": [[121, 123]], "long-forms": [[100, 119]]}, {"text": "studied three activation functions: 1. Rectified linear units (ReLUs) (Nair and Hinton, 2010):", "acronyms": [[63, 68]], "long-forms": [[39, 61]]}, {"text": "integrate Chinese word segmentation and NE  identification into a unified framework using a  class-based language model (LM).\u0016 &ODVV\u0010EDVHG\u0003/0 IRU\u00031(\u0003,GHQWLILFDWLRQ The n-gram LM is a stochastic model which ", "acronyms": [[121, 123], [40, 42], [175, 177]], "long-forms": [[105, 119]]}, {"text": "prim. = primary source; C06?C09 = CoNLL 2006?2009; I10 = ICON 2010; SM = shared modifier; CJ = conjunct; Nested CS = portion of CSs participating in nested CSs (both as the inner and outer CS); RT UAS = unlabeled attachment score of the roundtrip", "acronyms": [[68, 70], [90, 92], [112, 114], [128, 131], [156, 159], [189, 191], [194, 196], [197, 200]], "long-forms": [[73, 88], [95, 103]]}, {"text": "Section 7 concludes this article.  2 Automatic Speech Recognition (ASR)  Thai ASR research focused on two major topics.", "acronyms": [[67, 70], [78, 81]], "long-forms": [[37, 65]]}, {"text": "rithm to handle this setting. To do so, we use dynamic programming (DP) together with greedy search.", "acronyms": [[68, 70]], "long-forms": [[47, 66]]}, {"text": "1 In t roduct ion   For some NLP applications, it is important o  identify, \"named entities\" (NE), such as person  names, organization ames, time, date, or money ", "acronyms": [[94, 96]], "long-forms": [[77, 91]]}, {"text": "sible classes we show the accuracy of the correct hashtag being amongst the top 1,5 or 50 hashtags as well as the Mean Reciprocal Rank (MRR). The", "acronyms": [[136, 139]], "long-forms": [[114, 134]]}, {"text": "| lexica: The relative frequency of categories, based on the Linguistic Inquiry and Word Count (LIWC) dictionary (Pennebaker et al, 2007).", "acronyms": [[96, 100]], "long-forms": [[61, 94]]}, {"text": "Och and Ney (2003) show that for larger corpora, using word classes leads to lower Alignment Error Rate (AER). This is not", "acronyms": [[105, 108]], "long-forms": [[83, 103]]}, {"text": "until the current sentence (PENT) and the word entropy for the conversation subsequent to the current sentence (SENT). We hypothesize that informative", "acronyms": [[112, 116], [28, 32]], "long-forms": [[102, 110]]}, {"text": "A Robust Algorithm for the Tree Edit Distance.  Proceedings of the VLDB Endowment (PVLDB), 5(4):334?345.", "acronyms": [[83, 88]], "long-forms": [[48, 71]]}, {"text": "Chinese sentence into a sequence of words. This is  the task of Chinese word segmentation (CWS), an  important and challenging task in Chinese NLP.", "acronyms": [[91, 94], [143, 146]], "long-forms": [[64, 89]]}, {"text": "VB (Verb) is a major source of confusion in automatic tagging.  It is collapsed with VB (Verb). ", "acronyms": [[85, 87], [0, 2]], "long-forms": [[89, 93], [4, 8]]}, {"text": "CDD, which comprises a total of 173 gold annotated cues, we find that Classifier I mislabels 11 false positives (FPs) and seven false negatives (FNs). ", "acronyms": [[113, 116], [145, 148], [0, 3]], "long-forms": [[96, 111], [128, 143]]}, {"text": " Some implementation otes  The Carnegie Mellon Spoken Language Shell (CM-SLS)  was intentionally designed to have easily modifiable com- ", "acronyms": [[70, 76]], "long-forms": [[31, 68]]}, {"text": "124   Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 202?203, Vancouver, October 2005.", "acronyms": [[79, 83]], "long-forms": [[31, 77]]}, {"text": " 2 CFN and Its SRL task Chinese FrameNet(CFN) (You et al, 2005) is a research project that has been developed by Shanxi", "acronyms": [[41, 44], [3, 6], [15, 18]], "long-forms": [[24, 39]]}, {"text": "This system tags, lemmatizes and parses corpus data using the current version of the RASP (Robust Accurate Statistical Parsing) toolkit (Briscoe et al, 2006), and on the basis of resulting", "acronyms": [[85, 89]], "long-forms": [[91, 126]]}, {"text": "(e.g. adjective bivs?i, which means former in both languages), (b) the term partial false friends (PFF) describes pairs that are polysemous and", "acronyms": [[99, 102]], "long-forms": [[76, 97]]}, {"text": "ducted. The administrative body governing these decisions is the Institutional Review Board (IRB). ", "acronyms": [[93, 96]], "long-forms": [[65, 91]]}, {"text": "steels@arti.vub.ac.be Abstract Fluid Construction Grammar (FCG) is a new linguistic formalism designed to ex-", "acronyms": [[59, 62]], "long-forms": [[31, 57]]}, {"text": "Centro de Sondi E Imagen S.L. (Spain)  - Lead Industrial User  University of Sunderland (UK)  - Academic Research ", "acronyms": [[89, 91], [25, 28]], "long-forms": [[63, 87], [31, 36]]}, {"text": "level-2 domains) yet still did not sufficiently cover relevant subject fields identified by our users, such as IT, medicine and mechanical engineering. The Internal Classification for Standards (ICS) scheme was considered next, as it covers technical subject fields, but it was lacking with respect to legal and", "acronyms": [[195, 198], [111, 113]], "long-forms": [[156, 193]]}, {"text": "The stated  goal for this language model adaptation spoke was \"to  evaluate an incremental supervised language model (LM)  adaptation algorithm on a problem of sublanguage ", "acronyms": [[118, 120]], "long-forms": [[102, 116]]}, {"text": " 1 Introduction Most Open Information Extraction (Open-IE) systems (Banko et al, 2007) extract textual relational", "acronyms": [[50, 57]], "long-forms": [[21, 48]]}, {"text": "For the discourse  structure analysis, we suggest a statistical model  with discourse segment boundaries (DSBs)  similar to the idea of gaps suggested for a ", "acronyms": [[106, 110]], "long-forms": [[76, 104]]}, {"text": "tor. Together, these modifications reduce the BLEU score by 1.49 BLEU points (BP)9 at the largest training size.", "acronyms": [[78, 80], [46, 50]], "long-forms": [[65, 76]]}, {"text": "Cognitive Science Department at Xiamen University (XMU) ? ?  Harbin Institute of Technology Shenzhen Graduate School (HITSZGS)    National Taipei University of Technology (NTUT)   ", "acronyms": [[118, 125], [51, 54], [172, 176]], "long-forms": [[61, 116], [32, 49], [130, 170]]}, {"text": "This gave rise to a relatively new research area within the emerging field of Textto-Text Generation (TTG) called Multiple-Choice Test Item Generation (MCTIG).1", "acronyms": [[102, 105], [152, 157]], "long-forms": [[78, 100], [114, 150]]}, {"text": "n - c-dow British English American English Table 1: Example of tags assigned with coarse-grained Universal Tagset (UT) and fine-grained lexical type tagset (LTT).", "acronyms": [[115, 117], [157, 160]], "long-forms": [[97, 113], [136, 155]]}, {"text": "presented at the 16th International Conference on Computational Linguistics, Copenhagen. Gupta, D., Saul, M., & Gilbertson, J. (2004). Evaluation of a deidentification (DE-ID) software engine to share pathology reports and clinical documents for research. Am J Clin Pathol, 121(2), 176-186.", "acronyms": [[169, 174]], "long-forms": [[151, 167]]}, {"text": "In this shared task we test the feasibility of eliciting parallel data for Machine Translation (MT) using Mechanical Turk (MTurk). MT poses an interesting", "acronyms": [[123, 128], [96, 98], [131, 133]], "long-forms": [[106, 121], [75, 94]]}, {"text": "issue. Send membership applications and  address changes to Betty Walker (ACL),  Bellcore, 445 South Street, MRE 2A379, ", "acronyms": [[74, 77], [109, 112]], "long-forms": [[41, 72]]}, {"text": " In the medical domain, Castan?o et al (2002) used UMLS (Unified Medical Language System)7 as their knowledge source.", "acronyms": [[51, 55]], "long-forms": [[57, 90]]}, {"text": "2007), to machine translation (Wu and Fung 2009) and summarization (Melli et al 2005).  Most semantic role labeling (SRL) systems to date conceptualize the task as a supervised learning problem and rely on role-annotated data for model training.", "acronyms": [[117, 120]], "long-forms": [[93, 115]]}, {"text": "For biomedical terms other than genes/gene products, the Unified Medical Language System (UMLS) meta-thesaurus (Lindberg et al, 1993) is a large", "acronyms": [[90, 94]], "long-forms": [[57, 88]]}, {"text": "before the start of the current utterance.  Overlapping label (OL) an utterance on another channel with a particular DA tag overlaps the", "acronyms": [[63, 65], [117, 119]], "long-forms": [[44, 61]]}, {"text": "proach of (Liu et al, 2004), in which IDs (category seeds) and instances are represented by vectors in a usual IR-style Vector Space Model (VSM), and similarity is measured by the cosine function:", "acronyms": [[140, 143], [111, 113]], "long-forms": [[120, 138]]}, {"text": "the second sentence provides some further description of that entity. An Entity Relation (EntRel) was annotated for such sentence pairs as below.", "acronyms": [[90, 96]], "long-forms": [[73, 88]]}, {"text": "We implement MVM using generative model primitives drawn from Latent Dirichlet Allocation (LDA) and the Dirichlet Process (DP). |M | disparate", "acronyms": [[123, 125], [13, 16], [91, 94]], "long-forms": [[104, 121], [62, 89]]}, {"text": " To combat this inefficiency, after every state transition we estimate the effective sample size (ESS) of the particle weights as ??", "acronyms": [[98, 101]], "long-forms": [[75, 96]]}, {"text": "  The second one is a variant that we named  Double Levenshtein?s Edit Distance (DLED)  (see Table 9 for detail).", "acronyms": [[81, 85]], "long-forms": [[45, 79]]}, {"text": "Sentence). The dependency labels are NK (Noun Kernel), SB (Subject), AO (Object Accusative), HD (Head), MO (Modifier), AC (Adpositional Case Marker), CJ (Conjunct), and OC (Clausal Object).", "acronyms": [[93, 95], [104, 106], [119, 121], [150, 152], [37, 39], [55, 57], [69, 71], [169, 171]], "long-forms": [[97, 101], [108, 116], [123, 140], [154, 162], [41, 52], [59, 66], [73, 90], [173, 187]]}, {"text": "1125 VNC token expressions (CFS07 has 1180).  We then split them into a development (DEV) set and a test (TEST) set.", "acronyms": [[85, 88], [5, 8], [28, 33], [106, 110]], "long-forms": [[72, 83], [100, 104]]}, {"text": "(41a) PP = ~ Cat i (PN)  i i>0  (41b) NP = N ~ Cati(P N) i  1 ", "acronyms": [[38, 40], [6, 8], [20, 22]], "long-forms": [[43, 53]]}, {"text": "plies that 58% of the time, our approach has improved the question relevance compared to that of the original candidate list (OList). ", "acronyms": [[126, 131]], "long-forms": [[101, 124]]}, {"text": "The DM is bracketed between two other components, the Input Manager (IM) and the Output Manager (OM). The", "acronyms": [[97, 99], [4, 6], [69, 71]], "long-forms": [[81, 95], [54, 67]]}, {"text": " Twice it is labeled as a noun phrase (NP) and once as a prepositional phrase (PP). ", "acronyms": [[79, 81]], "long-forms": [[57, 77]]}, {"text": "mensionality reduction, such as Latent Semantic Analysis (LSA) in (Pad?o and Lapata, 2007) or Non-negative Matrix Factorization (NMF) (Zheng et al.,", "acronyms": [[129, 132], [58, 61]], "long-forms": [[98, 127], [32, 56]]}, {"text": " 4.3 Spanish?English (ES?EN), French?English (FR?EN) In Table 3, we see that on the ES?EN and", "acronyms": [[46, 51]], "long-forms": [[30, 44]]}, {"text": "for every language. All results in percent. LAS = labeled attachment score, UAS = unlabeled attachment score.", "acronyms": [[44, 47], [76, 79]], "long-forms": [[50, 74], [82, 108]]}, {"text": "1408 then apply our model to the well-established sequence labeling task: noun phrase (NP) chunking. ", "acronyms": [[87, 89]], "long-forms": [[74, 85]]}, {"text": "teacher for advice.  \u0000 RESL (result): Mother protects her children from any danger.", "acronyms": [[23, 27]], "long-forms": [[29, 35]]}, {"text": "The partitioning of the dataset is listed in the Table 1, where we also give the partitioning of Wall Street Journal (WSJ) (Marcus et al, 1993) used to train the English grammar.", "acronyms": [[118, 121]], "long-forms": [[97, 116]]}, {"text": " 1 Introduction  Lexical Acquisition (LA) processes strongly rely on  basic assumptions embodied by the source informa- ", "acronyms": [[38, 40]], "long-forms": [[17, 36]]}, {"text": " B. MTE features We use the following MTE metrics (MTFEATS), which compare the similarity between the question and a candidate answer:", "acronyms": [[51, 58], [4, 7], [38, 41]], "long-forms": [[42, 49]]}, {"text": "http://wordnet.princeton.edu/glosstag.shtml 1462 tive baseline, based on Greedy String Tiling (GST) (Wise, 1996).", "acronyms": [[95, 98]], "long-forms": [[73, 93]]}, {"text": "The lack of a  fully comprehensive bilingual dictionary including  the entries for all named entities (NEs) renders the  task of transliteration necessary for certain natural ", "acronyms": [[103, 106]], "long-forms": [[87, 101]]}]