[{"text": "Abstract This paper introduces a tensor-based approach to semantic role labeling (SRL). The motiva-", "acronyms": [[82, 85]], "long-forms": [[58, 80]]}, {"text": " 1 Introduction Weighted Context Free Grammars (WCFG) define an important class of languages.", "acronyms": [[48, 52]], "long-forms": [[16, 46]]}, {"text": "name along the path ? LCA (Lowest Common Ancestor) path that is from ORG name to its lowest common ancestor with PRO name", "acronyms": [[22, 25], [69, 72], [113, 116]], "long-forms": [[27, 49]]}, {"text": " 2004. Document understanding conferences (DUC). ", "acronyms": [[43, 46]], "long-forms": [[7, 41]]}, {"text": "transcripts of user utterances, and included lexical, syntactic, numeric, and features from the output of Linguistic Inquiry and Word Count (LIWC) (Pennebaker et al.,", "acronyms": [[141, 145]], "long-forms": [[106, 139]]}, {"text": "Given an occurrence of a word \u0002 in a natural language text, the task of word sense disambiguation (WSD) is to determine the correct sense of \u0002 in that context.", "acronyms": [[99, 102]], "long-forms": [[72, 97]]}, {"text": "constructed using only surface Alterf patterns; for the GLM and text versions, we can use either surface patterns, logical form (LF) patterns, or both. ", "acronyms": [[129, 131], [56, 59]], "long-forms": [[115, 127]]}, {"text": "7-3-1, Hongo, Bunkyo-ku  Tokyo 113, Japan  It is difficult for a natural language understanding system (NLUS) to deal  with ambiguities.", "acronyms": [[104, 108]], "long-forms": [[65, 102]]}, {"text": "Central to the predictive dialogue is the topic representation for each scenario, which enables the population of a Predictive Dialogue Network (PDN). ", "acronyms": [[145, 148]], "long-forms": [[116, 143]]}, {"text": " We compared the resulting ranked lists of bigrams with a list of target MWEs extracted from the British National Corpus (BNC)3. The target list was pro-", "acronyms": [[122, 125], [73, 77]], "long-forms": [[97, 120]]}, {"text": "3. Maximization of 1)arameters, A of at:tire fea-  tures 1)y I IS(hnproved Iterative Sealing) algo-  rithm.", "acronyms": [[63, 65]], "long-forms": [[75, 92]]}, {"text": "AT&T Labs-Research Abstract Statistical Machine Translation (SMT) systems are heavily dependent on the qual-", "acronyms": [[61, 64], [0, 4]], "long-forms": [[28, 59]]}, {"text": "f ~ r l r ~ f  TRANSFORIATICNS *llrllrt*  SCAN C A L L E D  AT 1 I  ANTEST CALLED FOR 1 '*REDVOW \" (AACC) ,SD= 2. RES= 6.", "acronyms": [[82, 85], [100, 104], [107, 109], [114, 117]], "long-forms": [[68, 81]]}, {"text": " 4 Evaluation and Experiments We use the General Inquirer (GI)8 data for evaluation.", "acronyms": [[59, 61]], "long-forms": [[41, 57]]}, {"text": "It predicts four type of reordering patterns, namely MA (monotone adjacent), MG (monotone gap), RA (reverse adjacent), and RG (reverse gap).", "acronyms": [[96, 98], [53, 55], [77, 79], [123, 125]], "long-forms": [[100, 116], [57, 74], [81, 93], [127, 138]]}, {"text": "strict our attention to documents on this topic.  Thomson Reuter?s Web of Science (WOS), a database of scientific journal and conference arti-", "acronyms": [[83, 86]], "long-forms": [[67, 81]]}, {"text": "2007. Identifying authorship by byte-level n-grams: The source code author profile (SCAP) method. Journal of Digital Evidence, 6(1).", "acronyms": [[84, 88]], "long-forms": [[56, 82]]}, {"text": "Our participation in the STS task is inspired by previous work on paraphrase recognition, in which machine translation (MT) evaluation metrics are used to identify whether a pair of sentences are", "acronyms": [[120, 122], [25, 28]], "long-forms": [[99, 118]]}, {"text": " Most of lexical networks, as networks extracted from real world, are small worlds (SW) networks.", "acronyms": [[84, 86]], "long-forms": [[70, 82]]}, {"text": "ing is how to identify a temporal relation between a pair of temporal entities such as events (EVENT) and time expressions (TIMEX) in a narrative. Af-", "acronyms": [[124, 129]], "long-forms": [[106, 122]]}, {"text": "10-best(+AG) 4.35 90.0 Table 1: Task completion rate according to using the AG (Agenda Graph) and n-best hypotheses for n=1 and n=10.", "acronyms": [[76, 78], [9, 11]], "long-forms": [[80, 92]]}, {"text": "than have them specified in a tag dictionary.  The Lexicon HMM (Lex-HMM) extends the Pitman-Yor HMM (PYP-HMM) described by", "acronyms": [[64, 71], [101, 108]], "long-forms": [[51, 62], [85, 99]]}, {"text": "Sample DCR entries specifying enumerated values for SynFeatureName, etc. The specification uses the Ontology Web Language (OWL) to list valid values for objects of the defined class. ", "acronyms": [[123, 126], [7, 10]], "long-forms": [[100, 121]]}, {"text": "Moreover, in (Hahn et al, 2008a) two more models are applied to SLU: a Maximum Entropy (EM) model and a model coming from the Statistical Machine Translation (SMT) commu-", "acronyms": [[88, 90], [64, 67], [159, 162]], "long-forms": [[79, 86], [126, 157]]}, {"text": "latent topic space. Values within vectors are the TF-ITF (term frequency - inverse topic frequency) scores which are calculated in a completely ana-", "acronyms": [[50, 56]], "long-forms": [[58, 98]]}, {"text": "the literature. In a recent Japanese NE workshop, a maximum entropy (ME) system outperformed decision tree sys-", "acronyms": [[69, 71]], "long-forms": [[52, 67]]}, {"text": "results in Die event. Recent improvements of convolutional neural networks (CNNs) have been proven to be efficient for capturing syntactic and", "acronyms": [[76, 80]], "long-forms": [[45, 74]]}, {"text": "Probabilistic ID/LP grammars  The idea of separating simple context-free rules into two, orthogunal rule sets, immediate  dominance(ID) rules, and linear precedence(LP) rules, gives a notation for writing grammars called  ID/LP.", "acronyms": [[165, 167], [14, 19], [132, 134], [222, 227]], "long-forms": [[147, 163], [111, 131]]}, {"text": "Long short-term memory neural network (LSTM) (Hochreiter and Schmidhuber, 1997) is a type of recurrent neural network (RNN) (Elman, 1990), and specifically addresses the", "acronyms": [[119, 122]], "long-forms": [[93, 117]]}, {"text": "Networks A more similar model to the proposed larger-context recurrent language model is a hierarchical recurrent encoder decoder (HRED) proposed recently by Serban et al (2015).", "acronyms": [[131, 135]], "long-forms": [[91, 129]]}, {"text": "Constituents are tagged with IsA class labels from a large, automatically extracted lexicon, using a probabilistic context free grammar (PCFG). ", "acronyms": [[137, 141]], "long-forms": [[101, 135]]}, {"text": " These models are trained only using negative entities which we refer to as Negative Entity (NE) objective. ", "acronyms": [[93, 95]], "long-forms": [[76, 91]]}, {"text": "thematic structure, and defined well formedness conditions on the thematic structure and on the relation between thematic structure (TH) and syntactic dominance (ID) structure.", "acronyms": [[133, 135], [162, 164]], "long-forms": [[113, 121], [0, 8]]}, {"text": "subsumption hierarchy of Patty is very sparse. It contains only 8,000 hypernymy links between phrases, and the entire taxonomy is kind of fragmented into a many-rooted DAG (directed acyclic graph). More-", "acronyms": [[168, 171]], "long-forms": [[173, 195]]}, {"text": " 3 In this work, we use HL (Hu and Liu, 2004), MPQA (Wilson et al.,", "acronyms": [[24, 26], [47, 51]], "long-forms": [[28, 38]]}, {"text": "ings. They evaluate their work against the SENSEVAL 2 AW test data (SV2AW). They tune the", "acronyms": [[68, 73]], "long-forms": [[43, 56]]}, {"text": "an algorithm that combines the reference choice rules for  reason and the reference choice rules for methods, to pro-  duce preverbal messages (PMs) from PCAs. As such, the ", "acronyms": [[144, 147]], "long-forms": [[124, 142]]}, {"text": "input format. For instance, if the input is annotated with word and PoS (WP), so must be the translation model.", "acronyms": [[73, 75]], "long-forms": [[59, 71]]}, {"text": "Semantic Interpretation of Prepositions for NLP Applications Sven Hartrumpf Hermann Helbig Rainer Osswald Intelligent Information and Communication Systems (IICS) University of Hagen (FernUniversita?t in Hagen)", "acronyms": [[157, 161], [44, 47]], "long-forms": [[106, 155]]}, {"text": "the 8th International Conference on Language Resources and Evaluation (LREC 2012), Istanbul, Turkey, may.  European Language Resources Association (ELRA). ", "acronyms": [[148, 152], [71, 75]], "long-forms": [[107, 146], [36, 53]]}, {"text": "1 Automatic Discovery of Phone(me)s Statistical models learnt from data are extensively used in modern automatic speech recognition (ASR) systems.", "acronyms": [[133, 136]], "long-forms": [[103, 131]]}, {"text": "tence in Japanese; N = noun, TOP = topic marker, ADV = adverbial particle, ADJ = adjective, COP = copula, EXCL = exclamation mark. ", "acronyms": [[106, 110], [29, 32], [49, 52], [75, 78], [92, 95]], "long-forms": [[113, 124], [23, 27], [35, 40], [55, 64], [81, 90], [98, 104]]}, {"text": "sense as a group of similar contexts of target word.  The context group discrimination (CGD) algorithm presented in (Schu?tze, 1998) adopted this strategy.", "acronyms": [[88, 91]], "long-forms": [[58, 86]]}, {"text": "processing. This paper explores grammatical issues in Scottish Gaelic by means of dependency tagging and combinatory categorial grammar (CCG), which we see as complementary approaches. As such it", "acronyms": [[137, 140]], "long-forms": [[105, 135]]}, {"text": " 3 Bridgeman Art Library Bridgeman Art Library (BAL)2 is one of the world?s top image libraries for art, culture and history.", "acronyms": [[48, 51]], "long-forms": [[25, 46]]}, {"text": "1997). Theory retinement is mainly used (and has its  origin) in Knowledge Based Systems (KBS) (Craw  and Sleeman, 1990).", "acronyms": [[90, 93]], "long-forms": [[65, 88]]}, {"text": "nese personal naming system. Therefore, we hold  Chinese personal name disambiguation (CPND) to  explore those problems.", "acronyms": [[87, 91]], "long-forms": [[49, 85]]}, {"text": " 1 Introduction Information extraction (IE), defined as the task of extracting structured information (e.g., events, bi-", "acronyms": [[40, 42]], "long-forms": [[16, 38]]}, {"text": "distinct verbs, not occurrences. The seventh column shows the number of verbs that  were misclassified (MC)--the sum of false positives and false negatives. The eighth ", "acronyms": [[104, 106]], "long-forms": [[89, 102]]}, {"text": "minimal human SO annotation Table 2: Key details of semantic orientation (SO) lexicons. ASL = affix seeds lexicon, GI = General Inquirer, MSOL = Macquarie semantic orientation lexicon, PSL = Pitt subjectivity lexicon, SWN =", "acronyms": [[88, 91], [74, 76], [115, 117], [138, 142], [185, 188], [218, 221]], "long-forms": [[94, 113], [52, 72], [120, 136], [145, 183], [191, 216]]}, {"text": "by ranking the set of utterances by our confidence that they contain the query word, a task known as Ranked Utterance Retrieval (RUR). In particular,", "acronyms": [[129, 132]], "long-forms": [[101, 127]]}, {"text": " Disco-En-Gold consists of 349 expressions divided into training (TrainD), validation (ValD), and test data (TestD) manually assigned scores from 0", "acronyms": [[87, 91], [109, 114], [66, 72]], "long-forms": [[75, 85], [98, 107], [43, 64]]}, {"text": " Proceedings of the lOth International Conference on  Computational Linguistics (COLING-84). Stanford ", "acronyms": [[81, 90]], "long-forms": [[54, 79]]}, {"text": "In the SIGHAN Bakeoff 2007, there are five training corpus for word segmentation (WS) task: AS  (Academia Sinica), CityU (City University of  Hong Kong) are traditional Chinese corpus; CTB ", "acronyms": [[115, 120], [82, 84], [92, 94], [185, 188]], "long-forms": [[122, 137], [63, 80], [97, 112]]}, {"text": "News stories typically describe real-world events.  Topic detection and tracking (TDT) aims to detect stories that discuss identical or directly related", "acronyms": [[82, 85]], "long-forms": [[52, 80]]}, {"text": "scribe the relation R. Most previous systems perform these steps by first using named entity recognition (NER) to identify possible arguments and then using a simple string match, but this crude", "acronyms": [[106, 109]], "long-forms": [[80, 104]]}, {"text": " We apply both support vector machine (SVM)  and Maximum Entropy (ME) algorithms with the  help of the SVM-light4 and Mallet5 tools.", "acronyms": [[66, 68], [39, 42], [103, 106]], "long-forms": [[49, 64], [15, 37]]}, {"text": " 246  AO = all objects  MO = matched objects ", "acronyms": [[6, 8], [24, 26]], "long-forms": [[11, 22], [29, 43]]}, {"text": " NOM (nominative), ACC (accusative), DAT (dative), ABL (ablative), CMI (comitative), GEN (genitive) and TOP (topic marker).", "acronyms": [[51, 54], [67, 70], [85, 88], [1, 4], [19, 22], [37, 40], [104, 107]], "long-forms": [[56, 64], [72, 82], [90, 98], [6, 16], [24, 34], [42, 48], [109, 121]]}, {"text": " 1 Introduction The approach to factoid question answering (QA) that we adopt was first described in (Whittaker et", "acronyms": [[60, 62]], "long-forms": [[40, 58]]}, {"text": " MUC marks locations (LOC), organisations (ORG) and personal names (PER), in addition to numerical and time information.", "acronyms": [[68, 71], [1, 4], [22, 25], [43, 46]], "long-forms": [[52, 60], [11, 20], [28, 41]]}, {"text": "Abstract  This paper proposes a novel reordering model  for statistical machine translation (SMT) by  means of modeling the translation orders of ", "acronyms": [[93, 96]], "long-forms": [[60, 91]]}, {"text": "and get close to the top level in several other tracks.  Recently, Maximum Entropy model(ME) and CRFs (Low et al, 2005)(Tseng et al, 2005) (Hai", "acronyms": [[89, 91], [97, 101]], "long-forms": [[67, 82]]}, {"text": " We explore how to utilize the source-language test corpus for adapting the language model (LM) and the translation model (TM).", "acronyms": [[92, 94], [123, 125]], "long-forms": [[76, 90], [104, 121]]}, {"text": "and BLANC (Recasens and Hovy, 2011). We use the average scores (AVG) of these four metrics as the main comparison metric.10", "acronyms": [[64, 67], [4, 9]], "long-forms": [[48, 55]]}, {"text": "In Proceedings of the 2nd Workshop on Treebanks and Linguistic Theories (TLT), pages 217?220, Va?xjo?. ", "acronyms": [[73, 76]], "long-forms": [[38, 71]]}, {"text": "The method seems to be a simple pattern  matching technique in a left-to-right fashion  but it helps in case of conjunct verbs (ConjVs). ", "acronyms": [[128, 134]], "long-forms": [[112, 126]]}, {"text": "fying the native language based on the manner of speaking and writing a second language is borrowed from Second Language Acquisition (SLA), where this is known as language transfer.", "acronyms": [[134, 137]], "long-forms": [[105, 132]]}, {"text": " 2 Background and Related Work Amazon?s Mechanical Turk (MTurk) is an online marketplace for work that gives employers", "acronyms": [[57, 62]], "long-forms": [[40, 55]]}, {"text": "Table 3: Results on DevTest and Test Sets compared with the Average Performance in CoNLL?07. LAS = Labelled Attachment Score, UAS = Unlabelled Attachment Score, LAcc = Label Accuracy, AV = Average score.", "acronyms": [[126, 129], [184, 186], [93, 96], [161, 165], [83, 88]], "long-forms": [[132, 159], [189, 196], [99, 124], [168, 182]]}, {"text": "2.1 The Machine Translation Performance Predictor (MTPP) In machine translation (MT), pairs of source and target sentences are used for training statistical", "acronyms": [[81, 83], [51, 55]], "long-forms": [[60, 79], [8, 49]]}, {"text": "200 Acknowledgments This research is developed by the Arabic Language Technologies (ALT) group at Qatar Computing Research Institute (QCRI) within the Qatar Foundation in collaboration with MIT.", "acronyms": [[84, 87], [134, 138]], "long-forms": [[54, 82], [98, 132]]}, {"text": "To v e r i f y  th'e r e l a t i o n s h i p s  between the s t a t i s t i c a l  models of word  importance and t h s  vector space model, dcsument c o l l e c t i o n s  are used i n  three  d i f f e r e n t  subjec t  a reas ,  including aerodynamics (cRAN),  medicine (MED) and  world a f f a i r s  (TIME).", "acronyms": [[275, 278], [257, 261]], "long-forms": [[265, 273]]}, {"text": "No normalization 68.52 (70.45) 84.34 (82.8) 37.4 (45.2) 67.8 (67.1) Table 2: Binary logistic regression 10-fold cross validation with different feature normalization approaches: Scores within brackets are when the female speaker data is removed; S = Stressed, US = Unstressed, MCB = Majority Class Baseline. ", "acronyms": [[260, 262], [277, 280]], "long-forms": [[265, 275], [283, 306]]}, {"text": "of spoken dialogue systems is database retrieval.  Some IVR (interactive voice response) systems using the speech recognition technology are being put", "acronyms": [[56, 59]], "long-forms": [[61, 87]]}, {"text": "CP OP LC RC where CP = Correspondence Part; OP = Operator; LC = Left Context; RC = Right Context There are four different kinds of rules that may be", "acronyms": [[59, 61], [78, 80], [0, 2], [3, 5], [6, 8], [9, 11], [18, 20], [44, 46]], "long-forms": [[64, 76], [83, 96], [23, 42], [49, 57]]}, {"text": " 1 In t roduct ion :  a problem  Grammar development environments (GDE's) for  analysis and for generation have not yet come to- ", "acronyms": [[67, 72]], "long-forms": [[33, 65]]}, {"text": "  Abstract  A Named Entity Recognizer (NER) generally  has worse performance on machine translated ", "acronyms": [[39, 42]], "long-forms": [[14, 37]]}, {"text": "tences, or the NP is an exophora, this is NULL.  Speaker Binary Whether the speakers of the predicate and the NP are the same (SAME) or not (OTHER).", "acronyms": [[127, 131], [42, 46], [110, 112]], "long-forms": [[121, 125]]}, {"text": "knowledge, mnong others in l:'ei~onal or DBMT systems.  Such Discovery Assistants (DA) slmuld certainly be  highly cooperative, namely show sensible interactivity ", "acronyms": [[83, 85], [41, 45]], "long-forms": [[61, 81]]}, {"text": " We propose a new algorithm: collective iterative classification (CIC) to perform approximate inference to find the maximum a posteriori", "acronyms": [[66, 69]], "long-forms": [[29, 64]]}, {"text": "scoring the candidate set of which class of anaphoric expression (DNOM = definite  NP, PER{I,2,3} = first/second/third person pronouns, POS{1,2,3} = first/second/third  person possessives, RELA = relative pronouns, REFL = reflexive/reciprocal pronouns). ", "acronyms": [[189, 193], [215, 219], [66, 70], [83, 85], [87, 90], [136, 139]], "long-forms": [[196, 204], [222, 231], [73, 81]]}, {"text": "this results in minimum expected word error rate (WER) hypothesis (Mangu et al, 2000) or equivalently minimum Bayes risk (MBR) under WER with uniform target sentence posterior distribution (Sim", "acronyms": [[122, 125]], "long-forms": [[102, 120]]}, {"text": "retrieval effectiveness. The following figure  shows the change of average precision (AvgP)  using CDQE (Model 2) along with the change of ", "acronyms": [[86, 90], [99, 103]], "long-forms": [[67, 84]]}, {"text": " 6 Conclusion In this work, we manually constructed a Phased Predicate Template Taxonomy (PPTT), which is a network of semantically coherent classes of templates and derived semantic relations including entailment", "acronyms": [[90, 94]], "long-forms": [[54, 88]]}, {"text": "That is, it learns some new knowledge.  Static Interactive Learning (SIL): Whenever the  system encounters a sentence out o f  i t s  processing ", "acronyms": [[69, 72]], "long-forms": [[40, 67]]}, {"text": "In Proceedings of ACM 12th International Conference on Intelligent User interfaces (IUI). ", "acronyms": [[84, 87], [18, 21]], "long-forms": [[55, 82]]}, {"text": "form is  employed to denote funct ion  i t se l f .   b) Conceptual  Phrase St ructure  (CPS) is  a data  s t ruc ture  in which syntact i c  and semant ic  in fo rma-  ", "acronyms": [[89, 92]], "long-forms": [[57, 86]]}, {"text": "UC 3 NLP, 1 BioNLP ML (Weka SVM) Table 2: Participation. UU = UofU, UZ = UZH, CU=ConcordU, UT = UTurku, UZ = UZH, US =", "acronyms": [[57, 59]], "long-forms": [[62, 66]]}, {"text": "Both Russian and Czech have relatively free word order, so it may seem an odd choice to use a Markov model (MM) tagger. Why should second order", "acronyms": [[108, 110]], "long-forms": [[101, 106]]}, {"text": "In  Proceedings of the 16th International Conference  on World Wide Web (WWW), pages 697-706. ", "acronyms": [[73, 76]], "long-forms": [[57, 71]]}, {"text": "M27 vp move past, vp pass, vp pass by, vp walk past (all AS) Actions correspond to expansions of lexemes (FV = filling status): 0=unfilled, 1=filled. ( SV = shared variables): the variables np actor (FV), relatum (FV), sentence (FV) and information need (0=low, 1=high) are shared by several subagents; the same applies to their", "acronyms": [[152, 154], [57, 59], [106, 108], [200, 202], [214, 216], [229, 231]], "long-forms": [[157, 173], [111, 125]]}, {"text": " 4 Active Learning Active Learning (AL) is a machine learning paradigm that let the learner decide which data it", "acronyms": [[36, 38]], "long-forms": [[19, 34]]}, {"text": ".  Reattachment Heuristic (RH) targets nonargument head errors that occur if a TL argument", "acronyms": [[27, 29], [79, 81]], "long-forms": [[3, 25]]}, {"text": "2.1 Download Initial Collection        The Yahoo Full Coverage Collection (YFCC) was  downloaded from http://fullcoverage.yahoo.com during ", "acronyms": [[75, 79]], "long-forms": [[43, 73]]}, {"text": " More recently, i2b2 organizers also reported a  Maximum Entropy (ME) based approach for the  2009 challenge (Halgrim, Xia, Solti, Cadag, & ", "acronyms": [[66, 68], [16, 20]], "long-forms": [[49, 64]]}, {"text": "based on the design the Princeton English Wordnet.  Arabic Wordnet (AWN) (Elkateb, 2006; Black and Fellbaum, 2006; Elkateb and Fellbaum, 2006) has", "acronyms": [[68, 71]], "long-forms": [[52, 66]]}, {"text": " The improvement of PAS analysis would benefit many natural language processing (NLP) applications, such as information extraction, summariza-", "acronyms": [[81, 84], [20, 23]], "long-forms": [[52, 79]]}, {"text": "3.1 Data We use the TiGer treebank release 2.2 (TIGER), and the NeGra treebank (NEGRA). For TIGER,", "acronyms": [[80, 85], [48, 53], [92, 97]], "long-forms": [[64, 78], [20, 34]]}, {"text": "(FW), SeekBw (BW), ScrollFw (FS), ScrollBw (BS), Ratechange Increase (RCI), Ratechange Decrease (RCD). ", "acronyms": [[97, 100], [1, 3], [14, 16], [29, 31], [44, 46], [70, 73]], "long-forms": [[76, 95], [6, 12], [19, 27], [34, 42], [49, 68]]}, {"text": " 2011b. Overview of the entity relations (REL) supporting task of BioNLP Shared Task 2011.", "acronyms": [[42, 45]], "long-forms": [[31, 40]]}, {"text": "level for natural  language unders tand ing  system. In case of a  Module  Package Layer( MPL ), there are two kinds of program  packages.", "acronyms": [[90, 93]], "long-forms": [[67, 88]]}, {"text": " The joint model is trained in max-margin fashion using a latent structural SVM (LSSVM) where the answer-entailing structures are latent.", "acronyms": [[81, 86]], "long-forms": [[58, 79]]}, {"text": "ley (2004). This framework for linguistic semantics is called Uni\u0002ed Eventity Representation (UER), because it is a true extension of the UML and not", "acronyms": [[94, 97], [138, 141]], "long-forms": [[62, 92]]}, {"text": "4.1 Base Extraction As first step of the mention selection stage, we extracted all the noun phrases (NP), pronouns (PRP), and possessive pronouns (PRP$) for English and", "acronyms": [[101, 103]], "long-forms": [[87, 99]]}, {"text": " Parsed* Recall t Prec/Rec t MLP Prob t  Left Corner (LC) 21797 91.75 9000 .76399 .78156 .175928  LB o LC 53026 96.75 7865 .77815 .78056 .359828 ", "acronyms": [[54, 56], [29, 32], [98, 100], [103, 105]], "long-forms": [[41, 52]]}, {"text": "nuqaqa llakiy qhachqa p?achakunata churakurqani.  Abbreviations: AMLQ = Academia Mayor de la Lengua Quechua en Cusco, norm = normalized, span = Spanish orthography, boliv = (old) Bolivian orthography Table 1: Different Orthographies with Corresponding Standardized Version", "acronyms": [[65, 69]], "long-forms": [[72, 107]]}, {"text": "Three query tasks were defined in TREC-2003 and TREC-2004 web track, which are home page finding (HP), named page finding (NP) and topic distillation (TD) (Voorhees, 2003; Voorhees, 2004).", "acronyms": [[123, 125], [34, 38], [48, 52], [98, 100], [151, 153]], "long-forms": [[103, 113], [79, 88], [131, 149]]}, {"text": "take scope over another.  Those natural language processing (NLP) systems that have managed to provide some sort of account of quantifier scope preferences have done so by using a separate", "acronyms": [[61, 64]], "long-forms": [[32, 59]]}, {"text": "145  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1092?1103, October 25-29, 2014, Doha, Qatar.", "acronyms": [[93, 98]], "long-forms": [[43, 91]]}, {"text": "transcripts. The print news consisted of 22 New York Times (NYT) articles from January 1998.", "acronyms": [[60, 63]], "long-forms": [[44, 58]]}, {"text": "cognitive system (Wilkes, 1997). We refer to this  subset of knowledge store (KS) in operation for and in  a given discourse as discourse model (DM) and hold ", "acronyms": [[78, 80], [145, 147]], "long-forms": [[61, 76], [128, 143]]}, {"text": "Cleveland Family study dceweb1.case.edu/ serc/collab/project_family.shtml), CHS (the Cardiovascular Heart Study www. ", "acronyms": [[76, 79]], "long-forms": [[85, 111]]}, {"text": "the points plus 10% of the surrounding area. For this, The Generic Map Tools (GMT)10 were used, in this case via HTTP.11", "acronyms": [[78, 81], [113, 120]], "long-forms": [[59, 76]]}, {"text": "to say\" and the \"what to say\" is still an open  question. RAGS (rags, 1999) proposes astandard  architecture for the data, but leaves the ", "acronyms": [[58, 62]], "long-forms": [[64, 68]]}, {"text": "I  zwemmen  (17) is ttms obtained by setting VPo = VPh Zo = Yo,  attd Zl = Vl.", "acronyms": [[51, 54], [45, 48], [70, 72]], "long-forms": [[55, 57]]}, {"text": " 5 for SK with the use of POS information (SK-POS). ", "acronyms": [[43, 49]], "long-forms": [[7, 29]]}, {"text": "of the first studies to investigate such constancy is Genzel and Charniak (2002), in which the authors proposed the Constant Entropy Rate (CER) hypothesis: in written text, the entropy per sig-", "acronyms": [[139, 142]], "long-forms": [[116, 137]]}, {"text": " 3. Transitional Phrases (TRP) We hypothesize that a more cohesive essay, being easier for a", "acronyms": [[26, 29]], "long-forms": [[4, 24]]}, {"text": "5. Introducing background knowledge via CCMs [30 min]   We will look at ways in which Constrained Conditional Models (CCMs)can be used to  augment probabilistic models with declarative constraints in order to support decisions ", "acronyms": [[118, 122], [40, 44]], "long-forms": [[86, 116]]}, {"text": "Theorem LG is NP-complete.  Bin Packing (BP) which is NP-complete is  polynomial-t ime Karp reducible to LG.", "acronyms": [[41, 43], [8, 10], [14, 16], [105, 107], [54, 56]], "long-forms": [[28, 39]]}, {"text": "? P5E3N3S3, F W A Computer Processable English (CPE) (Pulman 1996; Sukkarieh and Pulman 1999) is a controlled language that can be ?", "acronyms": [[48, 51], [2, 10]], "long-forms": [[18, 46]]}, {"text": "2 Dialogue data The dialogue corpus used to perform the experiments is the Switchboard database (SWBD). It", "acronyms": [[97, 101]], "long-forms": [[75, 95]]}, {"text": "WebDict 0.2919 Backoff 0.3282 Table 1: Mean Average Precision (MAP), averaged over 34 topics", "acronyms": [[63, 66]], "long-forms": [[39, 61]]}, {"text": "Results on the dev set using two metrics: instance classification accuracy (CA), and soundbite name  recognition accuracy (RA). The oracle RA is 79.1%.", "acronyms": [[123, 125], [76, 78], [139, 141]], "long-forms": [[101, 121], [51, 74]]}, {"text": "NNS?, in this paper; other work makes a distinction between ESL (English as a Second Language) speakers (who live and speak in a primarily English-speaking environment) or EFL", "acronyms": [[60, 63], [0, 4], [172, 175]], "long-forms": [[65, 93]]}, {"text": "1. Introduction  In a Spoken Language System (SLS) we must use all avail-  able knowledge sources (KSs) to decide on the spoken sen- ", "acronyms": [[46, 49], [99, 102]], "long-forms": [[22, 44], [80, 97]]}, {"text": " ? Subordinate clause reordering (SubCR) which involve moving postnominal relative", "acronyms": [[34, 39]], "long-forms": [[3, 32]]}, {"text": "ranking models on this data set, including Support Vector Machine (SVM) with a linear kernel, SVM with a radial basis function (RBF) kernel and Logistic Regression (LR).", "acronyms": [[128, 131], [67, 70], [94, 97], [165, 167]], "long-forms": [[105, 126], [43, 65], [144, 163]]}, {"text": "2007). Two 5 DOF sensors - TT (Tongue Tip)  and TB (Tongue Body Back) - were attached on  the midsagittal of the tongue.", "acronyms": [[48, 50], [27, 29], [13, 16]], "long-forms": [[52, 63], [31, 41]]}, {"text": "Frustratingly easy domain adaptation.  In Association for Computational Linguistics (ACL). ", "acronyms": [[85, 88]], "long-forms": [[42, 83]]}, {"text": "e .g .  M C ~  --7 SUM + PRED* + IOBJ + WBJ + PREP P  *PRED = predicator - not predicate  1-1  detailed analysis of first occurring element of ", "acronyms": [[55, 59], [25, 29], [33, 37], [40, 43], [46, 50]], "long-forms": [[62, 72]]}, {"text": "Turning to emerging structure, PTT assumes that participants perform (often fragmentary) contributions, discourse units (DUs), which are dynamic propositions (DRSs in the", "acronyms": [[121, 124], [31, 34], [159, 163]], "long-forms": [[104, 119]]}, {"text": "on the gender of the user.  User ID: The user ID (UID) labels are inspired by research on Arabic Twitter showing that a consid-", "acronyms": [[50, 53]], "long-forms": [[41, 48]]}, {"text": "with common sense knowledge.       Natural language processing (NLP) techniques  such as part of speech tagging and parse tree gen-", "acronyms": [[64, 67]], "long-forms": [[35, 62]]}, {"text": "performs two vital functions in the case of our Japanese  processing:  1 CN = common noun; SN = sa-inflection noun (  nominalized .verb); VB = verb; VSUF = verb suffix; CM = ", "acronyms": [[73, 75], [138, 140], [149, 153], [169, 171]], "long-forms": [[78, 89], [143, 147], [156, 167]]}, {"text": " When a CFG is associated with probabilistic information, as in a Probabilistic CFG (PCFG), it can be interesting to process only the n most likely", "acronyms": [[85, 89], [8, 11]], "long-forms": [[66, 83]]}, {"text": "gle word maze); B-M (beginning of multi-word 72 maze); I-M (in multi-word maze); and E-M (end of multi-word maze).", "acronyms": [[55, 58], [16, 19], [85, 88]], "long-forms": [[60, 68], [21, 39], [90, 103]]}, {"text": "vides brief details of each annotation dimension.   2.1 Knowledge Type (KT)  This dimension is responsible for capturing the ", "acronyms": [[72, 74]], "long-forms": [[56, 70]]}, {"text": "case where estimated user?s knowledge and preference are represented as discrete binary parameters instead of probability distributions (PDs). That is, the estimated", "acronyms": [[137, 140]], "long-forms": [[110, 135]]}, {"text": "and  Communications Industry Association (CCIA) filed differing recommendations  with the OMB on Federal automatic data processing (ADP) procurement. CBEW ", "acronyms": [[132, 135], [42, 46], [90, 93], [150, 154]], "long-forms": [[105, 130], [5, 40]]}, {"text": "1991), can be characterized asknowledge-rich  in that they presuppose that known lexical  items possess Conceptual Dependence(CD)-  like descriptions.", "acronyms": [[126, 128]], "long-forms": [[104, 124]]}, {"text": "F is a frame name, E a frame element name, and t and s are sequences of word indices (t is for the target (FEE)) Using this measure of partial agreement, we now", "acronyms": [[107, 110]], "long-forms": [[91, 105], [7, 17], [29, 41]]}, {"text": "most u n e x p a n d e d  node o f  TI: for  3 b t h i s  r e s u l t s  i n :   3 e .  (S ( V  m a i l )  (NP ( N P  ( N  B o x e s )  (N*)) P P * )  ( P P * ) ) .  ", "acronyms": [[108, 110], [142, 145]], "long-forms": [[113, 116]]}, {"text": "parsing accuracy will be reported using the standard metrics of labeled attachment score (LAS) and unlabeled attachment score (UAS).13 Statistical significance is checked using Dan Bikel?s", "acronyms": [[127, 130], [90, 93]], "long-forms": [[99, 125], [64, 88]]}, {"text": "nodes in their MRs mij . Then, after setting the context ci as the MR of the root node (MR(T ) ? ci),", "acronyms": [[88, 92], [15, 18]], "long-forms": [[67, 81]]}, {"text": "using the written and spoken language corpora.  Occurrence probabilities (OPs) of expressions in the written and spoken language corpora can be used to dis-", "acronyms": [[74, 77]], "long-forms": [[48, 72]]}, {"text": " Several algorithms have been evaluated using 80 multiple-choice synonym questions taken from the Test of English as a Foreign Language (TOEFL). An example of", "acronyms": [[137, 142]], "long-forms": [[98, 135]]}, {"text": "PARSEVAL scores for our parse results. We focus on the Labeled Precision (LP) and Labeled Recall (LR) scores only in this paper, as these are", "acronyms": [[74, 76], [0, 8], [98, 100]], "long-forms": [[55, 72], [82, 96]]}, {"text": "the boys) or part of a complex coordinating conjunction (both boys and girls), the Penn  Treebank tags both differently in each of these syntactic ontexts--as PDT (predeter-  miner), RB (adverb), NNS (plural common noun) and coordinating conjunction (CC),  respectively.", "acronyms": [[251, 253], [159, 162], [183, 185], [196, 199]], "long-forms": [[225, 249], [164, 173]]}, {"text": "1 3 Note that there is only one column for recall, which is unaffected by the choice o f Matched/Missing (M/M) versus All Templates (AT) . ", "acronyms": [[133, 135], [106, 109]], "long-forms": [[118, 131], [89, 104]]}, {"text": "labels.5 We simulate a user?s constraints by ranking words in the training split by their information gain (IG).6 After ranking the top 200 words for each class", "acronyms": [[108, 110]], "long-forms": [[90, 106]]}, {"text": "Non Verbal Behaviors.   Sources abbreviated as: SPKR = Speaker; F = Friendship; V = Visibility; Rte = Route,  ", "acronyms": [[48, 52], [96, 99]], "long-forms": [[55, 62], [68, 78], [84, 94], [102, 107]]}, {"text": "In Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL-2), pages 1?5. ", "acronyms": [[101, 111]], "long-forms": [[22, 99]]}, {"text": "+ BD 67.4 67.0 67.2 + NEG + BD 67.4 67.1 67.3 Table 1: Results on development corpus: LP = labeled precision, LR = labeled recall, F1 = balanced F-measure", "acronyms": [[86, 88], [110, 112], [2, 4], [22, 25], [28, 30]], "long-forms": [[91, 108], [115, 129], [145, 154]]}, {"text": "It consists mainly of four incremental (cas-  caded) processes that work on the blackboard-like  current conceptual structure (CCR). At first sight, ", "acronyms": [[127, 130]], "long-forms": [[97, 125]]}, {"text": " 1 Introduction As Machine Translation (MT) systems become widely adopted both for gisting purposes and to", "acronyms": [[40, 42]], "long-forms": [[19, 38]]}, {"text": "Huang and Chiang, 2005), which is used to represent all derivations (i.e. parse trees) for a given  sentence under a context free grammar (CFG). A ", "acronyms": [[139, 142]], "long-forms": [[117, 137]]}, {"text": " 6. Decision Tree (DT) - with 12,782 MWEs of D5.", "acronyms": [[19, 21]], "long-forms": [[4, 17]]}, {"text": "We conducted experiments on a number of different datasets: (1) the English Wall Street Journal (WSJ) part of the Penn Treebank (Marcus et al, 1993) with standard POS", "acronyms": [[97, 100], [163, 166]], "long-forms": [[76, 95]]}, {"text": "Elfardy H. and Diab M. 2012. Simplified guidelines for the creation of large scale dialectal arabic annotations. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC), Istanbul, Turkey. Elfardy H. and Diab M. 2013.", "acronyms": [[202, 206]], "long-forms": [[167, 185]]}, {"text": "construction relies on existing natural language processing tools, e.g., syntactic parsers (Wiebe, 2000), information extraction (IE) tools (Riloff and Wiebe, 2003) or rich lexical resources such", "acronyms": [[130, 132]], "long-forms": [[106, 128]]}, {"text": "review  ? Product feature level (PFL)  ?", "acronyms": [[33, 36]], "long-forms": [[10, 31]]}, {"text": "Combining keyphrase and collocation Yamamoto and Church (2001) compare two metrics, MI and Residual IDF (RIDF), and observed that MI is suitable for finding collocation and RIDF", "acronyms": [[105, 109], [84, 86], [130, 132], [173, 177]], "long-forms": [[91, 103]]}, {"text": "The scores are lowercased BLEU calculated on the held-out devtest set. NE = named entities. ", "acronyms": [[71, 73], [26, 30]], "long-forms": [[76, 90]]}, {"text": "redundancy at low and medium allophonic complexities, estimated by the Jaccard indices between their false positives (FP) and false negatives (FN). ", "acronyms": [[118, 120], [143, 145]], "long-forms": [[101, 116], [126, 141]]}, {"text": "or certain part-of-speech tags (e.g., interjection).8 4.2.3 Performance of the formality classifier We trained a Maximum Entropy (MaxEnt) classifier in the Mallet package (McCallum, 2002).", "acronyms": [[130, 136]], "long-forms": [[113, 128]]}, {"text": "six different domains: Newswire (NW), Broadcast News (BN), Broadcast Conversations (BC), Webblog (WL), Usenet (UN), and Conversational Telephone Speech (CTS).", "acronyms": [[111, 113], [33, 35], [54, 56], [84, 86], [98, 100], [153, 156]], "long-forms": [[103, 109], [23, 31], [38, 52], [59, 82], [89, 96], [120, 151]]}, {"text": "vector built from training set. However, this  could lead to many out of vocabulary (OOV)  cases, in addition to long vector.", "acronyms": [[85, 88]], "long-forms": [[66, 83]]}, {"text": "Pr(f |e) Pr(e) (2) where Pr(f |e) is the translation model and Pr(e) is the target language model (LM). This ap-", "acronyms": [[99, 101]], "long-forms": [[83, 97]]}, {"text": "Researchers have ex-plored the topic of CLI in the areas of lexical style (Jarvis et al 2012a), lexical n-grams (Jarvis & Paquot, 2012), character n-grams (Tsur & Rappo-prot, 2007), using variables related to cohesion, lexical sophistication, syntactic complexity and conceptual knowledge (Crossley & McNamara, 2012), error patterns (Bestgen, et al 2012; Wong & Dras, 2009), and a combination of these ap-proaches (Jarvis et al 2012b; Koppel et al 2005; Mayfield Tomokiyo & Jones, 2001, Wong & Dras, 2009).  Such studies have demonstrated relatively strong success rates for classifying an L2 writing sample based on the L1 of the writer. For instance, Jarvis and Paquot (2012), using 1-4-grams as pre-dictor variables on a subset of argumentative es-says included in the International Corpus of Learner English (ICLE) (Granger et al 2009) achieved a 53.6% classification accuracy for 12 groups of L1s. Crossley and McNamara (2012) used features related to cohesion, lexical sophisti-cation, syntactic complexity, and conceptual knowledge taken from the computational tool Coh-", "acronyms": [[813, 817], [40, 43], [590, 592], [621, 623]], "long-forms": [[772, 811]]}, {"text": "4.2 Preprocessing Part?Whole Lexico-Syntactic Patterns Since our discovery procedure is based on the semantic information provided by WordNet, we need to preprocess the noun phrases (NPs) extracted by the three clusters considered and identify the potential part and the whole concepts.", "acronyms": [[183, 186]], "long-forms": [[169, 181]]}, {"text": " 3.1 The Beta Process and the Bernoulli process The beta process(BP) (Thibaux and Jordan, 2007; Paisley and Carin, 2009) and the related Indian buf-", "acronyms": [[65, 67]], "long-forms": [[52, 64]]}, {"text": "1 In t roduct ion   Finding base noun phrases is a sensible first step  for many natural anguage processing (NLP) tasks:  Accurate identification of base noun phrases is ar- ", "acronyms": [[109, 112]], "long-forms": [[81, 107]]}, {"text": "Tipster (ADEPT) Program is a demonstration project  aimed at alleviating problems currently being faced by  the Office of Information Resources (OIR). OIR has ", "acronyms": [[145, 148], [9, 14], [151, 154]], "long-forms": [[112, 143]]}, {"text": "bilities. Experience has shown that this kind of  full-fledged question answering (QA) over texts  from a wide range of domains is so difficult for ", "acronyms": [[83, 85]], "long-forms": [[63, 81]]}, {"text": " means a type of source ? newswire (NW), broadcast news (BN), broadcast conversation (BC), mag-", "acronyms": [[36, 38], [57, 59], [86, 88]], "long-forms": [[26, 34], [41, 55], [62, 84]]}, {"text": " The first principle of a search engine is based  on shallow Natural Language Processing (NLP)  techniques, for instance, string matching, while ", "acronyms": [[90, 93]], "long-forms": [[61, 88]]}, {"text": "ity? have been designed so far for French L1 and only one for French as a foreign language (FFL) (see Section 2).", "acronyms": [[92, 95], [42, 44]], "long-forms": [[62, 90]]}, {"text": "restrictive relative clauses, and epithets ? trigger conventional implicatures (CI) whose truth is necessarily presupposed, even if the truth conditions", "acronyms": [[80, 82]], "long-forms": [[53, 78]]}, {"text": " scores cw(ei) are combined: MEAN CM (cM (eI1)) is computed as the geometric mean of the confidence scores of the", "acronyms": [[34, 36]], "long-forms": [[38, 40]]}, {"text": "NST = Noun Stem V-FLEX = Verbal Inflsxion  PRN = Pronoun A-FLEX = Adjectival Inflexion  CA = Case CL = Inflsxion Class GD = Gender MD = Mode  PF ~ Predicate Form PS = Person TN = Tense ", "acronyms": [[98, 100], [131, 133], [0, 3], [16, 22], [43, 46], [57, 63], [88, 90], [119, 121], [142, 144], [162, 164], [174, 176]], "long-forms": [[93, 97], [136, 140], [6, 15], [25, 41], [49, 56], [66, 86], [113, 118], [124, 130], [147, 161], [167, 173], [179, 184]]}, {"text": "siderable interest in robust knowledge extraction, both as an end in itself and as an intermediate step in a variety of Natural Language Processing (NLP) applications.", "acronyms": [[149, 152]], "long-forms": [[120, 147]]}, {"text": "Most common approaches to language model adaptation, such as count merging and model interpolation, are special cases of maximum a posteriori (MAP) estimation (Bacchiani and Roark, 2003).", "acronyms": [[143, 146]], "long-forms": [[121, 141]]}, {"text": "its nondecomposability, as well as a cross between B??? and word error rate (WER) that is decomposable down to the subsentential level (in a sense to be", "acronyms": [[77, 80]], "long-forms": [[60, 75]]}, {"text": "imated conversational characters from recordings of human performance. ACM Transactions on Graphics (TOG), 23(3):506?513.", "acronyms": [[101, 104], [71, 74]], "long-forms": [[75, 99]]}, {"text": "tagging. These errors in the training corpora affects badly to the machine learning (ML) based models. ", "acronyms": [[85, 87]], "long-forms": [[67, 83]]}, {"text": "1 Introduction After two decades of steady progress, research in statistical machine translation (SMT) started to cross its path with translation industry with tan-", "acronyms": [[98, 101]], "long-forms": [[65, 96]]}, {"text": " ? Shift(SH): Push NEXT onto the stack. ", "acronyms": [[9, 11], [19, 23]], "long-forms": [[3, 8]]}, {"text": "The availability of large scale data sets of manually annotated predicate?argument structures has recently favored the use of machine learning approaches to the design of automated semantic role labeling (SRL) systems. The main research in this area relates to the design choices", "acronyms": [[205, 208]], "long-forms": [[181, 203]]}, {"text": "formance. They are the One-error Loss (O-Loss) function, the Symmetric Loss (S-Loss) function, and the Hierarchical Loss (H-Loss) function:", "acronyms": [[77, 83], [39, 45], [122, 128]], "long-forms": [[61, 75], [23, 37], [104, 120]]}, {"text": "The generator  uses as its linguistic resource a lexicon encoded in a version  of Categorial Grammar (CG), the extension of which with  rules of function composition gives rise to a problem of ", "acronyms": [[102, 104]], "long-forms": [[82, 100]]}, {"text": "(01) AT (Singular Article)  (03) BED (were)  (05) BEG (being)  (07) BER (are, 're) ", "acronyms": [[50, 53], [5, 7], [33, 36], [68, 71]], "long-forms": [[55, 60], [18, 25], [38, 42], [73, 81]]}, {"text": "contains two data sets, training and devtest, which were used for training and testing, respectively. Each of these sets is further divided into three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews).", "acronyms": [[170, 175], [218, 223], [189, 195]], "long-forms": [[160, 168], [202, 216], [178, 187]]}, {"text": "event extraction primarily rely on elaborately designed features and complicated natural language processing (NLP) tools. ", "acronyms": [[110, 113]], "long-forms": [[81, 108]]}, {"text": "Results are shown through comparison against Latent Dirichlet Allocation (LDA), a parametric Bayesian model employed by Brody and Lapata (2009) for this task.", "acronyms": [[74, 77]], "long-forms": [[58, 72]]}, {"text": "(1987) presents in his Case grid.  Case Analysis (CA) extracts the acts and Case  constellations around them from the structure ", "acronyms": [[50, 52]], "long-forms": [[35, 48]]}, {"text": " On the other hand, the decline in performance for the composite feature vector baseline (CFV) may be attributed to the data sparseness phenomenon", "acronyms": [[90, 93]], "long-forms": [[55, 79]]}, {"text": "(AvgToRecipients) in emails sent by p, the percentage of emails p received in which he/she was in the To list (InToList%), boolean features denoting whether p added or removed people when", "acronyms": [[111, 120], [1, 16]], "long-forms": [[95, 109], [43, 53]]}, {"text": "Finally, it is clear from Figure 6 that certain relations are particularly difficult for both parsers. For example, indirect object (IObj) dependents are low scoring nodes: this is because they are often attached to the correct head but are", "acronyms": [[133, 137]], "long-forms": [[116, 131]]}, {"text": "Associated Press Worldstream English Service (APW) ? The New York Times Newswire Service (NYT) ? The Xinhua News Agency English Service (XIE) For each source, Gigaword articles are classified into several types, including newswire advisories, etc.  We restricted our investigations to actual news stories.", "acronyms": [[137, 140], [46, 49], [90, 93]], "long-forms": [[101, 135], [0, 28], [57, 71]]}, {"text": "3.2 Machine Learning Framework SVM-Light (Joachims, 1999), an implementation of Support Vector Machines (SVM), is used for the classification task.", "acronyms": [[105, 108], [31, 40]], "long-forms": [[80, 103]]}, {"text": "2013 Association for Computational Linguistics FCG offers a similar grammar engineering framework that follows the principles of Construction Grammar (CxG) (Goldberg 2003; Hoffmann and Trousdale 2013). CxG", "acronyms": [[151, 154], [47, 50], [202, 205]], "long-forms": [[129, 149]]}, {"text": "28  Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 39?47, October 25, 2014, Doha, Qatar.", "acronyms": [[82, 86], [23, 28]], "long-forms": [[46, 80]]}, {"text": " 1 Overv iew o f  the  IPS  pro jec t   The IPS (Interactive Parsing System) research  project, at the Linguistics Departement of the ", "acronyms": [[44, 47], [23, 26]], "long-forms": [[49, 75]]}, {"text": "for acquiring high quality non-expert knowledge from on-demand workforce using Amazon Mechanical Turk (MTurk). We show how ", "acronyms": [[103, 108]], "long-forms": [[86, 101]]}, {"text": "(see, e.g., (Moschitti, 2006) for more details).  Syntactic Tree Kernel (STK), also known as a subset tree kernel (Collins and Duffy, 2002), maps", "acronyms": [[73, 76]], "long-forms": [[50, 71]]}, {"text": "Lexical Entropy (LexH) -0.26 1.00 0.01 -0.40 0.43 -0.38 -0.03 0.02 0.11 -0.29 Syntactic Surprisal (SynS) 0.00 0.01 1.00 -0.12 0.08 0.18 0.77 0.21 0.38 -0.03 Lexical Surprisal (LexS) 0.24 -0.40 -0.12 1.00 -0.81 0.87 -0.10 -0.20 -0.35 0.64 Unigram Frequency (Freq) -0.24 0.43 0.08 -0.81 1.00 -0.69 0.02 0.18 0.31 -0.72", "acronyms": [[176, 180], [17, 21], [99, 103], [257, 261]], "long-forms": [[157, 174], [0, 15], [78, 97], [246, 255]]}, {"text": "then X Y =~ Z  then Y X ::~ Z  Permutation Closure of language L (PermL)  PermL = { s \\[ s' in L and s is a per- ", "acronyms": [[66, 71], [74, 79]], "long-forms": [[31, 64]]}, {"text": "ENTITY_A appos Figure 2: Dependency tree (DT) for the entity blinded sentence ?", "acronyms": [[42, 44]], "long-forms": [[25, 40]]}, {"text": " Therefore it makes sense to also extract data from machine readable dictionaries (MRDs). ", "acronyms": [[83, 87]], "long-forms": [[52, 81]]}, {"text": "Mihael Arcan and Paul Buitelaar Unit for Natural Language Processing, Digital Enterprise Research Institute (DERI) National University of Ireland Galway (NUIG)", "acronyms": [[109, 113], [154, 158]], "long-forms": [[70, 107], [115, 152]]}, {"text": "Ney discounting and interpolation. The evaluation of stream counts is done on EP+afe+nyt (EAN) corpus, consisting of 1.1 billion words.", "acronyms": [[90, 93]], "long-forms": [[78, 88]]}, {"text": "4.1 English training sets To train an SVO metaphor classifier, we employ the TroFi (Trope Finder) dataset. ", "acronyms": [[77, 82], [38, 41]], "long-forms": [[84, 96]]}, {"text": "usually similar with that in word sense disambiguation (WSD), including bag of word lemmas  in the sentence, n-grams and parts of speech (POS)  in a window, etc.", "acronyms": [[138, 141], [56, 59]], "long-forms": [[121, 136], [29, 54]]}, {"text": "tice to both characteristics mentioned above. The central construct in this framework is  that of context factor (CF). A CF is defined by a scope, which is a collection of individ- ", "acronyms": [[114, 116], [121, 123]], "long-forms": [[98, 112]]}, {"text": "questions evaluated in TREC1. For example questions 1The Text REtrieval Conferences (TREC) are evaluation workshops in which Information Retrieval tasks are annually", "acronyms": [[85, 89], [23, 27]], "long-forms": [[57, 83]]}, {"text": "There are three options: French (FR), Spanish (SP), or, Merged languages (ML), where the results are obtained by merging the English output of FR", "acronyms": [[74, 76], [33, 35], [47, 49], [143, 145]], "long-forms": [[56, 72], [25, 31], [38, 45]]}, {"text": "Natural Language Processing (NLP) techniques can be leveraged in detecting events from voluminous social media data. Events are associated with entities and NLP techniques can be applied to extract the entities that are mentioned in the text that defines an event. To perform Named Entity Recognition (NER) on tweets Ritter et. al. (", "acronyms": [[302, 305]], "long-forms": [[276, 300]]}, {"text": "While initial-state ECR provides a measure of the likelihood of a favorable outcome, it does not address how well a particular state representation captures key decision points. That is, it does not directly represent the extent to which each deci-sion along the path to a successful outcome con-tributed to that outcome, or whether the second-best decision in a particular state would have been equally useful. In order to measure this dif-ference, we introduce the Separation Ratio (SR), which represents how much better a particular policy is compared to its alternatives. SR for a state is calculated by taking the absolute differ-ence between the estimated values of two actions in that state and dividing by the mean of the two values.", "acronyms": [[485, 487], [576, 578], [20, 23]], "long-forms": [[467, 483]]}, {"text": ")( bwN We use the corpus provided by IR task of  NTCIR2 (NTCIR 2002) as the training set to  compute the mutual information of words.", "acronyms": [[49, 55], [37, 39]], "long-forms": [[57, 67]]}, {"text": "ABSTRACT  French auxilliaries and clitics have been analysed  in the flame of U.C.G. (Unification Categorial Grammar). ", "acronyms": [[78, 84]], "long-forms": [[86, 116]]}, {"text": "slightly simplified version of Webber's original rule  schema, says that for any formula that meets the  structural description (SD), a discourse ntity identified  by the ID formula is to be constructed.", "acronyms": [[129, 131], [171, 173]], "long-forms": [[105, 127]]}, {"text": "mantic relations between referents. This task has a long tradition in natural language processing (NLP) since the early days of artificial intelligence (Web-", "acronyms": [[99, 102]], "long-forms": [[70, 97]]}, {"text": " For all NER experiments, we use a sequential firstorder conditional random field (CRF) with a unit variance Normal prior, trained with L-BFGS until", "acronyms": [[83, 86], [9, 12], [136, 142]], "long-forms": [[57, 81]]}, {"text": "In the next experiments, we run experiments across three different locales in Places domain: United Kingdom (GB), Australia (AU), and India (IN).", "acronyms": [[125, 127], [109, 111], [141, 143]], "long-forms": [[114, 123], [93, 107], [134, 139]]}, {"text": "case. In this paper, we investigate using Amazon?s Mechanical Turk (MTurk) to make MT test sets cheaply.", "acronyms": [[68, 73]], "long-forms": [[51, 66]]}, {"text": "3.1 Div is ion  and  L inear l i za t ion  o f   Cases   At first, we define a translation pattern (TPi) as fol-  lows.", "acronyms": [[100, 103]], "long-forms": [[79, 98]]}, {"text": "the feature structures which are associated with each node, which prohibit certain compositions, are not shown. Note also that this is not a lexicalised TAG (LTAG). This is somewhat unusual; we intend, as", "acronyms": [[158, 162]], "long-forms": [[141, 156]]}, {"text": "five different linear classifiers to extract PPI from AIMed: L2-SVM, 1-norm soft-margin SVM (L1-SVM), logistic regression (LR) (Fan et al, 2008), averaged perceptron (AP) (Collins,", "acronyms": [[123, 125], [45, 48], [61, 67], [88, 91], [93, 99], [167, 169]], "long-forms": [[102, 121], [146, 165]]}, {"text": "we will describe in detail in Section 3. They then  introduced a ClueWordSummarizer (CWS), a  graph-based unsupervised summarization ap-", "acronyms": [[85, 88]], "long-forms": [[65, 83]]}, {"text": "2004. On clusterings: Good, bad and spectral. Journal of the ACM (JACM), 51(3):497?515.", "acronyms": [[66, 70]], "long-forms": [[46, 64]]}, {"text": "known as conditional random fields (CRFs) (Lafferty et al, 2001), when all variables are observed, and as hidden conditional random fields (HCRFs) (Quattoni et al, 2007), when only a subset of the variables are", "acronyms": [[140, 145], [36, 40]], "long-forms": [[106, 138], [9, 34]]}, {"text": "assignment. We use a generative model based on a Dirichlet Process (DP) defined over composed rules.", "acronyms": [[68, 70]], "long-forms": [[49, 66]]}, {"text": "TDP (target only) 62.60 33.04 Table 2: Results Generalized average precision (GAP) is a more precise measure than P", "acronyms": [[78, 81], [0, 3]], "long-forms": [[47, 76]]}, {"text": "mechanism for accurate named entity  (NE) translation in English?Chinese  question answering (QA). This mecha-", "acronyms": [[94, 96], [38, 40]], "long-forms": [[74, 92], [23, 35]]}, {"text": "matrix of the IBM Model 1. However, there is a signficant out of vocabulary (OOV) issue in the model since training data is limited.", "acronyms": [[77, 80], [14, 17]], "long-forms": [[58, 75]]}, {"text": "comparability between documents that are  chosen for exploitation in the current research,  are Mutual Infromation (MI) and Normalized  Mutual Infroamtion (NMI).", "acronyms": [[116, 118], [156, 159]], "long-forms": [[96, 114], [124, 154]]}, {"text": "Translation retrieval (TR) is a description of this process of selecting from the TM a set of translation records (TRecs) of maximum L1 similarity to a given input.", "acronyms": [[115, 120], [23, 25], [82, 84]], "long-forms": [[94, 113], [0, 21]]}, {"text": " ? Named entity (NE) representation in KBs poses another NED challenge.", "acronyms": [[17, 19], [39, 42], [57, 60]], "long-forms": [[3, 15]]}, {"text": "sic and Young, 2011; Williams, 2010; Young et al., 2010) and Bayesian network (BN)-based methods (Raux and Ma, 2011; Thomson and Young,", "acronyms": [[79, 81]], "long-forms": [[61, 77]]}, {"text": "grammatical features from a diachronic corpus of academic English, and visualise our extraction results with Structured Parallel Coordinates (SPC), a tool for the visualisation of structured multidi-", "acronyms": [[142, 145]], "long-forms": [[109, 140]]}, {"text": "features. Stolcke et al (1998) then expanded the prosodic tree model with a hidden event language model (LM) to identify sentence boundaries, filled pauses and IPs in", "acronyms": [[105, 107]], "long-forms": [[89, 103]]}, {"text": "The Multi-Perspective Question-Answering (MPQA) newswire corpus (Wilson and Wiebe, 2005) and the J. D. Power & Associates (JDPA) automotive review blog post (Kessler et al, 2010)", "acronyms": [[123, 127], [42, 46]], "long-forms": [[97, 121], [4, 40]]}, {"text": "even for very high-dimensional data.  4.2 Open Directory Project (ODP) Open Directory Project (ODP)7 is a multilingual", "acronyms": [[66, 69], [95, 98]], "long-forms": [[42, 64], [71, 93]]}, {"text": "programming alignment on the recognizer?s  hypothesis (HYP) and the non-literal transcription  that is used as reference (REF).  The alignment ", "acronyms": [[122, 125], [55, 58]], "long-forms": [[111, 120], [43, 53]]}, {"text": "constructions. The notion of construction is similar to the one in Construction Grammar (CxG)4, as in (Goldberg, 1995), where:", "acronyms": [[89, 92]], "long-forms": [[67, 87]]}, {"text": "idea was an early version of branching entropy, one of the experts in VE, and they developed an algorithm called Phoneme to Morpheme (PtM) around it. ", "acronyms": [[134, 137], [70, 72]], "long-forms": [[113, 132]]}, {"text": "3 Estimation  We estimate a model?s distributions with  probabilistic decision trees (DTs).4 We build  decision trees using the WinMine toolkit ", "acronyms": [[86, 89]], "long-forms": [[70, 84]]}, {"text": "The set of ncs in ? are selected from all the possibilities in the hyponym hierarchy according to the minimum description length (MDL) principle (Rissanen 1978) as used by Li and Abe (1995, 1998).", "acronyms": [[130, 133]], "long-forms": [[102, 128]]}, {"text": "the percentage of tokens that are assigned the correct head and dependency label, as well as the unlabeled attachment score (UAS), that is, the percentage of tokens with the correct head, and the label accuracy (LA), that is, the percentage of tokens with the correct dependency label.", "acronyms": [[212, 214], [125, 128]], "long-forms": [[196, 210], [97, 123]]}, {"text": "language processing. Specifically, stochastic finitestate transducers (SFSTs) have proved to be useful for machine translation tasks within restricted do-", "acronyms": [[71, 76]], "long-forms": [[35, 69]]}, {"text": " 1.1 Language Modeling Formally, a language model (LM) is a probability distribution over strings of a language:", "acronyms": [[51, 53]], "long-forms": [[35, 49]]}, {"text": "Knowledge-free induction of morphology using latent semantic analysis. In Proceedings of the Conference on Natural Language Learning 2000 (CoNLL-2000), pages 67?72, Lisbon, Portugal.", "acronyms": [[139, 149]], "long-forms": [[93, 137]]}, {"text": " 3.4.1 Arabic Named Entity Recognition Named Entity Recognition (NER) is a subtask of information extraction, where each proper name in", "acronyms": [[65, 68]], "long-forms": [[39, 63]]}, {"text": "2011a.  Overview of the Infectious Diseases (ID) task of BioNLP Shared Task 2011.", "acronyms": [[45, 47], [57, 63]], "long-forms": [[24, 43]]}, {"text": "conceptualizing the relation of coincidence or proximity with the whole  Landmark (LM) when it is conceived as a  point.", "acronyms": [[83, 85]], "long-forms": [[73, 81]]}, {"text": " 1 Introduction Machine translation (MT) systems have different strengths and weaknesses which can be exploited", "acronyms": [[37, 39]], "long-forms": [[16, 35]]}, {"text": " 1 Introduction Mental State Verbs (MSVs), such as think, know, and want, are very frequent in child-directed lan-", "acronyms": [[36, 40]], "long-forms": [[16, 34]]}, {"text": "The variants of random walk topic models are compared against LDA and the relational topic model (RTM), each with 100 topics (Chang and Blei, 2010).", "acronyms": [[98, 101], [62, 65]], "long-forms": [[74, 96]]}, {"text": "Implicit Incongruity (IMP) Boolean Incongruity of extracted implicit phrases (Rilof et.al, 2013) Explicit Incongruity (EXP) Integer Number of times a word follows a word of opposite polarity", "acronyms": [[119, 122], [22, 25]], "long-forms": [[97, 105]]}, {"text": " ? Adjuncts (AM-): General arguments that any verb may take optionally.", "acronyms": [[13, 16]], "long-forms": [[3, 11]]}, {"text": "Chunking Tree (CT) 86.17 86.21 Linear Features (Kl) 90.79 90.46 Kl w/o using LM feature (Kl-LM) 84.24 84.06 Composite Kernel (Kc: MST+Kl) 92.98 92.67", "acronyms": [[89, 94], [15, 17], [48, 50], [130, 133], [134, 136]], "long-forms": [[64, 79], [0, 13]]}, {"text": "The parser uses a semantic grammar with approx-  imately 1000 rules which maps the input sentence  onto an interlingua representation (ILT) which rep-  resents the meaning of the sentence in a language- ", "acronyms": [[135, 138]], "long-forms": [[107, 133]]}, {"text": "hypernym, hyponym, near-synonym, holonym, and mernoym are listed as below:  Hypernym(HYP) (a) IF x=ANT ", "acronyms": [[85, 88], [99, 102]], "long-forms": [[76, 83]]}, {"text": "Again, even the Table 5 Precision (PD), recall (RD), and F-measure (FD) for malapropism detection with five measures of semantic relatedness, varying the scope of the search for related words to 1, 3, or 5 paragraphs", "acronyms": [[35, 37], [48, 50], [68, 70]], "long-forms": [[24, 33], [40, 46], [57, 66]]}, {"text": "summarizing the work of the Corpora and Performance  Evaluation Committee (CPEC) of the DARPA Spoken Language  Systems (SLS) Program, with specific reports from several  working groups which have been dealing with various aspects ", "acronyms": [[120, 123], [75, 79], [88, 93]], "long-forms": [[94, 118], [28, 73]]}, {"text": "In Proc, of the lOth Pacific Asia  Conference on Language, Information and Com-  putation (PACLING), pages 163-172. ", "acronyms": [[91, 98], [3, 7]], "long-forms": [[21, 89]]}, {"text": "joining grammars. In Proceedings of the 12 th International  Conference on Computational Linguistics (COLING'88),  Budapest, Hungary, August 1988.", "acronyms": [[102, 111]], "long-forms": [[61, 100]]}, {"text": "6.2 Methodology We conducted experiments on MUC-6, ACE-2004, and ACE Phrase-2 (ACE-2). We evaluated our sys-", "acronyms": [[79, 84], [44, 47], [51, 54]], "long-forms": [[65, 77]]}, {"text": "middle value of 6.5, was tested.  The Lexile-like measure (LX) used the same two features as the Lexile measure: mean log frequency", "acronyms": [[59, 61]], "long-forms": [[38, 44]]}, {"text": "Abstract Microblogs are a popular way for users to communicate and have recently caught the attention of researchers in the natural language processing (NLP) field. However, regardless of their rising", "acronyms": [[153, 156]], "long-forms": [[124, 151]]}, {"text": "No 0 12 23 292 Table 4: Confusion matrix (SVM) for argument component classification (MC = Major Claim; Cl = Claim; Pr = Premise; No = None)", "acronyms": [[86, 88], [42, 46], [104, 106], [116, 118], [130, 132]], "long-forms": [[91, 102], [109, 114], [121, 128], [135, 139]]}, {"text": "Donnell, 1982).  Def in i t ion 1 A deterministic tree automaton (DTA)  is a 5-tuple M = (Q, ~, ~, qo, F), where Q is a finite ", "acronyms": [[66, 69]], "long-forms": [[36, 64]]}, {"text": "clickthrough data. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pages 133?142.", "acronyms": [[84, 87], [22, 25], [26, 32]], "long-forms": [[47, 75]]}, {"text": "nese kanji and words. The currently available  JWAD Version 1 (JWAD-V1) consists of  104,800 free word association responses col-", "acronyms": [[63, 70]], "long-forms": [[47, 61]]}, {"text": "  ME Classification  ME (Maximum Entropy) classification is used here  to directly estimate the posterior probability for ", "acronyms": [[21, 23], [2, 4]], "long-forms": [[25, 40]]}, {"text": "discussion in Ritchie(1984).  Functional unification (FU) grammar is a  grammatical formalism which allows descriptions of ", "acronyms": [[54, 56]], "long-forms": [[30, 52]]}, {"text": "tics.  Linguistic Data Consortium (LDC). 2013.", "acronyms": [[35, 38]], "long-forms": [[7, 33]]}, {"text": "guided learning. The approach taken has been to en-  code an artificial neural network (ANN) in a genome  which stores its architecture and learning rules.", "acronyms": [[88, 91]], "long-forms": [[61, 86]]}, {"text": "sponsored by the U.S. government. ACE 2004  defined 7 major entity types: PER (Person), ORG  (Organization), FAC (Facility), GPE (Geo-Political ", "acronyms": [[74, 77], [17, 20], [34, 37], [88, 91], [109, 112], [125, 128]], "long-forms": [[79, 85], [94, 106], [114, 122], [130, 143]]}, {"text": " Recently, there have been increasing interests for dialogue act (DA) recognition in spoken and written conversations, which include meetings,", "acronyms": [[66, 68]], "long-forms": [[52, 64]]}, {"text": "recognition) which describes a relationship between an input signal sequence and a word, the other is a language model (LM) which measures the likelihood of a sequence of words as a sen-", "acronyms": [[120, 122]], "long-forms": [[104, 118]]}, {"text": "I.e., we consider three increasingly constrained conditions: (1) substitution according only to the form constraints (FORM), (2) substitution according to both form and taboo", "acronyms": [[118, 122]], "long-forms": [[100, 104]]}, {"text": "?  Figure 2: Hierarchical Dirichlet Process (HDP) for WSI. ", "acronyms": [[45, 48], [54, 57]], "long-forms": [[13, 43]]}, {"text": "On all test sets, and for both the evaluation metrics used, the results achieved by the classifier built from the automatically annotated training set (AA) produces lower error rates (Weighted FPR-FDR)", "acronyms": [[152, 154], [193, 200]], "long-forms": [[114, 146]]}, {"text": "of binary relations that vary in length and since a  question representation (SRq) can be answered by a  sentence candidate (SRc) that includes more information  than the question specified, the Arity constraint i~ revised ", "acronyms": [[125, 128], [78, 81]], "long-forms": [[105, 123], [53, 76]]}, {"text": "data. The QA surveys are evaluated using nuggets drawn from citation texts (CT), or abstracts (AB), and DP surveys are evaluated using nuggets from", "acronyms": [[76, 78], [95, 97], [10, 12], [104, 106]], "long-forms": [[60, 74], [84, 93]]}, {"text": "ing (NLP) applications. In Information Retrieval (IR) and Question Answering (QA) it is typically termed query/question expansion (Moldovan and", "acronyms": [[78, 80], [5, 8], [50, 52]], "long-forms": [[58, 76], [27, 48]]}, {"text": "Spanish data set as Trec4S.  We used a Chinese-English lexicon from the  Linguistic Data Consortium (LDC). We pre- ", "acronyms": [[101, 104]], "long-forms": [[73, 99]]}, {"text": "8  end if  Active characters are discussed in the section about identifying the SC (Section 8),  because the raison d'etre of the active-character component of an interpretation is that ", "acronyms": [[80, 82]], "long-forms": [[84, 91]]}, {"text": "Reverse Gap 0.072 0.033 Table 1: Percentage of reordering patterns ` reverse gap (RG): The two source phrases are not adjacent, and are in the reverse order as", "acronyms": [[82, 84]], "long-forms": [[69, 80]]}, {"text": "The query-based selection model utilizes Support Vector Regression (SVR) models to predict the mean average precision (MAP) of each query from the ambiguity measures, and to choose an ap-", "acronyms": [[119, 122]], "long-forms": [[95, 117]]}, {"text": "consist of two verbs. The first  verb is termed as Full Verb (FV) that is present  at surface level either as conjunctive participial ", "acronyms": [[62, 64]], "long-forms": [[51, 60]]}, {"text": "1 will refer to pa~rs   primarily oriented towards the former goal as Practical Parsers (PP) and refer  to the others as Performance Model Parsers (PMP). With these distinctions ", "acronyms": [[148, 151], [89, 91]], "long-forms": [[121, 146], [70, 86]]}, {"text": "ging from Merialdo (1994). The approach involved training a standard Hidden Markov Model (HMM) using the Expectation Maximization (EM) algo-", "acronyms": [[90, 93], [131, 133]], "long-forms": [[69, 88], [105, 129]]}, {"text": "It is a comprehensive study but not directly related to ours, as we model our problem with Markov Decision Processes (MDP) and evaluate model-based and model-free algorithms on a", "acronyms": [[118, 121]], "long-forms": [[91, 116]]}, {"text": "UMLS Metathesaurus version 2003AC, the string mammectomy has been assigned the concept-unique identifier C0024881 (CUI), the lemma-unique identifier L0024669 (LUI), and the string-unique identifier S0059711 (SUI).", "acronyms": [[115, 118], [0, 4], [27, 33], [159, 162], [208, 211]], "long-forms": [[105, 113], [125, 157], [173, 206]]}, {"text": "derstanding our approach.  2.1.1 The Conversat ional  Roles Model  (COR)   In the field of information retrieval (IR) the interactive ", "acronyms": [[68, 71], [114, 116]], "long-forms": [[52, 65], [91, 112]]}, {"text": "The target set is built using the ? 88-?89 Wall Street Journal Corpus (WSJ) tagged using the (Ratnaparkhi, 1996) tagger and", "acronyms": [[71, 74]], "long-forms": [[43, 62]]}, {"text": " The  noun phrases we ex-  tract start with an optional determiner (DT)  or  possessive pronoun (PRP$) ,  followed by  a se-  quence of cardinal numbers  (CDs),  adjectives ", "acronyms": [[97, 101], [68, 70], [155, 158]], "long-forms": [[77, 95], [56, 66], [136, 144]]}, {"text": "natural_object(NOBJ) substance(SUB)  food(FOOD) artifact(AFT) article(ART)  location(LOC) psych_feature(PSY)  cognition(COG) feeling(FEEL) ", "acronyms": [[85, 88], [104, 107], [15, 19], [31, 34], [42, 46], [57, 60], [70, 73], [120, 123], [133, 137]], "long-forms": [[76, 84], [90, 102], [0, 14], [21, 30], [37, 41], [48, 56], [62, 69], [110, 119], [125, 132]]}, {"text": "ents) *100%  ? F1-score = 2*P*R / (P+R)  Two correctness criteria are used for constitu-", "acronyms": [[35, 38]], "long-forms": [[26, 31]]}, {"text": "of the set of terminal symbols) or empty strings. A Phrase Structure Tree (PST) is a tree in which all and only the leaf nodes are labeled with words or", "acronyms": [[75, 78]], "long-forms": [[52, 73]]}, {"text": "ficient. The remainder of the data can be partially addressed with noun phrase (NP) detectors (Abney, 1991; Ramshaw and Marcus, 1995; Mu?noz et", "acronyms": [[80, 82]], "long-forms": [[67, 78]]}, {"text": "of conditional random fields. In Annual Meeting of the Association for Computational Linguistics (ACL), pages 870?878.", "acronyms": [[98, 101]], "long-forms": [[55, 96]]}, {"text": "tying the feature parameters. In particular, we perform maximum entropy (MaxEnt) estimation over the conditional distribution using second-order gra-", "acronyms": [[73, 79]], "long-forms": [[56, 71]]}, {"text": "cation), TMP (time), DIS (discourse connectives), PRP (purpose) or DIR (direction). Negations (NEG) and modals (MOD) are also marked.", "acronyms": [[95, 98], [9, 12], [21, 24], [50, 53], [67, 70], [112, 115]], "long-forms": [[84, 93], [26, 35], [55, 62], [72, 81], [104, 110]]}, {"text": "As noted by Melamed (2000), the problem of finding the best set of links is the maximum-weighted bipartite matching (MWBM) problem: Given a weighted bipartite graph G = (V1 ? V2, E) with", "acronyms": [[117, 121]], "long-forms": [[107, 115], [159, 164]]}, {"text": "words, from this the subscript b (bag-of-words).  Subtree Kernel (SbtK) is one of the simplest tree kernels as it only generates complete subtrees, i.e.,", "acronyms": [[66, 70]], "long-forms": [[50, 64]]}, {"text": "tures. Since the Parallel Alignment TreeBank is a subset of the Chinese TreeBank (CTB) 8.0, we automatically parsed the CTB 8.0 by doing a 10-", "acronyms": [[82, 85], [120, 123]], "long-forms": [[64, 80]]}, {"text": "  Definition: Asymmetric nearest common  ancestor (ANCA)  The asymmetric nearest common ancestors from ", "acronyms": [[51, 55]], "long-forms": [[14, 49]]}, {"text": "1 The  SCAN System  SCAN was developed for the TREC-96 SDR task,  a known item information retrieval (IR) task from  approximately 47hours of the NIST/DARPA HUB4 ", "acronyms": [[102, 104], [47, 51], [55, 58], [146, 156], [157, 160]], "long-forms": [[79, 100]]}, {"text": "are not very demanding on resources: Inverse Consultation (IC) (Tanaka and Umemura, 1994) and Distributional Similarity (DS) (Kaji et al, 2008), their strong points and weaknesses, and proposed", "acronyms": [[121, 123], [59, 61]], "long-forms": [[94, 119], [37, 57]]}, {"text": "[NP : [XNOUNS : MERINO'S (NOUN) HOME (NOUN)] ] [NP : [XNOUNS : MERINO'S (NOUN)] ] [VP : [VERB_GROUP : HOME (VERB)] ] [XPPS : [PP : IN (PREPOSITION )", "acronyms": [[102, 106], [48, 50], [83, 85], [126, 128], [7, 13], [54, 60], [118, 122]], "long-forms": [[89, 99], [1, 3]]}, {"text": " 2003. Social Communication Questionnaire (SCQ). ", "acronyms": [[43, 46]], "long-forms": [[7, 41]]}, {"text": "mfly@sky.ru Abstract YARN (Yet Another RussNet) project started in 2013 aims at creating a large", "acronyms": [[21, 25]], "long-forms": [[27, 46]]}, {"text": "Format: type_of_word TAG type_of_word TAG ...  NN = Noun, NN-PL = Plural Noun  DET = Determiner, PREP = Preposition  POS = Possessive, J J = Adjective ", "acronyms": [[79, 82], [97, 101], [21, 24], [38, 41], [47, 49], [58, 63], [117, 120], [135, 138]], "long-forms": [[85, 95], [104, 115], [52, 56], [66, 77], [123, 133], [141, 150]]}, {"text": "the fragment space that can describe all the trees in Ms. Fragment Mining and Indexing (FMI) In Equation 1 it is possible to isolate the gradient ~w =?", "acronyms": [[88, 91]], "long-forms": [[58, 86]]}, {"text": "task. As reported in (Liu et al 2013a), we used a genetic algorithm (GA) (Cormen et al 2001) to au80", "acronyms": [[69, 71]], "long-forms": [[50, 67]]}, {"text": "interface.  The PRIDES User Interface Layer (PUI) is  responsible for creating and managing the screen ", "acronyms": [[45, 48]], "long-forms": [[16, 37]]}, {"text": "The most comparable tools to MT-EQuAl are PET (Aziz et al., 2012), COSTA (Chatzitheodorou and Chatzistamatis, 2013), TAUS DQF framework,", "acronyms": [[67, 72], [29, 36], [42, 45], [117, 121], [122, 125]], "long-forms": [[74, 108]]}, {"text": "assumption of which is the stratificational  approach to sentence analysis pursued by  Functional Sentence Perspective (FSP), a  linguistic theory developed by Jan Firbas in the ", "acronyms": [[120, 123]], "long-forms": [[87, 118]]}, {"text": "SemEval 2012 competition for evaluating Natural  Language Processing (NLP) systems presents a  new task called Semantic Textual Similarity (STS)  (Agirre et al, 2012).", "acronyms": [[140, 143], [70, 73]], "long-forms": [[111, 138], [40, 68]]}, {"text": " 4.1 BRAT The brat rapid annotation tool (BRAT) is an opensource web-based annotation tool that supports a", "acronyms": [[42, 46]], "long-forms": [[14, 40]]}, {"text": "corpora. For the preposition and determiner errors, we adopt a statistical machine translation (SMT)based approach, aiming at correcting errors in con-", "acronyms": [[96, 99]], "long-forms": [[63, 94]]}, {"text": "adapt the model to character or word level, or limit  the conversion target to only noun or expand it to  other Part of Speech (POS) tags, a series of  experiments has been performed.", "acronyms": [[128, 131]], "long-forms": [[112, 126]]}, {"text": "Associative Texture Is Lost In Translation. In Proceedings  of the Workshop on Discourse in Machine Translation (DiscoMT),  pages 27?32. ACL 2013 Conference, ", "acronyms": [[113, 120], [137, 140]], "long-forms": [[79, 111]]}, {"text": " The constructed ontology is evaluated using  cluster purity (CP), instances knowledge (IK),  and relation concept (RC).", "acronyms": [[62, 64], [88, 90], [116, 118]], "long-forms": [[46, 60], [67, 86], [98, 114]]}, {"text": "in the V column indicates that the verb conditions were used in the distance measure. LR = labeled recall; LP = labeled precision.", "acronyms": [[86, 88], [107, 109]], "long-forms": [[91, 105], [112, 129]]}, {"text": "4.2 Results Table 3 shows the results of our compression models by compression rate (CompR), dependencybased F1 (F1-Dep), and SRL-based F1 (F1-SRL).", "acronyms": [[85, 90], [126, 129], [140, 147]], "long-forms": [[67, 83]]}, {"text": " Reference:  MedLine sample # 6  Autonym:  decoy receptor 3 (DcR3)  Information a soluble decoy receptor  ", "acronyms": [[61, 65]], "long-forms": [[43, 59]]}, {"text": " Conventional machine learning techniques, such as Hidden Markov Model (HMM) and Maximum Entropy Model (ME), normally require a careful", "acronyms": [[72, 75], [104, 106]], "long-forms": [[51, 70], [81, 96]]}, {"text": "for our experiment: Telecommunication Services (TS, the sector with the smallest number of companies), Information Technology (IT), and Consumer Staples (CS), due to our familiarity with the", "acronyms": [[127, 129], [48, 50], [154, 156]], "long-forms": [[103, 125], [20, 46], [136, 152]]}, {"text": "bringert@chalmers.se Abstract Grammatical Framework (GF) is a grammar formalism which supports interlingua-", "acronyms": [[53, 55]], "long-forms": [[30, 51]]}, {"text": "ways available. We therefore generate the training data using a na??ve phrase aligner (NPA) instead of resorting to a real one.", "acronyms": [[87, 90]], "long-forms": [[64, 85]]}, {"text": "2 D IA        1 In order to test this hypothesis,            1   a double-stranded oligonucleotide probe that corresponds to bp +10 to +60 of the CCR3 gene was prepared, 3 0 NN            referred to as E1-FL (exon 1- full length, Figure 2A). 3 D A    1 1   This is the exact sequence 3 D N          that was deleted in the CCR3(-exon1).pGL3 plasmid 3 D N          that demonstrated decreased activity 3 D N      1   compared to the full length 1.6 kb construct [27].", "acronyms": [[203, 208], [146, 150], [174, 176], [324, 328]], "long-forms": [[210, 229]]}, {"text": "majority instances of all the clusters.   Mutual information (MI) is more theoretically  well-founded than purity.", "acronyms": [[62, 64]], "long-forms": [[42, 60]]}, {"text": "integral to membrane  membrane  The protein encoded by this gene is a receptor for interleukin 20 (IL20), a cytokine that may be involved in epidermal function.", "acronyms": [[99, 103]], "long-forms": [[83, 97]]}, {"text": "(Vehicle). Each mention of an entity has a mention  type: NAM (proper name), NOM (nominal) or                                                            ", "acronyms": [[77, 80]], "long-forms": [[82, 89]]}, {"text": " 0.7  0  20  40  60  80  100  120  140 information density (ID)Fisher information (FIR)query-by-committee (SVE)random NLPBA", "acronyms": [[60, 62], [83, 86], [107, 110], [118, 123]], "long-forms": [[39, 58], [63, 69]]}, {"text": "We tested the Arabic sentiment system on two existing Arabic datasets (Mourad and Darwish (2013) (MD) and Refaee and Rieser (2014a) (RR)) and two newly sentiment-annotated Arabic datasets (BBN", "acronyms": [[98, 100]], "long-forms": [[117, 123]]}, {"text": "However, we are interesting in the potential power of our model by incorporating lexical reordering (LR) models and comparing it with syntax-based models.", "acronyms": [[101, 103]], "long-forms": [[81, 99]]}, {"text": "each new domain and scenario, as discussed in the next section.  The lexical analysis module (LexAn) is responsible for splitting the document into sentences, and the sentences into tokens.", "acronyms": [[94, 99]], "long-forms": [[69, 85]]}, {"text": "(Zhao et al, 2014), The Meaning Factory (Bjerva et al, 2014), UNAL-NLP (Jimenez et al, 2014), and Illinois-LH (Lai and Hockenmaier, 2014). ", "acronyms": [[107, 109], [62, 70]], "long-forms": [[111, 130]]}, {"text": "There are two main threads in the research of paraphrasing, i.e., paraphrase recognition and paraphrase generation (PG). Paraphrase", "acronyms": [[116, 118]], "long-forms": [[93, 114]]}, {"text": "data. The first is a parser trained on the standard training sections of the PennTreebank (PTB) and the second is a parser trained on the training por-", "acronyms": [[91, 94]], "long-forms": [[77, 89]]}, {"text": "the Switchboard corpus.1 The standard measure of error used in ASR is word error rate (WER), computed as 100(I + D + S)/R, where I,D and S are the number of inser-", "acronyms": [[87, 90], [63, 66]], "long-forms": [[70, 85]]}, {"text": "1 Introduction Statistical machine translation (MT) uses large target language models (LMs) to improve the fluency of generated texts, and it is commonly", "acronyms": [[87, 90], [48, 50]], "long-forms": [[70, 85], [27, 46]]}, {"text": "It allows for testing interaction scenarios that employ one or more Language Technology Components (LTC). ", "acronyms": [[100, 103]], "long-forms": [[68, 98]]}, {"text": " 2 Story Segmentation using Modified Kmeans (MKM) Clustering The first step in multi-document summarization is", "acronyms": [[45, 48]], "long-forms": [[28, 43]]}, {"text": "The following are  typlcal relation names: NT (narrower term); PT (part); FUN (function);  SYN (syntax); EG (example). ", "acronyms": [[91, 94], [43, 45], [47, 60], [63, 65], [74, 77], [105, 107]], "long-forms": [[96, 102], [67, 71], [79, 87], [109, 116]]}, {"text": "System and Datasets We use the Moses phrasebased MT system (Koehn et al, 2007) and consider Urdu?English (UR?EN), Chinese?English (ZH?EN) translation, and Arabic?English", "acronyms": [[106, 111]], "long-forms": [[92, 104]]}, {"text": "various subsets of the documents in the English Gigaword corpus, chiefly drawn from New York Times (NYT) and Agence France Presse (AFP).1 2.1 Are Discounts Constant?", "acronyms": [[131, 134], [100, 103]], "long-forms": [[109, 129], [84, 98]]}, {"text": "and WLLR in this paper.  3.3 Information Gain (IG)  IG measures the number of bits of information ", "acronyms": [[47, 49], [4, 8], [52, 54]], "long-forms": [[29, 45]]}, {"text": " 1 Introduction Named entity recognition (NER) is the most studied information extraction (IE) task.", "acronyms": [[42, 45], [91, 93]], "long-forms": [[16, 40], [67, 89]]}, {"text": "In Proceedings  from the 16th International Conference on  Computational Linguistics (COLING-96), pages  592-597.", "acronyms": [[86, 95]], "long-forms": [[59, 84]]}, {"text": "We evaluated our Chinese word segmenter in the open track, on all 4 corpora, namely Academia Sinica (AS), City University of Hong Kong (CITYU), Microsoft Research (MSR), and", "acronyms": [[101, 103], [136, 141], [164, 167]], "long-forms": [[84, 99], [106, 121], [144, 162]]}, {"text": "than three thousand five hundred days of imprisonment .  Figure 4: Example translation using the back-off and the continuous space language model (CSLM). ", "acronyms": [[147, 151]], "long-forms": [[114, 145]]}, {"text": "called CPDB. We used these clues to build a Small Dataset (SD) and a Large Dataset (LD) for reranking.", "acronyms": [[84, 86], [7, 11], [59, 61]], "long-forms": [[69, 82], [44, 57]]}, {"text": "side were installed from 2003 to 2005.?  3.4 Sentence Reordering (RE) Some of the transformation operations results in", "acronyms": [[66, 68]], "long-forms": [[54, 64]]}, {"text": "freely available framenets for a number of languages (Boas, 2009), among these the Swedish FrameNet (SweFN) (Borin et al, 2010).5", "acronyms": [[101, 106]], "long-forms": [[83, 99]]}, {"text": "In that case partial semantic mapping will take place where no Logical Form is being built and only referring expressions are asserted in the Discourse Model ? but see below.  3.2 Lexical Information The output of grammatical modules is then fed onto the Binding Module(BM) which activates an algorithm for anaphoric binding in LFG (see [13]) terms using f-structures as domains and grammatical functions as entry points into the structure. We show here below the architecture of the system.", "acronyms": [[270, 272], [328, 331]], "long-forms": [[255, 268]]}, {"text": " University of Chicago Given a constraint set with k constraints in the framework of Optimality Theory (OT), what is its capacity as a classification scheme for linguistic data?", "acronyms": [[104, 106]], "long-forms": [[85, 102]]}, {"text": "machine learning algorithm is used to discover the morph set of the language in question, using minimum description length (MDL) as an optimization criterion.", "acronyms": [[124, 127]], "long-forms": [[96, 122]]}, {"text": "on Artificial Intelligence (KI2002), volume 2479 of Lecture Notes in Artificial Intelligence (LNAI), pages 18?32, Aachen, Germany, September. ", "acronyms": [[94, 98], [28, 34]], "long-forms": [[52, 92]]}, {"text": "maps: 2-d space-filling approach. ACM Transactions on Graphics (TOG), 11(1):92?99. ", "acronyms": [[64, 67], [34, 37]], "long-forms": [[38, 62]]}, {"text": "niscent of balanced-tree structures using left and right  rotations. A left rotation changes a (A(BC)) structure to  a ((AB)C) structure, and vice versa for a right rotation.", "acronyms": [[96, 100], [120, 126]], "long-forms": [[69, 92]]}, {"text": "related NIST metric (Doddington 2002), along with WER and PER, have been widely used by many machine translation researchers. The Translation Edit Rate (TER) (Snover et al 2006) and the CDER measure (Leusch, Ueffing, and Ney 2006) are based on the edit", "acronyms": [[153, 156], [8, 12], [50, 53], [58, 61], [186, 190]], "long-forms": [[130, 151]]}, {"text": "Wiebe, 2000).  4.1.4 Strong Polar Expressions (STROPO) Instead of adding intensifiers in order to put more", "acronyms": [[47, 53]], "long-forms": [[21, 45]]}, {"text": "They are the One-error Loss (O-Loss) function, the Symmetric Loss (S-Loss) function, and the Hierarchical Loss (H-Loss) function: ?", "acronyms": [[112, 118], [29, 35], [67, 73]], "long-forms": [[93, 110], [13, 27], [51, 65]]}, {"text": "Proceedings of the Fourteenth  International Joint Conference in Artificial  Intelligence (IJCAI?95), pp. 1395 ?", "acronyms": [[91, 99]], "long-forms": [[77, 89]]}, {"text": "many-to-one word-level alignments produced by the IBM series models (Brown et al, 1993) or the Hidden Markov Model (HMM) (Vogel et al, 1996).", "acronyms": [[116, 119], [50, 53]], "long-forms": [[95, 114]]}, {"text": "show how to construct MWE-aware training resources for them.  The corpora used in our experiments are the Penn Arabic Treebank (ATB) (Maamouri et al2004) and the French Treebank (FTB) (Abeill?,", "acronyms": [[128, 131], [22, 31], [179, 182]], "long-forms": [[111, 126], [162, 177]]}, {"text": "General-type: region Specific type: RCC Spatial value: PP (proper part) Dynamic", "acronyms": [[55, 57], [36, 39]], "long-forms": [[59, 70]]}, {"text": "unigram model (BoW)+HI, where in addition to representing what words occur in a text, we also represent what Harvard Inquirer (HI)3 word classes occur in it.", "acronyms": [[127, 129], [15, 18], [20, 23]], "long-forms": [[109, 125]]}, {"text": "Youtube2text: Recognizing and describing arbitrary activities using semantic hierarchies and zero-shot recognition. In IEEE International Conference on Computer Vision (ICCV), December.", "acronyms": [[169, 173], [119, 123]], "long-forms": [[124, 167]]}, {"text": "Hidden topic markov models. In Artificial Intelligence and Statistics (AISTATS), San Juan, Puerto Rico. ", "acronyms": [[71, 78]], "long-forms": [[31, 69]]}, {"text": "on its n?1 previous tokens, i.e. we directly model the following conditional probability (in practice, we choose n = 3, Tri-gram (TRI) ): p(w", "acronyms": [[130, 133]], "long-forms": [[120, 123]]}, {"text": " It is a Neo-Reichenbachian representation (Reichenbach,  1966) in that its s imple tense s t ructures  (STSs) re-  late the following three entities: the time of the event ", "acronyms": [[105, 109]], "long-forms": [[76, 102]]}, {"text": " 2.3 Named Entity Recognition Named Entity Recognition (NER) is the task of finding all instances of explicitly named entities", "acronyms": [[56, 59]], "long-forms": [[30, 54]]}, {"text": "ping observed sequences to possible ground truth sequences.  We do not use the Character Error Rate (CER) metric, since for almost all NLP applications the unit of", "acronyms": [[101, 104], [135, 138]], "long-forms": [[79, 99]]}, {"text": "these basic models for email conversations.  4.1 Latent Dirichlet Allocation (LDA) Our first model is the probabilistic LDA model", "acronyms": [[78, 81], [120, 123]], "long-forms": [[49, 76]]}, {"text": "Chinese research and applications. We refer to it  as CLO (Chinese Lexical Ontology). In addition ", "acronyms": [[54, 57]], "long-forms": [[59, 83]]}, {"text": "605  NP- - - -NP:NP NP=S:N I '  VP~-VP:VP  S~---S:S  NP=NI ' :PP  NP~-PP :NP  VP=VP:NP  S=S:N I '   NP  ~.-~NP :VP  PP -~-PP :PP  VP=VP:P I  ) S~S:  ", "acronyms": [[56, 58], [5, 7], [14, 16], [17, 19], [20, 22], [32, 38], [39, 41], [53, 55], [62, 64], [66, 72], [74, 76], [78, 80], [100, 102], [112, 114], [116, 118], [126, 128], [130, 132]], "long-forms": [[59, 62], [81, 86], [90, 93], [133, 137]]}, {"text": "Sentence) and McDonald (2006) on a sentence-by-sentence basis. Table 1 shows the compression rates (CompR) for the three systems and evaluates the quality of their output using grammatical relations F1.", "acronyms": [[100, 105]], "long-forms": [[81, 98]]}, {"text": "After grammatical ambiguities are removed  by the stochastic parser, the phrase is divided  into noun phrases(NP) and verb phrases(VP),  giving, ", "acronyms": [[110, 112], [131, 133]], "long-forms": [[97, 108], [118, 129]]}, {"text": "The TRIPS system here uses a wide range of statistically driven preprocessing, including part of speech tagging, constituent bracketing, inter-pretation of unknown words using WordNet, and named-entity recognition (Allen et al 2008). All these are generic off-the-shelf resources that ex-tend and help guide the deep parsing process.  The TRIPS LF (logical form) ontology1 is de-signed to be linguistically motivated and domain independent. The semantic types and selectional restrictions are driven by linguistic considera-tions rather than requirements from reasoning components in the system (Dzikovska et al 2003).", "acronyms": [[345, 347], [339, 344], [4, 9]], "long-forms": [[349, 361]]}, {"text": "(A~.TG, ~ROC)I ^  (SUBS, SUSU, VT),  (ARTG, PR.OC)I ^  (SUBS, SUSU, VT)2  , ARTG = article g~n&al  SUBS = substantif  compl~ment ", "acronyms": [[76, 80], [99, 103], [4, 6], [9, 12], [19, 23], [25, 29], [31, 33], [38, 42], [44, 49], [56, 60], [62, 66], [68, 70]], "long-forms": [[83, 97], [106, 116]]}, {"text": "in this paper. We choose the classical optimization algorithm limited memory BFGS (L-BFGS) (Liu and Nocedal, 1989).", "acronyms": [[83, 89]], "long-forms": [[62, 81]]}, {"text": " An alternative paradigm is to view error correction as a statistical machine translation (SMT) problem from ?", "acronyms": [[91, 94]], "long-forms": [[58, 89]]}, {"text": " 3.1 Ske le ta l  Phrase  S t ructure  Component   The role of phrase structure (PS) rules in our parser is similar to  their role in Lexical Functional Grammar \\[Kaplan 83\\], however they ", "acronyms": [[81, 83]], "long-forms": [[63, 79]]}, {"text": "word in context. In this article we present a WSD algorithm based on random walks over large Lexical Knowledge Bases (LKB). We show that our algorithm performs better than other graph-", "acronyms": [[118, 121], [46, 49]], "long-forms": [[93, 116]]}, {"text": "For each text pair on four cross levels, i.e., Paragraph to Sentence (P-S), Sentence to Phrase (S-Ph), Phrase to Word (Ph-W) and Word to Sense (W-Se), participants are required to re-", "acronyms": [[119, 123]], "long-forms": [[103, 117]]}, {"text": ", VP ...... Others (OTHER): The remaining cases of comma receive the OTHER label, indicating they do", "acronyms": [[20, 25]], "long-forms": [[12, 18]]}, {"text": "we used two other error-annotated learner corpora.  The NUS Corpus of Learner English (NUCLE) contains one million words of academic writing", "acronyms": [[87, 92]], "long-forms": [[56, 85]]}, {"text": "query, and their performance asymptotes by the time they get to the second query.  This effect is confirmed by an analysis of variance (ANOVA)8, which shows a highly significant effect of order of presentation (F = 9.8427; p< .0001).", "acronyms": [[136, 141]], "long-forms": [[114, 134]]}, {"text": "spect to the ISSC. We will refer to this expanded version of the SSC as the processed SSC (PSSC). ", "acronyms": [[91, 95], [13, 17], [65, 68]], "long-forms": [[76, 89]]}, {"text": "the vertex of the Abox which it expresses. Our current model uses the Tree Adjoining Grammar (TAG) formalism, see Joshi (1987), and the Atree acts as a", "acronyms": [[94, 97]], "long-forms": [[70, 92]]}, {"text": "task yet to be tackled by TM but identified as an important potential application for it (Lewin et al 2008): Cancer Risk Assessment (CRA). Over the", "acronyms": [[133, 136], [26, 28]], "long-forms": [[109, 131]]}, {"text": "294  The surface phonetic tones are:  LC = low constant (in Baule, only initial)  HC = high constant (only initial) ", "acronyms": [[38, 40], [82, 84]], "long-forms": [[43, 55], [87, 100]]}, {"text": "both tasks together would be desirable. In this section, we propose the use of factorial CRF (F-CRF) (Sutton et al, 2007), which has previously been", "acronyms": [[94, 99]], "long-forms": [[79, 92]]}, {"text": "clude substitution, splitting and merging statistics. Given  an input (ASCII) word, and the above statistics, candidate  (corrupted) words are generated based on simulating and pro- ", "acronyms": [[71, 76]], "long-forms": [[61, 69]]}, {"text": "22M 35.88 27.16 30.20 36.21 27.26 30.48 -0.33 -0.10 -0.28 Table 2: BLEU Score results for the Spanish Treelet Penalty experiments EX Treelet Phrasal Diff (T-P) Req Log WMT 2009 WMT 2010 Req Log WMT 2009 WMT 2010 Req Log WMT 2009 WMT 2010", "acronyms": [[155, 158], [67, 71], [130, 132], [177, 180], [194, 197], [203, 206], [220, 223], [229, 232]], "long-forms": [[133, 148]]}, {"text": "ciently or accurately than alternative approaches.  Constraint Programming (CP) is a field of research that develops algorithms and tools for", "acronyms": [[76, 78]], "long-forms": [[52, 74]]}, {"text": "AT(- +)  Stems to which the suffixes +ation and +ative may  attach are marked as (AT +), while those taking the  corresponding forms +ion and +ive are (AT -).", "acronyms": [[82, 86], [152, 154], [0, 2]], "long-forms": [[60, 66]]}, {"text": "Introduction  In a large natural language processing system,  such as a machine translation system (MTS), am-  biguity resolution is a critical problem.", "acronyms": [[100, 103]], "long-forms": [[72, 98]]}, {"text": "search tool, but it is insufficient for domain-  specific text, such as that encountered in  the MUCs (Message Understanding Confer-  ences).", "acronyms": [[97, 101]], "long-forms": [[103, 132]]}, {"text": "can formulate natural language-like patterns as exploratory queries for relations against a text corpus.  We draw inspiration from the information seeking paradigm of Exploratory Search (ES) (Marchionini, 2006; White and Roth, 2009), where users start with a vaguely defined information need and - with a mix", "acronyms": [[187, 189]], "long-forms": [[167, 185]]}, {"text": " 3.1 LSTMs for sequence generation A Recurrent Neural Network (RNN) is a generalization of feed forward neural networks to se-", "acronyms": [[63, 66], [5, 10]], "long-forms": [[37, 61]]}, {"text": "We parse each corpus sentence pair using the OpenCCG parser to yield a logical form (LF) as a semantic dependency graph with the gold-standard alignments projected", "acronyms": [[85, 87], [45, 52]], "long-forms": [[71, 83]]}, {"text": "To tackle this challenge, we incorporate multiple graphs probabilistic factorization with two alternatively designed combination strategies into collaborative topic regression (CTR). Experimental results on real dataset demonstrate", "acronyms": [[177, 180]], "long-forms": [[145, 175]]}, {"text": " Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that con-", "acronyms": [[77, 80]], "long-forms": [[53, 75]]}, {"text": " The CBDF similarity values between  100,000-word subsets of Original French (OF),  French translated from English (EF), from ", "acronyms": [[78, 80], [5, 9], [116, 118]], "long-forms": [[61, 76], [84, 114]]}, {"text": " 2007. The Syntax Augmented MT (SAMT) system at the Shared Task for the 2007 ACL Workshop on", "acronyms": [[32, 36], [77, 80]], "long-forms": [[11, 30]]}, {"text": "most blogged about articles? of the New York Times (NYT)1. ", "acronyms": [[52, 55]], "long-forms": [[36, 50]]}, {"text": "tion system; then the output is classified into a  small number of domain-specific classes called  Domain Acts (DAs) that can indicate directly to  the dispatcher the general intended meaning of ", "acronyms": [[112, 115]], "long-forms": [[99, 110]]}, {"text": "TEXT), DECL (Declarative), HON (Honorific), IMPER (Imperative), NOM (Nominative), ORTH (ORTHOGRAPHY), PST (Past), SYN (SYNTAX), SEM (SEMANTICS), RELS (RELATIONS), and POS (part of speech).", "acronyms": [[102, 105], [7, 11], [27, 30], [44, 49], [64, 67], [82, 86], [114, 117], [128, 131], [145, 149], [167, 170]], "long-forms": [[107, 111], [13, 24], [32, 41], [51, 61], [69, 79], [88, 99], [119, 125], [133, 142], [151, 160], [172, 186]]}, {"text": "a generalization of the Semitic root-and-template modeling. We use Egyptian Arabic (EGY), and German (GER) as our test languages.", "acronyms": [[84, 87], [102, 105]], "long-forms": [[67, 75], [94, 100]]}, {"text": "1985) in which Tree Adjoining Grammars fall. 3 Since the  set of Tree Adjoining Languages (TALs) is a strict super-  set of the set of Context Free Languages, in order to define ", "acronyms": [[91, 95]], "long-forms": [[65, 89]]}, {"text": "ence.  Semantic Textual Similarity (STS) is the task of judging the similarity of two sentences on a scale", "acronyms": [[36, 39]], "long-forms": [[7, 34]]}, {"text": " PRECISE (Popescu, Etzioni, and Kautz 2003) 88.0 88.0 ZC05 (Zettlemoyer and Collins 2005) 79.3 ? ", "acronyms": [[54, 58]], "long-forms": [[60, 88]]}, {"text": "Nearly 2,500 sets of related words in  LLOCE are organized according to 14 subjects and 129 topics (TOP). Cross references (REF) between sets,  topics, and subjects are also given to show various inter-sense r lations not captured within the same topic.", "acronyms": [[124, 127]], "long-forms": [[112, 122]]}, {"text": "our system; where we achieved 0.627 top1 accuracy for Japanese transliterated to Japanese Kanji(JJ), 0.713 for English-toChinese(E2C) and 0.510 for English-to-", "acronyms": [[96, 98], [129, 132]], "long-forms": [[81, 94], [111, 128]]}, {"text": "ghar.  Parse: The modern town of [NP (np Mumbai)  (punct ,) (advP about 50 km south of Navi ", "acronyms": [[34, 36], [61, 65]], "long-forms": [[38, 40]]}, {"text": "3.3 Adapting the POS tagset (STTS) To account for important differences between modern and Early Modern German (EMG), and to facilitate more accurate searches, we adapted the STTS", "acronyms": [[112, 115], [17, 20], [29, 33], [175, 179]], "long-forms": [[91, 110]]}, {"text": "1 Introduction Visualizing Web search results remains an open problem in Information Retrieval (IR). For exam-", "acronyms": [[96, 98]], "long-forms": [[73, 94]]}, {"text": "Building on the error analysis of the rule-based approach, we replace the rule-based component with support vector machine (SVM) classifiers trained on partial event annotation in the form of", "acronyms": [[124, 127]], "long-forms": [[100, 122]]}, {"text": " Results and Analysis  A finite state machine (FSM) description of user be-  havior was used to analyze session data.", "acronyms": [[47, 50]], "long-forms": [[25, 45]]}, {"text": "In order to capture the compositional effects with higher accuracy, we propose a new model called the Recursive Neural Tensor Network (RNTN). Recur-", "acronyms": [[135, 139]], "long-forms": [[102, 133]]}, {"text": "University of Southern California  Los Angeles, California 90089  Abstract Tiffs paper describes Kind Types (KT), a system which uses  commonsense knowledge to reason about natural anguage text.", "acronyms": [[109, 111]], "long-forms": [[97, 107]]}, {"text": "Ihe maohine translation problem has recently been replaced  by much narrower goals and computer processing of language has  become part df artificial intelligence (AI), speech recognition,  and structural pattern recognition.", "acronyms": [[164, 166]], "long-forms": [[139, 162]]}, {"text": "here we only consider clusters which contain at least one ? Person (PER)? entity.", "acronyms": [[68, 71]], "long-forms": [[60, 66]]}, {"text": "Abstract This paper suggests two ways of improving semantic role labeling (SRL). First, we intro-", "acronyms": [[75, 78]], "long-forms": [[51, 73]]}, {"text": "The approach involved training a standard Hidden Markov Model (HMM) using the Expectation Maximization (EM) algorithm (Dempster et al.,", "acronyms": [[104, 106], [63, 66]], "long-forms": [[78, 102], [42, 61]]}, {"text": "The DlmSum Summarization Clientprovldes a sum-  mary of a document in multiple dlmeuslons through  a graphical user interface (GUI) to smt dflferent  users' needs In contrast o a static view of a doc- ", "acronyms": [[127, 130]], "long-forms": [[101, 125]]}, {"text": "fer to semantically similar words. We have applied the Markov Cluster algorithm (MCL) (van Dongen, 2000) to group semantically similar terms together.", "acronyms": [[81, 84]], "long-forms": [[55, 79]]}, {"text": "is encoded in the attributes MODALITY and POLARITY. Modality at the syntactic level is encoded as an attribute of the tag SLINK (Subordination Link), which can have several values: factive, counterfactive, evidential, negative evidential, modal,", "acronyms": [[122, 127]], "long-forms": [[129, 147]]}, {"text": "Two-liners generated by three different algorithms were evaluated by each subject: Script model + Concept clustering (SM+CC) Both script opposition and incongruity are", "acronyms": [[118, 123]], "long-forms": [[83, 116]]}, {"text": "phrase (BADVP), base noun phrase (BNP),  73  base temporal phrase (BTN), base location  phrase (BNS), base verb phrase (BVP) and ", "acronyms": [[67, 70], [8, 13], [34, 37], [96, 99], [120, 123]], "long-forms": [[45, 65], [16, 32], [102, 118], [73, 94]]}, {"text": "We labeled the Reddit dataset using crowdworkers on Amazon Mechanical Turk (AMT), creating the first public corpus annotated with levels of dogmatism.", "acronyms": [[76, 79]], "long-forms": [[52, 74]]}, {"text": " In integrating this approach into a dialog system, we see that the dialog manager (DM) no longer determines surface strings to send to the TTS system, as is often the case in current dialog systems.", "acronyms": [[84, 86], [140, 143]], "long-forms": [[68, 82]]}, {"text": "Each accuracy measure is shown in a column, including the segmentation F-score (SF ), the overall tagging 894", "acronyms": [[80, 82]], "long-forms": [[58, 72]]}, {"text": "sociations to a number of affect categories including the six Ekman emotions (joy, sadness, anger, fear, disgust, and surprise).3 General Inquirer (GI) (Stone et al, 1966) has 11,788 words labeled with 182 cat-", "acronyms": [[148, 150]], "long-forms": [[130, 146]]}, {"text": "ailehor ~  The following entry is associated with the class of  verbs taking an NP as indirect objects(IOBJ) which  may be possibly found within a prepositional phrase or ", "acronyms": [[103, 107], [80, 82]], "long-forms": [[86, 101]]}, {"text": "in table 4. As we can see a small improvement is obtained for the interpretation error rate (IER) with the integrated strategy (strat2).", "acronyms": [[93, 96]], "long-forms": [[66, 91]]}, {"text": "Pseudo-disambiguation results for inverse selectional preferences (BNC as primary and secondary corpus, DISCR weighting). ER = Error rate; Cov = Coverage. ", "acronyms": [[122, 124]], "long-forms": [[127, 137]]}, {"text": "But still we can say that even in languages with  that kind of structural properties like Slavic languages have, named entities (NE) form a subset of  natural language expressions that demonstrates ", "acronyms": [[129, 131]], "long-forms": [[113, 127]]}, {"text": "3.4 Example  of  in tegrat ion   Figure 3 shows the starting point of an integra-  tion process with the trigger word (TW) lelter, its  definition, its temporary graph (TG), the concept ", "acronyms": [[119, 121], [169, 171]], "long-forms": [[105, 117], [152, 167]]}, {"text": "1 Reinforcement Learning in Dialogue Machine Learning techniques, and particularly Reinforcement Learning (RL), have recently received great interest in research on dialogue man-", "acronyms": [[107, 109]], "long-forms": [[83, 105]]}, {"text": "6 Scope Resolution One way of dealing with scope ambiguities is by using underspecified representations (URs). A", "acronyms": [[105, 108]], "long-forms": [[73, 103]]}, {"text": "C STORE SPEECH WAVE POINT  C  NBUF (NPT) =IFIX(YN)  750 CONTINUE ", "acronyms": [[36, 39], [47, 49]], "long-forms": [[30, 34]]}, {"text": "For POS tagging, the three main error categories are the confusion between adverbs (AD) and verbs with an  adverbial force, between measure words (M) and ", "acronyms": [[84, 86], [4, 7]], "long-forms": [[75, 82], [132, 139]]}, {"text": "We review the hierarchical Dirichlet document (HDD) model in section 2, and present our proposed hierarchical Dirichlet tree (HDT) document model in section 3.", "acronyms": [[126, 129], [47, 50]], "long-forms": [[97, 124], [14, 45]]}, {"text": "edge associated with it.  Definition 3 (Informative Feature Extraction (IF)) We define the Informative-Features(IF ) feature", "acronyms": [[72, 74], [112, 114]], "long-forms": [[40, 59], [91, 110]]}, {"text": "the set of required domains. Various classification systems were considered, including the Dewey Decimal Classification (DDC) and Universal Decimal Classification (UDC). These schemes, however, are", "acronyms": [[164, 167], [121, 124]], "long-forms": [[130, 162], [91, 119]]}, {"text": "amples in 3.2).  In section 4, we describe the  specification of Korean TimeML (KTimeML). ", "acronyms": [[80, 87]], "long-forms": [[65, 78]]}, {"text": "the sentences produced. Additionally, automated machine translation (MT) metrics are explored to quantify the amount of information missing from", "acronyms": [[69, 71]], "long-forms": [[48, 67]]}, {"text": "ings. The technique employed is adapted from unsupervised word sense disambiguation (WSD). ", "acronyms": [[85, 88]], "long-forms": [[58, 83]]}, {"text": "word w is defined as the largest connected subgraph that contains w. For each content  9 Other thesauri have been used for WSD, e.g., the German Hallig-Wartburg (see Schmidt \\[1988, 1991\\])  and the Longman Lexicon of Contemporary English (LLOCE) (Chen and Chang, this volume). ", "acronyms": [[240, 245], [123, 126]], "long-forms": [[199, 238]]}, {"text": " 1 Introduction Information extraction (IE) systems generally consist of multiple interdependent components, e.g., en-", "acronyms": [[40, 42]], "long-forms": [[16, 38]]}, {"text": "Noun Variation (NV) ? Adjective Variation (AdjV) ?", "acronyms": [[43, 47]], "long-forms": [[22, 41]]}, {"text": " ? LEAD (lead-based): n% sentences are chosen from the beginning of the text.", "acronyms": [[3, 7]], "long-forms": [[9, 13]]}, {"text": "Recently, a number of deep-learning based models have been proposed for the task of Visual Question Answering (VQA). The per-", "acronyms": [[111, 114]], "long-forms": [[84, 109]]}, {"text": "2.1 Purver, Ginzburg and Healey (PGH) Purver, Ginzburg and Healey (2003) investigated CRs in the British National Corpus (BNC) (Burnard, 2000).", "acronyms": [[122, 125], [33, 36], [86, 89]], "long-forms": [[97, 120], [4, 31]]}, {"text": "We  describe our approach towards building a Wordnet for Tunisian dialect (TD). We proceed, first-", "acronyms": [[75, 77]], "long-forms": [[57, 73]]}, {"text": " 3 Dataset & Experimental Setup We use the First Certificate in English (FCE) ESOL examination scripts2 (upper-intermediate level as-", "acronyms": [[73, 76]], "long-forms": [[43, 71]]}, {"text": "of MT and HT in terms of the following two ratios, LC = lexical cohesion devices / content words, RC = repetition / content words. ", "acronyms": [[98, 100], [3, 5], [10, 12], [51, 53]], "long-forms": [[103, 123], [56, 72]]}, {"text": "Transactions of the Association for Computational Linguistics (TACL), 1:25?36. ", "acronyms": [[63, 67]], "long-forms": [[0, 61]]}, {"text": "is a.t least cubic in t, ime, this fl)llows trivially  fronl the inequality  A a+B a <A a+:C4 ~B+aAB=+B a =(A+B)  a  for A,B positive - length of strings) ", "acronyms": [[108, 111]], "long-forms": [[94, 103]]}, {"text": " Symptom name recognition rate (RRdet),  recognition error rate (RERdet) and recognition  F-Measure (RFMdet): these metrics are designed ", "acronyms": [[65, 71], [32, 37], [101, 107]], "long-forms": [[41, 63], [14, 30], [77, 99]]}, {"text": " The absence of reliable single-sentence estimates points to a gap in natural language processing (NLP) research.", "acronyms": [[99, 102]], "long-forms": [[70, 97]]}, {"text": "uation contained in the RST Discourse Treebank (RST-DTB)(Carlson et al 2001) distributed by the Linguistic Data Consortium (LDC)3. The RST-DTB", "acronyms": [[124, 127], [48, 55], [135, 142]], "long-forms": [[96, 122], [24, 46]]}, {"text": "summaries, we have shown the effects of syntactic and shallow-semantic features over the bag of words (BOW) features. ", "acronyms": [[103, 106]], "long-forms": [[89, 101]]}, {"text": "features to argument classification models, but also  represent full parsing information as constraints in  integer linear programs (ILP) to resolve label inconsistencies.", "acronyms": [[133, 136]], "long-forms": [[108, 131]]}, {"text": "Total 2,910 1,086 3,996 Table 1: Number of annotated elements per category in our gold standard (CR=controlled requirements, UR=uncontrolled requirements)", "acronyms": [[97, 99], [125, 127]], "long-forms": [[100, 123], [128, 140]]}, {"text": "3 Experiments We conducted closed track experiments on three data sources: the Academia Sinica (AS) corpus, the Beijing University (PKU) corpus and the Hong", "acronyms": [[96, 98], [132, 135]], "long-forms": [[79, 94]]}, {"text": "This measure combines two metrics. The first metric, predicted frequency (PF), estimates the degree to which a word appears to be used consis-", "acronyms": [[74, 76]], "long-forms": [[53, 72]]}, {"text": "Certain schemes have been aimed at abstracts, e.g., (McKnight  &  Srinivasan, 2003; Ruch et al, 2007; Hirohata et al, 2008; Bj?rne et al, 2009). The work of Hirohata et al (2009) has been integrated with the MEDIE service5 (Miyao et al, 2006), allowing the user to query facts using conclusions, results, etc. For full papers, the most notable work has focussed on argumentative zoning (AZ) (Teufel et al, 1999; Teufel  &  Moens, 2002; Teufel et al, 2009; Teufel, 2010). An important aspect of AZ involves capturing the attribution of knowledge claims and citation function, and the scheme has been tested on information extraction and summarisation tasks with Computational Linguistics papers.", "acronyms": [[387, 389], [494, 496]], "long-forms": [[365, 385]]}, {"text": "Recently, McDonald et al (2005b) formalized dependency parsing as a maximum spanning tree (MST) problem, which can be solved in quadratic time relative", "acronyms": [[91, 94]], "long-forms": [[68, 89]]}, {"text": " ADEPT tags documents in a uniform fashion, using  Standard Generalized Markup (SGML) according to  OIR standards.", "acronyms": [[80, 84], [1, 6], [100, 103]], "long-forms": [[51, 78]]}, {"text": "      The system integrates both dependency parse  tree pattern and semantic role labeler (SRL) results  of each input sentence when extracting the triples.", "acronyms": [[91, 94]], "long-forms": [[68, 89]]}, {"text": "PropBank defines core roles ARG0 through ARG5, which receive different interpretations for different predicates. Additional modifier roles ARGM-* include ARGM-TMP (temporal) and ARGM-DIR (directional), as shown in Figure 2(a).", "acronyms": [[154, 162], [28, 32], [41, 45], [139, 145], [178, 186]], "long-forms": [[164, 172], [188, 199]]}, {"text": "tion), and thus mitigating the overfitting problem.  A Dirichlet process (DP) prior is typically used to achieve this interplay.", "acronyms": [[74, 76]], "long-forms": [[55, 72]]}, {"text": "j.nerbonne@rug.nl Abstract Pair Hidden Markov Models (PairHMMs) are trained to align the pronunciation tran-", "acronyms": [[54, 62]], "long-forms": [[27, 52]]}, {"text": "vised taggers. One commonly-used unsupervised tagger is the Hidden Markov model (HMM), which models the joint distribution of a word se-", "acronyms": [[81, 84]], "long-forms": [[60, 79]]}, {"text": "on the guidance of domain experts, who can devise pedagogically valuable reading lists that order docAutomatic Speech Recognition (ASR) with HMMs Noisy Channel Model Viterbi Decoding for ASR", "acronyms": [[131, 134], [187, 190]], "long-forms": [[101, 129]]}, {"text": " The structure of a Concept is completed by its set of  Structural Descriptions (SD's). These express how the ", "acronyms": [[81, 85]], "long-forms": [[56, 79]]}, {"text": "future research which are suggested by some af the techniques used in this program.  The SFRAME (semantic frame) concept. in which a sernantirl interpretation ", "acronyms": [[89, 95]], "long-forms": [[97, 111]]}, {"text": "translation quality include the ridge regression (RR) and support vector regression (SVR) with RBF (radial basis functions) kernel (Smola and Scho?lkopf, 2004).", "acronyms": [[95, 98], [50, 52], [85, 88]], "long-forms": [[100, 122], [32, 48], [58, 83]]}, {"text": "tially freely-available sources: Family Practitioner Inquiry Network (FPIN)2, Parkhurst Exchange Forum (PE)3, and BMJ Clinical Evidence (BMJ-CE)4 were used to design and develop the presented test", "acronyms": [[137, 143], [70, 74], [104, 106]], "long-forms": [[114, 135], [33, 68], [78, 102]]}, {"text": "reflecting the distribution of the genres in the MTC (Zeyrek et al 2009). The main objective of the project is to annotate discourse connectives with their two arguments, modifiers and supplementary text spans. Following the Penn Discourse Tree Bank (PDTB), we take discourse connectives as discourse-level predicates taking two (and only  two) arguments, called Arg1 and Arg2, which may span one or more clauses and sentences that are adjacent or nonadjacent to the connective (Prasad et al 2007, Webber, 2004).", "acronyms": [[251, 255], [49, 52]], "long-forms": [[225, 249]]}, {"text": " 310 X. Fan et al  Causality Na?ve Bayesian Classifier (CNB): For a document represented by a binary-valued vector d=(X1 ,X2 , ?,", "acronyms": [[56, 59]], "long-forms": [[19, 43]]}, {"text": "monolingual applications and have been used in commercial grammar checkers.1 These parsers produce a logical form (LF) representation that is compatible across multiple languages (see", "acronyms": [[115, 117]], "long-forms": [[101, 113]]}, {"text": "unified into one model. We refer to this model as the Unified Transition(UT) model. ", "acronyms": [[73, 75]], "long-forms": [[54, 72]]}, {"text": "uses the mapping of concept dog to the class of alternative  expressions for named individual (such as using the name,  2 VSFL (\"Very Simple Frame Language\") and SCORE CSproket  Core\") were developed at BBN Systems and Technologies by ", "acronyms": [[122, 126], [162, 167], [168, 176], [203, 206]], "long-forms": [[129, 155]]}, {"text": "lated by the original Penn Treebank grammar to total PCFG surprisal calculated by the Nguyen et al (2012) Generalized Categorial Grammar (GCG). ", "acronyms": [[138, 141], [53, 57]], "long-forms": [[106, 136]]}, {"text": " 1 Introduction Word Sense Disambiguation (WSD) is an important component in many information organization", "acronyms": [[43, 46]], "long-forms": [[16, 41]]}]